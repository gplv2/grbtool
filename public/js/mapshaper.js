(function(f){if(typeof exports==="object"&&typeof module!=="undefined"){module.exports=f()}else if(typeof define==="function"&&define.amd){define([],f)}else{var g;if(typeof window!=="undefined"){g=window}else if(typeof global!=="undefined"){g=global}else if(typeof self!=="undefined"){g=self}else{g=this}g.mapshaper = f()}})(function(){var define,module,exports;return (function(){function r(e,n,t){function o(i,f){if(!n[i]){if(!e[i]){var c="function"==typeof require&&require;if(!f&&c)return c(i,!0);if(u)return u(i,!0);var a=new Error("Cannot find module '"+i+"'");throw a.code="MODULE_NOT_FOUND",a}var p=n[i]={exports:{}};e[i][0].call(p.exports,function(r){var n=e[i][1][r];return o(n||r)},p,p.exports,r,e,n,t)}return n[i].exports}for(var u="function"==typeof require&&require,i=0;i<t.length;i++)o(t[i]);return o}return r})()({1:[function(require,module,exports){

},{}],2:[function(require,module,exports){
'use strict'

exports.byteLength = byteLength
exports.toByteArray = toByteArray
exports.fromByteArray = fromByteArray

var lookup = []
var revLookup = []
var Arr = typeof Uint8Array !== 'undefined' ? Uint8Array : Array

var code = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/'
for (var i = 0, len = code.length; i < len; ++i) {
  lookup[i] = code[i]
  revLookup[code.charCodeAt(i)] = i
}

// Support decoding URL-safe base64 strings, as Node.js does.
// See: https://en.wikipedia.org/wiki/Base64#URL_applications
revLookup['-'.charCodeAt(0)] = 62
revLookup['_'.charCodeAt(0)] = 63

function getLens (b64) {
  var len = b64.length

  if (len % 4 > 0) {
    throw new Error('Invalid string. Length must be a multiple of 4')
  }

  // Trim off extra bytes after placeholder bytes are found
  // See: https://github.com/beatgammit/base64-js/issues/42
  var validLen = b64.indexOf('=')
  if (validLen === -1) validLen = len

  var placeHoldersLen = validLen === len
    ? 0
    : 4 - (validLen % 4)

  return [validLen, placeHoldersLen]
}

// base64 is 4/3 + up to two characters of the original data
function byteLength (b64) {
  var lens = getLens(b64)
  var validLen = lens[0]
  var placeHoldersLen = lens[1]
  return ((validLen + placeHoldersLen) * 3 / 4) - placeHoldersLen
}

function _byteLength (b64, validLen, placeHoldersLen) {
  return ((validLen + placeHoldersLen) * 3 / 4) - placeHoldersLen
}

function toByteArray (b64) {
  var tmp
  var lens = getLens(b64)
  var validLen = lens[0]
  var placeHoldersLen = lens[1]

  var arr = new Arr(_byteLength(b64, validLen, placeHoldersLen))

  var curByte = 0

  // if there are placeholders, only get up to the last complete 4 chars
  var len = placeHoldersLen > 0
    ? validLen - 4
    : validLen

  var i
  for (i = 0; i < len; i += 4) {
    tmp =
      (revLookup[b64.charCodeAt(i)] << 18) |
      (revLookup[b64.charCodeAt(i + 1)] << 12) |
      (revLookup[b64.charCodeAt(i + 2)] << 6) |
      revLookup[b64.charCodeAt(i + 3)]
    arr[curByte++] = (tmp >> 16) & 0xFF
    arr[curByte++] = (tmp >> 8) & 0xFF
    arr[curByte++] = tmp & 0xFF
  }

  if (placeHoldersLen === 2) {
    tmp =
      (revLookup[b64.charCodeAt(i)] << 2) |
      (revLookup[b64.charCodeAt(i + 1)] >> 4)
    arr[curByte++] = tmp & 0xFF
  }

  if (placeHoldersLen === 1) {
    tmp =
      (revLookup[b64.charCodeAt(i)] << 10) |
      (revLookup[b64.charCodeAt(i + 1)] << 4) |
      (revLookup[b64.charCodeAt(i + 2)] >> 2)
    arr[curByte++] = (tmp >> 8) & 0xFF
    arr[curByte++] = tmp & 0xFF
  }

  return arr
}

function tripletToBase64 (num) {
  return lookup[num >> 18 & 0x3F] +
    lookup[num >> 12 & 0x3F] +
    lookup[num >> 6 & 0x3F] +
    lookup[num & 0x3F]
}

function encodeChunk (uint8, start, end) {
  var tmp
  var output = []
  for (var i = start; i < end; i += 3) {
    tmp =
      ((uint8[i] << 16) & 0xFF0000) +
      ((uint8[i + 1] << 8) & 0xFF00) +
      (uint8[i + 2] & 0xFF)
    output.push(tripletToBase64(tmp))
  }
  return output.join('')
}

function fromByteArray (uint8) {
  var tmp
  var len = uint8.length
  var extraBytes = len % 3 // if we have 1 byte left, pad 2 bytes
  var parts = []
  var maxChunkLength = 16383 // must be multiple of 3

  // go through the array every three bytes, we'll deal with trailing stuff later
  for (var i = 0, len2 = len - extraBytes; i < len2; i += maxChunkLength) {
    parts.push(encodeChunk(uint8, i, (i + maxChunkLength) > len2 ? len2 : (i + maxChunkLength)))
  }

  // pad the end with zeros, but make sure to not forget the extra bytes
  if (extraBytes === 1) {
    tmp = uint8[len - 1]
    parts.push(
      lookup[tmp >> 2] +
      lookup[(tmp << 4) & 0x3F] +
      '=='
    )
  } else if (extraBytes === 2) {
    tmp = (uint8[len - 2] << 8) + uint8[len - 1]
    parts.push(
      lookup[tmp >> 10] +
      lookup[(tmp >> 4) & 0x3F] +
      lookup[(tmp << 2) & 0x3F] +
      '='
    )
  }

  return parts.join('')
}

},{}],3:[function(require,module,exports){
arguments[4][1][0].apply(exports,arguments)
},{"dup":1}],4:[function(require,module,exports){
(function (Buffer){(function (){
/*!
 * The buffer module from node.js, for the browser.
 *
 * @author   Feross Aboukhadijeh <https://feross.org>
 * @license  MIT
 */
/* eslint-disable no-proto */

'use strict'

var base64 = require('base64-js')
var ieee754 = require('ieee754')

exports.Buffer = Buffer
exports.SlowBuffer = SlowBuffer
exports.INSPECT_MAX_BYTES = 50

var K_MAX_LENGTH = 0x7fffffff
exports.kMaxLength = K_MAX_LENGTH

/**
 * If `Buffer.TYPED_ARRAY_SUPPORT`:
 *   === true    Use Uint8Array implementation (fastest)
 *   === false   Print warning and recommend using `buffer` v4.x which has an Object
 *               implementation (most compatible, even IE6)
 *
 * Browsers that support typed arrays are IE 10+, Firefox 4+, Chrome 7+, Safari 5.1+,
 * Opera 11.6+, iOS 4.2+.
 *
 * We report that the browser does not support typed arrays if the are not subclassable
 * using __proto__. Firefox 4-29 lacks support for adding new properties to `Uint8Array`
 * (See: https://bugzilla.mozilla.org/show_bug.cgi?id=695438). IE 10 lacks support
 * for __proto__ and has a buggy typed array implementation.
 */
Buffer.TYPED_ARRAY_SUPPORT = typedArraySupport()

if (!Buffer.TYPED_ARRAY_SUPPORT && typeof console !== 'undefined' &&
    typeof console.error === 'function') {
  console.error(
    'This browser lacks typed array (Uint8Array) support which is required by ' +
    '`buffer` v5.x. Use `buffer` v4.x if you require old browser support.'
  )
}

function typedArraySupport () {
  // Can typed array instances can be augmented?
  try {
    var arr = new Uint8Array(1)
    arr.__proto__ = { __proto__: Uint8Array.prototype, foo: function () { return 42 } }
    return arr.foo() === 42
  } catch (e) {
    return false
  }
}

Object.defineProperty(Buffer.prototype, 'parent', {
  enumerable: true,
  get: function () {
    if (!Buffer.isBuffer(this)) return undefined
    return this.buffer
  }
})

Object.defineProperty(Buffer.prototype, 'offset', {
  enumerable: true,
  get: function () {
    if (!Buffer.isBuffer(this)) return undefined
    return this.byteOffset
  }
})

function createBuffer (length) {
  if (length > K_MAX_LENGTH) {
    throw new RangeError('The value "' + length + '" is invalid for option "size"')
  }
  // Return an augmented `Uint8Array` instance
  var buf = new Uint8Array(length)
  buf.__proto__ = Buffer.prototype
  return buf
}

/**
 * The Buffer constructor returns instances of `Uint8Array` that have their
 * prototype changed to `Buffer.prototype`. Furthermore, `Buffer` is a subclass of
 * `Uint8Array`, so the returned instances will have all the node `Buffer` methods
 * and the `Uint8Array` methods. Square bracket notation works as expected -- it
 * returns a single octet.
 *
 * The `Uint8Array` prototype remains unmodified.
 */

function Buffer (arg, encodingOrOffset, length) {
  // Common case.
  if (typeof arg === 'number') {
    if (typeof encodingOrOffset === 'string') {
      throw new TypeError(
        'The "string" argument must be of type string. Received type number'
      )
    }
    return allocUnsafe(arg)
  }
  return from(arg, encodingOrOffset, length)
}

// Fix subarray() in ES2016. See: https://github.com/feross/buffer/pull/97
if (typeof Symbol !== 'undefined' && Symbol.species != null &&
    Buffer[Symbol.species] === Buffer) {
  Object.defineProperty(Buffer, Symbol.species, {
    value: null,
    configurable: true,
    enumerable: false,
    writable: false
  })
}

Buffer.poolSize = 8192 // not used by this implementation

function from (value, encodingOrOffset, length) {
  if (typeof value === 'string') {
    return fromString(value, encodingOrOffset)
  }

  if (ArrayBuffer.isView(value)) {
    return fromArrayLike(value)
  }

  if (value == null) {
    throw TypeError(
      'The first argument must be one of type string, Buffer, ArrayBuffer, Array, ' +
      'or Array-like Object. Received type ' + (typeof value)
    )
  }

  if (isInstance(value, ArrayBuffer) ||
      (value && isInstance(value.buffer, ArrayBuffer))) {
    return fromArrayBuffer(value, encodingOrOffset, length)
  }

  if (typeof value === 'number') {
    throw new TypeError(
      'The "value" argument must not be of type number. Received type number'
    )
  }

  var valueOf = value.valueOf && value.valueOf()
  if (valueOf != null && valueOf !== value) {
    return Buffer.from(valueOf, encodingOrOffset, length)
  }

  var b = fromObject(value)
  if (b) return b

  if (typeof Symbol !== 'undefined' && Symbol.toPrimitive != null &&
      typeof value[Symbol.toPrimitive] === 'function') {
    return Buffer.from(
      value[Symbol.toPrimitive]('string'), encodingOrOffset, length
    )
  }

  throw new TypeError(
    'The first argument must be one of type string, Buffer, ArrayBuffer, Array, ' +
    'or Array-like Object. Received type ' + (typeof value)
  )
}

/**
 * Functionally equivalent to Buffer(arg, encoding) but throws a TypeError
 * if value is a number.
 * Buffer.from(str[, encoding])
 * Buffer.from(array)
 * Buffer.from(buffer)
 * Buffer.from(arrayBuffer[, byteOffset[, length]])
 **/
Buffer.from = function (value, encodingOrOffset, length) {
  return from(value, encodingOrOffset, length)
}

// Note: Change prototype *after* Buffer.from is defined to workaround Chrome bug:
// https://github.com/feross/buffer/pull/148
Buffer.prototype.__proto__ = Uint8Array.prototype
Buffer.__proto__ = Uint8Array

function assertSize (size) {
  if (typeof size !== 'number') {
    throw new TypeError('"size" argument must be of type number')
  } else if (size < 0) {
    throw new RangeError('The value "' + size + '" is invalid for option "size"')
  }
}

function alloc (size, fill, encoding) {
  assertSize(size)
  if (size <= 0) {
    return createBuffer(size)
  }
  if (fill !== undefined) {
    // Only pay attention to encoding if it's a string. This
    // prevents accidentally sending in a number that would
    // be interpretted as a start offset.
    return typeof encoding === 'string'
      ? createBuffer(size).fill(fill, encoding)
      : createBuffer(size).fill(fill)
  }
  return createBuffer(size)
}

/**
 * Creates a new filled Buffer instance.
 * alloc(size[, fill[, encoding]])
 **/
Buffer.alloc = function (size, fill, encoding) {
  return alloc(size, fill, encoding)
}

function allocUnsafe (size) {
  assertSize(size)
  return createBuffer(size < 0 ? 0 : checked(size) | 0)
}

/**
 * Equivalent to Buffer(num), by default creates a non-zero-filled Buffer instance.
 * */
Buffer.allocUnsafe = function (size) {
  return allocUnsafe(size)
}
/**
 * Equivalent to SlowBuffer(num), by default creates a non-zero-filled Buffer instance.
 */
Buffer.allocUnsafeSlow = function (size) {
  return allocUnsafe(size)
}

function fromString (string, encoding) {
  if (typeof encoding !== 'string' || encoding === '') {
    encoding = 'utf8'
  }

  if (!Buffer.isEncoding(encoding)) {
    throw new TypeError('Unknown encoding: ' + encoding)
  }

  var length = byteLength(string, encoding) | 0
  var buf = createBuffer(length)

  var actual = buf.write(string, encoding)

  if (actual !== length) {
    // Writing a hex string, for example, that contains invalid characters will
    // cause everything after the first invalid character to be ignored. (e.g.
    // 'abxxcd' will be treated as 'ab')
    buf = buf.slice(0, actual)
  }

  return buf
}

function fromArrayLike (array) {
  var length = array.length < 0 ? 0 : checked(array.length) | 0
  var buf = createBuffer(length)
  for (var i = 0; i < length; i += 1) {
    buf[i] = array[i] & 255
  }
  return buf
}

function fromArrayBuffer (array, byteOffset, length) {
  if (byteOffset < 0 || array.byteLength < byteOffset) {
    throw new RangeError('"offset" is outside of buffer bounds')
  }

  if (array.byteLength < byteOffset + (length || 0)) {
    throw new RangeError('"length" is outside of buffer bounds')
  }

  var buf
  if (byteOffset === undefined && length === undefined) {
    buf = new Uint8Array(array)
  } else if (length === undefined) {
    buf = new Uint8Array(array, byteOffset)
  } else {
    buf = new Uint8Array(array, byteOffset, length)
  }

  // Return an augmented `Uint8Array` instance
  buf.__proto__ = Buffer.prototype
  return buf
}

function fromObject (obj) {
  if (Buffer.isBuffer(obj)) {
    var len = checked(obj.length) | 0
    var buf = createBuffer(len)

    if (buf.length === 0) {
      return buf
    }

    obj.copy(buf, 0, 0, len)
    return buf
  }

  if (obj.length !== undefined) {
    if (typeof obj.length !== 'number' || numberIsNaN(obj.length)) {
      return createBuffer(0)
    }
    return fromArrayLike(obj)
  }

  if (obj.type === 'Buffer' && Array.isArray(obj.data)) {
    return fromArrayLike(obj.data)
  }
}

function checked (length) {
  // Note: cannot use `length < K_MAX_LENGTH` here because that fails when
  // length is NaN (which is otherwise coerced to zero.)
  if (length >= K_MAX_LENGTH) {
    throw new RangeError('Attempt to allocate Buffer larger than maximum ' +
                         'size: 0x' + K_MAX_LENGTH.toString(16) + ' bytes')
  }
  return length | 0
}

function SlowBuffer (length) {
  if (+length != length) { // eslint-disable-line eqeqeq
    length = 0
  }
  return Buffer.alloc(+length)
}

Buffer.isBuffer = function isBuffer (b) {
  return b != null && b._isBuffer === true &&
    b !== Buffer.prototype // so Buffer.isBuffer(Buffer.prototype) will be false
}

Buffer.compare = function compare (a, b) {
  if (isInstance(a, Uint8Array)) a = Buffer.from(a, a.offset, a.byteLength)
  if (isInstance(b, Uint8Array)) b = Buffer.from(b, b.offset, b.byteLength)
  if (!Buffer.isBuffer(a) || !Buffer.isBuffer(b)) {
    throw new TypeError(
      'The "buf1", "buf2" arguments must be one of type Buffer or Uint8Array'
    )
  }

  if (a === b) return 0

  var x = a.length
  var y = b.length

  for (var i = 0, len = Math.min(x, y); i < len; ++i) {
    if (a[i] !== b[i]) {
      x = a[i]
      y = b[i]
      break
    }
  }

  if (x < y) return -1
  if (y < x) return 1
  return 0
}

Buffer.isEncoding = function isEncoding (encoding) {
  switch (String(encoding).toLowerCase()) {
    case 'hex':
    case 'utf8':
    case 'utf-8':
    case 'ascii':
    case 'latin1':
    case 'binary':
    case 'base64':
    case 'ucs2':
    case 'ucs-2':
    case 'utf16le':
    case 'utf-16le':
      return true
    default:
      return false
  }
}

Buffer.concat = function concat (list, length) {
  if (!Array.isArray(list)) {
    throw new TypeError('"list" argument must be an Array of Buffers')
  }

  if (list.length === 0) {
    return Buffer.alloc(0)
  }

  var i
  if (length === undefined) {
    length = 0
    for (i = 0; i < list.length; ++i) {
      length += list[i].length
    }
  }

  var buffer = Buffer.allocUnsafe(length)
  var pos = 0
  for (i = 0; i < list.length; ++i) {
    var buf = list[i]
    if (isInstance(buf, Uint8Array)) {
      buf = Buffer.from(buf)
    }
    if (!Buffer.isBuffer(buf)) {
      throw new TypeError('"list" argument must be an Array of Buffers')
    }
    buf.copy(buffer, pos)
    pos += buf.length
  }
  return buffer
}

function byteLength (string, encoding) {
  if (Buffer.isBuffer(string)) {
    return string.length
  }
  if (ArrayBuffer.isView(string) || isInstance(string, ArrayBuffer)) {
    return string.byteLength
  }
  if (typeof string !== 'string') {
    throw new TypeError(
      'The "string" argument must be one of type string, Buffer, or ArrayBuffer. ' +
      'Received type ' + typeof string
    )
  }

  var len = string.length
  var mustMatch = (arguments.length > 2 && arguments[2] === true)
  if (!mustMatch && len === 0) return 0

  // Use a for loop to avoid recursion
  var loweredCase = false
  for (;;) {
    switch (encoding) {
      case 'ascii':
      case 'latin1':
      case 'binary':
        return len
      case 'utf8':
      case 'utf-8':
        return utf8ToBytes(string).length
      case 'ucs2':
      case 'ucs-2':
      case 'utf16le':
      case 'utf-16le':
        return len * 2
      case 'hex':
        return len >>> 1
      case 'base64':
        return base64ToBytes(string).length
      default:
        if (loweredCase) {
          return mustMatch ? -1 : utf8ToBytes(string).length // assume utf8
        }
        encoding = ('' + encoding).toLowerCase()
        loweredCase = true
    }
  }
}
Buffer.byteLength = byteLength

function slowToString (encoding, start, end) {
  var loweredCase = false

  // No need to verify that "this.length <= MAX_UINT32" since it's a read-only
  // property of a typed array.

  // This behaves neither like String nor Uint8Array in that we set start/end
  // to their upper/lower bounds if the value passed is out of range.
  // undefined is handled specially as per ECMA-262 6th Edition,
  // Section 13.3.3.7 Runtime Semantics: KeyedBindingInitialization.
  if (start === undefined || start < 0) {
    start = 0
  }
  // Return early if start > this.length. Done here to prevent potential uint32
  // coercion fail below.
  if (start > this.length) {
    return ''
  }

  if (end === undefined || end > this.length) {
    end = this.length
  }

  if (end <= 0) {
    return ''
  }

  // Force coersion to uint32. This will also coerce falsey/NaN values to 0.
  end >>>= 0
  start >>>= 0

  if (end <= start) {
    return ''
  }

  if (!encoding) encoding = 'utf8'

  while (true) {
    switch (encoding) {
      case 'hex':
        return hexSlice(this, start, end)

      case 'utf8':
      case 'utf-8':
        return utf8Slice(this, start, end)

      case 'ascii':
        return asciiSlice(this, start, end)

      case 'latin1':
      case 'binary':
        return latin1Slice(this, start, end)

      case 'base64':
        return base64Slice(this, start, end)

      case 'ucs2':
      case 'ucs-2':
      case 'utf16le':
      case 'utf-16le':
        return utf16leSlice(this, start, end)

      default:
        if (loweredCase) throw new TypeError('Unknown encoding: ' + encoding)
        encoding = (encoding + '').toLowerCase()
        loweredCase = true
    }
  }
}

// This property is used by `Buffer.isBuffer` (and the `is-buffer` npm package)
// to detect a Buffer instance. It's not possible to use `instanceof Buffer`
// reliably in a browserify context because there could be multiple different
// copies of the 'buffer' package in use. This method works even for Buffer
// instances that were created from another copy of the `buffer` package.
// See: https://github.com/feross/buffer/issues/154
Buffer.prototype._isBuffer = true

function swap (b, n, m) {
  var i = b[n]
  b[n] = b[m]
  b[m] = i
}

Buffer.prototype.swap16 = function swap16 () {
  var len = this.length
  if (len % 2 !== 0) {
    throw new RangeError('Buffer size must be a multiple of 16-bits')
  }
  for (var i = 0; i < len; i += 2) {
    swap(this, i, i + 1)
  }
  return this
}

Buffer.prototype.swap32 = function swap32 () {
  var len = this.length
  if (len % 4 !== 0) {
    throw new RangeError('Buffer size must be a multiple of 32-bits')
  }
  for (var i = 0; i < len; i += 4) {
    swap(this, i, i + 3)
    swap(this, i + 1, i + 2)
  }
  return this
}

Buffer.prototype.swap64 = function swap64 () {
  var len = this.length
  if (len % 8 !== 0) {
    throw new RangeError('Buffer size must be a multiple of 64-bits')
  }
  for (var i = 0; i < len; i += 8) {
    swap(this, i, i + 7)
    swap(this, i + 1, i + 6)
    swap(this, i + 2, i + 5)
    swap(this, i + 3, i + 4)
  }
  return this
}

Buffer.prototype.toString = function toString () {
  var length = this.length
  if (length === 0) return ''
  if (arguments.length === 0) return utf8Slice(this, 0, length)
  return slowToString.apply(this, arguments)
}

Buffer.prototype.toLocaleString = Buffer.prototype.toString

Buffer.prototype.equals = function equals (b) {
  if (!Buffer.isBuffer(b)) throw new TypeError('Argument must be a Buffer')
  if (this === b) return true
  return Buffer.compare(this, b) === 0
}

Buffer.prototype.inspect = function inspect () {
  var str = ''
  var max = exports.INSPECT_MAX_BYTES
  str = this.toString('hex', 0, max).replace(/(.{2})/g, '$1 ').trim()
  if (this.length > max) str += ' ... '
  return '<Buffer ' + str + '>'
}

Buffer.prototype.compare = function compare (target, start, end, thisStart, thisEnd) {
  if (isInstance(target, Uint8Array)) {
    target = Buffer.from(target, target.offset, target.byteLength)
  }
  if (!Buffer.isBuffer(target)) {
    throw new TypeError(
      'The "target" argument must be one of type Buffer or Uint8Array. ' +
      'Received type ' + (typeof target)
    )
  }

  if (start === undefined) {
    start = 0
  }
  if (end === undefined) {
    end = target ? target.length : 0
  }
  if (thisStart === undefined) {
    thisStart = 0
  }
  if (thisEnd === undefined) {
    thisEnd = this.length
  }

  if (start < 0 || end > target.length || thisStart < 0 || thisEnd > this.length) {
    throw new RangeError('out of range index')
  }

  if (thisStart >= thisEnd && start >= end) {
    return 0
  }
  if (thisStart >= thisEnd) {
    return -1
  }
  if (start >= end) {
    return 1
  }

  start >>>= 0
  end >>>= 0
  thisStart >>>= 0
  thisEnd >>>= 0

  if (this === target) return 0

  var x = thisEnd - thisStart
  var y = end - start
  var len = Math.min(x, y)

  var thisCopy = this.slice(thisStart, thisEnd)
  var targetCopy = target.slice(start, end)

  for (var i = 0; i < len; ++i) {
    if (thisCopy[i] !== targetCopy[i]) {
      x = thisCopy[i]
      y = targetCopy[i]
      break
    }
  }

  if (x < y) return -1
  if (y < x) return 1
  return 0
}

// Finds either the first index of `val` in `buffer` at offset >= `byteOffset`,
// OR the last index of `val` in `buffer` at offset <= `byteOffset`.
//
// Arguments:
// - buffer - a Buffer to search
// - val - a string, Buffer, or number
// - byteOffset - an index into `buffer`; will be clamped to an int32
// - encoding - an optional encoding, relevant is val is a string
// - dir - true for indexOf, false for lastIndexOf
function bidirectionalIndexOf (buffer, val, byteOffset, encoding, dir) {
  // Empty buffer means no match
  if (buffer.length === 0) return -1

  // Normalize byteOffset
  if (typeof byteOffset === 'string') {
    encoding = byteOffset
    byteOffset = 0
  } else if (byteOffset > 0x7fffffff) {
    byteOffset = 0x7fffffff
  } else if (byteOffset < -0x80000000) {
    byteOffset = -0x80000000
  }
  byteOffset = +byteOffset // Coerce to Number.
  if (numberIsNaN(byteOffset)) {
    // byteOffset: it it's undefined, null, NaN, "foo", etc, search whole buffer
    byteOffset = dir ? 0 : (buffer.length - 1)
  }

  // Normalize byteOffset: negative offsets start from the end of the buffer
  if (byteOffset < 0) byteOffset = buffer.length + byteOffset
  if (byteOffset >= buffer.length) {
    if (dir) return -1
    else byteOffset = buffer.length - 1
  } else if (byteOffset < 0) {
    if (dir) byteOffset = 0
    else return -1
  }

  // Normalize val
  if (typeof val === 'string') {
    val = Buffer.from(val, encoding)
  }

  // Finally, search either indexOf (if dir is true) or lastIndexOf
  if (Buffer.isBuffer(val)) {
    // Special case: looking for empty string/buffer always fails
    if (val.length === 0) {
      return -1
    }
    return arrayIndexOf(buffer, val, byteOffset, encoding, dir)
  } else if (typeof val === 'number') {
    val = val & 0xFF // Search for a byte value [0-255]
    if (typeof Uint8Array.prototype.indexOf === 'function') {
      if (dir) {
        return Uint8Array.prototype.indexOf.call(buffer, val, byteOffset)
      } else {
        return Uint8Array.prototype.lastIndexOf.call(buffer, val, byteOffset)
      }
    }
    return arrayIndexOf(buffer, [ val ], byteOffset, encoding, dir)
  }

  throw new TypeError('val must be string, number or Buffer')
}

function arrayIndexOf (arr, val, byteOffset, encoding, dir) {
  var indexSize = 1
  var arrLength = arr.length
  var valLength = val.length

  if (encoding !== undefined) {
    encoding = String(encoding).toLowerCase()
    if (encoding === 'ucs2' || encoding === 'ucs-2' ||
        encoding === 'utf16le' || encoding === 'utf-16le') {
      if (arr.length < 2 || val.length < 2) {
        return -1
      }
      indexSize = 2
      arrLength /= 2
      valLength /= 2
      byteOffset /= 2
    }
  }

  function read (buf, i) {
    if (indexSize === 1) {
      return buf[i]
    } else {
      return buf.readUInt16BE(i * indexSize)
    }
  }

  var i
  if (dir) {
    var foundIndex = -1
    for (i = byteOffset; i < arrLength; i++) {
      if (read(arr, i) === read(val, foundIndex === -1 ? 0 : i - foundIndex)) {
        if (foundIndex === -1) foundIndex = i
        if (i - foundIndex + 1 === valLength) return foundIndex * indexSize
      } else {
        if (foundIndex !== -1) i -= i - foundIndex
        foundIndex = -1
      }
    }
  } else {
    if (byteOffset + valLength > arrLength) byteOffset = arrLength - valLength
    for (i = byteOffset; i >= 0; i--) {
      var found = true
      for (var j = 0; j < valLength; j++) {
        if (read(arr, i + j) !== read(val, j)) {
          found = false
          break
        }
      }
      if (found) return i
    }
  }

  return -1
}

Buffer.prototype.includes = function includes (val, byteOffset, encoding) {
  return this.indexOf(val, byteOffset, encoding) !== -1
}

Buffer.prototype.indexOf = function indexOf (val, byteOffset, encoding) {
  return bidirectionalIndexOf(this, val, byteOffset, encoding, true)
}

Buffer.prototype.lastIndexOf = function lastIndexOf (val, byteOffset, encoding) {
  return bidirectionalIndexOf(this, val, byteOffset, encoding, false)
}

function hexWrite (buf, string, offset, length) {
  offset = Number(offset) || 0
  var remaining = buf.length - offset
  if (!length) {
    length = remaining
  } else {
    length = Number(length)
    if (length > remaining) {
      length = remaining
    }
  }

  var strLen = string.length

  if (length > strLen / 2) {
    length = strLen / 2
  }
  for (var i = 0; i < length; ++i) {
    var parsed = parseInt(string.substr(i * 2, 2), 16)
    if (numberIsNaN(parsed)) return i
    buf[offset + i] = parsed
  }
  return i
}

function utf8Write (buf, string, offset, length) {
  return blitBuffer(utf8ToBytes(string, buf.length - offset), buf, offset, length)
}

function asciiWrite (buf, string, offset, length) {
  return blitBuffer(asciiToBytes(string), buf, offset, length)
}

function latin1Write (buf, string, offset, length) {
  return asciiWrite(buf, string, offset, length)
}

function base64Write (buf, string, offset, length) {
  return blitBuffer(base64ToBytes(string), buf, offset, length)
}

function ucs2Write (buf, string, offset, length) {
  return blitBuffer(utf16leToBytes(string, buf.length - offset), buf, offset, length)
}

Buffer.prototype.write = function write (string, offset, length, encoding) {
  // Buffer#write(string)
  if (offset === undefined) {
    encoding = 'utf8'
    length = this.length
    offset = 0
  // Buffer#write(string, encoding)
  } else if (length === undefined && typeof offset === 'string') {
    encoding = offset
    length = this.length
    offset = 0
  // Buffer#write(string, offset[, length][, encoding])
  } else if (isFinite(offset)) {
    offset = offset >>> 0
    if (isFinite(length)) {
      length = length >>> 0
      if (encoding === undefined) encoding = 'utf8'
    } else {
      encoding = length
      length = undefined
    }
  } else {
    throw new Error(
      'Buffer.write(string, encoding, offset[, length]) is no longer supported'
    )
  }

  var remaining = this.length - offset
  if (length === undefined || length > remaining) length = remaining

  if ((string.length > 0 && (length < 0 || offset < 0)) || offset > this.length) {
    throw new RangeError('Attempt to write outside buffer bounds')
  }

  if (!encoding) encoding = 'utf8'

  var loweredCase = false
  for (;;) {
    switch (encoding) {
      case 'hex':
        return hexWrite(this, string, offset, length)

      case 'utf8':
      case 'utf-8':
        return utf8Write(this, string, offset, length)

      case 'ascii':
        return asciiWrite(this, string, offset, length)

      case 'latin1':
      case 'binary':
        return latin1Write(this, string, offset, length)

      case 'base64':
        // Warning: maxLength not taken into account in base64Write
        return base64Write(this, string, offset, length)

      case 'ucs2':
      case 'ucs-2':
      case 'utf16le':
      case 'utf-16le':
        return ucs2Write(this, string, offset, length)

      default:
        if (loweredCase) throw new TypeError('Unknown encoding: ' + encoding)
        encoding = ('' + encoding).toLowerCase()
        loweredCase = true
    }
  }
}

Buffer.prototype.toJSON = function toJSON () {
  return {
    type: 'Buffer',
    data: Array.prototype.slice.call(this._arr || this, 0)
  }
}

function base64Slice (buf, start, end) {
  if (start === 0 && end === buf.length) {
    return base64.fromByteArray(buf)
  } else {
    return base64.fromByteArray(buf.slice(start, end))
  }
}

function utf8Slice (buf, start, end) {
  end = Math.min(buf.length, end)
  var res = []

  var i = start
  while (i < end) {
    var firstByte = buf[i]
    var codePoint = null
    var bytesPerSequence = (firstByte > 0xEF) ? 4
      : (firstByte > 0xDF) ? 3
        : (firstByte > 0xBF) ? 2
          : 1

    if (i + bytesPerSequence <= end) {
      var secondByte, thirdByte, fourthByte, tempCodePoint

      switch (bytesPerSequence) {
        case 1:
          if (firstByte < 0x80) {
            codePoint = firstByte
          }
          break
        case 2:
          secondByte = buf[i + 1]
          if ((secondByte & 0xC0) === 0x80) {
            tempCodePoint = (firstByte & 0x1F) << 0x6 | (secondByte & 0x3F)
            if (tempCodePoint > 0x7F) {
              codePoint = tempCodePoint
            }
          }
          break
        case 3:
          secondByte = buf[i + 1]
          thirdByte = buf[i + 2]
          if ((secondByte & 0xC0) === 0x80 && (thirdByte & 0xC0) === 0x80) {
            tempCodePoint = (firstByte & 0xF) << 0xC | (secondByte & 0x3F) << 0x6 | (thirdByte & 0x3F)
            if (tempCodePoint > 0x7FF && (tempCodePoint < 0xD800 || tempCodePoint > 0xDFFF)) {
              codePoint = tempCodePoint
            }
          }
          break
        case 4:
          secondByte = buf[i + 1]
          thirdByte = buf[i + 2]
          fourthByte = buf[i + 3]
          if ((secondByte & 0xC0) === 0x80 && (thirdByte & 0xC0) === 0x80 && (fourthByte & 0xC0) === 0x80) {
            tempCodePoint = (firstByte & 0xF) << 0x12 | (secondByte & 0x3F) << 0xC | (thirdByte & 0x3F) << 0x6 | (fourthByte & 0x3F)
            if (tempCodePoint > 0xFFFF && tempCodePoint < 0x110000) {
              codePoint = tempCodePoint
            }
          }
      }
    }

    if (codePoint === null) {
      // we did not generate a valid codePoint so insert a
      // replacement char (U+FFFD) and advance only 1 byte
      codePoint = 0xFFFD
      bytesPerSequence = 1
    } else if (codePoint > 0xFFFF) {
      // encode to utf16 (surrogate pair dance)
      codePoint -= 0x10000
      res.push(codePoint >>> 10 & 0x3FF | 0xD800)
      codePoint = 0xDC00 | codePoint & 0x3FF
    }

    res.push(codePoint)
    i += bytesPerSequence
  }

  return decodeCodePointsArray(res)
}

// Based on http://stackoverflow.com/a/22747272/680742, the browser with
// the lowest limit is Chrome, with 0x10000 args.
// We go 1 magnitude less, for safety
var MAX_ARGUMENTS_LENGTH = 0x1000

function decodeCodePointsArray (codePoints) {
  var len = codePoints.length
  if (len <= MAX_ARGUMENTS_LENGTH) {
    return String.fromCharCode.apply(String, codePoints) // avoid extra slice()
  }

  // Decode in chunks to avoid "call stack size exceeded".
  var res = ''
  var i = 0
  while (i < len) {
    res += String.fromCharCode.apply(
      String,
      codePoints.slice(i, i += MAX_ARGUMENTS_LENGTH)
    )
  }
  return res
}

function asciiSlice (buf, start, end) {
  var ret = ''
  end = Math.min(buf.length, end)

  for (var i = start; i < end; ++i) {
    ret += String.fromCharCode(buf[i] & 0x7F)
  }
  return ret
}

function latin1Slice (buf, start, end) {
  var ret = ''
  end = Math.min(buf.length, end)

  for (var i = start; i < end; ++i) {
    ret += String.fromCharCode(buf[i])
  }
  return ret
}

function hexSlice (buf, start, end) {
  var len = buf.length

  if (!start || start < 0) start = 0
  if (!end || end < 0 || end > len) end = len

  var out = ''
  for (var i = start; i < end; ++i) {
    out += toHex(buf[i])
  }
  return out
}

function utf16leSlice (buf, start, end) {
  var bytes = buf.slice(start, end)
  var res = ''
  for (var i = 0; i < bytes.length; i += 2) {
    res += String.fromCharCode(bytes[i] + (bytes[i + 1] * 256))
  }
  return res
}

Buffer.prototype.slice = function slice (start, end) {
  var len = this.length
  start = ~~start
  end = end === undefined ? len : ~~end

  if (start < 0) {
    start += len
    if (start < 0) start = 0
  } else if (start > len) {
    start = len
  }

  if (end < 0) {
    end += len
    if (end < 0) end = 0
  } else if (end > len) {
    end = len
  }

  if (end < start) end = start

  var newBuf = this.subarray(start, end)
  // Return an augmented `Uint8Array` instance
  newBuf.__proto__ = Buffer.prototype
  return newBuf
}

/*
 * Need to make sure that buffer isn't trying to write out of bounds.
 */
function checkOffset (offset, ext, length) {
  if ((offset % 1) !== 0 || offset < 0) throw new RangeError('offset is not uint')
  if (offset + ext > length) throw new RangeError('Trying to access beyond buffer length')
}

Buffer.prototype.readUIntLE = function readUIntLE (offset, byteLength, noAssert) {
  offset = offset >>> 0
  byteLength = byteLength >>> 0
  if (!noAssert) checkOffset(offset, byteLength, this.length)

  var val = this[offset]
  var mul = 1
  var i = 0
  while (++i < byteLength && (mul *= 0x100)) {
    val += this[offset + i] * mul
  }

  return val
}

Buffer.prototype.readUIntBE = function readUIntBE (offset, byteLength, noAssert) {
  offset = offset >>> 0
  byteLength = byteLength >>> 0
  if (!noAssert) {
    checkOffset(offset, byteLength, this.length)
  }

  var val = this[offset + --byteLength]
  var mul = 1
  while (byteLength > 0 && (mul *= 0x100)) {
    val += this[offset + --byteLength] * mul
  }

  return val
}

Buffer.prototype.readUInt8 = function readUInt8 (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 1, this.length)
  return this[offset]
}

Buffer.prototype.readUInt16LE = function readUInt16LE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 2, this.length)
  return this[offset] | (this[offset + 1] << 8)
}

Buffer.prototype.readUInt16BE = function readUInt16BE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 2, this.length)
  return (this[offset] << 8) | this[offset + 1]
}

Buffer.prototype.readUInt32LE = function readUInt32LE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 4, this.length)

  return ((this[offset]) |
      (this[offset + 1] << 8) |
      (this[offset + 2] << 16)) +
      (this[offset + 3] * 0x1000000)
}

Buffer.prototype.readUInt32BE = function readUInt32BE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 4, this.length)

  return (this[offset] * 0x1000000) +
    ((this[offset + 1] << 16) |
    (this[offset + 2] << 8) |
    this[offset + 3])
}

Buffer.prototype.readIntLE = function readIntLE (offset, byteLength, noAssert) {
  offset = offset >>> 0
  byteLength = byteLength >>> 0
  if (!noAssert) checkOffset(offset, byteLength, this.length)

  var val = this[offset]
  var mul = 1
  var i = 0
  while (++i < byteLength && (mul *= 0x100)) {
    val += this[offset + i] * mul
  }
  mul *= 0x80

  if (val >= mul) val -= Math.pow(2, 8 * byteLength)

  return val
}

Buffer.prototype.readIntBE = function readIntBE (offset, byteLength, noAssert) {
  offset = offset >>> 0
  byteLength = byteLength >>> 0
  if (!noAssert) checkOffset(offset, byteLength, this.length)

  var i = byteLength
  var mul = 1
  var val = this[offset + --i]
  while (i > 0 && (mul *= 0x100)) {
    val += this[offset + --i] * mul
  }
  mul *= 0x80

  if (val >= mul) val -= Math.pow(2, 8 * byteLength)

  return val
}

Buffer.prototype.readInt8 = function readInt8 (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 1, this.length)
  if (!(this[offset] & 0x80)) return (this[offset])
  return ((0xff - this[offset] + 1) * -1)
}

Buffer.prototype.readInt16LE = function readInt16LE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 2, this.length)
  var val = this[offset] | (this[offset + 1] << 8)
  return (val & 0x8000) ? val | 0xFFFF0000 : val
}

Buffer.prototype.readInt16BE = function readInt16BE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 2, this.length)
  var val = this[offset + 1] | (this[offset] << 8)
  return (val & 0x8000) ? val | 0xFFFF0000 : val
}

Buffer.prototype.readInt32LE = function readInt32LE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 4, this.length)

  return (this[offset]) |
    (this[offset + 1] << 8) |
    (this[offset + 2] << 16) |
    (this[offset + 3] << 24)
}

Buffer.prototype.readInt32BE = function readInt32BE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 4, this.length)

  return (this[offset] << 24) |
    (this[offset + 1] << 16) |
    (this[offset + 2] << 8) |
    (this[offset + 3])
}

Buffer.prototype.readFloatLE = function readFloatLE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 4, this.length)
  return ieee754.read(this, offset, true, 23, 4)
}

Buffer.prototype.readFloatBE = function readFloatBE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 4, this.length)
  return ieee754.read(this, offset, false, 23, 4)
}

Buffer.prototype.readDoubleLE = function readDoubleLE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 8, this.length)
  return ieee754.read(this, offset, true, 52, 8)
}

Buffer.prototype.readDoubleBE = function readDoubleBE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 8, this.length)
  return ieee754.read(this, offset, false, 52, 8)
}

function checkInt (buf, value, offset, ext, max, min) {
  if (!Buffer.isBuffer(buf)) throw new TypeError('"buffer" argument must be a Buffer instance')
  if (value > max || value < min) throw new RangeError('"value" argument is out of bounds')
  if (offset + ext > buf.length) throw new RangeError('Index out of range')
}

Buffer.prototype.writeUIntLE = function writeUIntLE (value, offset, byteLength, noAssert) {
  value = +value
  offset = offset >>> 0
  byteLength = byteLength >>> 0
  if (!noAssert) {
    var maxBytes = Math.pow(2, 8 * byteLength) - 1
    checkInt(this, value, offset, byteLength, maxBytes, 0)
  }

  var mul = 1
  var i = 0
  this[offset] = value & 0xFF
  while (++i < byteLength && (mul *= 0x100)) {
    this[offset + i] = (value / mul) & 0xFF
  }

  return offset + byteLength
}

Buffer.prototype.writeUIntBE = function writeUIntBE (value, offset, byteLength, noAssert) {
  value = +value
  offset = offset >>> 0
  byteLength = byteLength >>> 0
  if (!noAssert) {
    var maxBytes = Math.pow(2, 8 * byteLength) - 1
    checkInt(this, value, offset, byteLength, maxBytes, 0)
  }

  var i = byteLength - 1
  var mul = 1
  this[offset + i] = value & 0xFF
  while (--i >= 0 && (mul *= 0x100)) {
    this[offset + i] = (value / mul) & 0xFF
  }

  return offset + byteLength
}

Buffer.prototype.writeUInt8 = function writeUInt8 (value, offset, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) checkInt(this, value, offset, 1, 0xff, 0)
  this[offset] = (value & 0xff)
  return offset + 1
}

Buffer.prototype.writeUInt16LE = function writeUInt16LE (value, offset, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) checkInt(this, value, offset, 2, 0xffff, 0)
  this[offset] = (value & 0xff)
  this[offset + 1] = (value >>> 8)
  return offset + 2
}

Buffer.prototype.writeUInt16BE = function writeUInt16BE (value, offset, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) checkInt(this, value, offset, 2, 0xffff, 0)
  this[offset] = (value >>> 8)
  this[offset + 1] = (value & 0xff)
  return offset + 2
}

Buffer.prototype.writeUInt32LE = function writeUInt32LE (value, offset, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) checkInt(this, value, offset, 4, 0xffffffff, 0)
  this[offset + 3] = (value >>> 24)
  this[offset + 2] = (value >>> 16)
  this[offset + 1] = (value >>> 8)
  this[offset] = (value & 0xff)
  return offset + 4
}

Buffer.prototype.writeUInt32BE = function writeUInt32BE (value, offset, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) checkInt(this, value, offset, 4, 0xffffffff, 0)
  this[offset] = (value >>> 24)
  this[offset + 1] = (value >>> 16)
  this[offset + 2] = (value >>> 8)
  this[offset + 3] = (value & 0xff)
  return offset + 4
}

Buffer.prototype.writeIntLE = function writeIntLE (value, offset, byteLength, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) {
    var limit = Math.pow(2, (8 * byteLength) - 1)

    checkInt(this, value, offset, byteLength, limit - 1, -limit)
  }

  var i = 0
  var mul = 1
  var sub = 0
  this[offset] = value & 0xFF
  while (++i < byteLength && (mul *= 0x100)) {
    if (value < 0 && sub === 0 && this[offset + i - 1] !== 0) {
      sub = 1
    }
    this[offset + i] = ((value / mul) >> 0) - sub & 0xFF
  }

  return offset + byteLength
}

Buffer.prototype.writeIntBE = function writeIntBE (value, offset, byteLength, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) {
    var limit = Math.pow(2, (8 * byteLength) - 1)

    checkInt(this, value, offset, byteLength, limit - 1, -limit)
  }

  var i = byteLength - 1
  var mul = 1
  var sub = 0
  this[offset + i] = value & 0xFF
  while (--i >= 0 && (mul *= 0x100)) {
    if (value < 0 && sub === 0 && this[offset + i + 1] !== 0) {
      sub = 1
    }
    this[offset + i] = ((value / mul) >> 0) - sub & 0xFF
  }

  return offset + byteLength
}

Buffer.prototype.writeInt8 = function writeInt8 (value, offset, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) checkInt(this, value, offset, 1, 0x7f, -0x80)
  if (value < 0) value = 0xff + value + 1
  this[offset] = (value & 0xff)
  return offset + 1
}

Buffer.prototype.writeInt16LE = function writeInt16LE (value, offset, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) checkInt(this, value, offset, 2, 0x7fff, -0x8000)
  this[offset] = (value & 0xff)
  this[offset + 1] = (value >>> 8)
  return offset + 2
}

Buffer.prototype.writeInt16BE = function writeInt16BE (value, offset, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) checkInt(this, value, offset, 2, 0x7fff, -0x8000)
  this[offset] = (value >>> 8)
  this[offset + 1] = (value & 0xff)
  return offset + 2
}

Buffer.prototype.writeInt32LE = function writeInt32LE (value, offset, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) checkInt(this, value, offset, 4, 0x7fffffff, -0x80000000)
  this[offset] = (value & 0xff)
  this[offset + 1] = (value >>> 8)
  this[offset + 2] = (value >>> 16)
  this[offset + 3] = (value >>> 24)
  return offset + 4
}

Buffer.prototype.writeInt32BE = function writeInt32BE (value, offset, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) checkInt(this, value, offset, 4, 0x7fffffff, -0x80000000)
  if (value < 0) value = 0xffffffff + value + 1
  this[offset] = (value >>> 24)
  this[offset + 1] = (value >>> 16)
  this[offset + 2] = (value >>> 8)
  this[offset + 3] = (value & 0xff)
  return offset + 4
}

function checkIEEE754 (buf, value, offset, ext, max, min) {
  if (offset + ext > buf.length) throw new RangeError('Index out of range')
  if (offset < 0) throw new RangeError('Index out of range')
}

function writeFloat (buf, value, offset, littleEndian, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) {
    checkIEEE754(buf, value, offset, 4, 3.4028234663852886e+38, -3.4028234663852886e+38)
  }
  ieee754.write(buf, value, offset, littleEndian, 23, 4)
  return offset + 4
}

Buffer.prototype.writeFloatLE = function writeFloatLE (value, offset, noAssert) {
  return writeFloat(this, value, offset, true, noAssert)
}

Buffer.prototype.writeFloatBE = function writeFloatBE (value, offset, noAssert) {
  return writeFloat(this, value, offset, false, noAssert)
}

function writeDouble (buf, value, offset, littleEndian, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) {
    checkIEEE754(buf, value, offset, 8, 1.7976931348623157E+308, -1.7976931348623157E+308)
  }
  ieee754.write(buf, value, offset, littleEndian, 52, 8)
  return offset + 8
}

Buffer.prototype.writeDoubleLE = function writeDoubleLE (value, offset, noAssert) {
  return writeDouble(this, value, offset, true, noAssert)
}

Buffer.prototype.writeDoubleBE = function writeDoubleBE (value, offset, noAssert) {
  return writeDouble(this, value, offset, false, noAssert)
}

// copy(targetBuffer, targetStart=0, sourceStart=0, sourceEnd=buffer.length)
Buffer.prototype.copy = function copy (target, targetStart, start, end) {
  if (!Buffer.isBuffer(target)) throw new TypeError('argument should be a Buffer')
  if (!start) start = 0
  if (!end && end !== 0) end = this.length
  if (targetStart >= target.length) targetStart = target.length
  if (!targetStart) targetStart = 0
  if (end > 0 && end < start) end = start

  // Copy 0 bytes; we're done
  if (end === start) return 0
  if (target.length === 0 || this.length === 0) return 0

  // Fatal error conditions
  if (targetStart < 0) {
    throw new RangeError('targetStart out of bounds')
  }
  if (start < 0 || start >= this.length) throw new RangeError('Index out of range')
  if (end < 0) throw new RangeError('sourceEnd out of bounds')

  // Are we oob?
  if (end > this.length) end = this.length
  if (target.length - targetStart < end - start) {
    end = target.length - targetStart + start
  }

  var len = end - start

  if (this === target && typeof Uint8Array.prototype.copyWithin === 'function') {
    // Use built-in when available, missing from IE11
    this.copyWithin(targetStart, start, end)
  } else if (this === target && start < targetStart && targetStart < end) {
    // descending copy from end
    for (var i = len - 1; i >= 0; --i) {
      target[i + targetStart] = this[i + start]
    }
  } else {
    Uint8Array.prototype.set.call(
      target,
      this.subarray(start, end),
      targetStart
    )
  }

  return len
}

// Usage:
//    buffer.fill(number[, offset[, end]])
//    buffer.fill(buffer[, offset[, end]])
//    buffer.fill(string[, offset[, end]][, encoding])
Buffer.prototype.fill = function fill (val, start, end, encoding) {
  // Handle string cases:
  if (typeof val === 'string') {
    if (typeof start === 'string') {
      encoding = start
      start = 0
      end = this.length
    } else if (typeof end === 'string') {
      encoding = end
      end = this.length
    }
    if (encoding !== undefined && typeof encoding !== 'string') {
      throw new TypeError('encoding must be a string')
    }
    if (typeof encoding === 'string' && !Buffer.isEncoding(encoding)) {
      throw new TypeError('Unknown encoding: ' + encoding)
    }
    if (val.length === 1) {
      var code = val.charCodeAt(0)
      if ((encoding === 'utf8' && code < 128) ||
          encoding === 'latin1') {
        // Fast path: If `val` fits into a single byte, use that numeric value.
        val = code
      }
    }
  } else if (typeof val === 'number') {
    val = val & 255
  }

  // Invalid ranges are not set to a default, so can range check early.
  if (start < 0 || this.length < start || this.length < end) {
    throw new RangeError('Out of range index')
  }

  if (end <= start) {
    return this
  }

  start = start >>> 0
  end = end === undefined ? this.length : end >>> 0

  if (!val) val = 0

  var i
  if (typeof val === 'number') {
    for (i = start; i < end; ++i) {
      this[i] = val
    }
  } else {
    var bytes = Buffer.isBuffer(val)
      ? val
      : Buffer.from(val, encoding)
    var len = bytes.length
    if (len === 0) {
      throw new TypeError('The value "' + val +
        '" is invalid for argument "value"')
    }
    for (i = 0; i < end - start; ++i) {
      this[i + start] = bytes[i % len]
    }
  }

  return this
}

// HELPER FUNCTIONS
// ================

var INVALID_BASE64_RE = /[^+/0-9A-Za-z-_]/g

function base64clean (str) {
  // Node takes equal signs as end of the Base64 encoding
  str = str.split('=')[0]
  // Node strips out invalid characters like \n and \t from the string, base64-js does not
  str = str.trim().replace(INVALID_BASE64_RE, '')
  // Node converts strings with length < 2 to ''
  if (str.length < 2) return ''
  // Node allows for non-padded base64 strings (missing trailing ===), base64-js does not
  while (str.length % 4 !== 0) {
    str = str + '='
  }
  return str
}

function toHex (n) {
  if (n < 16) return '0' + n.toString(16)
  return n.toString(16)
}

function utf8ToBytes (string, units) {
  units = units || Infinity
  var codePoint
  var length = string.length
  var leadSurrogate = null
  var bytes = []

  for (var i = 0; i < length; ++i) {
    codePoint = string.charCodeAt(i)

    // is surrogate component
    if (codePoint > 0xD7FF && codePoint < 0xE000) {
      // last char was a lead
      if (!leadSurrogate) {
        // no lead yet
        if (codePoint > 0xDBFF) {
          // unexpected trail
          if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)
          continue
        } else if (i + 1 === length) {
          // unpaired lead
          if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)
          continue
        }

        // valid lead
        leadSurrogate = codePoint

        continue
      }

      // 2 leads in a row
      if (codePoint < 0xDC00) {
        if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)
        leadSurrogate = codePoint
        continue
      }

      // valid surrogate pair
      codePoint = (leadSurrogate - 0xD800 << 10 | codePoint - 0xDC00) + 0x10000
    } else if (leadSurrogate) {
      // valid bmp char, but last char was a lead
      if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)
    }

    leadSurrogate = null

    // encode utf8
    if (codePoint < 0x80) {
      if ((units -= 1) < 0) break
      bytes.push(codePoint)
    } else if (codePoint < 0x800) {
      if ((units -= 2) < 0) break
      bytes.push(
        codePoint >> 0x6 | 0xC0,
        codePoint & 0x3F | 0x80
      )
    } else if (codePoint < 0x10000) {
      if ((units -= 3) < 0) break
      bytes.push(
        codePoint >> 0xC | 0xE0,
        codePoint >> 0x6 & 0x3F | 0x80,
        codePoint & 0x3F | 0x80
      )
    } else if (codePoint < 0x110000) {
      if ((units -= 4) < 0) break
      bytes.push(
        codePoint >> 0x12 | 0xF0,
        codePoint >> 0xC & 0x3F | 0x80,
        codePoint >> 0x6 & 0x3F | 0x80,
        codePoint & 0x3F | 0x80
      )
    } else {
      throw new Error('Invalid code point')
    }
  }

  return bytes
}

function asciiToBytes (str) {
  var byteArray = []
  for (var i = 0; i < str.length; ++i) {
    // Node's code seems to be doing this and not & 0x7F..
    byteArray.push(str.charCodeAt(i) & 0xFF)
  }
  return byteArray
}

function utf16leToBytes (str, units) {
  var c, hi, lo
  var byteArray = []
  for (var i = 0; i < str.length; ++i) {
    if ((units -= 2) < 0) break

    c = str.charCodeAt(i)
    hi = c >> 8
    lo = c % 256
    byteArray.push(lo)
    byteArray.push(hi)
  }

  return byteArray
}

function base64ToBytes (str) {
  return base64.toByteArray(base64clean(str))
}

function blitBuffer (src, dst, offset, length) {
  for (var i = 0; i < length; ++i) {
    if ((i + offset >= dst.length) || (i >= src.length)) break
    dst[i + offset] = src[i]
  }
  return i
}

// ArrayBuffer or Uint8Array objects from other contexts (i.e. iframes) do not pass
// the `instanceof` check but they should be treated as of that type.
// See: https://github.com/feross/buffer/issues/166
function isInstance (obj, type) {
  return obj instanceof type ||
    (obj != null && obj.constructor != null && obj.constructor.name != null &&
      obj.constructor.name === type.name)
}
function numberIsNaN (obj) {
  // For IE11 support
  return obj !== obj // eslint-disable-line no-self-compare
}

}).call(this)}).call(this,require("buffer").Buffer)
},{"base64-js":2,"buffer":4,"ieee754":5}],5:[function(require,module,exports){
/*! ieee754. BSD-3-Clause License. Feross Aboukhadijeh <https://feross.org/opensource> */
exports.read = function (buffer, offset, isLE, mLen, nBytes) {
  var e, m
  var eLen = (nBytes * 8) - mLen - 1
  var eMax = (1 << eLen) - 1
  var eBias = eMax >> 1
  var nBits = -7
  var i = isLE ? (nBytes - 1) : 0
  var d = isLE ? -1 : 1
  var s = buffer[offset + i]

  i += d

  e = s & ((1 << (-nBits)) - 1)
  s >>= (-nBits)
  nBits += eLen
  for (; nBits > 0; e = (e * 256) + buffer[offset + i], i += d, nBits -= 8) {}

  m = e & ((1 << (-nBits)) - 1)
  e >>= (-nBits)
  nBits += mLen
  for (; nBits > 0; m = (m * 256) + buffer[offset + i], i += d, nBits -= 8) {}

  if (e === 0) {
    e = 1 - eBias
  } else if (e === eMax) {
    return m ? NaN : ((s ? -1 : 1) * Infinity)
  } else {
    m = m + Math.pow(2, mLen)
    e = e - eBias
  }
  return (s ? -1 : 1) * m * Math.pow(2, e - mLen)
}

exports.write = function (buffer, value, offset, isLE, mLen, nBytes) {
  var e, m, c
  var eLen = (nBytes * 8) - mLen - 1
  var eMax = (1 << eLen) - 1
  var eBias = eMax >> 1
  var rt = (mLen === 23 ? Math.pow(2, -24) - Math.pow(2, -77) : 0)
  var i = isLE ? 0 : (nBytes - 1)
  var d = isLE ? 1 : -1
  var s = value < 0 || (value === 0 && 1 / value < 0) ? 1 : 0

  value = Math.abs(value)

  if (isNaN(value) || value === Infinity) {
    m = isNaN(value) ? 1 : 0
    e = eMax
  } else {
    e = Math.floor(Math.log(value) / Math.LN2)
    if (value * (c = Math.pow(2, -e)) < 1) {
      e--
      c *= 2
    }
    if (e + eBias >= 1) {
      value += rt / c
    } else {
      value += rt * Math.pow(2, 1 - eBias)
    }
    if (value * c >= 2) {
      e++
      c /= 2
    }

    if (e + eBias >= eMax) {
      m = 0
      e = eMax
    } else if (e + eBias >= 1) {
      m = ((value * c) - 1) * Math.pow(2, mLen)
      e = e + eBias
    } else {
      m = value * Math.pow(2, eBias - 1) * Math.pow(2, mLen)
      e = 0
    }
  }

  for (; mLen >= 8; buffer[offset + i] = m & 0xff, i += d, m /= 256, mLen -= 8) {}

  e = (e << mLen) | m
  eLen += mLen
  for (; eLen > 0; buffer[offset + i] = e & 0xff, i += d, e /= 256, eLen -= 8) {}

  buffer[offset + i - d] |= s * 128
}

},{}],6:[function(require,module,exports){
(function (process){(function (){
// 'path' module extracted from Node.js v8.11.1 (only the posix part)
// transplited with Babel

// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.

'use strict';

function assertPath(path) {
  if (typeof path !== 'string') {
    throw new TypeError('Path must be a string. Received ' + JSON.stringify(path));
  }
}

// Resolves . and .. elements in a path with directory names
function normalizeStringPosix(path, allowAboveRoot) {
  var res = '';
  var lastSegmentLength = 0;
  var lastSlash = -1;
  var dots = 0;
  var code;
  for (var i = 0; i <= path.length; ++i) {
    if (i < path.length)
      code = path.charCodeAt(i);
    else if (code === 47 /*/*/)
      break;
    else
      code = 47 /*/*/;
    if (code === 47 /*/*/) {
      if (lastSlash === i - 1 || dots === 1) {
        // NOOP
      } else if (lastSlash !== i - 1 && dots === 2) {
        if (res.length < 2 || lastSegmentLength !== 2 || res.charCodeAt(res.length - 1) !== 46 /*.*/ || res.charCodeAt(res.length - 2) !== 46 /*.*/) {
          if (res.length > 2) {
            var lastSlashIndex = res.lastIndexOf('/');
            if (lastSlashIndex !== res.length - 1) {
              if (lastSlashIndex === -1) {
                res = '';
                lastSegmentLength = 0;
              } else {
                res = res.slice(0, lastSlashIndex);
                lastSegmentLength = res.length - 1 - res.lastIndexOf('/');
              }
              lastSlash = i;
              dots = 0;
              continue;
            }
          } else if (res.length === 2 || res.length === 1) {
            res = '';
            lastSegmentLength = 0;
            lastSlash = i;
            dots = 0;
            continue;
          }
        }
        if (allowAboveRoot) {
          if (res.length > 0)
            res += '/..';
          else
            res = '..';
          lastSegmentLength = 2;
        }
      } else {
        if (res.length > 0)
          res += '/' + path.slice(lastSlash + 1, i);
        else
          res = path.slice(lastSlash + 1, i);
        lastSegmentLength = i - lastSlash - 1;
      }
      lastSlash = i;
      dots = 0;
    } else if (code === 46 /*.*/ && dots !== -1) {
      ++dots;
    } else {
      dots = -1;
    }
  }
  return res;
}

function _format(sep, pathObject) {
  var dir = pathObject.dir || pathObject.root;
  var base = pathObject.base || (pathObject.name || '') + (pathObject.ext || '');
  if (!dir) {
    return base;
  }
  if (dir === pathObject.root) {
    return dir + base;
  }
  return dir + sep + base;
}

var posix = {
  // path.resolve([from ...], to)
  resolve: function resolve() {
    var resolvedPath = '';
    var resolvedAbsolute = false;
    var cwd;

    for (var i = arguments.length - 1; i >= -1 && !resolvedAbsolute; i--) {
      var path;
      if (i >= 0)
        path = arguments[i];
      else {
        if (cwd === undefined)
          cwd = process.cwd();
        path = cwd;
      }

      assertPath(path);

      // Skip empty entries
      if (path.length === 0) {
        continue;
      }

      resolvedPath = path + '/' + resolvedPath;
      resolvedAbsolute = path.charCodeAt(0) === 47 /*/*/;
    }

    // At this point the path should be resolved to a full absolute path, but
    // handle relative paths to be safe (might happen when process.cwd() fails)

    // Normalize the path
    resolvedPath = normalizeStringPosix(resolvedPath, !resolvedAbsolute);

    if (resolvedAbsolute) {
      if (resolvedPath.length > 0)
        return '/' + resolvedPath;
      else
        return '/';
    } else if (resolvedPath.length > 0) {
      return resolvedPath;
    } else {
      return '.';
    }
  },

  normalize: function normalize(path) {
    assertPath(path);

    if (path.length === 0) return '.';

    var isAbsolute = path.charCodeAt(0) === 47 /*/*/;
    var trailingSeparator = path.charCodeAt(path.length - 1) === 47 /*/*/;

    // Normalize the path
    path = normalizeStringPosix(path, !isAbsolute);

    if (path.length === 0 && !isAbsolute) path = '.';
    if (path.length > 0 && trailingSeparator) path += '/';

    if (isAbsolute) return '/' + path;
    return path;
  },

  isAbsolute: function isAbsolute(path) {
    assertPath(path);
    return path.length > 0 && path.charCodeAt(0) === 47 /*/*/;
  },

  join: function join() {
    if (arguments.length === 0)
      return '.';
    var joined;
    for (var i = 0; i < arguments.length; ++i) {
      var arg = arguments[i];
      assertPath(arg);
      if (arg.length > 0) {
        if (joined === undefined)
          joined = arg;
        else
          joined += '/' + arg;
      }
    }
    if (joined === undefined)
      return '.';
    return posix.normalize(joined);
  },

  relative: function relative(from, to) {
    assertPath(from);
    assertPath(to);

    if (from === to) return '';

    from = posix.resolve(from);
    to = posix.resolve(to);

    if (from === to) return '';

    // Trim any leading backslashes
    var fromStart = 1;
    for (; fromStart < from.length; ++fromStart) {
      if (from.charCodeAt(fromStart) !== 47 /*/*/)
        break;
    }
    var fromEnd = from.length;
    var fromLen = fromEnd - fromStart;

    // Trim any leading backslashes
    var toStart = 1;
    for (; toStart < to.length; ++toStart) {
      if (to.charCodeAt(toStart) !== 47 /*/*/)
        break;
    }
    var toEnd = to.length;
    var toLen = toEnd - toStart;

    // Compare paths to find the longest common path from root
    var length = fromLen < toLen ? fromLen : toLen;
    var lastCommonSep = -1;
    var i = 0;
    for (; i <= length; ++i) {
      if (i === length) {
        if (toLen > length) {
          if (to.charCodeAt(toStart + i) === 47 /*/*/) {
            // We get here if `from` is the exact base path for `to`.
            // For example: from='/foo/bar'; to='/foo/bar/baz'
            return to.slice(toStart + i + 1);
          } else if (i === 0) {
            // We get here if `from` is the root
            // For example: from='/'; to='/foo'
            return to.slice(toStart + i);
          }
        } else if (fromLen > length) {
          if (from.charCodeAt(fromStart + i) === 47 /*/*/) {
            // We get here if `to` is the exact base path for `from`.
            // For example: from='/foo/bar/baz'; to='/foo/bar'
            lastCommonSep = i;
          } else if (i === 0) {
            // We get here if `to` is the root.
            // For example: from='/foo'; to='/'
            lastCommonSep = 0;
          }
        }
        break;
      }
      var fromCode = from.charCodeAt(fromStart + i);
      var toCode = to.charCodeAt(toStart + i);
      if (fromCode !== toCode)
        break;
      else if (fromCode === 47 /*/*/)
        lastCommonSep = i;
    }

    var out = '';
    // Generate the relative path based on the path difference between `to`
    // and `from`
    for (i = fromStart + lastCommonSep + 1; i <= fromEnd; ++i) {
      if (i === fromEnd || from.charCodeAt(i) === 47 /*/*/) {
        if (out.length === 0)
          out += '..';
        else
          out += '/..';
      }
    }

    // Lastly, append the rest of the destination (`to`) path that comes after
    // the common path parts
    if (out.length > 0)
      return out + to.slice(toStart + lastCommonSep);
    else {
      toStart += lastCommonSep;
      if (to.charCodeAt(toStart) === 47 /*/*/)
        ++toStart;
      return to.slice(toStart);
    }
  },

  _makeLong: function _makeLong(path) {
    return path;
  },

  dirname: function dirname(path) {
    assertPath(path);
    if (path.length === 0) return '.';
    var code = path.charCodeAt(0);
    var hasRoot = code === 47 /*/*/;
    var end = -1;
    var matchedSlash = true;
    for (var i = path.length - 1; i >= 1; --i) {
      code = path.charCodeAt(i);
      if (code === 47 /*/*/) {
          if (!matchedSlash) {
            end = i;
            break;
          }
        } else {
        // We saw the first non-path separator
        matchedSlash = false;
      }
    }

    if (end === -1) return hasRoot ? '/' : '.';
    if (hasRoot && end === 1) return '//';
    return path.slice(0, end);
  },

  basename: function basename(path, ext) {
    if (ext !== undefined && typeof ext !== 'string') throw new TypeError('"ext" argument must be a string');
    assertPath(path);

    var start = 0;
    var end = -1;
    var matchedSlash = true;
    var i;

    if (ext !== undefined && ext.length > 0 && ext.length <= path.length) {
      if (ext.length === path.length && ext === path) return '';
      var extIdx = ext.length - 1;
      var firstNonSlashEnd = -1;
      for (i = path.length - 1; i >= 0; --i) {
        var code = path.charCodeAt(i);
        if (code === 47 /*/*/) {
            // If we reached a path separator that was not part of a set of path
            // separators at the end of the string, stop now
            if (!matchedSlash) {
              start = i + 1;
              break;
            }
          } else {
          if (firstNonSlashEnd === -1) {
            // We saw the first non-path separator, remember this index in case
            // we need it if the extension ends up not matching
            matchedSlash = false;
            firstNonSlashEnd = i + 1;
          }
          if (extIdx >= 0) {
            // Try to match the explicit extension
            if (code === ext.charCodeAt(extIdx)) {
              if (--extIdx === -1) {
                // We matched the extension, so mark this as the end of our path
                // component
                end = i;
              }
            } else {
              // Extension does not match, so our result is the entire path
              // component
              extIdx = -1;
              end = firstNonSlashEnd;
            }
          }
        }
      }

      if (start === end) end = firstNonSlashEnd;else if (end === -1) end = path.length;
      return path.slice(start, end);
    } else {
      for (i = path.length - 1; i >= 0; --i) {
        if (path.charCodeAt(i) === 47 /*/*/) {
            // If we reached a path separator that was not part of a set of path
            // separators at the end of the string, stop now
            if (!matchedSlash) {
              start = i + 1;
              break;
            }
          } else if (end === -1) {
          // We saw the first non-path separator, mark this as the end of our
          // path component
          matchedSlash = false;
          end = i + 1;
        }
      }

      if (end === -1) return '';
      return path.slice(start, end);
    }
  },

  extname: function extname(path) {
    assertPath(path);
    var startDot = -1;
    var startPart = 0;
    var end = -1;
    var matchedSlash = true;
    // Track the state of characters (if any) we see before our first dot and
    // after any path separator we find
    var preDotState = 0;
    for (var i = path.length - 1; i >= 0; --i) {
      var code = path.charCodeAt(i);
      if (code === 47 /*/*/) {
          // If we reached a path separator that was not part of a set of path
          // separators at the end of the string, stop now
          if (!matchedSlash) {
            startPart = i + 1;
            break;
          }
          continue;
        }
      if (end === -1) {
        // We saw the first non-path separator, mark this as the end of our
        // extension
        matchedSlash = false;
        end = i + 1;
      }
      if (code === 46 /*.*/) {
          // If this is our first dot, mark it as the start of our extension
          if (startDot === -1)
            startDot = i;
          else if (preDotState !== 1)
            preDotState = 1;
      } else if (startDot !== -1) {
        // We saw a non-dot and non-path separator before our dot, so we should
        // have a good chance at having a non-empty extension
        preDotState = -1;
      }
    }

    if (startDot === -1 || end === -1 ||
        // We saw a non-dot character immediately before the dot
        preDotState === 0 ||
        // The (right-most) trimmed path component is exactly '..'
        preDotState === 1 && startDot === end - 1 && startDot === startPart + 1) {
      return '';
    }
    return path.slice(startDot, end);
  },

  format: function format(pathObject) {
    if (pathObject === null || typeof pathObject !== 'object') {
      throw new TypeError('The "pathObject" argument must be of type Object. Received type ' + typeof pathObject);
    }
    return _format('/', pathObject);
  },

  parse: function parse(path) {
    assertPath(path);

    var ret = { root: '', dir: '', base: '', ext: '', name: '' };
    if (path.length === 0) return ret;
    var code = path.charCodeAt(0);
    var isAbsolute = code === 47 /*/*/;
    var start;
    if (isAbsolute) {
      ret.root = '/';
      start = 1;
    } else {
      start = 0;
    }
    var startDot = -1;
    var startPart = 0;
    var end = -1;
    var matchedSlash = true;
    var i = path.length - 1;

    // Track the state of characters (if any) we see before our first dot and
    // after any path separator we find
    var preDotState = 0;

    // Get non-dir info
    for (; i >= start; --i) {
      code = path.charCodeAt(i);
      if (code === 47 /*/*/) {
          // If we reached a path separator that was not part of a set of path
          // separators at the end of the string, stop now
          if (!matchedSlash) {
            startPart = i + 1;
            break;
          }
          continue;
        }
      if (end === -1) {
        // We saw the first non-path separator, mark this as the end of our
        // extension
        matchedSlash = false;
        end = i + 1;
      }
      if (code === 46 /*.*/) {
          // If this is our first dot, mark it as the start of our extension
          if (startDot === -1) startDot = i;else if (preDotState !== 1) preDotState = 1;
        } else if (startDot !== -1) {
        // We saw a non-dot and non-path separator before our dot, so we should
        // have a good chance at having a non-empty extension
        preDotState = -1;
      }
    }

    if (startDot === -1 || end === -1 ||
    // We saw a non-dot character immediately before the dot
    preDotState === 0 ||
    // The (right-most) trimmed path component is exactly '..'
    preDotState === 1 && startDot === end - 1 && startDot === startPart + 1) {
      if (end !== -1) {
        if (startPart === 0 && isAbsolute) ret.base = ret.name = path.slice(1, end);else ret.base = ret.name = path.slice(startPart, end);
      }
    } else {
      if (startPart === 0 && isAbsolute) {
        ret.name = path.slice(1, startDot);
        ret.base = path.slice(1, end);
      } else {
        ret.name = path.slice(startPart, startDot);
        ret.base = path.slice(startPart, end);
      }
      ret.ext = path.slice(startDot, end);
    }

    if (startPart > 0) ret.dir = path.slice(0, startPart - 1);else if (isAbsolute) ret.dir = '/';

    return ret;
  },

  sep: '/',
  delimiter: ':',
  win32: null,
  posix: null
};

posix.posix = posix;

module.exports = posix;

}).call(this)}).call(this,require('_process'))
},{"_process":7}],7:[function(require,module,exports){
// shim for using process in browser
var process = module.exports = {};

// cached from whatever global is present so that test runners that stub it
// don't break things.  But we need to wrap it in a try catch in case it is
// wrapped in strict mode code which doesn't define any globals.  It's inside a
// function because try/catches deoptimize in certain engines.

var cachedSetTimeout;
var cachedClearTimeout;

function defaultSetTimout() {
    throw new Error('setTimeout has not been defined');
}
function defaultClearTimeout () {
    throw new Error('clearTimeout has not been defined');
}
(function () {
    try {
        if (typeof setTimeout === 'function') {
            cachedSetTimeout = setTimeout;
        } else {
            cachedSetTimeout = defaultSetTimout;
        }
    } catch (e) {
        cachedSetTimeout = defaultSetTimout;
    }
    try {
        if (typeof clearTimeout === 'function') {
            cachedClearTimeout = clearTimeout;
        } else {
            cachedClearTimeout = defaultClearTimeout;
        }
    } catch (e) {
        cachedClearTimeout = defaultClearTimeout;
    }
} ())
function runTimeout(fun) {
    if (cachedSetTimeout === setTimeout) {
        //normal enviroments in sane situations
        return setTimeout(fun, 0);
    }
    // if setTimeout wasn't available but was latter defined
    if ((cachedSetTimeout === defaultSetTimout || !cachedSetTimeout) && setTimeout) {
        cachedSetTimeout = setTimeout;
        return setTimeout(fun, 0);
    }
    try {
        // when when somebody has screwed with setTimeout but no I.E. maddness
        return cachedSetTimeout(fun, 0);
    } catch(e){
        try {
            // When we are in I.E. but the script has been evaled so I.E. doesn't trust the global object when called normally
            return cachedSetTimeout.call(null, fun, 0);
        } catch(e){
            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error
            return cachedSetTimeout.call(this, fun, 0);
        }
    }


}
function runClearTimeout(marker) {
    if (cachedClearTimeout === clearTimeout) {
        //normal enviroments in sane situations
        return clearTimeout(marker);
    }
    // if clearTimeout wasn't available but was latter defined
    if ((cachedClearTimeout === defaultClearTimeout || !cachedClearTimeout) && clearTimeout) {
        cachedClearTimeout = clearTimeout;
        return clearTimeout(marker);
    }
    try {
        // when when somebody has screwed with setTimeout but no I.E. maddness
        return cachedClearTimeout(marker);
    } catch (e){
        try {
            // When we are in I.E. but the script has been evaled so I.E. doesn't  trust the global object when called normally
            return cachedClearTimeout.call(null, marker);
        } catch (e){
            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error.
            // Some versions of I.E. have different rules for clearTimeout vs setTimeout
            return cachedClearTimeout.call(this, marker);
        }
    }



}
var queue = [];
var draining = false;
var currentQueue;
var queueIndex = -1;

function cleanUpNextTick() {
    if (!draining || !currentQueue) {
        return;
    }
    draining = false;
    if (currentQueue.length) {
        queue = currentQueue.concat(queue);
    } else {
        queueIndex = -1;
    }
    if (queue.length) {
        drainQueue();
    }
}

function drainQueue() {
    if (draining) {
        return;
    }
    var timeout = runTimeout(cleanUpNextTick);
    draining = true;

    var len = queue.length;
    while(len) {
        currentQueue = queue;
        queue = [];
        while (++queueIndex < len) {
            if (currentQueue) {
                currentQueue[queueIndex].run();
            }
        }
        queueIndex = -1;
        len = queue.length;
    }
    currentQueue = null;
    draining = false;
    runClearTimeout(timeout);
}

process.nextTick = function (fun) {
    var args = new Array(arguments.length - 1);
    if (arguments.length > 1) {
        for (var i = 1; i < arguments.length; i++) {
            args[i - 1] = arguments[i];
        }
    }
    queue.push(new Item(fun, args));
    if (queue.length === 1 && !draining) {
        runTimeout(drainQueue);
    }
};

// v8 likes predictible objects
function Item(fun, array) {
    this.fun = fun;
    this.array = array;
}
Item.prototype.run = function () {
    this.fun.apply(null, this.array);
};
process.title = 'browser';
process.browser = true;
process.env = {};
process.argv = [];
process.version = ''; // empty string to avoid regexp issues
process.versions = {};

function noop() {}

process.on = noop;
process.addListener = noop;
process.once = noop;
process.off = noop;
process.removeListener = noop;
process.removeAllListeners = noop;
process.emit = noop;
process.prependListener = noop;
process.prependOnceListener = noop;

process.listeners = function (name) { return [] }

process.binding = function (name) {
    throw new Error('process.binding is not supported');
};

process.cwd = function () { return '/' };
process.chdir = function (dir) {
    throw new Error('process.chdir is not supported');
};
process.umask = function() { return 0; };

},{}],8:[function(require,module,exports){
/*! safe-buffer. MIT License. Feross Aboukhadijeh <https://feross.org/opensource> */
/* eslint-disable node/no-deprecated-api */
var buffer = require('buffer')
var Buffer = buffer.Buffer

// alternative to using Object.keys for old browsers
function copyProps (src, dst) {
  for (var key in src) {
    dst[key] = src[key]
  }
}
if (Buffer.from && Buffer.alloc && Buffer.allocUnsafe && Buffer.allocUnsafeSlow) {
  module.exports = buffer
} else {
  // Copy properties from require('buffer')
  copyProps(buffer, exports)
  exports.Buffer = SafeBuffer
}

function SafeBuffer (arg, encodingOrOffset, length) {
  return Buffer(arg, encodingOrOffset, length)
}

SafeBuffer.prototype = Object.create(Buffer.prototype)

// Copy static methods from Buffer
copyProps(Buffer, SafeBuffer)

SafeBuffer.from = function (arg, encodingOrOffset, length) {
  if (typeof arg === 'number') {
    throw new TypeError('Argument must not be a number')
  }
  return Buffer(arg, encodingOrOffset, length)
}

SafeBuffer.alloc = function (size, fill, encoding) {
  if (typeof size !== 'number') {
    throw new TypeError('Argument must be a number')
  }
  var buf = Buffer(size)
  if (fill !== undefined) {
    if (typeof encoding === 'string') {
      buf.fill(fill, encoding)
    } else {
      buf.fill(fill)
    }
  } else {
    buf.fill(0)
  }
  return buf
}

SafeBuffer.allocUnsafe = function (size) {
  if (typeof size !== 'number') {
    throw new TypeError('Argument must be a number')
  }
  return Buffer(size)
}

SafeBuffer.allocUnsafeSlow = function (size) {
  if (typeof size !== 'number') {
    throw new TypeError('Argument must be a number')
  }
  return buffer.SlowBuffer(size)
}

},{"buffer":4}],9:[function(require,module,exports){
// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.

'use strict';

/*<replacement>*/

var Buffer = require('safe-buffer').Buffer;
/*</replacement>*/

var isEncoding = Buffer.isEncoding || function (encoding) {
  encoding = '' + encoding;
  switch (encoding && encoding.toLowerCase()) {
    case 'hex':case 'utf8':case 'utf-8':case 'ascii':case 'binary':case 'base64':case 'ucs2':case 'ucs-2':case 'utf16le':case 'utf-16le':case 'raw':
      return true;
    default:
      return false;
  }
};

function _normalizeEncoding(enc) {
  if (!enc) return 'utf8';
  var retried;
  while (true) {
    switch (enc) {
      case 'utf8':
      case 'utf-8':
        return 'utf8';
      case 'ucs2':
      case 'ucs-2':
      case 'utf16le':
      case 'utf-16le':
        return 'utf16le';
      case 'latin1':
      case 'binary':
        return 'latin1';
      case 'base64':
      case 'ascii':
      case 'hex':
        return enc;
      default:
        if (retried) return; // undefined
        enc = ('' + enc).toLowerCase();
        retried = true;
    }
  }
};

// Do not cache `Buffer.isEncoding` when checking encoding names as some
// modules monkey-patch it to support additional encodings
function normalizeEncoding(enc) {
  var nenc = _normalizeEncoding(enc);
  if (typeof nenc !== 'string' && (Buffer.isEncoding === isEncoding || !isEncoding(enc))) throw new Error('Unknown encoding: ' + enc);
  return nenc || enc;
}

// StringDecoder provides an interface for efficiently splitting a series of
// buffers into a series of JS strings without breaking apart multi-byte
// characters.
exports.StringDecoder = StringDecoder;
function StringDecoder(encoding) {
  this.encoding = normalizeEncoding(encoding);
  var nb;
  switch (this.encoding) {
    case 'utf16le':
      this.text = utf16Text;
      this.end = utf16End;
      nb = 4;
      break;
    case 'utf8':
      this.fillLast = utf8FillLast;
      nb = 4;
      break;
    case 'base64':
      this.text = base64Text;
      this.end = base64End;
      nb = 3;
      break;
    default:
      this.write = simpleWrite;
      this.end = simpleEnd;
      return;
  }
  this.lastNeed = 0;
  this.lastTotal = 0;
  this.lastChar = Buffer.allocUnsafe(nb);
}

StringDecoder.prototype.write = function (buf) {
  if (buf.length === 0) return '';
  var r;
  var i;
  if (this.lastNeed) {
    r = this.fillLast(buf);
    if (r === undefined) return '';
    i = this.lastNeed;
    this.lastNeed = 0;
  } else {
    i = 0;
  }
  if (i < buf.length) return r ? r + this.text(buf, i) : this.text(buf, i);
  return r || '';
};

StringDecoder.prototype.end = utf8End;

// Returns only complete characters in a Buffer
StringDecoder.prototype.text = utf8Text;

// Attempts to complete a partial non-UTF-8 character using bytes from a Buffer
StringDecoder.prototype.fillLast = function (buf) {
  if (this.lastNeed <= buf.length) {
    buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, this.lastNeed);
    return this.lastChar.toString(this.encoding, 0, this.lastTotal);
  }
  buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, buf.length);
  this.lastNeed -= buf.length;
};

// Checks the type of a UTF-8 byte, whether it's ASCII, a leading byte, or a
// continuation byte. If an invalid byte is detected, -2 is returned.
function utf8CheckByte(byte) {
  if (byte <= 0x7F) return 0;else if (byte >> 5 === 0x06) return 2;else if (byte >> 4 === 0x0E) return 3;else if (byte >> 3 === 0x1E) return 4;
  return byte >> 6 === 0x02 ? -1 : -2;
}

// Checks at most 3 bytes at the end of a Buffer in order to detect an
// incomplete multi-byte UTF-8 character. The total number of bytes (2, 3, or 4)
// needed to complete the UTF-8 character (if applicable) are returned.
function utf8CheckIncomplete(self, buf, i) {
  var j = buf.length - 1;
  if (j < i) return 0;
  var nb = utf8CheckByte(buf[j]);
  if (nb >= 0) {
    if (nb > 0) self.lastNeed = nb - 1;
    return nb;
  }
  if (--j < i || nb === -2) return 0;
  nb = utf8CheckByte(buf[j]);
  if (nb >= 0) {
    if (nb > 0) self.lastNeed = nb - 2;
    return nb;
  }
  if (--j < i || nb === -2) return 0;
  nb = utf8CheckByte(buf[j]);
  if (nb >= 0) {
    if (nb > 0) {
      if (nb === 2) nb = 0;else self.lastNeed = nb - 3;
    }
    return nb;
  }
  return 0;
}

// Validates as many continuation bytes for a multi-byte UTF-8 character as
// needed or are available. If we see a non-continuation byte where we expect
// one, we "replace" the validated continuation bytes we've seen so far with
// a single UTF-8 replacement character ('\ufffd'), to match v8's UTF-8 decoding
// behavior. The continuation byte check is included three times in the case
// where all of the continuation bytes for a character exist in the same buffer.
// It is also done this way as a slight performance increase instead of using a
// loop.
function utf8CheckExtraBytes(self, buf, p) {
  if ((buf[0] & 0xC0) !== 0x80) {
    self.lastNeed = 0;
    return '\ufffd';
  }
  if (self.lastNeed > 1 && buf.length > 1) {
    if ((buf[1] & 0xC0) !== 0x80) {
      self.lastNeed = 1;
      return '\ufffd';
    }
    if (self.lastNeed > 2 && buf.length > 2) {
      if ((buf[2] & 0xC0) !== 0x80) {
        self.lastNeed = 2;
        return '\ufffd';
      }
    }
  }
}

// Attempts to complete a multi-byte UTF-8 character using bytes from a Buffer.
function utf8FillLast(buf) {
  var p = this.lastTotal - this.lastNeed;
  var r = utf8CheckExtraBytes(this, buf, p);
  if (r !== undefined) return r;
  if (this.lastNeed <= buf.length) {
    buf.copy(this.lastChar, p, 0, this.lastNeed);
    return this.lastChar.toString(this.encoding, 0, this.lastTotal);
  }
  buf.copy(this.lastChar, p, 0, buf.length);
  this.lastNeed -= buf.length;
}

// Returns all complete UTF-8 characters in a Buffer. If the Buffer ended on a
// partial character, the character's bytes are buffered until the required
// number of bytes are available.
function utf8Text(buf, i) {
  var total = utf8CheckIncomplete(this, buf, i);
  if (!this.lastNeed) return buf.toString('utf8', i);
  this.lastTotal = total;
  var end = buf.length - (total - this.lastNeed);
  buf.copy(this.lastChar, 0, end);
  return buf.toString('utf8', i, end);
}

// For UTF-8, a replacement character is added when ending on a partial
// character.
function utf8End(buf) {
  var r = buf && buf.length ? this.write(buf) : '';
  if (this.lastNeed) return r + '\ufffd';
  return r;
}

// UTF-16LE typically needs two bytes per character, but even if we have an even
// number of bytes available, we need to check if we end on a leading/high
// surrogate. In that case, we need to wait for the next two bytes in order to
// decode the last character properly.
function utf16Text(buf, i) {
  if ((buf.length - i) % 2 === 0) {
    var r = buf.toString('utf16le', i);
    if (r) {
      var c = r.charCodeAt(r.length - 1);
      if (c >= 0xD800 && c <= 0xDBFF) {
        this.lastNeed = 2;
        this.lastTotal = 4;
        this.lastChar[0] = buf[buf.length - 2];
        this.lastChar[1] = buf[buf.length - 1];
        return r.slice(0, -1);
      }
    }
    return r;
  }
  this.lastNeed = 1;
  this.lastTotal = 2;
  this.lastChar[0] = buf[buf.length - 1];
  return buf.toString('utf16le', i, buf.length - 1);
}

// For UTF-16LE we do not explicitly append special replacement characters if we
// end on a partial character, we simply let v8 handle that.
function utf16End(buf) {
  var r = buf && buf.length ? this.write(buf) : '';
  if (this.lastNeed) {
    var end = this.lastTotal - this.lastNeed;
    return r + this.lastChar.toString('utf16le', 0, end);
  }
  return r;
}

function base64Text(buf, i) {
  var n = (buf.length - i) % 3;
  if (n === 0) return buf.toString('base64', i);
  this.lastNeed = 3 - n;
  this.lastTotal = 3;
  if (n === 1) {
    this.lastChar[0] = buf[buf.length - 1];
  } else {
    this.lastChar[0] = buf[buf.length - 2];
    this.lastChar[1] = buf[buf.length - 1];
  }
  return buf.toString('base64', i, buf.length - n);
}

function base64End(buf) {
  var r = buf && buf.length ? this.write(buf) : '';
  if (this.lastNeed) return r + this.lastChar.toString('base64', 0, 3 - this.lastNeed);
  return r;
}

// Pass bytes on through for single-byte encodings (e.g. ascii, latin1, hex)
function simpleWrite(buf) {
  return buf.toString(this.encoding);
}

function simpleEnd(buf) {
  return buf && buf.length ? this.write(buf) : '';
}
},{"safe-buffer":8}],10:[function(require,module,exports){
(function (setImmediate,clearImmediate){(function (){
var nextTick = require('process/browser.js').nextTick;
var apply = Function.prototype.apply;
var slice = Array.prototype.slice;
var immediateIds = {};
var nextImmediateId = 0;

// DOM APIs, for completeness

exports.setTimeout = function() {
  return new Timeout(apply.call(setTimeout, window, arguments), clearTimeout);
};
exports.setInterval = function() {
  return new Timeout(apply.call(setInterval, window, arguments), clearInterval);
};
exports.clearTimeout =
exports.clearInterval = function(timeout) { timeout.close(); };

function Timeout(id, clearFn) {
  this._id = id;
  this._clearFn = clearFn;
}
Timeout.prototype.unref = Timeout.prototype.ref = function() {};
Timeout.prototype.close = function() {
  this._clearFn.call(window, this._id);
};

// Does not start the time, just sets up the members needed.
exports.enroll = function(item, msecs) {
  clearTimeout(item._idleTimeoutId);
  item._idleTimeout = msecs;
};

exports.unenroll = function(item) {
  clearTimeout(item._idleTimeoutId);
  item._idleTimeout = -1;
};

exports._unrefActive = exports.active = function(item) {
  clearTimeout(item._idleTimeoutId);

  var msecs = item._idleTimeout;
  if (msecs >= 0) {
    item._idleTimeoutId = setTimeout(function onTimeout() {
      if (item._onTimeout)
        item._onTimeout();
    }, msecs);
  }
};

// That's not how node.js implements it but the exposed api is the same.
exports.setImmediate = typeof setImmediate === "function" ? setImmediate : function(fn) {
  var id = nextImmediateId++;
  var args = arguments.length < 2 ? false : slice.call(arguments, 1);

  immediateIds[id] = true;

  nextTick(function onNextTick() {
    if (immediateIds[id]) {
      // fn.call() is faster so we optimize for the common use-case
      // @see http://jsperf.com/call-apply-segu
      if (args) {
        fn.apply(null, args);
      } else {
        fn.call(null);
      }
      // Prevent ids from leaking
      exports.clearImmediate(id);
    }
  });

  return id;
};

exports.clearImmediate = typeof clearImmediate === "function" ? clearImmediate : function(id) {
  delete immediateIds[id];
};
}).call(this)}).call(this,require("timers").setImmediate,require("timers").clearImmediate)
},{"process/browser.js":7,"timers":10}],11:[function(require,module,exports){
// https://d3js.org/d3-color/ v2.0.0 Copyright 2020 Mike Bostock
(function (global, factory) {
typeof exports === 'object' && typeof module !== 'undefined' ? factory(exports) :
typeof define === 'function' && define.amd ? define(['exports'], factory) :
(global = global || self, factory(global.d3 = global.d3 || {}));
}(this, function (exports) { 'use strict';

function define(constructor, factory, prototype) {
  constructor.prototype = factory.prototype = prototype;
  prototype.constructor = constructor;
}

function extend(parent, definition) {
  var prototype = Object.create(parent.prototype);
  for (var key in definition) prototype[key] = definition[key];
  return prototype;
}

function Color() {}

var darker = 0.7;
var brighter = 1 / darker;

var reI = "\\s*([+-]?\\d+)\\s*",
    reN = "\\s*([+-]?\\d*\\.?\\d+(?:[eE][+-]?\\d+)?)\\s*",
    reP = "\\s*([+-]?\\d*\\.?\\d+(?:[eE][+-]?\\d+)?)%\\s*",
    reHex = /^#([0-9a-f]{3,8})$/,
    reRgbInteger = new RegExp("^rgb\\(" + [reI, reI, reI] + "\\)$"),
    reRgbPercent = new RegExp("^rgb\\(" + [reP, reP, reP] + "\\)$"),
    reRgbaInteger = new RegExp("^rgba\\(" + [reI, reI, reI, reN] + "\\)$"),
    reRgbaPercent = new RegExp("^rgba\\(" + [reP, reP, reP, reN] + "\\)$"),
    reHslPercent = new RegExp("^hsl\\(" + [reN, reP, reP] + "\\)$"),
    reHslaPercent = new RegExp("^hsla\\(" + [reN, reP, reP, reN] + "\\)$");

var named = {
  aliceblue: 0xf0f8ff,
  antiquewhite: 0xfaebd7,
  aqua: 0x00ffff,
  aquamarine: 0x7fffd4,
  azure: 0xf0ffff,
  beige: 0xf5f5dc,
  bisque: 0xffe4c4,
  black: 0x000000,
  blanchedalmond: 0xffebcd,
  blue: 0x0000ff,
  blueviolet: 0x8a2be2,
  brown: 0xa52a2a,
  burlywood: 0xdeb887,
  cadetblue: 0x5f9ea0,
  chartreuse: 0x7fff00,
  chocolate: 0xd2691e,
  coral: 0xff7f50,
  cornflowerblue: 0x6495ed,
  cornsilk: 0xfff8dc,
  crimson: 0xdc143c,
  cyan: 0x00ffff,
  darkblue: 0x00008b,
  darkcyan: 0x008b8b,
  darkgoldenrod: 0xb8860b,
  darkgray: 0xa9a9a9,
  darkgreen: 0x006400,
  darkgrey: 0xa9a9a9,
  darkkhaki: 0xbdb76b,
  darkmagenta: 0x8b008b,
  darkolivegreen: 0x556b2f,
  darkorange: 0xff8c00,
  darkorchid: 0x9932cc,
  darkred: 0x8b0000,
  darksalmon: 0xe9967a,
  darkseagreen: 0x8fbc8f,
  darkslateblue: 0x483d8b,
  darkslategray: 0x2f4f4f,
  darkslategrey: 0x2f4f4f,
  darkturquoise: 0x00ced1,
  darkviolet: 0x9400d3,
  deeppink: 0xff1493,
  deepskyblue: 0x00bfff,
  dimgray: 0x696969,
  dimgrey: 0x696969,
  dodgerblue: 0x1e90ff,
  firebrick: 0xb22222,
  floralwhite: 0xfffaf0,
  forestgreen: 0x228b22,
  fuchsia: 0xff00ff,
  gainsboro: 0xdcdcdc,
  ghostwhite: 0xf8f8ff,
  gold: 0xffd700,
  goldenrod: 0xdaa520,
  gray: 0x808080,
  green: 0x008000,
  greenyellow: 0xadff2f,
  grey: 0x808080,
  honeydew: 0xf0fff0,
  hotpink: 0xff69b4,
  indianred: 0xcd5c5c,
  indigo: 0x4b0082,
  ivory: 0xfffff0,
  khaki: 0xf0e68c,
  lavender: 0xe6e6fa,
  lavenderblush: 0xfff0f5,
  lawngreen: 0x7cfc00,
  lemonchiffon: 0xfffacd,
  lightblue: 0xadd8e6,
  lightcoral: 0xf08080,
  lightcyan: 0xe0ffff,
  lightgoldenrodyellow: 0xfafad2,
  lightgray: 0xd3d3d3,
  lightgreen: 0x90ee90,
  lightgrey: 0xd3d3d3,
  lightpink: 0xffb6c1,
  lightsalmon: 0xffa07a,
  lightseagreen: 0x20b2aa,
  lightskyblue: 0x87cefa,
  lightslategray: 0x778899,
  lightslategrey: 0x778899,
  lightsteelblue: 0xb0c4de,
  lightyellow: 0xffffe0,
  lime: 0x00ff00,
  limegreen: 0x32cd32,
  linen: 0xfaf0e6,
  magenta: 0xff00ff,
  maroon: 0x800000,
  mediumaquamarine: 0x66cdaa,
  mediumblue: 0x0000cd,
  mediumorchid: 0xba55d3,
  mediumpurple: 0x9370db,
  mediumseagreen: 0x3cb371,
  mediumslateblue: 0x7b68ee,
  mediumspringgreen: 0x00fa9a,
  mediumturquoise: 0x48d1cc,
  mediumvioletred: 0xc71585,
  midnightblue: 0x191970,
  mintcream: 0xf5fffa,
  mistyrose: 0xffe4e1,
  moccasin: 0xffe4b5,
  navajowhite: 0xffdead,
  navy: 0x000080,
  oldlace: 0xfdf5e6,
  olive: 0x808000,
  olivedrab: 0x6b8e23,
  orange: 0xffa500,
  orangered: 0xff4500,
  orchid: 0xda70d6,
  palegoldenrod: 0xeee8aa,
  palegreen: 0x98fb98,
  paleturquoise: 0xafeeee,
  palevioletred: 0xdb7093,
  papayawhip: 0xffefd5,
  peachpuff: 0xffdab9,
  peru: 0xcd853f,
  pink: 0xffc0cb,
  plum: 0xdda0dd,
  powderblue: 0xb0e0e6,
  purple: 0x800080,
  rebeccapurple: 0x663399,
  red: 0xff0000,
  rosybrown: 0xbc8f8f,
  royalblue: 0x4169e1,
  saddlebrown: 0x8b4513,
  salmon: 0xfa8072,
  sandybrown: 0xf4a460,
  seagreen: 0x2e8b57,
  seashell: 0xfff5ee,
  sienna: 0xa0522d,
  silver: 0xc0c0c0,
  skyblue: 0x87ceeb,
  slateblue: 0x6a5acd,
  slategray: 0x708090,
  slategrey: 0x708090,
  snow: 0xfffafa,
  springgreen: 0x00ff7f,
  steelblue: 0x4682b4,
  tan: 0xd2b48c,
  teal: 0x008080,
  thistle: 0xd8bfd8,
  tomato: 0xff6347,
  turquoise: 0x40e0d0,
  violet: 0xee82ee,
  wheat: 0xf5deb3,
  white: 0xffffff,
  whitesmoke: 0xf5f5f5,
  yellow: 0xffff00,
  yellowgreen: 0x9acd32
};

define(Color, color, {
  copy: function(channels) {
    return Object.assign(new this.constructor, this, channels);
  },
  displayable: function() {
    return this.rgb().displayable();
  },
  hex: color_formatHex, // Deprecated! Use color.formatHex.
  formatHex: color_formatHex,
  formatHsl: color_formatHsl,
  formatRgb: color_formatRgb,
  toString: color_formatRgb
});

function color_formatHex() {
  return this.rgb().formatHex();
}

function color_formatHsl() {
  return hslConvert(this).formatHsl();
}

function color_formatRgb() {
  return this.rgb().formatRgb();
}

function color(format) {
  var m, l;
  format = (format + "").trim().toLowerCase();
  return (m = reHex.exec(format)) ? (l = m[1].length, m = parseInt(m[1], 16), l === 6 ? rgbn(m) // #ff0000
      : l === 3 ? new Rgb((m >> 8 & 0xf) | (m >> 4 & 0xf0), (m >> 4 & 0xf) | (m & 0xf0), ((m & 0xf) << 4) | (m & 0xf), 1) // #f00
      : l === 8 ? rgba(m >> 24 & 0xff, m >> 16 & 0xff, m >> 8 & 0xff, (m & 0xff) / 0xff) // #ff000000
      : l === 4 ? rgba((m >> 12 & 0xf) | (m >> 8 & 0xf0), (m >> 8 & 0xf) | (m >> 4 & 0xf0), (m >> 4 & 0xf) | (m & 0xf0), (((m & 0xf) << 4) | (m & 0xf)) / 0xff) // #f000
      : null) // invalid hex
      : (m = reRgbInteger.exec(format)) ? new Rgb(m[1], m[2], m[3], 1) // rgb(255, 0, 0)
      : (m = reRgbPercent.exec(format)) ? new Rgb(m[1] * 255 / 100, m[2] * 255 / 100, m[3] * 255 / 100, 1) // rgb(100%, 0%, 0%)
      : (m = reRgbaInteger.exec(format)) ? rgba(m[1], m[2], m[3], m[4]) // rgba(255, 0, 0, 1)
      : (m = reRgbaPercent.exec(format)) ? rgba(m[1] * 255 / 100, m[2] * 255 / 100, m[3] * 255 / 100, m[4]) // rgb(100%, 0%, 0%, 1)
      : (m = reHslPercent.exec(format)) ? hsla(m[1], m[2] / 100, m[3] / 100, 1) // hsl(120, 50%, 50%)
      : (m = reHslaPercent.exec(format)) ? hsla(m[1], m[2] / 100, m[3] / 100, m[4]) // hsla(120, 50%, 50%, 1)
      : named.hasOwnProperty(format) ? rgbn(named[format]) // eslint-disable-line no-prototype-builtins
      : format === "transparent" ? new Rgb(NaN, NaN, NaN, 0)
      : null;
}

function rgbn(n) {
  return new Rgb(n >> 16 & 0xff, n >> 8 & 0xff, n & 0xff, 1);
}

function rgba(r, g, b, a) {
  if (a <= 0) r = g = b = NaN;
  return new Rgb(r, g, b, a);
}

function rgbConvert(o) {
  if (!(o instanceof Color)) o = color(o);
  if (!o) return new Rgb;
  o = o.rgb();
  return new Rgb(o.r, o.g, o.b, o.opacity);
}

function rgb(r, g, b, opacity) {
  return arguments.length === 1 ? rgbConvert(r) : new Rgb(r, g, b, opacity == null ? 1 : opacity);
}

function Rgb(r, g, b, opacity) {
  this.r = +r;
  this.g = +g;
  this.b = +b;
  this.opacity = +opacity;
}

define(Rgb, rgb, extend(Color, {
  brighter: function(k) {
    k = k == null ? brighter : Math.pow(brighter, k);
    return new Rgb(this.r * k, this.g * k, this.b * k, this.opacity);
  },
  darker: function(k) {
    k = k == null ? darker : Math.pow(darker, k);
    return new Rgb(this.r * k, this.g * k, this.b * k, this.opacity);
  },
  rgb: function() {
    return this;
  },
  displayable: function() {
    return (-0.5 <= this.r && this.r < 255.5)
        && (-0.5 <= this.g && this.g < 255.5)
        && (-0.5 <= this.b && this.b < 255.5)
        && (0 <= this.opacity && this.opacity <= 1);
  },
  hex: rgb_formatHex, // Deprecated! Use color.formatHex.
  formatHex: rgb_formatHex,
  formatRgb: rgb_formatRgb,
  toString: rgb_formatRgb
}));

function rgb_formatHex() {
  return "#" + hex(this.r) + hex(this.g) + hex(this.b);
}

function rgb_formatRgb() {
  var a = this.opacity; a = isNaN(a) ? 1 : Math.max(0, Math.min(1, a));
  return (a === 1 ? "rgb(" : "rgba(")
      + Math.max(0, Math.min(255, Math.round(this.r) || 0)) + ", "
      + Math.max(0, Math.min(255, Math.round(this.g) || 0)) + ", "
      + Math.max(0, Math.min(255, Math.round(this.b) || 0))
      + (a === 1 ? ")" : ", " + a + ")");
}

function hex(value) {
  value = Math.max(0, Math.min(255, Math.round(value) || 0));
  return (value < 16 ? "0" : "") + value.toString(16);
}

function hsla(h, s, l, a) {
  if (a <= 0) h = s = l = NaN;
  else if (l <= 0 || l >= 1) h = s = NaN;
  else if (s <= 0) h = NaN;
  return new Hsl(h, s, l, a);
}

function hslConvert(o) {
  if (o instanceof Hsl) return new Hsl(o.h, o.s, o.l, o.opacity);
  if (!(o instanceof Color)) o = color(o);
  if (!o) return new Hsl;
  if (o instanceof Hsl) return o;
  o = o.rgb();
  var r = o.r / 255,
      g = o.g / 255,
      b = o.b / 255,
      min = Math.min(r, g, b),
      max = Math.max(r, g, b),
      h = NaN,
      s = max - min,
      l = (max + min) / 2;
  if (s) {
    if (r === max) h = (g - b) / s + (g < b) * 6;
    else if (g === max) h = (b - r) / s + 2;
    else h = (r - g) / s + 4;
    s /= l < 0.5 ? max + min : 2 - max - min;
    h *= 60;
  } else {
    s = l > 0 && l < 1 ? 0 : h;
  }
  return new Hsl(h, s, l, o.opacity);
}

function hsl(h, s, l, opacity) {
  return arguments.length === 1 ? hslConvert(h) : new Hsl(h, s, l, opacity == null ? 1 : opacity);
}

function Hsl(h, s, l, opacity) {
  this.h = +h;
  this.s = +s;
  this.l = +l;
  this.opacity = +opacity;
}

define(Hsl, hsl, extend(Color, {
  brighter: function(k) {
    k = k == null ? brighter : Math.pow(brighter, k);
    return new Hsl(this.h, this.s, this.l * k, this.opacity);
  },
  darker: function(k) {
    k = k == null ? darker : Math.pow(darker, k);
    return new Hsl(this.h, this.s, this.l * k, this.opacity);
  },
  rgb: function() {
    var h = this.h % 360 + (this.h < 0) * 360,
        s = isNaN(h) || isNaN(this.s) ? 0 : this.s,
        l = this.l,
        m2 = l + (l < 0.5 ? l : 1 - l) * s,
        m1 = 2 * l - m2;
    return new Rgb(
      hsl2rgb(h >= 240 ? h - 240 : h + 120, m1, m2),
      hsl2rgb(h, m1, m2),
      hsl2rgb(h < 120 ? h + 240 : h - 120, m1, m2),
      this.opacity
    );
  },
  displayable: function() {
    return (0 <= this.s && this.s <= 1 || isNaN(this.s))
        && (0 <= this.l && this.l <= 1)
        && (0 <= this.opacity && this.opacity <= 1);
  },
  formatHsl: function() {
    var a = this.opacity; a = isNaN(a) ? 1 : Math.max(0, Math.min(1, a));
    return (a === 1 ? "hsl(" : "hsla(")
        + (this.h || 0) + ", "
        + (this.s || 0) * 100 + "%, "
        + (this.l || 0) * 100 + "%"
        + (a === 1 ? ")" : ", " + a + ")");
  }
}));

/* From FvD 13.37, CSS Color Module Level 3 */
function hsl2rgb(h, m1, m2) {
  return (h < 60 ? m1 + (m2 - m1) * h / 60
      : h < 180 ? m2
      : h < 240 ? m1 + (m2 - m1) * (240 - h) / 60
      : m1) * 255;
}

const radians = Math.PI / 180;
const degrees = 180 / Math.PI;

// https://observablehq.com/@mbostock/lab-and-rgb
const K = 18,
    Xn = 0.96422,
    Yn = 1,
    Zn = 0.82521,
    t0 = 4 / 29,
    t1 = 6 / 29,
    t2 = 3 * t1 * t1,
    t3 = t1 * t1 * t1;

function labConvert(o) {
  if (o instanceof Lab) return new Lab(o.l, o.a, o.b, o.opacity);
  if (o instanceof Hcl) return hcl2lab(o);
  if (!(o instanceof Rgb)) o = rgbConvert(o);
  var r = rgb2lrgb(o.r),
      g = rgb2lrgb(o.g),
      b = rgb2lrgb(o.b),
      y = xyz2lab((0.2225045 * r + 0.7168786 * g + 0.0606169 * b) / Yn), x, z;
  if (r === g && g === b) x = z = y; else {
    x = xyz2lab((0.4360747 * r + 0.3850649 * g + 0.1430804 * b) / Xn);
    z = xyz2lab((0.0139322 * r + 0.0971045 * g + 0.7141733 * b) / Zn);
  }
  return new Lab(116 * y - 16, 500 * (x - y), 200 * (y - z), o.opacity);
}

function gray(l, opacity) {
  return new Lab(l, 0, 0, opacity == null ? 1 : opacity);
}

function lab(l, a, b, opacity) {
  return arguments.length === 1 ? labConvert(l) : new Lab(l, a, b, opacity == null ? 1 : opacity);
}

function Lab(l, a, b, opacity) {
  this.l = +l;
  this.a = +a;
  this.b = +b;
  this.opacity = +opacity;
}

define(Lab, lab, extend(Color, {
  brighter: function(k) {
    return new Lab(this.l + K * (k == null ? 1 : k), this.a, this.b, this.opacity);
  },
  darker: function(k) {
    return new Lab(this.l - K * (k == null ? 1 : k), this.a, this.b, this.opacity);
  },
  rgb: function() {
    var y = (this.l + 16) / 116,
        x = isNaN(this.a) ? y : y + this.a / 500,
        z = isNaN(this.b) ? y : y - this.b / 200;
    x = Xn * lab2xyz(x);
    y = Yn * lab2xyz(y);
    z = Zn * lab2xyz(z);
    return new Rgb(
      lrgb2rgb( 3.1338561 * x - 1.6168667 * y - 0.4906146 * z),
      lrgb2rgb(-0.9787684 * x + 1.9161415 * y + 0.0334540 * z),
      lrgb2rgb( 0.0719453 * x - 0.2289914 * y + 1.4052427 * z),
      this.opacity
    );
  }
}));

function xyz2lab(t) {
  return t > t3 ? Math.pow(t, 1 / 3) : t / t2 + t0;
}

function lab2xyz(t) {
  return t > t1 ? t * t * t : t2 * (t - t0);
}

function lrgb2rgb(x) {
  return 255 * (x <= 0.0031308 ? 12.92 * x : 1.055 * Math.pow(x, 1 / 2.4) - 0.055);
}

function rgb2lrgb(x) {
  return (x /= 255) <= 0.04045 ? x / 12.92 : Math.pow((x + 0.055) / 1.055, 2.4);
}

function hclConvert(o) {
  if (o instanceof Hcl) return new Hcl(o.h, o.c, o.l, o.opacity);
  if (!(o instanceof Lab)) o = labConvert(o);
  if (o.a === 0 && o.b === 0) return new Hcl(NaN, 0 < o.l && o.l < 100 ? 0 : NaN, o.l, o.opacity);
  var h = Math.atan2(o.b, o.a) * degrees;
  return new Hcl(h < 0 ? h + 360 : h, Math.sqrt(o.a * o.a + o.b * o.b), o.l, o.opacity);
}

function lch(l, c, h, opacity) {
  return arguments.length === 1 ? hclConvert(l) : new Hcl(h, c, l, opacity == null ? 1 : opacity);
}

function hcl(h, c, l, opacity) {
  return arguments.length === 1 ? hclConvert(h) : new Hcl(h, c, l, opacity == null ? 1 : opacity);
}

function Hcl(h, c, l, opacity) {
  this.h = +h;
  this.c = +c;
  this.l = +l;
  this.opacity = +opacity;
}

function hcl2lab(o) {
  if (isNaN(o.h)) return new Lab(o.l, 0, 0, o.opacity);
  var h = o.h * radians;
  return new Lab(o.l, Math.cos(h) * o.c, Math.sin(h) * o.c, o.opacity);
}

define(Hcl, hcl, extend(Color, {
  brighter: function(k) {
    return new Hcl(this.h, this.c, this.l + K * (k == null ? 1 : k), this.opacity);
  },
  darker: function(k) {
    return new Hcl(this.h, this.c, this.l - K * (k == null ? 1 : k), this.opacity);
  },
  rgb: function() {
    return hcl2lab(this).rgb();
  }
}));

var A = -0.14861,
    B = +1.78277,
    C = -0.29227,
    D = -0.90649,
    E = +1.97294,
    ED = E * D,
    EB = E * B,
    BC_DA = B * C - D * A;

function cubehelixConvert(o) {
  if (o instanceof Cubehelix) return new Cubehelix(o.h, o.s, o.l, o.opacity);
  if (!(o instanceof Rgb)) o = rgbConvert(o);
  var r = o.r / 255,
      g = o.g / 255,
      b = o.b / 255,
      l = (BC_DA * b + ED * r - EB * g) / (BC_DA + ED - EB),
      bl = b - l,
      k = (E * (g - l) - C * bl) / D,
      s = Math.sqrt(k * k + bl * bl) / (E * l * (1 - l)), // NaN if l=0 or l=1
      h = s ? Math.atan2(k, bl) * degrees - 120 : NaN;
  return new Cubehelix(h < 0 ? h + 360 : h, s, l, o.opacity);
}

function cubehelix(h, s, l, opacity) {
  return arguments.length === 1 ? cubehelixConvert(h) : new Cubehelix(h, s, l, opacity == null ? 1 : opacity);
}

function Cubehelix(h, s, l, opacity) {
  this.h = +h;
  this.s = +s;
  this.l = +l;
  this.opacity = +opacity;
}

define(Cubehelix, cubehelix, extend(Color, {
  brighter: function(k) {
    k = k == null ? brighter : Math.pow(brighter, k);
    return new Cubehelix(this.h, this.s, this.l * k, this.opacity);
  },
  darker: function(k) {
    k = k == null ? darker : Math.pow(darker, k);
    return new Cubehelix(this.h, this.s, this.l * k, this.opacity);
  },
  rgb: function() {
    var h = isNaN(this.h) ? 0 : (this.h + 120) * radians,
        l = +this.l,
        a = isNaN(this.s) ? 0 : this.s * l * (1 - l),
        cosh = Math.cos(h),
        sinh = Math.sin(h);
    return new Rgb(
      255 * (l + a * (A * cosh + B * sinh)),
      255 * (l + a * (C * cosh + D * sinh)),
      255 * (l + a * (E * cosh)),
      this.opacity
    );
  }
}));

exports.color = color;
exports.cubehelix = cubehelix;
exports.gray = gray;
exports.hcl = hcl;
exports.hsl = hsl;
exports.lab = lab;
exports.lch = lch;
exports.rgb = rgb;

Object.defineProperty(exports, '__esModule', { value: true });

}));

},{}],12:[function(require,module,exports){
// https://d3js.org/d3-interpolate/ v2.0.1 Copyright 2020 Mike Bostock
(function (global, factory) {
typeof exports === 'object' && typeof module !== 'undefined' ? factory(exports, require('d3-color')) :
typeof define === 'function' && define.amd ? define(['exports', 'd3-color'], factory) :
(global = global || self, factory(global.d3 = global.d3 || {}, global.d3));
}(this, function (exports, d3Color) { 'use strict';

function basis(t1, v0, v1, v2, v3) {
  var t2 = t1 * t1, t3 = t2 * t1;
  return ((1 - 3 * t1 + 3 * t2 - t3) * v0
      + (4 - 6 * t2 + 3 * t3) * v1
      + (1 + 3 * t1 + 3 * t2 - 3 * t3) * v2
      + t3 * v3) / 6;
}

function basis$1(values) {
  var n = values.length - 1;
  return function(t) {
    var i = t <= 0 ? (t = 0) : t >= 1 ? (t = 1, n - 1) : Math.floor(t * n),
        v1 = values[i],
        v2 = values[i + 1],
        v0 = i > 0 ? values[i - 1] : 2 * v1 - v2,
        v3 = i < n - 1 ? values[i + 2] : 2 * v2 - v1;
    return basis((t - i / n) * n, v0, v1, v2, v3);
  };
}

function basisClosed(values) {
  var n = values.length;
  return function(t) {
    var i = Math.floor(((t %= 1) < 0 ? ++t : t) * n),
        v0 = values[(i + n - 1) % n],
        v1 = values[i % n],
        v2 = values[(i + 1) % n],
        v3 = values[(i + 2) % n];
    return basis((t - i / n) * n, v0, v1, v2, v3);
  };
}

var constant = x => () => x;

function linear(a, d) {
  return function(t) {
    return a + t * d;
  };
}

function exponential(a, b, y) {
  return a = Math.pow(a, y), b = Math.pow(b, y) - a, y = 1 / y, function(t) {
    return Math.pow(a + t * b, y);
  };
}

function hue(a, b) {
  var d = b - a;
  return d ? linear(a, d > 180 || d < -180 ? d - 360 * Math.round(d / 360) : d) : constant(isNaN(a) ? b : a);
}

function gamma(y) {
  return (y = +y) === 1 ? nogamma : function(a, b) {
    return b - a ? exponential(a, b, y) : constant(isNaN(a) ? b : a);
  };
}

function nogamma(a, b) {
  var d = b - a;
  return d ? linear(a, d) : constant(isNaN(a) ? b : a);
}

var rgb = (function rgbGamma(y) {
  var color = gamma(y);

  function rgb(start, end) {
    var r = color((start = d3Color.rgb(start)).r, (end = d3Color.rgb(end)).r),
        g = color(start.g, end.g),
        b = color(start.b, end.b),
        opacity = nogamma(start.opacity, end.opacity);
    return function(t) {
      start.r = r(t);
      start.g = g(t);
      start.b = b(t);
      start.opacity = opacity(t);
      return start + "";
    };
  }

  rgb.gamma = rgbGamma;

  return rgb;
})(1);

function rgbSpline(spline) {
  return function(colors) {
    var n = colors.length,
        r = new Array(n),
        g = new Array(n),
        b = new Array(n),
        i, color;
    for (i = 0; i < n; ++i) {
      color = d3Color.rgb(colors[i]);
      r[i] = color.r || 0;
      g[i] = color.g || 0;
      b[i] = color.b || 0;
    }
    r = spline(r);
    g = spline(g);
    b = spline(b);
    color.opacity = 1;
    return function(t) {
      color.r = r(t);
      color.g = g(t);
      color.b = b(t);
      return color + "";
    };
  };
}

var rgbBasis = rgbSpline(basis$1);
var rgbBasisClosed = rgbSpline(basisClosed);

function numberArray(a, b) {
  if (!b) b = [];
  var n = a ? Math.min(b.length, a.length) : 0,
      c = b.slice(),
      i;
  return function(t) {
    for (i = 0; i < n; ++i) c[i] = a[i] * (1 - t) + b[i] * t;
    return c;
  };
}

function isNumberArray(x) {
  return ArrayBuffer.isView(x) && !(x instanceof DataView);
}

function array(a, b) {
  return (isNumberArray(b) ? numberArray : genericArray)(a, b);
}

function genericArray(a, b) {
  var nb = b ? b.length : 0,
      na = a ? Math.min(nb, a.length) : 0,
      x = new Array(na),
      c = new Array(nb),
      i;

  for (i = 0; i < na; ++i) x[i] = value(a[i], b[i]);
  for (; i < nb; ++i) c[i] = b[i];

  return function(t) {
    for (i = 0; i < na; ++i) c[i] = x[i](t);
    return c;
  };
}

function date(a, b) {
  var d = new Date;
  return a = +a, b = +b, function(t) {
    return d.setTime(a * (1 - t) + b * t), d;
  };
}

function number(a, b) {
  return a = +a, b = +b, function(t) {
    return a * (1 - t) + b * t;
  };
}

function object(a, b) {
  var i = {},
      c = {},
      k;

  if (a === null || typeof a !== "object") a = {};
  if (b === null || typeof b !== "object") b = {};

  for (k in b) {
    if (k in a) {
      i[k] = value(a[k], b[k]);
    } else {
      c[k] = b[k];
    }
  }

  return function(t) {
    for (k in i) c[k] = i[k](t);
    return c;
  };
}

var reA = /[-+]?(?:\d+\.?\d*|\.?\d+)(?:[eE][-+]?\d+)?/g,
    reB = new RegExp(reA.source, "g");

function zero(b) {
  return function() {
    return b;
  };
}

function one(b) {
  return function(t) {
    return b(t) + "";
  };
}

function string(a, b) {
  var bi = reA.lastIndex = reB.lastIndex = 0, // scan index for next number in b
      am, // current match in a
      bm, // current match in b
      bs, // string preceding current number in b, if any
      i = -1, // index in s
      s = [], // string constants and placeholders
      q = []; // number interpolators

  // Coerce inputs to strings.
  a = a + "", b = b + "";

  // Interpolate pairs of numbers in a & b.
  while ((am = reA.exec(a))
      && (bm = reB.exec(b))) {
    if ((bs = bm.index) > bi) { // a string precedes the next number in b
      bs = b.slice(bi, bs);
      if (s[i]) s[i] += bs; // coalesce with previous string
      else s[++i] = bs;
    }
    if ((am = am[0]) === (bm = bm[0])) { // numbers in a & b match
      if (s[i]) s[i] += bm; // coalesce with previous string
      else s[++i] = bm;
    } else { // interpolate non-matching numbers
      s[++i] = null;
      q.push({i: i, x: number(am, bm)});
    }
    bi = reB.lastIndex;
  }

  // Add remains of b.
  if (bi < b.length) {
    bs = b.slice(bi);
    if (s[i]) s[i] += bs; // coalesce with previous string
    else s[++i] = bs;
  }

  // Special optimization for only a single match.
  // Otherwise, interpolate each of the numbers and rejoin the string.
  return s.length < 2 ? (q[0]
      ? one(q[0].x)
      : zero(b))
      : (b = q.length, function(t) {
          for (var i = 0, o; i < b; ++i) s[(o = q[i]).i] = o.x(t);
          return s.join("");
        });
}

function value(a, b) {
  var t = typeof b, c;
  return b == null || t === "boolean" ? constant(b)
      : (t === "number" ? number
      : t === "string" ? ((c = d3Color.color(b)) ? (b = c, rgb) : string)
      : b instanceof d3Color.color ? rgb
      : b instanceof Date ? date
      : isNumberArray(b) ? numberArray
      : Array.isArray(b) ? genericArray
      : typeof b.valueOf !== "function" && typeof b.toString !== "function" || isNaN(b) ? object
      : number)(a, b);
}

function discrete(range) {
  var n = range.length;
  return function(t) {
    return range[Math.max(0, Math.min(n - 1, Math.floor(t * n)))];
  };
}

function hue$1(a, b) {
  var i = hue(+a, +b);
  return function(t) {
    var x = i(t);
    return x - 360 * Math.floor(x / 360);
  };
}

function round(a, b) {
  return a = +a, b = +b, function(t) {
    return Math.round(a * (1 - t) + b * t);
  };
}

var degrees = 180 / Math.PI;

var identity = {
  translateX: 0,
  translateY: 0,
  rotate: 0,
  skewX: 0,
  scaleX: 1,
  scaleY: 1
};

function decompose(a, b, c, d, e, f) {
  var scaleX, scaleY, skewX;
  if (scaleX = Math.sqrt(a * a + b * b)) a /= scaleX, b /= scaleX;
  if (skewX = a * c + b * d) c -= a * skewX, d -= b * skewX;
  if (scaleY = Math.sqrt(c * c + d * d)) c /= scaleY, d /= scaleY, skewX /= scaleY;
  if (a * d < b * c) a = -a, b = -b, skewX = -skewX, scaleX = -scaleX;
  return {
    translateX: e,
    translateY: f,
    rotate: Math.atan2(b, a) * degrees,
    skewX: Math.atan(skewX) * degrees,
    scaleX: scaleX,
    scaleY: scaleY
  };
}

var svgNode;

/* eslint-disable no-undef */
function parseCss(value) {
  const m = new (typeof DOMMatrix === "function" ? DOMMatrix : WebKitCSSMatrix)(value + "");
  return m.isIdentity ? identity : decompose(m.a, m.b, m.c, m.d, m.e, m.f);
}

function parseSvg(value) {
  if (value == null) return identity;
  if (!svgNode) svgNode = document.createElementNS("http://www.w3.org/2000/svg", "g");
  svgNode.setAttribute("transform", value);
  if (!(value = svgNode.transform.baseVal.consolidate())) return identity;
  value = value.matrix;
  return decompose(value.a, value.b, value.c, value.d, value.e, value.f);
}

function interpolateTransform(parse, pxComma, pxParen, degParen) {

  function pop(s) {
    return s.length ? s.pop() + " " : "";
  }

  function translate(xa, ya, xb, yb, s, q) {
    if (xa !== xb || ya !== yb) {
      var i = s.push("translate(", null, pxComma, null, pxParen);
      q.push({i: i - 4, x: number(xa, xb)}, {i: i - 2, x: number(ya, yb)});
    } else if (xb || yb) {
      s.push("translate(" + xb + pxComma + yb + pxParen);
    }
  }

  function rotate(a, b, s, q) {
    if (a !== b) {
      if (a - b > 180) b += 360; else if (b - a > 180) a += 360; // shortest path
      q.push({i: s.push(pop(s) + "rotate(", null, degParen) - 2, x: number(a, b)});
    } else if (b) {
      s.push(pop(s) + "rotate(" + b + degParen);
    }
  }

  function skewX(a, b, s, q) {
    if (a !== b) {
      q.push({i: s.push(pop(s) + "skewX(", null, degParen) - 2, x: number(a, b)});
    } else if (b) {
      s.push(pop(s) + "skewX(" + b + degParen);
    }
  }

  function scale(xa, ya, xb, yb, s, q) {
    if (xa !== xb || ya !== yb) {
      var i = s.push(pop(s) + "scale(", null, ",", null, ")");
      q.push({i: i - 4, x: number(xa, xb)}, {i: i - 2, x: number(ya, yb)});
    } else if (xb !== 1 || yb !== 1) {
      s.push(pop(s) + "scale(" + xb + "," + yb + ")");
    }
  }

  return function(a, b) {
    var s = [], // string constants and placeholders
        q = []; // number interpolators
    a = parse(a), b = parse(b);
    translate(a.translateX, a.translateY, b.translateX, b.translateY, s, q);
    rotate(a.rotate, b.rotate, s, q);
    skewX(a.skewX, b.skewX, s, q);
    scale(a.scaleX, a.scaleY, b.scaleX, b.scaleY, s, q);
    a = b = null; // gc
    return function(t) {
      var i = -1, n = q.length, o;
      while (++i < n) s[(o = q[i]).i] = o.x(t);
      return s.join("");
    };
  };
}

var interpolateTransformCss = interpolateTransform(parseCss, "px, ", "px)", "deg)");
var interpolateTransformSvg = interpolateTransform(parseSvg, ", ", ")", ")");

var epsilon2 = 1e-12;

function cosh(x) {
  return ((x = Math.exp(x)) + 1 / x) / 2;
}

function sinh(x) {
  return ((x = Math.exp(x)) - 1 / x) / 2;
}

function tanh(x) {
  return ((x = Math.exp(2 * x)) - 1) / (x + 1);
}

var zoom = (function zoomRho(rho, rho2, rho4) {

  // p0 = [ux0, uy0, w0]
  // p1 = [ux1, uy1, w1]
  function zoom(p0, p1) {
    var ux0 = p0[0], uy0 = p0[1], w0 = p0[2],
        ux1 = p1[0], uy1 = p1[1], w1 = p1[2],
        dx = ux1 - ux0,
        dy = uy1 - uy0,
        d2 = dx * dx + dy * dy,
        i,
        S;

    // Special case for u0  u1.
    if (d2 < epsilon2) {
      S = Math.log(w1 / w0) / rho;
      i = function(t) {
        return [
          ux0 + t * dx,
          uy0 + t * dy,
          w0 * Math.exp(rho * t * S)
        ];
      };
    }

    // General case.
    else {
      var d1 = Math.sqrt(d2),
          b0 = (w1 * w1 - w0 * w0 + rho4 * d2) / (2 * w0 * rho2 * d1),
          b1 = (w1 * w1 - w0 * w0 - rho4 * d2) / (2 * w1 * rho2 * d1),
          r0 = Math.log(Math.sqrt(b0 * b0 + 1) - b0),
          r1 = Math.log(Math.sqrt(b1 * b1 + 1) - b1);
      S = (r1 - r0) / rho;
      i = function(t) {
        var s = t * S,
            coshr0 = cosh(r0),
            u = w0 / (rho2 * d1) * (coshr0 * tanh(rho * s + r0) - sinh(r0));
        return [
          ux0 + u * dx,
          uy0 + u * dy,
          w0 * coshr0 / cosh(rho * s + r0)
        ];
      };
    }

    i.duration = S * 1000 * rho / Math.SQRT2;

    return i;
  }

  zoom.rho = function(_) {
    var _1 = Math.max(1e-3, +_), _2 = _1 * _1, _4 = _2 * _2;
    return zoomRho(_1, _2, _4);
  };

  return zoom;
})(Math.SQRT2, 2, 4);

function hsl(hue) {
  return function(start, end) {
    var h = hue((start = d3Color.hsl(start)).h, (end = d3Color.hsl(end)).h),
        s = nogamma(start.s, end.s),
        l = nogamma(start.l, end.l),
        opacity = nogamma(start.opacity, end.opacity);
    return function(t) {
      start.h = h(t);
      start.s = s(t);
      start.l = l(t);
      start.opacity = opacity(t);
      return start + "";
    };
  }
}

var hsl$1 = hsl(hue);
var hslLong = hsl(nogamma);

function lab(start, end) {
  var l = nogamma((start = d3Color.lab(start)).l, (end = d3Color.lab(end)).l),
      a = nogamma(start.a, end.a),
      b = nogamma(start.b, end.b),
      opacity = nogamma(start.opacity, end.opacity);
  return function(t) {
    start.l = l(t);
    start.a = a(t);
    start.b = b(t);
    start.opacity = opacity(t);
    return start + "";
  };
}

function hcl(hue) {
  return function(start, end) {
    var h = hue((start = d3Color.hcl(start)).h, (end = d3Color.hcl(end)).h),
        c = nogamma(start.c, end.c),
        l = nogamma(start.l, end.l),
        opacity = nogamma(start.opacity, end.opacity);
    return function(t) {
      start.h = h(t);
      start.c = c(t);
      start.l = l(t);
      start.opacity = opacity(t);
      return start + "";
    };
  }
}

var hcl$1 = hcl(hue);
var hclLong = hcl(nogamma);

function cubehelix(hue) {
  return (function cubehelixGamma(y) {
    y = +y;

    function cubehelix(start, end) {
      var h = hue((start = d3Color.cubehelix(start)).h, (end = d3Color.cubehelix(end)).h),
          s = nogamma(start.s, end.s),
          l = nogamma(start.l, end.l),
          opacity = nogamma(start.opacity, end.opacity);
      return function(t) {
        start.h = h(t);
        start.s = s(t);
        start.l = l(Math.pow(t, y));
        start.opacity = opacity(t);
        return start + "";
      };
    }

    cubehelix.gamma = cubehelixGamma;

    return cubehelix;
  })(1);
}

var cubehelix$1 = cubehelix(hue);
var cubehelixLong = cubehelix(nogamma);

function piecewise(interpolate, values) {
  if (values === undefined) values = interpolate, interpolate = value;
  var i = 0, n = values.length - 1, v = values[0], I = new Array(n < 0 ? 0 : n);
  while (i < n) I[i] = interpolate(v, v = values[++i]);
  return function(t) {
    var i = Math.max(0, Math.min(n - 1, Math.floor(t *= n)));
    return I[i](t - i);
  };
}

function quantize(interpolator, n) {
  var samples = new Array(n);
  for (var i = 0; i < n; ++i) samples[i] = interpolator(i / (n - 1));
  return samples;
}

exports.interpolate = value;
exports.interpolateArray = array;
exports.interpolateBasis = basis$1;
exports.interpolateBasisClosed = basisClosed;
exports.interpolateCubehelix = cubehelix$1;
exports.interpolateCubehelixLong = cubehelixLong;
exports.interpolateDate = date;
exports.interpolateDiscrete = discrete;
exports.interpolateHcl = hcl$1;
exports.interpolateHclLong = hclLong;
exports.interpolateHsl = hsl$1;
exports.interpolateHslLong = hslLong;
exports.interpolateHue = hue$1;
exports.interpolateLab = lab;
exports.interpolateNumber = number;
exports.interpolateNumberArray = numberArray;
exports.interpolateObject = object;
exports.interpolateRgb = rgb;
exports.interpolateRgbBasis = rgbBasis;
exports.interpolateRgbBasisClosed = rgbBasisClosed;
exports.interpolateRound = round;
exports.interpolateString = string;
exports.interpolateTransformCss = interpolateTransformCss;
exports.interpolateTransformSvg = interpolateTransformSvg;
exports.interpolateZoom = zoom;
exports.piecewise = piecewise;
exports.quantize = quantize;

Object.defineProperty(exports, '__esModule', { value: true });

}));

},{"d3-color":11}],13:[function(require,module,exports){
// https://d3js.org/d3-scale-chromatic/ v2.0.0 Copyright 2020 Mike Bostock
(function (global, factory) {
typeof exports === 'object' && typeof module !== 'undefined' ? factory(exports, require('d3-interpolate'), require('d3-color')) :
typeof define === 'function' && define.amd ? define(['exports', 'd3-interpolate', 'd3-color'], factory) :
(global = global || self, factory(global.d3 = global.d3 || {}, global.d3, global.d3));
}(this, function (exports, d3Interpolate, d3Color) { 'use strict';

function colors(specifier) {
  var n = specifier.length / 6 | 0, colors = new Array(n), i = 0;
  while (i < n) colors[i] = "#" + specifier.slice(i * 6, ++i * 6);
  return colors;
}

var category10 = colors("1f77b4ff7f0e2ca02cd627289467bd8c564be377c27f7f7fbcbd2217becf");

var Accent = colors("7fc97fbeaed4fdc086ffff99386cb0f0027fbf5b17666666");

var Dark2 = colors("1b9e77d95f027570b3e7298a66a61ee6ab02a6761d666666");

var Paired = colors("a6cee31f78b4b2df8a33a02cfb9a99e31a1cfdbf6fff7f00cab2d66a3d9affff99b15928");

var Pastel1 = colors("fbb4aeb3cde3ccebc5decbe4fed9a6ffffcce5d8bdfddaecf2f2f2");

var Pastel2 = colors("b3e2cdfdcdaccbd5e8f4cae4e6f5c9fff2aef1e2cccccccc");

var Set1 = colors("e41a1c377eb84daf4a984ea3ff7f00ffff33a65628f781bf999999");

var Set2 = colors("66c2a5fc8d628da0cbe78ac3a6d854ffd92fe5c494b3b3b3");

var Set3 = colors("8dd3c7ffffb3bebadafb807280b1d3fdb462b3de69fccde5d9d9d9bc80bdccebc5ffed6f");

var Tableau10 = colors("4e79a7f28e2ce1575976b7b259a14fedc949af7aa1ff9da79c755fbab0ab");

var ramp = scheme => d3Interpolate.interpolateRgbBasis(scheme[scheme.length - 1]);

var scheme = new Array(3).concat(
  "d8b365f5f5f55ab4ac",
  "a6611adfc27d80cdc1018571",
  "a6611adfc27df5f5f580cdc1018571",
  "8c510ad8b365f6e8c3c7eae55ab4ac01665e",
  "8c510ad8b365f6e8c3f5f5f5c7eae55ab4ac01665e",
  "8c510abf812ddfc27df6e8c3c7eae580cdc135978f01665e",
  "8c510abf812ddfc27df6e8c3f5f5f5c7eae580cdc135978f01665e",
  "5430058c510abf812ddfc27df6e8c3c7eae580cdc135978f01665e003c30",
  "5430058c510abf812ddfc27df6e8c3f5f5f5c7eae580cdc135978f01665e003c30"
).map(colors);

var BrBG = ramp(scheme);

var scheme$1 = new Array(3).concat(
  "af8dc3f7f7f77fbf7b",
  "7b3294c2a5cfa6dba0008837",
  "7b3294c2a5cff7f7f7a6dba0008837",
  "762a83af8dc3e7d4e8d9f0d37fbf7b1b7837",
  "762a83af8dc3e7d4e8f7f7f7d9f0d37fbf7b1b7837",
  "762a839970abc2a5cfe7d4e8d9f0d3a6dba05aae611b7837",
  "762a839970abc2a5cfe7d4e8f7f7f7d9f0d3a6dba05aae611b7837",
  "40004b762a839970abc2a5cfe7d4e8d9f0d3a6dba05aae611b783700441b",
  "40004b762a839970abc2a5cfe7d4e8f7f7f7d9f0d3a6dba05aae611b783700441b"
).map(colors);

var PRGn = ramp(scheme$1);

var scheme$2 = new Array(3).concat(
  "e9a3c9f7f7f7a1d76a",
  "d01c8bf1b6dab8e1864dac26",
  "d01c8bf1b6daf7f7f7b8e1864dac26",
  "c51b7de9a3c9fde0efe6f5d0a1d76a4d9221",
  "c51b7de9a3c9fde0eff7f7f7e6f5d0a1d76a4d9221",
  "c51b7dde77aef1b6dafde0efe6f5d0b8e1867fbc414d9221",
  "c51b7dde77aef1b6dafde0eff7f7f7e6f5d0b8e1867fbc414d9221",
  "8e0152c51b7dde77aef1b6dafde0efe6f5d0b8e1867fbc414d9221276419",
  "8e0152c51b7dde77aef1b6dafde0eff7f7f7e6f5d0b8e1867fbc414d9221276419"
).map(colors);

var PiYG = ramp(scheme$2);

var scheme$3 = new Array(3).concat(
  "998ec3f7f7f7f1a340",
  "5e3c99b2abd2fdb863e66101",
  "5e3c99b2abd2f7f7f7fdb863e66101",
  "542788998ec3d8daebfee0b6f1a340b35806",
  "542788998ec3d8daebf7f7f7fee0b6f1a340b35806",
  "5427888073acb2abd2d8daebfee0b6fdb863e08214b35806",
  "5427888073acb2abd2d8daebf7f7f7fee0b6fdb863e08214b35806",
  "2d004b5427888073acb2abd2d8daebfee0b6fdb863e08214b358067f3b08",
  "2d004b5427888073acb2abd2d8daebf7f7f7fee0b6fdb863e08214b358067f3b08"
).map(colors);

var PuOr = ramp(scheme$3);

var scheme$4 = new Array(3).concat(
  "ef8a62f7f7f767a9cf",
  "ca0020f4a58292c5de0571b0",
  "ca0020f4a582f7f7f792c5de0571b0",
  "b2182bef8a62fddbc7d1e5f067a9cf2166ac",
  "b2182bef8a62fddbc7f7f7f7d1e5f067a9cf2166ac",
  "b2182bd6604df4a582fddbc7d1e5f092c5de4393c32166ac",
  "b2182bd6604df4a582fddbc7f7f7f7d1e5f092c5de4393c32166ac",
  "67001fb2182bd6604df4a582fddbc7d1e5f092c5de4393c32166ac053061",
  "67001fb2182bd6604df4a582fddbc7f7f7f7d1e5f092c5de4393c32166ac053061"
).map(colors);

var RdBu = ramp(scheme$4);

var scheme$5 = new Array(3).concat(
  "ef8a62ffffff999999",
  "ca0020f4a582bababa404040",
  "ca0020f4a582ffffffbababa404040",
  "b2182bef8a62fddbc7e0e0e09999994d4d4d",
  "b2182bef8a62fddbc7ffffffe0e0e09999994d4d4d",
  "b2182bd6604df4a582fddbc7e0e0e0bababa8787874d4d4d",
  "b2182bd6604df4a582fddbc7ffffffe0e0e0bababa8787874d4d4d",
  "67001fb2182bd6604df4a582fddbc7e0e0e0bababa8787874d4d4d1a1a1a",
  "67001fb2182bd6604df4a582fddbc7ffffffe0e0e0bababa8787874d4d4d1a1a1a"
).map(colors);

var RdGy = ramp(scheme$5);

var scheme$6 = new Array(3).concat(
  "fc8d59ffffbf91bfdb",
  "d7191cfdae61abd9e92c7bb6",
  "d7191cfdae61ffffbfabd9e92c7bb6",
  "d73027fc8d59fee090e0f3f891bfdb4575b4",
  "d73027fc8d59fee090ffffbfe0f3f891bfdb4575b4",
  "d73027f46d43fdae61fee090e0f3f8abd9e974add14575b4",
  "d73027f46d43fdae61fee090ffffbfe0f3f8abd9e974add14575b4",
  "a50026d73027f46d43fdae61fee090e0f3f8abd9e974add14575b4313695",
  "a50026d73027f46d43fdae61fee090ffffbfe0f3f8abd9e974add14575b4313695"
).map(colors);

var RdYlBu = ramp(scheme$6);

var scheme$7 = new Array(3).concat(
  "fc8d59ffffbf91cf60",
  "d7191cfdae61a6d96a1a9641",
  "d7191cfdae61ffffbfa6d96a1a9641",
  "d73027fc8d59fee08bd9ef8b91cf601a9850",
  "d73027fc8d59fee08bffffbfd9ef8b91cf601a9850",
  "d73027f46d43fdae61fee08bd9ef8ba6d96a66bd631a9850",
  "d73027f46d43fdae61fee08bffffbfd9ef8ba6d96a66bd631a9850",
  "a50026d73027f46d43fdae61fee08bd9ef8ba6d96a66bd631a9850006837",
  "a50026d73027f46d43fdae61fee08bffffbfd9ef8ba6d96a66bd631a9850006837"
).map(colors);

var RdYlGn = ramp(scheme$7);

var scheme$8 = new Array(3).concat(
  "fc8d59ffffbf99d594",
  "d7191cfdae61abdda42b83ba",
  "d7191cfdae61ffffbfabdda42b83ba",
  "d53e4ffc8d59fee08be6f59899d5943288bd",
  "d53e4ffc8d59fee08bffffbfe6f59899d5943288bd",
  "d53e4ff46d43fdae61fee08be6f598abdda466c2a53288bd",
  "d53e4ff46d43fdae61fee08bffffbfe6f598abdda466c2a53288bd",
  "9e0142d53e4ff46d43fdae61fee08be6f598abdda466c2a53288bd5e4fa2",
  "9e0142d53e4ff46d43fdae61fee08bffffbfe6f598abdda466c2a53288bd5e4fa2"
).map(colors);

var Spectral = ramp(scheme$8);

var scheme$9 = new Array(3).concat(
  "e5f5f999d8c92ca25f",
  "edf8fbb2e2e266c2a4238b45",
  "edf8fbb2e2e266c2a42ca25f006d2c",
  "edf8fbccece699d8c966c2a42ca25f006d2c",
  "edf8fbccece699d8c966c2a441ae76238b45005824",
  "f7fcfde5f5f9ccece699d8c966c2a441ae76238b45005824",
  "f7fcfde5f5f9ccece699d8c966c2a441ae76238b45006d2c00441b"
).map(colors);

var BuGn = ramp(scheme$9);

var scheme$a = new Array(3).concat(
  "e0ecf49ebcda8856a7",
  "edf8fbb3cde38c96c688419d",
  "edf8fbb3cde38c96c68856a7810f7c",
  "edf8fbbfd3e69ebcda8c96c68856a7810f7c",
  "edf8fbbfd3e69ebcda8c96c68c6bb188419d6e016b",
  "f7fcfde0ecf4bfd3e69ebcda8c96c68c6bb188419d6e016b",
  "f7fcfde0ecf4bfd3e69ebcda8c96c68c6bb188419d810f7c4d004b"
).map(colors);

var BuPu = ramp(scheme$a);

var scheme$b = new Array(3).concat(
  "e0f3dba8ddb543a2ca",
  "f0f9e8bae4bc7bccc42b8cbe",
  "f0f9e8bae4bc7bccc443a2ca0868ac",
  "f0f9e8ccebc5a8ddb57bccc443a2ca0868ac",
  "f0f9e8ccebc5a8ddb57bccc44eb3d32b8cbe08589e",
  "f7fcf0e0f3dbccebc5a8ddb57bccc44eb3d32b8cbe08589e",
  "f7fcf0e0f3dbccebc5a8ddb57bccc44eb3d32b8cbe0868ac084081"
).map(colors);

var GnBu = ramp(scheme$b);

var scheme$c = new Array(3).concat(
  "fee8c8fdbb84e34a33",
  "fef0d9fdcc8afc8d59d7301f",
  "fef0d9fdcc8afc8d59e34a33b30000",
  "fef0d9fdd49efdbb84fc8d59e34a33b30000",
  "fef0d9fdd49efdbb84fc8d59ef6548d7301f990000",
  "fff7ecfee8c8fdd49efdbb84fc8d59ef6548d7301f990000",
  "fff7ecfee8c8fdd49efdbb84fc8d59ef6548d7301fb300007f0000"
).map(colors);

var OrRd = ramp(scheme$c);

var scheme$d = new Array(3).concat(
  "ece2f0a6bddb1c9099",
  "f6eff7bdc9e167a9cf02818a",
  "f6eff7bdc9e167a9cf1c9099016c59",
  "f6eff7d0d1e6a6bddb67a9cf1c9099016c59",
  "f6eff7d0d1e6a6bddb67a9cf3690c002818a016450",
  "fff7fbece2f0d0d1e6a6bddb67a9cf3690c002818a016450",
  "fff7fbece2f0d0d1e6a6bddb67a9cf3690c002818a016c59014636"
).map(colors);

var PuBuGn = ramp(scheme$d);

var scheme$e = new Array(3).concat(
  "ece7f2a6bddb2b8cbe",
  "f1eef6bdc9e174a9cf0570b0",
  "f1eef6bdc9e174a9cf2b8cbe045a8d",
  "f1eef6d0d1e6a6bddb74a9cf2b8cbe045a8d",
  "f1eef6d0d1e6a6bddb74a9cf3690c00570b0034e7b",
  "fff7fbece7f2d0d1e6a6bddb74a9cf3690c00570b0034e7b",
  "fff7fbece7f2d0d1e6a6bddb74a9cf3690c00570b0045a8d023858"
).map(colors);

var PuBu = ramp(scheme$e);

var scheme$f = new Array(3).concat(
  "e7e1efc994c7dd1c77",
  "f1eef6d7b5d8df65b0ce1256",
  "f1eef6d7b5d8df65b0dd1c77980043",
  "f1eef6d4b9dac994c7df65b0dd1c77980043",
  "f1eef6d4b9dac994c7df65b0e7298ace125691003f",
  "f7f4f9e7e1efd4b9dac994c7df65b0e7298ace125691003f",
  "f7f4f9e7e1efd4b9dac994c7df65b0e7298ace125698004367001f"
).map(colors);

var PuRd = ramp(scheme$f);

var scheme$g = new Array(3).concat(
  "fde0ddfa9fb5c51b8a",
  "feebe2fbb4b9f768a1ae017e",
  "feebe2fbb4b9f768a1c51b8a7a0177",
  "feebe2fcc5c0fa9fb5f768a1c51b8a7a0177",
  "feebe2fcc5c0fa9fb5f768a1dd3497ae017e7a0177",
  "fff7f3fde0ddfcc5c0fa9fb5f768a1dd3497ae017e7a0177",
  "fff7f3fde0ddfcc5c0fa9fb5f768a1dd3497ae017e7a017749006a"
).map(colors);

var RdPu = ramp(scheme$g);

var scheme$h = new Array(3).concat(
  "edf8b17fcdbb2c7fb8",
  "ffffcca1dab441b6c4225ea8",
  "ffffcca1dab441b6c42c7fb8253494",
  "ffffccc7e9b47fcdbb41b6c42c7fb8253494",
  "ffffccc7e9b47fcdbb41b6c41d91c0225ea80c2c84",
  "ffffd9edf8b1c7e9b47fcdbb41b6c41d91c0225ea80c2c84",
  "ffffd9edf8b1c7e9b47fcdbb41b6c41d91c0225ea8253494081d58"
).map(colors);

var YlGnBu = ramp(scheme$h);

var scheme$i = new Array(3).concat(
  "f7fcb9addd8e31a354",
  "ffffccc2e69978c679238443",
  "ffffccc2e69978c67931a354006837",
  "ffffccd9f0a3addd8e78c67931a354006837",
  "ffffccd9f0a3addd8e78c67941ab5d238443005a32",
  "ffffe5f7fcb9d9f0a3addd8e78c67941ab5d238443005a32",
  "ffffe5f7fcb9d9f0a3addd8e78c67941ab5d238443006837004529"
).map(colors);

var YlGn = ramp(scheme$i);

var scheme$j = new Array(3).concat(
  "fff7bcfec44fd95f0e",
  "ffffd4fed98efe9929cc4c02",
  "ffffd4fed98efe9929d95f0e993404",
  "ffffd4fee391fec44ffe9929d95f0e993404",
  "ffffd4fee391fec44ffe9929ec7014cc4c028c2d04",
  "ffffe5fff7bcfee391fec44ffe9929ec7014cc4c028c2d04",
  "ffffe5fff7bcfee391fec44ffe9929ec7014cc4c02993404662506"
).map(colors);

var YlOrBr = ramp(scheme$j);

var scheme$k = new Array(3).concat(
  "ffeda0feb24cf03b20",
  "ffffb2fecc5cfd8d3ce31a1c",
  "ffffb2fecc5cfd8d3cf03b20bd0026",
  "ffffb2fed976feb24cfd8d3cf03b20bd0026",
  "ffffb2fed976feb24cfd8d3cfc4e2ae31a1cb10026",
  "ffffccffeda0fed976feb24cfd8d3cfc4e2ae31a1cb10026",
  "ffffccffeda0fed976feb24cfd8d3cfc4e2ae31a1cbd0026800026"
).map(colors);

var YlOrRd = ramp(scheme$k);

var scheme$l = new Array(3).concat(
  "deebf79ecae13182bd",
  "eff3ffbdd7e76baed62171b5",
  "eff3ffbdd7e76baed63182bd08519c",
  "eff3ffc6dbef9ecae16baed63182bd08519c",
  "eff3ffc6dbef9ecae16baed64292c62171b5084594",
  "f7fbffdeebf7c6dbef9ecae16baed64292c62171b5084594",
  "f7fbffdeebf7c6dbef9ecae16baed64292c62171b508519c08306b"
).map(colors);

var Blues = ramp(scheme$l);

var scheme$m = new Array(3).concat(
  "e5f5e0a1d99b31a354",
  "edf8e9bae4b374c476238b45",
  "edf8e9bae4b374c47631a354006d2c",
  "edf8e9c7e9c0a1d99b74c47631a354006d2c",
  "edf8e9c7e9c0a1d99b74c47641ab5d238b45005a32",
  "f7fcf5e5f5e0c7e9c0a1d99b74c47641ab5d238b45005a32",
  "f7fcf5e5f5e0c7e9c0a1d99b74c47641ab5d238b45006d2c00441b"
).map(colors);

var Greens = ramp(scheme$m);

var scheme$n = new Array(3).concat(
  "f0f0f0bdbdbd636363",
  "f7f7f7cccccc969696525252",
  "f7f7f7cccccc969696636363252525",
  "f7f7f7d9d9d9bdbdbd969696636363252525",
  "f7f7f7d9d9d9bdbdbd969696737373525252252525",
  "fffffff0f0f0d9d9d9bdbdbd969696737373525252252525",
  "fffffff0f0f0d9d9d9bdbdbd969696737373525252252525000000"
).map(colors);

var Greys = ramp(scheme$n);

var scheme$o = new Array(3).concat(
  "efedf5bcbddc756bb1",
  "f2f0f7cbc9e29e9ac86a51a3",
  "f2f0f7cbc9e29e9ac8756bb154278f",
  "f2f0f7dadaebbcbddc9e9ac8756bb154278f",
  "f2f0f7dadaebbcbddc9e9ac8807dba6a51a34a1486",
  "fcfbfdefedf5dadaebbcbddc9e9ac8807dba6a51a34a1486",
  "fcfbfdefedf5dadaebbcbddc9e9ac8807dba6a51a354278f3f007d"
).map(colors);

var Purples = ramp(scheme$o);

var scheme$p = new Array(3).concat(
  "fee0d2fc9272de2d26",
  "fee5d9fcae91fb6a4acb181d",
  "fee5d9fcae91fb6a4ade2d26a50f15",
  "fee5d9fcbba1fc9272fb6a4ade2d26a50f15",
  "fee5d9fcbba1fc9272fb6a4aef3b2ccb181d99000d",
  "fff5f0fee0d2fcbba1fc9272fb6a4aef3b2ccb181d99000d",
  "fff5f0fee0d2fcbba1fc9272fb6a4aef3b2ccb181da50f1567000d"
).map(colors);

var Reds = ramp(scheme$p);

var scheme$q = new Array(3).concat(
  "fee6cefdae6be6550d",
  "feeddefdbe85fd8d3cd94701",
  "feeddefdbe85fd8d3ce6550da63603",
  "feeddefdd0a2fdae6bfd8d3ce6550da63603",
  "feeddefdd0a2fdae6bfd8d3cf16913d948018c2d04",
  "fff5ebfee6cefdd0a2fdae6bfd8d3cf16913d948018c2d04",
  "fff5ebfee6cefdd0a2fdae6bfd8d3cf16913d94801a636037f2704"
).map(colors);

var Oranges = ramp(scheme$q);

function cividis(t) {
  t = Math.max(0, Math.min(1, t));
  return "rgb("
      + Math.max(0, Math.min(255, Math.round(-4.54 - t * (35.34 - t * (2381.73 - t * (6402.7 - t * (7024.72 - t * 2710.57))))))) + ", "
      + Math.max(0, Math.min(255, Math.round(32.49 + t * (170.73 + t * (52.82 - t * (131.46 - t * (176.58 - t * 67.37))))))) + ", "
      + Math.max(0, Math.min(255, Math.round(81.24 + t * (442.36 - t * (2482.43 - t * (6167.24 - t * (6614.94 - t * 2475.67)))))))
      + ")";
}

var cubehelix = d3Interpolate.interpolateCubehelixLong(d3Color.cubehelix(300, 0.5, 0.0), d3Color.cubehelix(-240, 0.5, 1.0));

var warm = d3Interpolate.interpolateCubehelixLong(d3Color.cubehelix(-100, 0.75, 0.35), d3Color.cubehelix(80, 1.50, 0.8));

var cool = d3Interpolate.interpolateCubehelixLong(d3Color.cubehelix(260, 0.75, 0.35), d3Color.cubehelix(80, 1.50, 0.8));

var c = d3Color.cubehelix();

function rainbow(t) {
  if (t < 0 || t > 1) t -= Math.floor(t);
  var ts = Math.abs(t - 0.5);
  c.h = 360 * t - 100;
  c.s = 1.5 - 1.5 * ts;
  c.l = 0.8 - 0.9 * ts;
  return c + "";
}

var c$1 = d3Color.rgb(),
    pi_1_3 = Math.PI / 3,
    pi_2_3 = Math.PI * 2 / 3;

function sinebow(t) {
  var x;
  t = (0.5 - t) * Math.PI;
  c$1.r = 255 * (x = Math.sin(t)) * x;
  c$1.g = 255 * (x = Math.sin(t + pi_1_3)) * x;
  c$1.b = 255 * (x = Math.sin(t + pi_2_3)) * x;
  return c$1 + "";
}

function turbo(t) {
  t = Math.max(0, Math.min(1, t));
  return "rgb("
      + Math.max(0, Math.min(255, Math.round(34.61 + t * (1172.33 - t * (10793.56 - t * (33300.12 - t * (38394.49 - t * 14825.05))))))) + ", "
      + Math.max(0, Math.min(255, Math.round(23.31 + t * (557.33 + t * (1225.33 - t * (3574.96 - t * (1073.77 + t * 707.56))))))) + ", "
      + Math.max(0, Math.min(255, Math.round(27.2 + t * (3211.1 - t * (15327.97 - t * (27814 - t * (22569.18 - t * 6838.66)))))))
      + ")";
}

function ramp$1(range) {
  var n = range.length;
  return function(t) {
    return range[Math.max(0, Math.min(n - 1, Math.floor(t * n)))];
  };
}

var viridis = ramp$1(colors("44015444025645045745055946075a46085c460a5d460b5e470d60470e6147106347116447136548146748166848176948186a481a6c481b6d481c6e481d6f481f70482071482173482374482475482576482677482878482979472a7a472c7a472d7b472e7c472f7d46307e46327e46337f463480453581453781453882443983443a83443b84433d84433e85423f854240864241864142874144874045884046883f47883f48893e49893e4a893e4c8a3d4d8a3d4e8a3c4f8a3c508b3b518b3b528b3a538b3a548c39558c39568c38588c38598c375a8c375b8d365c8d365d8d355e8d355f8d34608d34618d33628d33638d32648e32658e31668e31678e31688e30698e306a8e2f6b8e2f6c8e2e6d8e2e6e8e2e6f8e2d708e2d718e2c718e2c728e2c738e2b748e2b758e2a768e2a778e2a788e29798e297a8e297b8e287c8e287d8e277e8e277f8e27808e26818e26828e26828e25838e25848e25858e24868e24878e23888e23898e238a8d228b8d228c8d228d8d218e8d218f8d21908d21918c20928c20928c20938c1f948c1f958b1f968b1f978b1f988b1f998a1f9a8a1e9b8a1e9c891e9d891f9e891f9f881fa0881fa1881fa1871fa28720a38620a48621a58521a68522a78522a88423a98324aa8325ab8225ac8226ad8127ad8128ae8029af7f2ab07f2cb17e2db27d2eb37c2fb47c31b57b32b67a34b67935b77937b87838b9773aba763bbb753dbc743fbc7340bd7242be7144bf7046c06f48c16e4ac16d4cc26c4ec36b50c46a52c56954c56856c66758c7655ac8645cc8635ec96260ca6063cb5f65cb5e67cc5c69cd5b6ccd5a6ece5870cf5773d05675d05477d1537ad1517cd2507fd34e81d34d84d44b86d54989d5488bd6468ed64590d74393d74195d84098d83e9bd93c9dd93ba0da39a2da37a5db36a8db34aadc32addc30b0dd2fb2dd2db5de2bb8de29bade28bddf26c0df25c2df23c5e021c8e020cae11fcde11dd0e11cd2e21bd5e21ad8e219dae319dde318dfe318e2e418e5e419e7e419eae51aece51befe51cf1e51df4e61ef6e620f8e621fbe723fde725"));

var magma = ramp$1(colors("00000401000501010601010802010902020b02020d03030f03031204041405041606051806051a07061c08071e0907200a08220b09240c09260d0a290e0b2b100b2d110c2f120d31130d34140e36150e38160f3b180f3d19103f1a10421c10441d11471e114920114b21114e22115024125325125527125829115a2a115c2c115f2d11612f116331116533106734106936106b38106c390f6e3b0f703d0f713f0f72400f74420f75440f764510774710784910784a10794c117a4e117b4f127b51127c52137c54137d56147d57157e59157e5a167e5c167f5d177f5f187f601880621980641a80651a80671b80681c816a1c816b1d816d1d816e1e81701f81721f817320817521817621817822817922827b23827c23827e24828025828125818326818426818627818827818928818b29818c29818e2a81902a81912b81932b80942c80962c80982d80992d809b2e7f9c2e7f9e2f7fa02f7fa1307ea3307ea5317ea6317da8327daa337dab337cad347cae347bb0357bb2357bb3367ab5367ab73779b83779ba3878bc3978bd3977bf3a77c03a76c23b75c43c75c53c74c73d73c83e73ca3e72cc3f71cd4071cf4070d0416fd2426fd3436ed5446dd6456cd8456cd9466bdb476adc4869de4968df4a68e04c67e24d66e34e65e44f64e55064e75263e85362e95462ea5661eb5760ec5860ed5a5fee5b5eef5d5ef05f5ef1605df2625df2645cf3655cf4675cf4695cf56b5cf66c5cf66e5cf7705cf7725cf8745cf8765cf9785df9795df97b5dfa7d5efa7f5efa815ffb835ffb8560fb8761fc8961fc8a62fc8c63fc8e64fc9065fd9266fd9467fd9668fd9869fd9a6afd9b6bfe9d6cfe9f6dfea16efea36ffea571fea772fea973feaa74feac76feae77feb078feb27afeb47bfeb67cfeb77efeb97ffebb81febd82febf84fec185fec287fec488fec68afec88cfeca8dfecc8ffecd90fecf92fed194fed395fed597fed799fed89afdda9cfddc9efddea0fde0a1fde2a3fde3a5fde5a7fde7a9fde9aafdebacfcecaefceeb0fcf0b2fcf2b4fcf4b6fcf6b8fcf7b9fcf9bbfcfbbdfcfdbf"));

var inferno = ramp$1(colors("00000401000501010601010802010a02020c02020e03021004031204031405041706041907051b08051d09061f0a07220b07240c08260d08290e092b10092d110a30120a32140b34150b37160b39180c3c190c3e1b0c411c0c431e0c451f0c48210c4a230c4c240c4f260c51280b53290b552b0b572d0b592f0a5b310a5c320a5e340a5f3609613809623909633b09643d09653e0966400a67420a68440a68450a69470b6a490b6a4a0c6b4c0c6b4d0d6c4f0d6c510e6c520e6d540f6d550f6d57106e59106e5a116e5c126e5d126e5f136e61136e62146e64156e65156e67166e69166e6a176e6c186e6d186e6f196e71196e721a6e741a6e751b6e771c6d781c6d7a1d6d7c1d6d7d1e6d7f1e6c801f6c82206c84206b85216b87216b88226a8a226a8c23698d23698f24699025689225689326679526679727669827669a28659b29649d29649f2a63a02a63a22b62a32c61a52c60a62d60a82e5fa92e5eab2f5ead305dae305cb0315bb1325ab3325ab43359b63458b73557b93556ba3655bc3754bd3853bf3952c03a51c13a50c33b4fc43c4ec63d4dc73e4cc83f4bca404acb4149cc4248ce4347cf4446d04545d24644d34743d44842d54a41d74b3fd84c3ed94d3dda4e3cdb503bdd513ade5238df5337e05536e15635e25734e35933e45a31e55c30e65d2fe75e2ee8602de9612bea632aeb6429eb6628ec6726ed6925ee6a24ef6c23ef6e21f06f20f1711ff1731df2741cf3761bf37819f47918f57b17f57d15f67e14f68013f78212f78410f8850ff8870ef8890cf98b0bf98c0af98e09fa9008fa9207fa9407fb9606fb9706fb9906fb9b06fb9d07fc9f07fca108fca309fca50afca60cfca80dfcaa0ffcac11fcae12fcb014fcb216fcb418fbb61afbb81dfbba1ffbbc21fbbe23fac026fac228fac42afac62df9c72ff9c932f9cb35f8cd37f8cf3af7d13df7d340f6d543f6d746f5d949f5db4cf4dd4ff4df53f4e156f3e35af3e55df2e661f2e865f2ea69f1ec6df1ed71f1ef75f1f179f2f27df2f482f3f586f3f68af4f88ef5f992f6fa96f8fb9af9fc9dfafda1fcffa4"));

var plasma = ramp$1(colors("0d088710078813078916078a19068c1b068d1d068e20068f2206902406912605912805922a05932c05942e05952f059631059733059735049837049938049a3a049a3c049b3e049c3f049c41049d43039e44039e46039f48039f4903a04b03a14c02a14e02a25002a25102a35302a35502a45601a45801a45901a55b01a55c01a65e01a66001a66100a76300a76400a76600a76700a86900a86a00a86c00a86e00a86f00a87100a87201a87401a87501a87701a87801a87a02a87b02a87d03a87e03a88004a88104a78305a78405a78606a68707a68808a68a09a58b0aa58d0ba58e0ca48f0da4910ea3920fa39410a29511a19613a19814a099159f9a169f9c179e9d189d9e199da01a9ca11b9ba21d9aa31e9aa51f99a62098a72197a82296aa2395ab2494ac2694ad2793ae2892b02991b12a90b22b8fb32c8eb42e8db52f8cb6308bb7318ab83289ba3388bb3488bc3587bd3786be3885bf3984c03a83c13b82c23c81c33d80c43e7fc5407ec6417dc7427cc8437bc9447aca457acb4679cc4778cc4977cd4a76ce4b75cf4c74d04d73d14e72d24f71d35171d45270d5536fd5546ed6556dd7566cd8576bd9586ada5a6ada5b69db5c68dc5d67dd5e66de5f65de6164df6263e06363e16462e26561e26660e3685fe4695ee56a5de56b5de66c5ce76e5be76f5ae87059e97158e97257ea7457eb7556eb7655ec7754ed7953ed7a52ee7b51ef7c51ef7e50f07f4ff0804ef1814df1834cf2844bf3854bf3874af48849f48948f58b47f58c46f68d45f68f44f79044f79143f79342f89441f89540f9973ff9983ef99a3efa9b3dfa9c3cfa9e3bfb9f3afba139fba238fca338fca537fca636fca835fca934fdab33fdac33fdae32fdaf31fdb130fdb22ffdb42ffdb52efeb72dfeb82cfeba2cfebb2bfebd2afebe2afec029fdc229fdc328fdc527fdc627fdc827fdca26fdcb26fccd25fcce25fcd025fcd225fbd324fbd524fbd724fad824fada24f9dc24f9dd25f8df25f8e125f7e225f7e425f6e626f6e826f5e926f5eb27f4ed27f3ee27f3f027f2f227f1f426f1f525f0f724f0f921"));

exports.interpolateBlues = Blues;
exports.interpolateBrBG = BrBG;
exports.interpolateBuGn = BuGn;
exports.interpolateBuPu = BuPu;
exports.interpolateCividis = cividis;
exports.interpolateCool = cool;
exports.interpolateCubehelixDefault = cubehelix;
exports.interpolateGnBu = GnBu;
exports.interpolateGreens = Greens;
exports.interpolateGreys = Greys;
exports.interpolateInferno = inferno;
exports.interpolateMagma = magma;
exports.interpolateOrRd = OrRd;
exports.interpolateOranges = Oranges;
exports.interpolatePRGn = PRGn;
exports.interpolatePiYG = PiYG;
exports.interpolatePlasma = plasma;
exports.interpolatePuBu = PuBu;
exports.interpolatePuBuGn = PuBuGn;
exports.interpolatePuOr = PuOr;
exports.interpolatePuRd = PuRd;
exports.interpolatePurples = Purples;
exports.interpolateRainbow = rainbow;
exports.interpolateRdBu = RdBu;
exports.interpolateRdGy = RdGy;
exports.interpolateRdPu = RdPu;
exports.interpolateRdYlBu = RdYlBu;
exports.interpolateRdYlGn = RdYlGn;
exports.interpolateReds = Reds;
exports.interpolateSinebow = sinebow;
exports.interpolateSpectral = Spectral;
exports.interpolateTurbo = turbo;
exports.interpolateViridis = viridis;
exports.interpolateWarm = warm;
exports.interpolateYlGn = YlGn;
exports.interpolateYlGnBu = YlGnBu;
exports.interpolateYlOrBr = YlOrBr;
exports.interpolateYlOrRd = YlOrRd;
exports.schemeAccent = Accent;
exports.schemeBlues = scheme$l;
exports.schemeBrBG = scheme;
exports.schemeBuGn = scheme$9;
exports.schemeBuPu = scheme$a;
exports.schemeCategory10 = category10;
exports.schemeDark2 = Dark2;
exports.schemeGnBu = scheme$b;
exports.schemeGreens = scheme$m;
exports.schemeGreys = scheme$n;
exports.schemeOrRd = scheme$c;
exports.schemeOranges = scheme$q;
exports.schemePRGn = scheme$1;
exports.schemePaired = Paired;
exports.schemePastel1 = Pastel1;
exports.schemePastel2 = Pastel2;
exports.schemePiYG = scheme$2;
exports.schemePuBu = scheme$e;
exports.schemePuBuGn = scheme$d;
exports.schemePuOr = scheme$3;
exports.schemePuRd = scheme$f;
exports.schemePurples = scheme$o;
exports.schemeRdBu = scheme$4;
exports.schemeRdGy = scheme$5;
exports.schemeRdPu = scheme$g;
exports.schemeRdYlBu = scheme$6;
exports.schemeRdYlGn = scheme$7;
exports.schemeReds = scheme$p;
exports.schemeSet1 = Set1;
exports.schemeSet2 = Set2;
exports.schemeSet3 = Set3;
exports.schemeSpectral = scheme$8;
exports.schemeTableau10 = Tableau10;
exports.schemeYlGn = scheme$i;
exports.schemeYlGnBu = scheme$h;
exports.schemeYlOrBr = scheme$j;
exports.schemeYlOrRd = scheme$k;

Object.defineProperty(exports, '__esModule', { value: true });

}));

},{"d3-color":11,"d3-interpolate":12}],14:[function(require,module,exports){
(function (global, factory) {
typeof exports === 'object' && typeof module !== 'undefined' ? module.exports = factory() :
typeof define === 'function' && define.amd ? define(factory) :
(global = global || self, global.Flatbush = factory());
}(this, (function () { 'use strict';

var FlatQueue = function FlatQueue() {
    this.ids = [];
    this.values = [];
    this.length = 0;
};

FlatQueue.prototype.clear = function clear () {
    this.length = 0;
};

FlatQueue.prototype.push = function push (id, value) {
    var pos = this.length++;
    this.ids[pos] = id;
    this.values[pos] = value;

    while (pos > 0) {
        var parent = (pos - 1) >> 1;
        var parentValue = this.values[parent];
        if (value >= parentValue) { break; }
        this.ids[pos] = this.ids[parent];
        this.values[pos] = parentValue;
        pos = parent;
    }

    this.ids[pos] = id;
    this.values[pos] = value;
};

FlatQueue.prototype.pop = function pop () {
    if (this.length === 0) { return undefined; }

    var top = this.ids[0];
    this.length--;

    if (this.length > 0) {
        var id = this.ids[0] = this.ids[this.length];
        var value = this.values[0] = this.values[this.length];
        var halfLength = this.length >> 1;
        var pos = 0;

        while (pos < halfLength) {
            var left = (pos << 1) + 1;
            var right = left + 1;
            var bestIndex = this.ids[left];
            var bestValue = this.values[left];
            var rightValue = this.values[right];

            if (right < this.length && rightValue < bestValue) {
                left = right;
                bestIndex = this.ids[right];
                bestValue = rightValue;
            }
            if (bestValue >= value) { break; }

            this.ids[pos] = bestIndex;
            this.values[pos] = bestValue;
            pos = left;
        }

        this.ids[pos] = id;
        this.values[pos] = value;
    }

    return top;
};

FlatQueue.prototype.peek = function peek () {
    return this.ids[0];
};

FlatQueue.prototype.peekValue = function peekValue () {
    return this.values[0];
};

var ARRAY_TYPES = [
    Int8Array, Uint8Array, Uint8ClampedArray, Int16Array, Uint16Array,
    Int32Array, Uint32Array, Float32Array, Float64Array
];

var VERSION = 3; // serialized format version

var Flatbush = function Flatbush(numItems, nodeSize, ArrayType, data) {
    if ( nodeSize === void 0 ) nodeSize = 16;
    if ( ArrayType === void 0 ) ArrayType = Float64Array;

    if (numItems === undefined) { throw new Error('Missing required argument: numItems.'); }
    if (isNaN(numItems) || numItems <= 0) { throw new Error(("Unpexpected numItems value: " + numItems + ".")); }

    this.numItems = +numItems;
    this.nodeSize = Math.min(Math.max(+nodeSize, 2), 65535);

    // calculate the total number of nodes in the R-tree to allocate space for
    // and the index of each tree level (used in search later)
    var n = numItems;
    var numNodes = n;
    this._levelBounds = [n * 4];
    do {
        n = Math.ceil(n / this.nodeSize);
        numNodes += n;
        this._levelBounds.push(numNodes * 4);
    } while (n !== 1);

    this.ArrayType = ArrayType || Float64Array;
    this.IndexArrayType = numNodes < 16384 ? Uint16Array : Uint32Array;

    var arrayTypeIndex = ARRAY_TYPES.indexOf(this.ArrayType);
    var nodesByteSize = numNodes * 4 * this.ArrayType.BYTES_PER_ELEMENT;

    if (arrayTypeIndex < 0) {
        throw new Error(("Unexpected typed array class: " + ArrayType + "."));
    }

    if (data && (data instanceof ArrayBuffer)) {
        this.data = data;
        this._boxes = new this.ArrayType(this.data, 8, numNodes * 4);
        this._indices = new this.IndexArrayType(this.data, 8 + nodesByteSize, numNodes);

        this._pos = numNodes * 4;
        this.minX = this._boxes[this._pos - 4];
        this.minY = this._boxes[this._pos - 3];
        this.maxX = this._boxes[this._pos - 2];
        this.maxY = this._boxes[this._pos - 1];

    } else {
        this.data = new ArrayBuffer(8 + nodesByteSize + numNodes * this.IndexArrayType.BYTES_PER_ELEMENT);
        this._boxes = new this.ArrayType(this.data, 8, numNodes * 4);
        this._indices = new this.IndexArrayType(this.data, 8 + nodesByteSize, numNodes);
        this._pos = 0;
        this.minX = Infinity;
        this.minY = Infinity;
        this.maxX = -Infinity;
        this.maxY = -Infinity;

        new Uint8Array(this.data, 0, 2).set([0xfb, (VERSION << 4) + arrayTypeIndex]);
        new Uint16Array(this.data, 2, 1)[0] = nodeSize;
        new Uint32Array(this.data, 4, 1)[0] = numItems;
    }

    // a priority queue for k-nearest-neighbors queries
    this._queue = new FlatQueue();
};

Flatbush.from = function from (data) {
    if (!(data instanceof ArrayBuffer)) {
        throw new Error('Data must be an instance of ArrayBuffer.');
    }
    var ref = new Uint8Array(data, 0, 2);
        var magic = ref[0];
        var versionAndType = ref[1];
    if (magic !== 0xfb) {
        throw new Error('Data does not appear to be in a Flatbush format.');
    }
    if (versionAndType >> 4 !== VERSION) {
        throw new Error(("Got v" + (versionAndType >> 4) + " data when expected v" + VERSION + "."));
    }
    var ref$1 = new Uint16Array(data, 2, 1);
        var nodeSize = ref$1[0];
    var ref$2 = new Uint32Array(data, 4, 1);
        var numItems = ref$2[0];

    return new Flatbush(numItems, nodeSize, ARRAY_TYPES[versionAndType & 0x0f], data);
};

Flatbush.prototype.add = function add (minX, minY, maxX, maxY) {
    var index = this._pos >> 2;
    this._indices[index] = index;
    this._boxes[this._pos++] = minX;
    this._boxes[this._pos++] = minY;
    this._boxes[this._pos++] = maxX;
    this._boxes[this._pos++] = maxY;

    if (minX < this.minX) { this.minX = minX; }
    if (minY < this.minY) { this.minY = minY; }
    if (maxX > this.maxX) { this.maxX = maxX; }
    if (maxY > this.maxY) { this.maxY = maxY; }

    return index;
};

Flatbush.prototype.finish = function finish () {
    if (this._pos >> 2 !== this.numItems) {
        throw new Error(("Added " + (this._pos >> 2) + " items when expected " + (this.numItems) + "."));
    }

    if (this.numItems <= this.nodeSize) {
        // only one node, skip sorting and just fill the root box
        this._boxes[this._pos++] = this.minX;
        this._boxes[this._pos++] = this.minY;
        this._boxes[this._pos++] = this.maxX;
        this._boxes[this._pos++] = this.maxY;
        return;
    }

    var width = this.maxX - this.minX;
    var height = this.maxY - this.minY;
    var hilbertValues = new Uint32Array(this.numItems);
    var hilbertMax = (1 << 16) - 1;

    // map item centers into Hilbert coordinate space and calculate Hilbert values
    for (var i = 0; i < this.numItems; i++) {
        var pos = 4 * i;
        var minX = this._boxes[pos++];
        var minY = this._boxes[pos++];
        var maxX = this._boxes[pos++];
        var maxY = this._boxes[pos++];
        var x = Math.floor(hilbertMax * ((minX + maxX) / 2 - this.minX) / width);
        var y = Math.floor(hilbertMax * ((minY + maxY) / 2 - this.minY) / height);
        hilbertValues[i] = hilbert(x, y);
    }

    // sort items by their Hilbert value (for packing later)
    sort(hilbertValues, this._boxes, this._indices, 0, this.numItems - 1, this.nodeSize);

    // generate nodes at each tree level, bottom-up
    for (var i$1 = 0, pos$1 = 0; i$1 < this._levelBounds.length - 1; i$1++) {
        var end = this._levelBounds[i$1];

        // generate a parent node for each block of consecutive <nodeSize> nodes
        while (pos$1 < end) {
            var nodeIndex = pos$1;

            // calculate bbox for the new node
            var nodeMinX = Infinity;
            var nodeMinY = Infinity;
            var nodeMaxX = -Infinity;
            var nodeMaxY = -Infinity;
            for (var i$2 = 0; i$2 < this.nodeSize && pos$1 < end; i$2++) {
                nodeMinX = Math.min(nodeMinX, this._boxes[pos$1++]);
                nodeMinY = Math.min(nodeMinY, this._boxes[pos$1++]);
                nodeMaxX = Math.max(nodeMaxX, this._boxes[pos$1++]);
                nodeMaxY = Math.max(nodeMaxY, this._boxes[pos$1++]);
            }

            // add the new node to the tree data
            this._indices[this._pos >> 2] = nodeIndex;
            this._boxes[this._pos++] = nodeMinX;
            this._boxes[this._pos++] = nodeMinY;
            this._boxes[this._pos++] = nodeMaxX;
            this._boxes[this._pos++] = nodeMaxY;
        }
    }
};

Flatbush.prototype.search = function search (minX, minY, maxX, maxY, filterFn) {
    if (this._pos !== this._boxes.length) {
        throw new Error('Data not yet indexed - call index.finish().');
    }

    var nodeIndex = this._boxes.length - 4;
    var queue = [];
    var results = [];

    while (nodeIndex !== undefined) {
        // find the end index of the node
        var end = Math.min(nodeIndex + this.nodeSize * 4, upperBound(nodeIndex, this._levelBounds));

        // search through child nodes
        for (var pos = nodeIndex; pos < end; pos += 4) {
            var index = this._indices[pos >> 2] | 0;

            // check if node bbox intersects with query bbox
            if (maxX < this._boxes[pos]) { continue; } // maxX < nodeMinX
            if (maxY < this._boxes[pos + 1]) { continue; } // maxY < nodeMinY
            if (minX > this._boxes[pos + 2]) { continue; } // minX > nodeMaxX
            if (minY > this._boxes[pos + 3]) { continue; } // minY > nodeMaxY

            if (nodeIndex < this.numItems * 4) {
                if (filterFn === undefined || filterFn(index)) {
                    results.push(index); // leaf item
                }

            } else {
                queue.push(index); // node; add it to the search queue
            }
        }

        nodeIndex = queue.pop();
    }

    return results;
};

Flatbush.prototype.neighbors = function neighbors (x, y, maxResults, maxDistance, filterFn) {
        if ( maxResults === void 0 ) maxResults = Infinity;
        if ( maxDistance === void 0 ) maxDistance = Infinity;

    if (this._pos !== this._boxes.length) {
        throw new Error('Data not yet indexed - call index.finish().');
    }

    var nodeIndex = this._boxes.length - 4;
    var q = this._queue;
    var results = [];
    var maxDistSquared = maxDistance * maxDistance;

    while (nodeIndex !== undefined) {
        // find the end index of the node
        var end = Math.min(nodeIndex + this.nodeSize * 4, upperBound(nodeIndex, this._levelBounds));

        // add child nodes to the queue
        for (var pos = nodeIndex; pos < end; pos += 4) {
            var index = this._indices[pos >> 2] | 0;

            var dx = axisDist(x, this._boxes[pos], this._boxes[pos + 2]);
            var dy = axisDist(y, this._boxes[pos + 1], this._boxes[pos + 3]);
            var dist = dx * dx + dy * dy;

            if (nodeIndex < this.numItems * 4) { // leaf node
                if (filterFn === undefined || filterFn(index)) {
                    // put a negative index if it's an item rather than a node, to recognize later
                    q.push(-index - 1, dist);
                }
            } else {
                q.push(index, dist);
            }
        }

        // pop items from the queue
        while (q.length && q.peek() < 0) {
            var dist$1 = q.peekValue();
            if (dist$1 > maxDistSquared) {
                q.clear();
                return results;
            }
            results.push(-q.pop() - 1);

            if (results.length === maxResults) {
                q.clear();
                return results;
            }
        }

        nodeIndex = q.pop();
    }

    q.clear();
    return results;
};

function axisDist(k, min, max) {
    return k < min ? min - k : k <= max ? 0 : k - max;
}

// binary search for the first value in the array bigger than the given
function upperBound(value, arr) {
    var i = 0;
    var j = arr.length - 1;
    while (i < j) {
        var m = (i + j) >> 1;
        if (arr[m] > value) {
            j = m;
        } else {
            i = m + 1;
        }
    }
    return arr[i];
}

// custom quicksort that partially sorts bbox data alongside the hilbert values
function sort(values, boxes, indices, left, right, nodeSize) {
    if (Math.floor(left / nodeSize) >= Math.floor(right / nodeSize)) { return; }

    var pivot = values[(left + right) >> 1];
    var i = left - 1;
    var j = right + 1;

    while (true) {
        do { i++; } while (values[i] < pivot);
        do { j--; } while (values[j] > pivot);
        if (i >= j) { break; }
        swap(values, boxes, indices, i, j);
    }

    sort(values, boxes, indices, left, j, nodeSize);
    sort(values, boxes, indices, j + 1, right, nodeSize);
}

// swap two values and two corresponding boxes
function swap(values, boxes, indices, i, j) {
    var temp = values[i];
    values[i] = values[j];
    values[j] = temp;

    var k = 4 * i;
    var m = 4 * j;

    var a = boxes[k];
    var b = boxes[k + 1];
    var c = boxes[k + 2];
    var d = boxes[k + 3];
    boxes[k] = boxes[m];
    boxes[k + 1] = boxes[m + 1];
    boxes[k + 2] = boxes[m + 2];
    boxes[k + 3] = boxes[m + 3];
    boxes[m] = a;
    boxes[m + 1] = b;
    boxes[m + 2] = c;
    boxes[m + 3] = d;

    var e = indices[i];
    indices[i] = indices[j];
    indices[j] = e;
}

// Fast Hilbert curve algorithm by http://threadlocalmutex.com/
// Ported from C++ https://github.com/rawrunprotected/hilbert_curves (public domain)
function hilbert(x, y) {
    var a = x ^ y;
    var b = 0xFFFF ^ a;
    var c = 0xFFFF ^ (x | y);
    var d = x & (y ^ 0xFFFF);

    var A = a | (b >> 1);
    var B = (a >> 1) ^ a;
    var C = ((c >> 1) ^ (b & (d >> 1))) ^ c;
    var D = ((a & (c >> 1)) ^ (d >> 1)) ^ d;

    a = A; b = B; c = C; d = D;
    A = ((a & (a >> 2)) ^ (b & (b >> 2)));
    B = ((a & (b >> 2)) ^ (b & ((a ^ b) >> 2)));
    C ^= ((a & (c >> 2)) ^ (b & (d >> 2)));
    D ^= ((b & (c >> 2)) ^ ((a ^ b) & (d >> 2)));

    a = A; b = B; c = C; d = D;
    A = ((a & (a >> 4)) ^ (b & (b >> 4)));
    B = ((a & (b >> 4)) ^ (b & ((a ^ b) >> 4)));
    C ^= ((a & (c >> 4)) ^ (b & (d >> 4)));
    D ^= ((b & (c >> 4)) ^ ((a ^ b) & (d >> 4)));

    a = A; b = B; c = C; d = D;
    C ^= ((a & (c >> 8)) ^ (b & (d >> 8)));
    D ^= ((b & (c >> 8)) ^ ((a ^ b) & (d >> 8)));

    a = C ^ (C >> 1);
    b = D ^ (D >> 1);

    var i0 = x ^ y;
    var i1 = b | (0xFFFF ^ (i0 | a));

    i0 = (i0 | (i0 << 8)) & 0x00FF00FF;
    i0 = (i0 | (i0 << 4)) & 0x0F0F0F0F;
    i0 = (i0 | (i0 << 2)) & 0x33333333;
    i0 = (i0 | (i0 << 1)) & 0x55555555;

    i1 = (i1 | (i1 << 8)) & 0x00FF00FF;
    i1 = (i1 | (i1 << 4)) & 0x0F0F0F0F;
    i1 = (i1 | (i1 << 2)) & 0x33333333;
    i1 = (i1 | (i1 << 1)) & 0x55555555;

    return ((i1 << 1) | i0) >>> 0;
}

return Flatbush;

})));

},{}],15:[function(require,module,exports){
"use strict";
/**
 * A response from a web request
 */
var Response = /** @class */ (function () {
    function Response(statusCode, headers, body, url) {
        if (typeof statusCode !== 'number') {
            throw new TypeError('statusCode must be a number but was ' + typeof statusCode);
        }
        if (headers === null) {
            throw new TypeError('headers cannot be null');
        }
        if (typeof headers !== 'object') {
            throw new TypeError('headers must be an object but was ' + typeof headers);
        }
        this.statusCode = statusCode;
        var headersToLowerCase = {};
        for (var key in headers) {
            headersToLowerCase[key.toLowerCase()] = headers[key];
        }
        this.headers = headersToLowerCase;
        this.body = body;
        this.url = url;
    }
    Response.prototype.isError = function () {
        return this.statusCode === 0 || this.statusCode >= 400;
    };
    Response.prototype.getBody = function (encoding) {
        if (this.statusCode === 0) {
            var err = new Error('This request to ' +
                this.url +
                ' resulted in a status code of 0. This usually indicates some kind of network error in a browser (e.g. CORS not being set up or the DNS failing to resolve):\n' +
                this.body.toString());
            err.statusCode = this.statusCode;
            err.headers = this.headers;
            err.body = this.body;
            err.url = this.url;
            throw err;
        }
        if (this.statusCode >= 300) {
            var err = new Error('Server responded to ' +
                this.url +
                ' with status code ' +
                this.statusCode +
                ':\n' +
                this.body.toString());
            err.statusCode = this.statusCode;
            err.headers = this.headers;
            err.body = this.body;
            err.url = this.url;
            throw err;
        }
        if (!encoding || typeof this.body === 'string') {
            return this.body;
        }
        return this.body.toString(encoding);
    };
    return Response;
}());
module.exports = Response;

},{}],16:[function(require,module,exports){
"use strict";
var Buffer = require("safer-buffer").Buffer;

// Multibyte codec. In this scheme, a character is represented by 1 or more bytes.
// Our codec supports UTF-16 surrogates, extensions for GB18030 and unicode sequences.
// To save memory and loading time, we read table files only when requested.

exports._dbcs = DBCSCodec;

var UNASSIGNED = -1,
    GB18030_CODE = -2,
    SEQ_START  = -10,
    NODE_START = -1000,
    UNASSIGNED_NODE = new Array(0x100),
    DEF_CHAR = -1;

for (var i = 0; i < 0x100; i++)
    UNASSIGNED_NODE[i] = UNASSIGNED;


// Class DBCSCodec reads and initializes mapping tables.
function DBCSCodec(codecOptions, iconv) {
    this.encodingName = codecOptions.encodingName;
    if (!codecOptions)
        throw new Error("DBCS codec is called without the data.")
    if (!codecOptions.table)
        throw new Error("Encoding '" + this.encodingName + "' has no data.");

    // Load tables.
    var mappingTable = codecOptions.table();


    // Decode tables: MBCS -> Unicode.

    // decodeTables is a trie, encoded as an array of arrays of integers. Internal arrays are trie nodes and all have len = 256.
    // Trie root is decodeTables[0].
    // Values: >=  0 -> unicode character code. can be > 0xFFFF
    //         == UNASSIGNED -> unknown/unassigned sequence.
    //         == GB18030_CODE -> this is the end of a GB18030 4-byte sequence.
    //         <= NODE_START -> index of the next node in our trie to process next byte.
    //         <= SEQ_START  -> index of the start of a character code sequence, in decodeTableSeq.
    this.decodeTables = [];
    this.decodeTables[0] = UNASSIGNED_NODE.slice(0); // Create root node.

    // Sometimes a MBCS char corresponds to a sequence of unicode chars. We store them as arrays of integers here. 
    this.decodeTableSeq = [];

    // Actual mapping tables consist of chunks. Use them to fill up decode tables.
    for (var i = 0; i < mappingTable.length; i++)
        this._addDecodeChunk(mappingTable[i]);

    this.defaultCharUnicode = iconv.defaultCharUnicode;

    
    // Encode tables: Unicode -> DBCS.

    // `encodeTable` is array mapping from unicode char to encoded char. All its values are integers for performance.
    // Because it can be sparse, it is represented as array of buckets by 256 chars each. Bucket can be null.
    // Values: >=  0 -> it is a normal char. Write the value (if <=256 then 1 byte, if <=65536 then 2 bytes, etc.).
    //         == UNASSIGNED -> no conversion found. Output a default char.
    //         <= SEQ_START  -> it's an index in encodeTableSeq, see below. The character starts a sequence.
    this.encodeTable = [];
    
    // `encodeTableSeq` is used when a sequence of unicode characters is encoded as a single code. We use a tree of
    // objects where keys correspond to characters in sequence and leafs are the encoded dbcs values. A special DEF_CHAR key
    // means end of sequence (needed when one sequence is a strict subsequence of another).
    // Objects are kept separately from encodeTable to increase performance.
    this.encodeTableSeq = [];

    // Some chars can be decoded, but need not be encoded.
    var skipEncodeChars = {};
    if (codecOptions.encodeSkipVals)
        for (var i = 0; i < codecOptions.encodeSkipVals.length; i++) {
            var val = codecOptions.encodeSkipVals[i];
            if (typeof val === 'number')
                skipEncodeChars[val] = true;
            else
                for (var j = val.from; j <= val.to; j++)
                    skipEncodeChars[j] = true;
        }
        
    // Use decode trie to recursively fill out encode tables.
    this._fillEncodeTable(0, 0, skipEncodeChars);

    // Add more encoding pairs when needed.
    if (codecOptions.encodeAdd) {
        for (var uChar in codecOptions.encodeAdd)
            if (Object.prototype.hasOwnProperty.call(codecOptions.encodeAdd, uChar))
                this._setEncodeChar(uChar.charCodeAt(0), codecOptions.encodeAdd[uChar]);
    }

    this.defCharSB  = this.encodeTable[0][iconv.defaultCharSingleByte.charCodeAt(0)];
    if (this.defCharSB === UNASSIGNED) this.defCharSB = this.encodeTable[0]['?'];
    if (this.defCharSB === UNASSIGNED) this.defCharSB = "?".charCodeAt(0);


    // Load & create GB18030 tables when needed.
    if (typeof codecOptions.gb18030 === 'function') {
        this.gb18030 = codecOptions.gb18030(); // Load GB18030 ranges.

        // Add GB18030 decode tables.
        var thirdByteNodeIdx = this.decodeTables.length;
        var thirdByteNode = this.decodeTables[thirdByteNodeIdx] = UNASSIGNED_NODE.slice(0);

        var fourthByteNodeIdx = this.decodeTables.length;
        var fourthByteNode = this.decodeTables[fourthByteNodeIdx] = UNASSIGNED_NODE.slice(0);

        for (var i = 0x81; i <= 0xFE; i++) {
            var secondByteNodeIdx = NODE_START - this.decodeTables[0][i];
            var secondByteNode = this.decodeTables[secondByteNodeIdx];
            for (var j = 0x30; j <= 0x39; j++)
                secondByteNode[j] = NODE_START - thirdByteNodeIdx;
        }
        for (var i = 0x81; i <= 0xFE; i++)
            thirdByteNode[i] = NODE_START - fourthByteNodeIdx;
        for (var i = 0x30; i <= 0x39; i++)
            fourthByteNode[i] = GB18030_CODE
    }        
}

DBCSCodec.prototype.encoder = DBCSEncoder;
DBCSCodec.prototype.decoder = DBCSDecoder;

// Decoder helpers
DBCSCodec.prototype._getDecodeTrieNode = function(addr) {
    var bytes = [];
    for (; addr > 0; addr >>= 8)
        bytes.push(addr & 0xFF);
    if (bytes.length == 0)
        bytes.push(0);

    var node = this.decodeTables[0];
    for (var i = bytes.length-1; i > 0; i--) { // Traverse nodes deeper into the trie.
        var val = node[bytes[i]];

        if (val == UNASSIGNED) { // Create new node.
            node[bytes[i]] = NODE_START - this.decodeTables.length;
            this.decodeTables.push(node = UNASSIGNED_NODE.slice(0));
        }
        else if (val <= NODE_START) { // Existing node.
            node = this.decodeTables[NODE_START - val];
        }
        else
            throw new Error("Overwrite byte in " + this.encodingName + ", addr: " + addr.toString(16));
    }
    return node;
}


DBCSCodec.prototype._addDecodeChunk = function(chunk) {
    // First element of chunk is the hex mbcs code where we start.
    var curAddr = parseInt(chunk[0], 16);

    // Choose the decoding node where we'll write our chars.
    var writeTable = this._getDecodeTrieNode(curAddr);
    curAddr = curAddr & 0xFF;

    // Write all other elements of the chunk to the table.
    for (var k = 1; k < chunk.length; k++) {
        var part = chunk[k];
        if (typeof part === "string") { // String, write as-is.
            for (var l = 0; l < part.length;) {
                var code = part.charCodeAt(l++);
                if (0xD800 <= code && code < 0xDC00) { // Decode surrogate
                    var codeTrail = part.charCodeAt(l++);
                    if (0xDC00 <= codeTrail && codeTrail < 0xE000)
                        writeTable[curAddr++] = 0x10000 + (code - 0xD800) * 0x400 + (codeTrail - 0xDC00);
                    else
                        throw new Error("Incorrect surrogate pair in "  + this.encodingName + " at chunk " + chunk[0]);
                }
                else if (0x0FF0 < code && code <= 0x0FFF) { // Character sequence (our own encoding used)
                    var len = 0xFFF - code + 2;
                    var seq = [];
                    for (var m = 0; m < len; m++)
                        seq.push(part.charCodeAt(l++)); // Simple variation: don't support surrogates or subsequences in seq.

                    writeTable[curAddr++] = SEQ_START - this.decodeTableSeq.length;
                    this.decodeTableSeq.push(seq);
                }
                else
                    writeTable[curAddr++] = code; // Basic char
            }
        } 
        else if (typeof part === "number") { // Integer, meaning increasing sequence starting with prev character.
            var charCode = writeTable[curAddr - 1] + 1;
            for (var l = 0; l < part; l++)
                writeTable[curAddr++] = charCode++;
        }
        else
            throw new Error("Incorrect type '" + typeof part + "' given in "  + this.encodingName + " at chunk " + chunk[0]);
    }
    if (curAddr > 0xFF)
        throw new Error("Incorrect chunk in "  + this.encodingName + " at addr " + chunk[0] + ": too long" + curAddr);
}

// Encoder helpers
DBCSCodec.prototype._getEncodeBucket = function(uCode) {
    var high = uCode >> 8; // This could be > 0xFF because of astral characters.
    if (this.encodeTable[high] === undefined)
        this.encodeTable[high] = UNASSIGNED_NODE.slice(0); // Create bucket on demand.
    return this.encodeTable[high];
}

DBCSCodec.prototype._setEncodeChar = function(uCode, dbcsCode) {
    var bucket = this._getEncodeBucket(uCode);
    var low = uCode & 0xFF;
    if (bucket[low] <= SEQ_START)
        this.encodeTableSeq[SEQ_START-bucket[low]][DEF_CHAR] = dbcsCode; // There's already a sequence, set a single-char subsequence of it.
    else if (bucket[low] == UNASSIGNED)
        bucket[low] = dbcsCode;
}

DBCSCodec.prototype._setEncodeSequence = function(seq, dbcsCode) {
    
    // Get the root of character tree according to first character of the sequence.
    var uCode = seq[0];
    var bucket = this._getEncodeBucket(uCode);
    var low = uCode & 0xFF;

    var node;
    if (bucket[low] <= SEQ_START) {
        // There's already a sequence with  - use it.
        node = this.encodeTableSeq[SEQ_START-bucket[low]];
    }
    else {
        // There was no sequence object - allocate a new one.
        node = {};
        if (bucket[low] !== UNASSIGNED) node[DEF_CHAR] = bucket[low]; // If a char was set before - make it a single-char subsequence.
        bucket[low] = SEQ_START - this.encodeTableSeq.length;
        this.encodeTableSeq.push(node);
    }

    // Traverse the character tree, allocating new nodes as needed.
    for (var j = 1; j < seq.length-1; j++) {
        var oldVal = node[uCode];
        if (typeof oldVal === 'object')
            node = oldVal;
        else {
            node = node[uCode] = {}
            if (oldVal !== undefined)
                node[DEF_CHAR] = oldVal
        }
    }

    // Set the leaf to given dbcsCode.
    uCode = seq[seq.length-1];
    node[uCode] = dbcsCode;
}

DBCSCodec.prototype._fillEncodeTable = function(nodeIdx, prefix, skipEncodeChars) {
    var node = this.decodeTables[nodeIdx];
    for (var i = 0; i < 0x100; i++) {
        var uCode = node[i];
        var mbCode = prefix + i;
        if (skipEncodeChars[mbCode])
            continue;

        if (uCode >= 0)
            this._setEncodeChar(uCode, mbCode);
        else if (uCode <= NODE_START)
            this._fillEncodeTable(NODE_START - uCode, mbCode << 8, skipEncodeChars);
        else if (uCode <= SEQ_START)
            this._setEncodeSequence(this.decodeTableSeq[SEQ_START - uCode], mbCode);
    }
}



// == Encoder ==================================================================

function DBCSEncoder(options, codec) {
    // Encoder state
    this.leadSurrogate = -1;
    this.seqObj = undefined;
    
    // Static data
    this.encodeTable = codec.encodeTable;
    this.encodeTableSeq = codec.encodeTableSeq;
    this.defaultCharSingleByte = codec.defCharSB;
    this.gb18030 = codec.gb18030;
}

DBCSEncoder.prototype.write = function(str) {
    var newBuf = Buffer.alloc(str.length * (this.gb18030 ? 4 : 3)),
        leadSurrogate = this.leadSurrogate,
        seqObj = this.seqObj, nextChar = -1,
        i = 0, j = 0;

    while (true) {
        // 0. Get next character.
        if (nextChar === -1) {
            if (i == str.length) break;
            var uCode = str.charCodeAt(i++);
        }
        else {
            var uCode = nextChar;
            nextChar = -1;    
        }

        // 1. Handle surrogates.
        if (0xD800 <= uCode && uCode < 0xE000) { // Char is one of surrogates.
            if (uCode < 0xDC00) { // We've got lead surrogate.
                if (leadSurrogate === -1) {
                    leadSurrogate = uCode;
                    continue;
                } else {
                    leadSurrogate = uCode;
                    // Double lead surrogate found.
                    uCode = UNASSIGNED;
                }
            } else { // We've got trail surrogate.
                if (leadSurrogate !== -1) {
                    uCode = 0x10000 + (leadSurrogate - 0xD800) * 0x400 + (uCode - 0xDC00);
                    leadSurrogate = -1;
                } else {
                    // Incomplete surrogate pair - only trail surrogate found.
                    uCode = UNASSIGNED;
                }
                
            }
        }
        else if (leadSurrogate !== -1) {
            // Incomplete surrogate pair - only lead surrogate found.
            nextChar = uCode; uCode = UNASSIGNED; // Write an error, then current char.
            leadSurrogate = -1;
        }

        // 2. Convert uCode character.
        var dbcsCode = UNASSIGNED;
        if (seqObj !== undefined && uCode != UNASSIGNED) { // We are in the middle of the sequence
            var resCode = seqObj[uCode];
            if (typeof resCode === 'object') { // Sequence continues.
                seqObj = resCode;
                continue;

            } else if (typeof resCode == 'number') { // Sequence finished. Write it.
                dbcsCode = resCode;

            } else if (resCode == undefined) { // Current character is not part of the sequence.

                // Try default character for this sequence
                resCode = seqObj[DEF_CHAR];
                if (resCode !== undefined) {
                    dbcsCode = resCode; // Found. Write it.
                    nextChar = uCode; // Current character will be written too in the next iteration.

                } else {
                    // TODO: What if we have no default? (resCode == undefined)
                    // Then, we should write first char of the sequence as-is and try the rest recursively.
                    // Didn't do it for now because no encoding has this situation yet.
                    // Currently, just skip the sequence and write current char.
                }
            }
            seqObj = undefined;
        }
        else if (uCode >= 0) {  // Regular character
            var subtable = this.encodeTable[uCode >> 8];
            if (subtable !== undefined)
                dbcsCode = subtable[uCode & 0xFF];
            
            if (dbcsCode <= SEQ_START) { // Sequence start
                seqObj = this.encodeTableSeq[SEQ_START-dbcsCode];
                continue;
            }

            if (dbcsCode == UNASSIGNED && this.gb18030) {
                // Use GB18030 algorithm to find character(s) to write.
                var idx = findIdx(this.gb18030.uChars, uCode);
                if (idx != -1) {
                    var dbcsCode = this.gb18030.gbChars[idx] + (uCode - this.gb18030.uChars[idx]);
                    newBuf[j++] = 0x81 + Math.floor(dbcsCode / 12600); dbcsCode = dbcsCode % 12600;
                    newBuf[j++] = 0x30 + Math.floor(dbcsCode / 1260); dbcsCode = dbcsCode % 1260;
                    newBuf[j++] = 0x81 + Math.floor(dbcsCode / 10); dbcsCode = dbcsCode % 10;
                    newBuf[j++] = 0x30 + dbcsCode;
                    continue;
                }
            }
        }

        // 3. Write dbcsCode character.
        if (dbcsCode === UNASSIGNED)
            dbcsCode = this.defaultCharSingleByte;
        
        if (dbcsCode < 0x100) {
            newBuf[j++] = dbcsCode;
        }
        else if (dbcsCode < 0x10000) {
            newBuf[j++] = dbcsCode >> 8;   // high byte
            newBuf[j++] = dbcsCode & 0xFF; // low byte
        }
        else {
            newBuf[j++] = dbcsCode >> 16;
            newBuf[j++] = (dbcsCode >> 8) & 0xFF;
            newBuf[j++] = dbcsCode & 0xFF;
        }
    }

    this.seqObj = seqObj;
    this.leadSurrogate = leadSurrogate;
    return newBuf.slice(0, j);
}

DBCSEncoder.prototype.end = function() {
    if (this.leadSurrogate === -1 && this.seqObj === undefined)
        return; // All clean. Most often case.

    var newBuf = Buffer.alloc(10), j = 0;

    if (this.seqObj) { // We're in the sequence.
        var dbcsCode = this.seqObj[DEF_CHAR];
        if (dbcsCode !== undefined) { // Write beginning of the sequence.
            if (dbcsCode < 0x100) {
                newBuf[j++] = dbcsCode;
            }
            else {
                newBuf[j++] = dbcsCode >> 8;   // high byte
                newBuf[j++] = dbcsCode & 0xFF; // low byte
            }
        } else {
            // See todo above.
        }
        this.seqObj = undefined;
    }

    if (this.leadSurrogate !== -1) {
        // Incomplete surrogate pair - only lead surrogate found.
        newBuf[j++] = this.defaultCharSingleByte;
        this.leadSurrogate = -1;
    }
    
    return newBuf.slice(0, j);
}

// Export for testing
DBCSEncoder.prototype.findIdx = findIdx;


// == Decoder ==================================================================

function DBCSDecoder(options, codec) {
    // Decoder state
    this.nodeIdx = 0;
    this.prevBuf = Buffer.alloc(0);

    // Static data
    this.decodeTables = codec.decodeTables;
    this.decodeTableSeq = codec.decodeTableSeq;
    this.defaultCharUnicode = codec.defaultCharUnicode;
    this.gb18030 = codec.gb18030;
}

DBCSDecoder.prototype.write = function(buf) {
    var newBuf = Buffer.alloc(buf.length*2),
        nodeIdx = this.nodeIdx, 
        prevBuf = this.prevBuf, prevBufOffset = this.prevBuf.length,
        seqStart = -this.prevBuf.length, // idx of the start of current parsed sequence.
        uCode;

    if (prevBufOffset > 0) // Make prev buf overlap a little to make it easier to slice later.
        prevBuf = Buffer.concat([prevBuf, buf.slice(0, 10)]);
    
    for (var i = 0, j = 0; i < buf.length; i++) {
        var curByte = (i >= 0) ? buf[i] : prevBuf[i + prevBufOffset];

        // Lookup in current trie node.
        var uCode = this.decodeTables[nodeIdx][curByte];

        if (uCode >= 0) { 
            // Normal character, just use it.
        }
        else if (uCode === UNASSIGNED) { // Unknown char.
            // TODO: Callback with seq.
            //var curSeq = (seqStart >= 0) ? buf.slice(seqStart, i+1) : prevBuf.slice(seqStart + prevBufOffset, i+1 + prevBufOffset);
            i = seqStart; // Try to parse again, after skipping first byte of the sequence ('i' will be incremented by 'for' cycle).
            uCode = this.defaultCharUnicode.charCodeAt(0);
        }
        else if (uCode === GB18030_CODE) {
            var curSeq = (seqStart >= 0) ? buf.slice(seqStart, i+1) : prevBuf.slice(seqStart + prevBufOffset, i+1 + prevBufOffset);
            var ptr = (curSeq[0]-0x81)*12600 + (curSeq[1]-0x30)*1260 + (curSeq[2]-0x81)*10 + (curSeq[3]-0x30);
            var idx = findIdx(this.gb18030.gbChars, ptr);
            uCode = this.gb18030.uChars[idx] + ptr - this.gb18030.gbChars[idx];
        }
        else if (uCode <= NODE_START) { // Go to next trie node.
            nodeIdx = NODE_START - uCode;
            continue;
        }
        else if (uCode <= SEQ_START) { // Output a sequence of chars.
            var seq = this.decodeTableSeq[SEQ_START - uCode];
            for (var k = 0; k < seq.length - 1; k++) {
                uCode = seq[k];
                newBuf[j++] = uCode & 0xFF;
                newBuf[j++] = uCode >> 8;
            }
            uCode = seq[seq.length-1];
        }
        else
            throw new Error("iconv-lite internal error: invalid decoding table value " + uCode + " at " + nodeIdx + "/" + curByte);

        // Write the character to buffer, handling higher planes using surrogate pair.
        if (uCode > 0xFFFF) { 
            uCode -= 0x10000;
            var uCodeLead = 0xD800 + Math.floor(uCode / 0x400);
            newBuf[j++] = uCodeLead & 0xFF;
            newBuf[j++] = uCodeLead >> 8;

            uCode = 0xDC00 + uCode % 0x400;
        }
        newBuf[j++] = uCode & 0xFF;
        newBuf[j++] = uCode >> 8;

        // Reset trie node.
        nodeIdx = 0; seqStart = i+1;
    }

    this.nodeIdx = nodeIdx;
    this.prevBuf = (seqStart >= 0) ? buf.slice(seqStart) : prevBuf.slice(seqStart + prevBufOffset);
    return newBuf.slice(0, j).toString('ucs2');
}

DBCSDecoder.prototype.end = function() {
    var ret = '';

    // Try to parse all remaining chars.
    while (this.prevBuf.length > 0) {
        // Skip 1 character in the buffer.
        ret += this.defaultCharUnicode;
        var buf = this.prevBuf.slice(1);

        // Parse remaining as usual.
        this.prevBuf = Buffer.alloc(0);
        this.nodeIdx = 0;
        if (buf.length > 0)
            ret += this.write(buf);
    }

    this.nodeIdx = 0;
    return ret;
}

// Binary search for GB18030. Returns largest i such that table[i] <= val.
function findIdx(table, val) {
    if (table[0] > val)
        return -1;

    var l = 0, r = table.length;
    while (l < r-1) { // always table[l] <= val < table[r]
        var mid = l + Math.floor((r-l+1)/2);
        if (table[mid] <= val)
            l = mid;
        else
            r = mid;
    }
    return l;
}


},{"safer-buffer":51}],17:[function(require,module,exports){
"use strict";

// Description of supported double byte encodings and aliases.
// Tables are not require()-d until they are needed to speed up library load.
// require()-s are direct to support Browserify.

module.exports = {
    
    // == Japanese/ShiftJIS ====================================================
    // All japanese encodings are based on JIS X set of standards:
    // JIS X 0201 - Single-byte encoding of ASCII +  + Kana chars at 0xA1-0xDF.
    // JIS X 0208 - Main set of 6879 characters, placed in 94x94 plane, to be encoded by 2 bytes. 
    //              Has several variations in 1978, 1983, 1990 and 1997.
    // JIS X 0212 - Supplementary plane of 6067 chars in 94x94 plane. 1990. Effectively dead.
    // JIS X 0213 - Extension and modern replacement of 0208 and 0212. Total chars: 11233.
    //              2 planes, first is superset of 0208, second - revised 0212.
    //              Introduced in 2000, revised 2004. Some characters are in Unicode Plane 2 (0x2xxxx)

    // Byte encodings are:
    //  * Shift_JIS: Compatible with 0201, uses not defined chars in top half as lead bytes for double-byte
    //               encoding of 0208. Lead byte ranges: 0x81-0x9F, 0xE0-0xEF; Trail byte ranges: 0x40-0x7E, 0x80-0x9E, 0x9F-0xFC.
    //               Windows CP932 is a superset of Shift_JIS. Some companies added more chars, notably KDDI.
    //  * EUC-JP:    Up to 3 bytes per character. Used mostly on *nixes.
    //               0x00-0x7F       - lower part of 0201
    //               0x8E, 0xA1-0xDF - upper part of 0201
    //               (0xA1-0xFE)x2   - 0208 plane (94x94).
    //               0x8F, (0xA1-0xFE)x2 - 0212 plane (94x94).
    //  * JIS X 208: 7-bit, direct encoding of 0208. Byte ranges: 0x21-0x7E (94 values). Uncommon.
    //               Used as-is in ISO2022 family.
    //  * ISO2022-JP: Stateful encoding, with escape sequences to switch between ASCII, 
    //                0201-1976 Roman, 0208-1978, 0208-1983.
    //  * ISO2022-JP-1: Adds esc seq for 0212-1990.
    //  * ISO2022-JP-2: Adds esc seq for GB2313-1980, KSX1001-1992, ISO8859-1, ISO8859-7.
    //  * ISO2022-JP-3: Adds esc seq for 0201-1976 Kana set, 0213-2000 Planes 1, 2.
    //  * ISO2022-JP-2004: Adds 0213-2004 Plane 1.
    //
    // After JIS X 0213 appeared, Shift_JIS-2004, EUC-JISX0213 and ISO2022-JP-2004 followed, with just changing the planes.
    //
    // Overall, it seems that it's a mess :( http://www8.plala.or.jp/tkubota1/unicode-symbols-map2.html

    'shiftjis': {
        type: '_dbcs',
        table: function() { return require('./tables/shiftjis.json') },
        encodeAdd: {'\u00a5': 0x5C, '\u203E': 0x7E},
        encodeSkipVals: [{from: 0xED40, to: 0xF940}],
    },
    'csshiftjis': 'shiftjis',
    'mskanji': 'shiftjis',
    'sjis': 'shiftjis',
    'windows31j': 'shiftjis',
    'ms31j': 'shiftjis',
    'xsjis': 'shiftjis',
    'windows932': 'shiftjis',
    'ms932': 'shiftjis',
    '932': 'shiftjis',
    'cp932': 'shiftjis',

    'eucjp': {
        type: '_dbcs',
        table: function() { return require('./tables/eucjp.json') },
        encodeAdd: {'\u00a5': 0x5C, '\u203E': 0x7E},
    },

    // TODO: KDDI extension to Shift_JIS
    // TODO: IBM CCSID 942 = CP932, but F0-F9 custom chars and other char changes.
    // TODO: IBM CCSID 943 = Shift_JIS = CP932 with original Shift_JIS lower 128 chars.


    // == Chinese/GBK ==========================================================
    // http://en.wikipedia.org/wiki/GBK
    // We mostly implement W3C recommendation: https://www.w3.org/TR/encoding/#gbk-encoder

    // Oldest GB2312 (1981, ~7600 chars) is a subset of CP936
    'gb2312': 'cp936',
    'gb231280': 'cp936',
    'gb23121980': 'cp936',
    'csgb2312': 'cp936',
    'csiso58gb231280': 'cp936',
    'euccn': 'cp936',

    // Microsoft's CP936 is a subset and approximation of GBK.
    'windows936': 'cp936',
    'ms936': 'cp936',
    '936': 'cp936',
    'cp936': {
        type: '_dbcs',
        table: function() { return require('./tables/cp936.json') },
    },

    // GBK (~22000 chars) is an extension of CP936 that added user-mapped chars and some other.
    'gbk': {
        type: '_dbcs',
        table: function() { return require('./tables/cp936.json').concat(require('./tables/gbk-added.json')) },
    },
    'xgbk': 'gbk',
    'isoir58': 'gbk',

    // GB18030 is an algorithmic extension of GBK.
    // Main source: https://www.w3.org/TR/encoding/#gbk-encoder
    // http://icu-project.org/docs/papers/gb18030.html
    // http://source.icu-project.org/repos/icu/data/trunk/charset/data/xml/gb-18030-2000.xml
    // http://www.khngai.com/chinese/charmap/tblgbk.php?page=0
    'gb18030': {
        type: '_dbcs',
        table: function() { return require('./tables/cp936.json').concat(require('./tables/gbk-added.json')) },
        gb18030: function() { return require('./tables/gb18030-ranges.json') },
        encodeSkipVals: [0x80],
        encodeAdd: {'': 0xA2E3},
    },

    'chinese': 'gb18030',


    // == Korean ===============================================================
    // EUC-KR, KS_C_5601 and KS X 1001 are exactly the same.
    'windows949': 'cp949',
    'ms949': 'cp949',
    '949': 'cp949',
    'cp949': {
        type: '_dbcs',
        table: function() { return require('./tables/cp949.json') },
    },

    'cseuckr': 'cp949',
    'csksc56011987': 'cp949',
    'euckr': 'cp949',
    'isoir149': 'cp949',
    'korean': 'cp949',
    'ksc56011987': 'cp949',
    'ksc56011989': 'cp949',
    'ksc5601': 'cp949',


    // == Big5/Taiwan/Hong Kong ================================================
    // There are lots of tables for Big5 and cp950. Please see the following links for history:
    // http://moztw.org/docs/big5/  http://www.haible.de/bruno/charsets/conversion-tables/Big5.html
    // Variations, in roughly number of defined chars:
    //  * Windows CP 950: Microsoft variant of Big5. Canonical: http://www.unicode.org/Public/MAPPINGS/VENDORS/MICSFT/WINDOWS/CP950.TXT
    //  * Windows CP 951: Microsoft variant of Big5-HKSCS-2001. Seems to be never public. http://me.abelcheung.org/articles/research/what-is-cp951/
    //  * Big5-2003 (Taiwan standard) almost superset of cp950.
    //  * Unicode-at-on (UAO) / Mozilla 1.8. Falling out of use on the Web. Not supported by other browsers.
    //  * Big5-HKSCS (-2001, -2004, -2008). Hong Kong standard. 
    //    many unicode code points moved from PUA to Supplementary plane (U+2XXXX) over the years.
    //    Plus, it has 4 combining sequences.
    //    Seems that Mozilla refused to support it for 10 yrs. https://bugzilla.mozilla.org/show_bug.cgi?id=162431 https://bugzilla.mozilla.org/show_bug.cgi?id=310299
    //    because big5-hkscs is the only encoding to include astral characters in non-algorithmic way.
    //    Implementations are not consistent within browsers; sometimes labeled as just big5.
    //    MS Internet Explorer switches from big5 to big5-hkscs when a patch applied.
    //    Great discussion & recap of what's going on https://bugzilla.mozilla.org/show_bug.cgi?id=912470#c31
    //    In the encoder, it might make sense to support encoding old PUA mappings to Big5 bytes seq-s.
    //    Official spec: http://www.ogcio.gov.hk/en/business/tech_promotion/ccli/terms/doc/2003cmp_2008.txt
    //                   http://www.ogcio.gov.hk/tc/business/tech_promotion/ccli/terms/doc/hkscs-2008-big5-iso.txt
    // 
    // Current understanding of how to deal with Big5(-HKSCS) is in the Encoding Standard, http://encoding.spec.whatwg.org/#big5-encoder
    // Unicode mapping (http://www.unicode.org/Public/MAPPINGS/OBSOLETE/EASTASIA/OTHER/BIG5.TXT) is said to be wrong.

    'windows950': 'cp950',
    'ms950': 'cp950',
    '950': 'cp950',
    'cp950': {
        type: '_dbcs',
        table: function() { return require('./tables/cp950.json') },
    },

    // Big5 has many variations and is an extension of cp950. We use Encoding Standard's as a consensus.
    'big5': 'big5hkscs',
    'big5hkscs': {
        type: '_dbcs',
        table: function() { return require('./tables/cp950.json').concat(require('./tables/big5-added.json')) },
        encodeSkipVals: [0xa2cc],
    },

    'cnbig5': 'big5hkscs',
    'csbig5': 'big5hkscs',
    'xxbig5': 'big5hkscs',
};

},{"./tables/big5-added.json":23,"./tables/cp936.json":24,"./tables/cp949.json":25,"./tables/cp950.json":26,"./tables/eucjp.json":27,"./tables/gb18030-ranges.json":28,"./tables/gbk-added.json":29,"./tables/shiftjis.json":30}],18:[function(require,module,exports){
"use strict";

// Update this array if you add/rename/remove files in this directory.
// We support Browserify by skipping automatic module discovery and requiring modules directly.
var modules = [
    require("./internal"),
    require("./utf16"),
    require("./utf7"),
    require("./sbcs-codec"),
    require("./sbcs-data"),
    require("./sbcs-data-generated"),
    require("./dbcs-codec"),
    require("./dbcs-data"),
];

// Put all encoding/alias/codec definitions to single object and export it. 
for (var i = 0; i < modules.length; i++) {
    var module = modules[i];
    for (var enc in module)
        if (Object.prototype.hasOwnProperty.call(module, enc))
            exports[enc] = module[enc];
}

},{"./dbcs-codec":16,"./dbcs-data":17,"./internal":19,"./sbcs-codec":20,"./sbcs-data":22,"./sbcs-data-generated":21,"./utf16":31,"./utf7":32}],19:[function(require,module,exports){
"use strict";
var Buffer = require("safer-buffer").Buffer;

// Export Node.js internal encodings.

module.exports = {
    // Encodings
    utf8:   { type: "_internal", bomAware: true},
    cesu8:  { type: "_internal", bomAware: true},
    unicode11utf8: "utf8",

    ucs2:   { type: "_internal", bomAware: true},
    utf16le: "ucs2",

    binary: { type: "_internal" },
    base64: { type: "_internal" },
    hex:    { type: "_internal" },

    // Codec.
    _internal: InternalCodec,
};

//------------------------------------------------------------------------------

function InternalCodec(codecOptions, iconv) {
    this.enc = codecOptions.encodingName;
    this.bomAware = codecOptions.bomAware;

    if (this.enc === "base64")
        this.encoder = InternalEncoderBase64;
    else if (this.enc === "cesu8") {
        this.enc = "utf8"; // Use utf8 for decoding.
        this.encoder = InternalEncoderCesu8;

        // Add decoder for versions of Node not supporting CESU-8
        if (Buffer.from('eda0bdedb2a9', 'hex').toString() !== '') {
            this.decoder = InternalDecoderCesu8;
            this.defaultCharUnicode = iconv.defaultCharUnicode;
        }
    }
}

InternalCodec.prototype.encoder = InternalEncoder;
InternalCodec.prototype.decoder = InternalDecoder;

//------------------------------------------------------------------------------

// We use node.js internal decoder. Its signature is the same as ours.
var StringDecoder = require('string_decoder').StringDecoder;

if (!StringDecoder.prototype.end) // Node v0.8 doesn't have this method.
    StringDecoder.prototype.end = function() {};


function InternalDecoder(options, codec) {
    StringDecoder.call(this, codec.enc);
}

InternalDecoder.prototype = StringDecoder.prototype;


//------------------------------------------------------------------------------
// Encoder is mostly trivial

function InternalEncoder(options, codec) {
    this.enc = codec.enc;
}

InternalEncoder.prototype.write = function(str) {
    return Buffer.from(str, this.enc);
}

InternalEncoder.prototype.end = function() {
}


//------------------------------------------------------------------------------
// Except base64 encoder, which must keep its state.

function InternalEncoderBase64(options, codec) {
    this.prevStr = '';
}

InternalEncoderBase64.prototype.write = function(str) {
    str = this.prevStr + str;
    var completeQuads = str.length - (str.length % 4);
    this.prevStr = str.slice(completeQuads);
    str = str.slice(0, completeQuads);

    return Buffer.from(str, "base64");
}

InternalEncoderBase64.prototype.end = function() {
    return Buffer.from(this.prevStr, "base64");
}


//------------------------------------------------------------------------------
// CESU-8 encoder is also special.

function InternalEncoderCesu8(options, codec) {
}

InternalEncoderCesu8.prototype.write = function(str) {
    var buf = Buffer.alloc(str.length * 3), bufIdx = 0;
    for (var i = 0; i < str.length; i++) {
        var charCode = str.charCodeAt(i);
        // Naive implementation, but it works because CESU-8 is especially easy
        // to convert from UTF-16 (which all JS strings are encoded in).
        if (charCode < 0x80)
            buf[bufIdx++] = charCode;
        else if (charCode < 0x800) {
            buf[bufIdx++] = 0xC0 + (charCode >>> 6);
            buf[bufIdx++] = 0x80 + (charCode & 0x3f);
        }
        else { // charCode will always be < 0x10000 in javascript.
            buf[bufIdx++] = 0xE0 + (charCode >>> 12);
            buf[bufIdx++] = 0x80 + ((charCode >>> 6) & 0x3f);
            buf[bufIdx++] = 0x80 + (charCode & 0x3f);
        }
    }
    return buf.slice(0, bufIdx);
}

InternalEncoderCesu8.prototype.end = function() {
}

//------------------------------------------------------------------------------
// CESU-8 decoder is not implemented in Node v4.0+

function InternalDecoderCesu8(options, codec) {
    this.acc = 0;
    this.contBytes = 0;
    this.accBytes = 0;
    this.defaultCharUnicode = codec.defaultCharUnicode;
}

InternalDecoderCesu8.prototype.write = function(buf) {
    var acc = this.acc, contBytes = this.contBytes, accBytes = this.accBytes, 
        res = '';
    for (var i = 0; i < buf.length; i++) {
        var curByte = buf[i];
        if ((curByte & 0xC0) !== 0x80) { // Leading byte
            if (contBytes > 0) { // Previous code is invalid
                res += this.defaultCharUnicode;
                contBytes = 0;
            }

            if (curByte < 0x80) { // Single-byte code
                res += String.fromCharCode(curByte);
            } else if (curByte < 0xE0) { // Two-byte code
                acc = curByte & 0x1F;
                contBytes = 1; accBytes = 1;
            } else if (curByte < 0xF0) { // Three-byte code
                acc = curByte & 0x0F;
                contBytes = 2; accBytes = 1;
            } else { // Four or more are not supported for CESU-8.
                res += this.defaultCharUnicode;
            }
        } else { // Continuation byte
            if (contBytes > 0) { // We're waiting for it.
                acc = (acc << 6) | (curByte & 0x3f);
                contBytes--; accBytes++;
                if (contBytes === 0) {
                    // Check for overlong encoding, but support Modified UTF-8 (encoding NULL as C0 80)
                    if (accBytes === 2 && acc < 0x80 && acc > 0)
                        res += this.defaultCharUnicode;
                    else if (accBytes === 3 && acc < 0x800)
                        res += this.defaultCharUnicode;
                    else
                        // Actually add character.
                        res += String.fromCharCode(acc);
                }
            } else { // Unexpected continuation byte
                res += this.defaultCharUnicode;
            }
        }
    }
    this.acc = acc; this.contBytes = contBytes; this.accBytes = accBytes;
    return res;
}

InternalDecoderCesu8.prototype.end = function() {
    var res = 0;
    if (this.contBytes > 0)
        res += this.defaultCharUnicode;
    return res;
}

},{"safer-buffer":51,"string_decoder":9}],20:[function(require,module,exports){
"use strict";
var Buffer = require("safer-buffer").Buffer;

// Single-byte codec. Needs a 'chars' string parameter that contains 256 or 128 chars that
// correspond to encoded bytes (if 128 - then lower half is ASCII). 

exports._sbcs = SBCSCodec;
function SBCSCodec(codecOptions, iconv) {
    if (!codecOptions)
        throw new Error("SBCS codec is called without the data.")
    
    // Prepare char buffer for decoding.
    if (!codecOptions.chars || (codecOptions.chars.length !== 128 && codecOptions.chars.length !== 256))
        throw new Error("Encoding '"+codecOptions.type+"' has incorrect 'chars' (must be of len 128 or 256)");
    
    if (codecOptions.chars.length === 128) {
        var asciiString = "";
        for (var i = 0; i < 128; i++)
            asciiString += String.fromCharCode(i);
        codecOptions.chars = asciiString + codecOptions.chars;
    }

    this.decodeBuf = Buffer.from(codecOptions.chars, 'ucs2');
    
    // Encoding buffer.
    var encodeBuf = Buffer.alloc(65536, iconv.defaultCharSingleByte.charCodeAt(0));

    for (var i = 0; i < codecOptions.chars.length; i++)
        encodeBuf[codecOptions.chars.charCodeAt(i)] = i;

    this.encodeBuf = encodeBuf;
}

SBCSCodec.prototype.encoder = SBCSEncoder;
SBCSCodec.prototype.decoder = SBCSDecoder;


function SBCSEncoder(options, codec) {
    this.encodeBuf = codec.encodeBuf;
}

SBCSEncoder.prototype.write = function(str) {
    var buf = Buffer.alloc(str.length);
    for (var i = 0; i < str.length; i++)
        buf[i] = this.encodeBuf[str.charCodeAt(i)];
    
    return buf;
}

SBCSEncoder.prototype.end = function() {
}


function SBCSDecoder(options, codec) {
    this.decodeBuf = codec.decodeBuf;
}

SBCSDecoder.prototype.write = function(buf) {
    // Strings are immutable in JS -> we use ucs2 buffer to speed up computations.
    var decodeBuf = this.decodeBuf;
    var newBuf = Buffer.alloc(buf.length*2);
    var idx1 = 0, idx2 = 0;
    for (var i = 0; i < buf.length; i++) {
        idx1 = buf[i]*2; idx2 = i*2;
        newBuf[idx2] = decodeBuf[idx1];
        newBuf[idx2+1] = decodeBuf[idx1+1];
    }
    return newBuf.toString('ucs2');
}

SBCSDecoder.prototype.end = function() {
}

},{"safer-buffer":51}],21:[function(require,module,exports){
"use strict";

// Generated data for sbcs codec. Don't edit manually. Regenerate using generation/gen-sbcs.js script.
module.exports = {
  "437": "cp437",
  "737": "cp737",
  "775": "cp775",
  "850": "cp850",
  "852": "cp852",
  "855": "cp855",
  "856": "cp856",
  "857": "cp857",
  "858": "cp858",
  "860": "cp860",
  "861": "cp861",
  "862": "cp862",
  "863": "cp863",
  "864": "cp864",
  "865": "cp865",
  "866": "cp866",
  "869": "cp869",
  "874": "windows874",
  "922": "cp922",
  "1046": "cp1046",
  "1124": "cp1124",
  "1125": "cp1125",
  "1129": "cp1129",
  "1133": "cp1133",
  "1161": "cp1161",
  "1162": "cp1162",
  "1163": "cp1163",
  "1250": "windows1250",
  "1251": "windows1251",
  "1252": "windows1252",
  "1253": "windows1253",
  "1254": "windows1254",
  "1255": "windows1255",
  "1256": "windows1256",
  "1257": "windows1257",
  "1258": "windows1258",
  "28591": "iso88591",
  "28592": "iso88592",
  "28593": "iso88593",
  "28594": "iso88594",
  "28595": "iso88595",
  "28596": "iso88596",
  "28597": "iso88597",
  "28598": "iso88598",
  "28599": "iso88599",
  "28600": "iso885910",
  "28601": "iso885911",
  "28603": "iso885913",
  "28604": "iso885914",
  "28605": "iso885915",
  "28606": "iso885916",
  "windows874": {
    "type": "_sbcs",
    "chars": ""
  },
  "win874": "windows874",
  "cp874": "windows874",
  "windows1250": {
    "type": "_sbcs",
    "chars": ""
  },
  "win1250": "windows1250",
  "cp1250": "windows1250",
  "windows1251": {
    "type": "_sbcs",
    "chars": ""
  },
  "win1251": "windows1251",
  "cp1251": "windows1251",
  "windows1252": {
    "type": "_sbcs",
    "chars": ""
  },
  "win1252": "windows1252",
  "cp1252": "windows1252",
  "windows1253": {
    "type": "_sbcs",
    "chars": ""
  },
  "win1253": "windows1253",
  "cp1253": "windows1253",
  "windows1254": {
    "type": "_sbcs",
    "chars": ""
  },
  "win1254": "windows1254",
  "cp1254": "windows1254",
  "windows1255": {
    "type": "_sbcs",
    "chars": ""
  },
  "win1255": "windows1255",
  "cp1255": "windows1255",
  "windows1256": {
    "type": "_sbcs",
    "chars": ""
  },
  "win1256": "windows1256",
  "cp1256": "windows1256",
  "windows1257": {
    "type": "_sbcs",
    "chars": ""
  },
  "win1257": "windows1257",
  "cp1257": "windows1257",
  "windows1258": {
    "type": "_sbcs",
    "chars": ""
  },
  "win1258": "windows1258",
  "cp1258": "windows1258",
  "iso88591": {
    "type": "_sbcs",
    "chars": ""
  },
  "cp28591": "iso88591",
  "iso88592": {
    "type": "_sbcs",
    "chars": ""
  },
  "cp28592": "iso88592",
  "iso88593": {
    "type": "_sbcs",
    "chars": ""
  },
  "cp28593": "iso88593",
  "iso88594": {
    "type": "_sbcs",
    "chars": ""
  },
  "cp28594": "iso88594",
  "iso88595": {
    "type": "_sbcs",
    "chars": ""
  },
  "cp28595": "iso88595",
  "iso88596": {
    "type": "_sbcs",
    "chars": ""
  },
  "cp28596": "iso88596",
  "iso88597": {
    "type": "_sbcs",
    "chars": ""
  },
  "cp28597": "iso88597",
  "iso88598": {
    "type": "_sbcs",
    "chars": ""
  },
  "cp28598": "iso88598",
  "iso88599": {
    "type": "_sbcs",
    "chars": ""
  },
  "cp28599": "iso88599",
  "iso885910": {
    "type": "_sbcs",
    "chars": ""
  },
  "cp28600": "iso885910",
  "iso885911": {
    "type": "_sbcs",
    "chars": ""
  },
  "cp28601": "iso885911",
  "iso885913": {
    "type": "_sbcs",
    "chars": ""
  },
  "cp28603": "iso885913",
  "iso885914": {
    "type": "_sbcs",
    "chars": ""
  },
  "cp28604": "iso885914",
  "iso885915": {
    "type": "_sbcs",
    "chars": ""
  },
  "cp28605": "iso885915",
  "iso885916": {
    "type": "_sbcs",
    "chars": ""
  },
  "cp28606": "iso885916",
  "cp437": {
    "type": "_sbcs",
    "chars": ""
  },
  "ibm437": "cp437",
  "csibm437": "cp437",
  "cp737": {
    "type": "_sbcs",
    "chars": ""
  },
  "ibm737": "cp737",
  "csibm737": "cp737",
  "cp775": {
    "type": "_sbcs",
    "chars": ""
  },
  "ibm775": "cp775",
  "csibm775": "cp775",
  "cp850": {
    "type": "_sbcs",
    "chars": ""
  },
  "ibm850": "cp850",
  "csibm850": "cp850",
  "cp852": {
    "type": "_sbcs",
    "chars": ""
  },
  "ibm852": "cp852",
  "csibm852": "cp852",
  "cp855": {
    "type": "_sbcs",
    "chars": ""
  },
  "ibm855": "cp855",
  "csibm855": "cp855",
  "cp856": {
    "type": "_sbcs",
    "chars": ""
  },
  "ibm856": "cp856",
  "csibm856": "cp856",
  "cp857": {
    "type": "_sbcs",
    "chars": ""
  },
  "ibm857": "cp857",
  "csibm857": "cp857",
  "cp858": {
    "type": "_sbcs",
    "chars": ""
  },
  "ibm858": "cp858",
  "csibm858": "cp858",
  "cp860": {
    "type": "_sbcs",
    "chars": ""
  },
  "ibm860": "cp860",
  "csibm860": "cp860",
  "cp861": {
    "type": "_sbcs",
    "chars": ""
  },
  "ibm861": "cp861",
  "csibm861": "cp861",
  "cp862": {
    "type": "_sbcs",
    "chars": ""
  },
  "ibm862": "cp862",
  "csibm862": "cp862",
  "cp863": {
    "type": "_sbcs",
    "chars": ""
  },
  "ibm863": "cp863",
  "csibm863": "cp863",
  "cp864": {
    "type": "_sbcs",
    "chars": "\u0000\u0001\u0002\u0003\u0004\u0005\u0006\u0007\b\t\n\u000b\f\r\u000e\u000f\u0010\u0011\u0012\u0013\u0014\u0015\u0016\u0017\u0018\u0019\u001a\u001b\u001c\u001d\u001e\u001f !\"#$&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~"
  },
  "ibm864": "cp864",
  "csibm864": "cp864",
  "cp865": {
    "type": "_sbcs",
    "chars": ""
  },
  "ibm865": "cp865",
  "csibm865": "cp865",
  "cp866": {
    "type": "_sbcs",
    "chars": ""
  },
  "ibm866": "cp866",
  "csibm866": "cp866",
  "cp869": {
    "type": "_sbcs",
    "chars": ""
  },
  "ibm869": "cp869",
  "csibm869": "cp869",
  "cp922": {
    "type": "_sbcs",
    "chars": ""
  },
  "ibm922": "cp922",
  "csibm922": "cp922",
  "cp1046": {
    "type": "_sbcs",
    "chars": ""
  },
  "ibm1046": "cp1046",
  "csibm1046": "cp1046",
  "cp1124": {
    "type": "_sbcs",
    "chars": ""
  },
  "ibm1124": "cp1124",
  "csibm1124": "cp1124",
  "cp1125": {
    "type": "_sbcs",
    "chars": ""
  },
  "ibm1125": "cp1125",
  "csibm1125": "cp1125",
  "cp1129": {
    "type": "_sbcs",
    "chars": ""
  },
  "ibm1129": "cp1129",
  "csibm1129": "cp1129",
  "cp1133": {
    "type": "_sbcs",
    "chars": ""
  },
  "ibm1133": "cp1133",
  "csibm1133": "cp1133",
  "cp1161": {
    "type": "_sbcs",
    "chars": ""
  },
  "ibm1161": "cp1161",
  "csibm1161": "cp1161",
  "cp1162": {
    "type": "_sbcs",
    "chars": ""
  },
  "ibm1162": "cp1162",
  "csibm1162": "cp1162",
  "cp1163": {
    "type": "_sbcs",
    "chars": ""
  },
  "ibm1163": "cp1163",
  "csibm1163": "cp1163",
  "maccroatian": {
    "type": "_sbcs",
    "chars": ""
  },
  "maccyrillic": {
    "type": "_sbcs",
    "chars": ""
  },
  "macgreek": {
    "type": "_sbcs",
    "chars": ""
  },
  "maciceland": {
    "type": "_sbcs",
    "chars": ""
  },
  "macroman": {
    "type": "_sbcs",
    "chars": ""
  },
  "macromania": {
    "type": "_sbcs",
    "chars": ""
  },
  "macthai": {
    "type": "_sbcs",
    "chars": ""
  },
  "macturkish": {
    "type": "_sbcs",
    "chars": ""
  },
  "macukraine": {
    "type": "_sbcs",
    "chars": ""
  },
  "koi8r": {
    "type": "_sbcs",
    "chars": ""
  },
  "koi8u": {
    "type": "_sbcs",
    "chars": ""
  },
  "koi8ru": {
    "type": "_sbcs",
    "chars": ""
  },
  "koi8t": {
    "type": "_sbcs",
    "chars": ""
  },
  "armscii8": {
    "type": "_sbcs",
    "chars": ")(.,-"
  },
  "rk1048": {
    "type": "_sbcs",
    "chars": ""
  },
  "tcvn": {
    "type": "_sbcs",
    "chars": "\u0000\u0003\u0007\b\t\n\u000b\f\r\u000e\u000f\u0010\u0018\u0019\u001a\u001b\u001c\u001d\u001e\u001f !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~"
  },
  "georgianacademy": {
    "type": "_sbcs",
    "chars": ""
  },
  "georgianps": {
    "type": "_sbcs",
    "chars": ""
  },
  "pt154": {
    "type": "_sbcs",
    "chars": ""
  },
  "viscii": {
    "type": "_sbcs",
    "chars": "\u0000\u0001\u0003\u0004\u0007\b\t\n\u000b\f\r\u000e\u000f\u0010\u0011\u0012\u0013\u0015\u0016\u0017\u0018\u001a\u001b\u001c\u001d\u001f !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}~"
  },
  "iso646cn": {
    "type": "_sbcs",
    "chars": "\u0000\u0001\u0002\u0003\u0004\u0005\u0006\u0007\b\t\n\u000b\f\r\u000e\u000f\u0010\u0011\u0012\u0013\u0014\u0015\u0016\u0017\u0018\u0019\u001a\u001b\u001c\u001d\u001e\u001f !\"#%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\]^_`abcdefghijklmnopqrstuvwxyz{|}"
  },
  "iso646jp": {
    "type": "_sbcs",
    "chars": "\u0000\u0001\u0002\u0003\u0004\u0005\u0006\u0007\b\t\n\u000b\f\r\u000e\u000f\u0010\u0011\u0012\u0013\u0014\u0015\u0016\u0017\u0018\u0019\u001a\u001b\u001c\u001d\u001e\u001f !\"#$%&'()*+,-./0123456789:;<=>?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[]^_`abcdefghijklmnopqrstuvwxyz{|}"
  },
  "hproman8": {
    "type": "_sbcs",
    "chars": ""
  },
  "macintosh": {
    "type": "_sbcs",
    "chars": ""
  },
  "ascii": {
    "type": "_sbcs",
    "chars": ""
  },
  "tis620": {
    "type": "_sbcs",
    "chars": ""
  }
}
},{}],22:[function(require,module,exports){
"use strict";

// Manually added data to be used by sbcs codec in addition to generated one.

module.exports = {
    // Not supported by iconv, not sure why.
    "10029": "maccenteuro",
    "maccenteuro": {
        "type": "_sbcs",
        "chars": ""
    },

    "808": "cp808",
    "ibm808": "cp808",
    "cp808": {
        "type": "_sbcs",
        "chars": ""
    },

    "mik": {
        "type": "_sbcs",
        "chars": ""
    },

    // Aliases of generated encodings.
    "ascii8bit": "ascii",
    "usascii": "ascii",
    "ansix34": "ascii",
    "ansix341968": "ascii",
    "ansix341986": "ascii",
    "csascii": "ascii",
    "cp367": "ascii",
    "ibm367": "ascii",
    "isoir6": "ascii",
    "iso646us": "ascii",
    "iso646irv": "ascii",
    "us": "ascii",

    "latin1": "iso88591",
    "latin2": "iso88592",
    "latin3": "iso88593",
    "latin4": "iso88594",
    "latin5": "iso88599",
    "latin6": "iso885910",
    "latin7": "iso885913",
    "latin8": "iso885914",
    "latin9": "iso885915",
    "latin10": "iso885916",

    "csisolatin1": "iso88591",
    "csisolatin2": "iso88592",
    "csisolatin3": "iso88593",
    "csisolatin4": "iso88594",
    "csisolatincyrillic": "iso88595",
    "csisolatinarabic": "iso88596",
    "csisolatingreek" : "iso88597",
    "csisolatinhebrew": "iso88598",
    "csisolatin5": "iso88599",
    "csisolatin6": "iso885910",

    "l1": "iso88591",
    "l2": "iso88592",
    "l3": "iso88593",
    "l4": "iso88594",
    "l5": "iso88599",
    "l6": "iso885910",
    "l7": "iso885913",
    "l8": "iso885914",
    "l9": "iso885915",
    "l10": "iso885916",

    "isoir14": "iso646jp",
    "isoir57": "iso646cn",
    "isoir100": "iso88591",
    "isoir101": "iso88592",
    "isoir109": "iso88593",
    "isoir110": "iso88594",
    "isoir144": "iso88595",
    "isoir127": "iso88596",
    "isoir126": "iso88597",
    "isoir138": "iso88598",
    "isoir148": "iso88599",
    "isoir157": "iso885910",
    "isoir166": "tis620",
    "isoir179": "iso885913",
    "isoir199": "iso885914",
    "isoir203": "iso885915",
    "isoir226": "iso885916",

    "cp819": "iso88591",
    "ibm819": "iso88591",

    "cyrillic": "iso88595",

    "arabic": "iso88596",
    "arabic8": "iso88596",
    "ecma114": "iso88596",
    "asmo708": "iso88596",

    "greek" : "iso88597",
    "greek8" : "iso88597",
    "ecma118" : "iso88597",
    "elot928" : "iso88597",

    "hebrew": "iso88598",
    "hebrew8": "iso88598",

    "turkish": "iso88599",
    "turkish8": "iso88599",

    "thai": "iso885911",
    "thai8": "iso885911",

    "celtic": "iso885914",
    "celtic8": "iso885914",
    "isoceltic": "iso885914",

    "tis6200": "tis620",
    "tis62025291": "tis620",
    "tis62025330": "tis620",

    "10000": "macroman",
    "10006": "macgreek",
    "10007": "maccyrillic",
    "10079": "maciceland",
    "10081": "macturkish",

    "cspc8codepage437": "cp437",
    "cspc775baltic": "cp775",
    "cspc850multilingual": "cp850",
    "cspcp852": "cp852",
    "cspc862latinhebrew": "cp862",
    "cpgr": "cp869",

    "msee": "cp1250",
    "mscyrl": "cp1251",
    "msansi": "cp1252",
    "msgreek": "cp1253",
    "msturk": "cp1254",
    "mshebr": "cp1255",
    "msarab": "cp1256",
    "winbaltrim": "cp1257",

    "cp20866": "koi8r",
    "20866": "koi8r",
    "ibm878": "koi8r",
    "cskoi8r": "koi8r",

    "cp21866": "koi8u",
    "21866": "koi8u",
    "ibm1168": "koi8u",

    "strk10482002": "rk1048",

    "tcvn5712": "tcvn",
    "tcvn57121": "tcvn",

    "gb198880": "iso646cn",
    "cn": "iso646cn",

    "csiso14jisc6220ro": "iso646jp",
    "jisc62201969ro": "iso646jp",
    "jp": "iso646jp",

    "cshproman8": "hproman8",
    "r8": "hproman8",
    "roman8": "hproman8",
    "xroman8": "hproman8",
    "ibm1051": "hproman8",

    "mac": "macintosh",
    "csmacintosh": "macintosh",
};


},{}],23:[function(require,module,exports){
module.exports=[
["8740",""],
["8767",""],
["87a1",""],
["8840","",4,""],
["88a1",""],
["8940",""],
["8943",""],
["8946",""],
["894c",""],
["89a1",""],
["89ab",""],
["89b0",""],
["89b5",""],
["89c1",""],
["89c5",""],
["8a40",""],
["8a43",""],
["8a64",""],
["8a76",""],
["8aa1",""],
["8aac",""],
["8ab2",""],
["8abb",""],
["8ac9",""],
["8ace",""],
["8adf",""],
["8af6",""],
["8b40",""],
["8b55",""],
["8ba1",""],
["8bde",""],
["8c40",""],
["8ca1",""],
["8ca7",""],
["8cc9",""],
["8cce",""],
["8ce6",""],
["8d40",""],
["8d42",""],
["8da1",""],
["8e40",""],
["8ea1",""],
["8f40",""],
["8fa1",""],
["9040",""],
["90a1",""],
["9140",""],
["91a1",""],
["9240",""],
["92a1",""],
["9340",""],
["93a1",""],
["9440",""],
["94a1",""],
["9540",""],
["95a1",""],
["9640",""],
["96a1",""],
["9740",""],
["97a1",""],
["9840",""],
["98a1",""],
["9940",""],
["99a1",""],
["9a40",""],
["9aa1",""],
["9b40",""],
["9b62",""],
["9ba1",""],
["9c40",""],
["9ca1",""],
["9d40",""],
["9da1",""],
["9e40",""],
["9ea1",""],
["9ead",""],
["9ec5",""],
["9ef5",""],
["9f40",""],
["9f4f",""],
["9fa1",""],
["9fae",""],
["9fb2",""],
["9fc1",""],
["9fc9",""],
["9fdb",""],
["9fe7",""],
["9feb",""],
["9ff0",""],
["a040",""],
["a055",""],
["a058",""],
["a05b",""],
["a063",""],
["a073",""],
["a0a1",""],
["a0a6",""],
["a0ae",""],
["a0b0",""],
["a0d4",""],
["a0e2",""],
["a3c0","",31,""],
["c6a1","",9,"",9,"",9,"",23],
["c740","",58,""],
["c7a1","",81,"",5,"",4],
["c840","",26,"",25,""],
["c8a1",""],
["c8cd",""],
["c8f5",""],
["f9fe",""],
["fa40",""],
["faa1",""],
["fb40",""],
["fba1",""],
["fc40",""],
["fca1",""],
["fd40",""],
["fda1",""],
["fe40",""],
["fea1",""]
]

},{}],24:[function(require,module,exports){
module.exports=[
["0","\u0000",127,""],
["8140","",5,"",9,"",6,""],
["8180","",6,"",4,"",4,"",5,""],
["8240","",4,"",8,"",4,"",11],
["8280","",10,"",4,"",7,"",5,"",8,"",20,"",4,"",6,""],
["8340","",17,"",5,"",10,"",4,"",9,""],
["8380","",5,"",13,"",28,"",4,"",4,"",5],
["8440","",5,"",5,""],
["8480","",9,"",4,"",6,"",6,"",9,"",5,"",10,"",7,""],
["8540","",9,""],
["8580","",4,"",6,"",4,"",4,"",7,""],
["8640","",4,"",5,"",4,"",5,""],
["8680","",4,"",4,"",5,"",6,"",8,"",4,"",4,"",4,""],
["8740","",7,"",11,"",4,"",4],
["8780","",7,"",6,"",14,"",10,"",6,"",12,"",8,"",5,"",6],
["8840","",9,"",4,"",4,""],
["8880","",4,"",6,"",8,"",6,"",7,"",4,"",4,"",7],
["8940","",5,"",6,"",4,"",5,"",4,"",16,""],
["8980","",4,"",4,"",7,"",17,"",10,"",13,"",5,"",7,"",4,""],
["8a40","",4,"",12,""],
["8a80","",5,"",6,"",4,"",11,"",6,"",4,"",4,"",9,"",5],
["8b40","",8,"",17,"",6,"",13,""],
["8b80","",4,"",4,"",5,"",4,"",4,"",22,"",11,"",25,"",7,"",6],
["8c40","",7,""],
["8c80","",8,"",4,"",6,"",6,"",6,"",4,"",4,"",4],
["8d40","",5,"",5,"",5,"",6,"",9,"",4],
["8d80","",5,"",4,"",4,"",4,"",7,"",7,"",10,"",10,"",12,"",21,""],
["8e40","",21,"",12,"",6,"",12,""],
["8e80","",4,"",7,"",4,"",4,"",5,"",6,"",4,"",14,"",4,"",4,"",6],
["8f40","",5,"",11,"",8,""],
["8f80","",6,"",14,"",5,"",5,"",4,""],
["9040","",4,"",4,"",6,""],
["9080","",7,"",4,"",4,"",4,"",4,"",18,"",6],
["9140","",6,"",6,"",18,"",4,""],
["9180","",6,"",8,"",9,"",5,"",4,"",4,"",16,"",13,"",8,"",5,"",4,""],
["9240","",6,"",5,""],
["9280","",5,"",7,"",6,""],
["9340","",6,"",4,"",4,"",5,""],
["9380","",5,"",4,"",6,"",4,"",7,"",9,"",6,"",8,"",4,"",6,""],
["9440","",24,"",7,"",7,"",4,"",8],
["9480","",4,"",4,"",14,"",7,"",7,""],
["9540","",4,"",4,"",6,""],
["9580","",4,"",4,"",8,"",4,"",4,"",25,"",7,"",5,""],
["9640","",5,"",4,""],
["9680","",7,"",9,"",7,"",4,"",6,"",6,"",5],
["9740","",7,"",8,"",7,"",9,""],
["9780","",6,"",5,"",4,"",9,"",4,"",11,"",7,"",16,""],
["9840","",4,"",5,"",9,""],
["9880","",7,"",5,"",11,"",9,"",9,"",11,"",5,"",5,"",6,"",4,"",7,"",6,""],
["9940","",4,"",10,"",6,"",8,"",4,"",7,"",5],
["9980","",114,"",6],
["9a40","",11,"",7,"",13,""],
["9a80","",4,"",7,"",7,"",6,"",4,"",4,"",7,"",6,"",4,"",4,""],
["9b40","",4,""],
["9b80","",5,"",4,"",4,"",5,""],
["9c40","",7,""],
["9c80","",7,"",7,"",10,"",14,"",4,"",6,"",5],
["9d40","",7,"",4,"",9,"",6,""],
["9d80","",9,"",5,"",6,"",12,"",4,"",10,"",5,"",5,"",6,"",10,""],
["9e40","",7,"",32,"",7,"",6,"",6],
["9e80","",9,"",17,"",13,"",11,"",12,"",12,""],
["9f40","",6,"",10,"",4,"",10,"",7,""],
["9f80","",13,"",12,"",4,"",4,"",5,"",4,"",4,"",6,"",5,"",8,"",9,"",4],
["a040","",9,"",5,"",9,"",11,"",19],
["a080","",9,"",6,"",4,"",11,"",11,"",6,""],
["a1a1","",7,""],
["a2a1","",9],
["a2b1","",19,"",19,"",9],
["a2e5","",9],
["a2f1","",11],
["a3a1","",88,""],
["a4a1","",82],
["a5a1","",85],
["a6a1","",16,"",6],
["a6c1","",16,"",6],
["a6e0",""],
["a6ee",""],
["a6f4",""],
["a7a1","",5,"",25],
["a7d1","",5,"",25],
["a840","",35,"",6],
["a880","",7,""],
["a8a1",""],
["a8bd",""],
["a8c0",""],
["a8c5","",36],
["a940","",8,""],
["a959",""],
["a95c",""],
["a960","",9,"",8],
["a980","",4,""],
["a996",""],
["a9a4","",75],
["aa40","",5,"",5,"",8],
["aa80","",7,"",10,""],
["ab40","",11,"",4,"",5,"",4],
["ab80","",6,"",4],
["ac40","",10,"",8,"",5,"",4,"",11],
["ac80","",6,"",12,"",4,""],
["ad40","",10,"",7,"",15,"",12],
["ad80","",9,"",8,"",6,""],
["ae40","",6,"",7,"",4,""],
["ae80","",7,"",6,"",4,""],
["af40","",4,""],
["af80",""],
["b040","",6,"",5,"",4,"",6,"",7,""],
["b080","",7,"",8,"",9,""],
["b140","",4,"",7,"",10,""],
["b180","",4,"",7,"",7,""],
["b240","",11,"",5,"",11,"",4],
["b280","",12,"",8,"",4,""],
["b340","",5,""],
["b380","",11,"",7,"",6,""],
["b440","",7,"",9],
["b480","",4,"",5,"",6,""],
["b540","",5,"",9,"",4,"",14,"",4,"",8,""],
["b580","",6,"",4,""],
["b640","",6,"",11,"",10,"",4,"",5,""],
["b680","",6,"",4,""],
["b740","",14,"",5,"",9,"",4,"",16],
["b780","",6,""],
["b840","",4,"",10,"",10,"",9,"",5,""],
["b880","",4,""],
["b940","",5,"",10,"",6,""],
["b980","",7,""],
["ba40","",4,"",4,"",7,"",5,""],
["ba80","",4,"",5,"",12,"",5,""],
["bb40","",9,"",36,"",5,"",9],
["bb80","",6,"",4,""],
["bc40","",6,"",6,"",5,"",7,"",13,"",5],
["bc80","",14,"",6,""],
["bd40","",54,"",7],
["bd80","",32,""],
["be40","",12,"",6,"",42],
["be80","",32,""],
["bf40","",62],
["bf80","",4,"",4,"",21,""],
["c040","",35,"",23,""],
["c080","",6,"",9,""],
["c140","",4,"",7,"",4,"",4,"",6,""],
["c180","",4,"",4,"",5,""],
["c240","",6,"",5,""],
["c280","",13,"",5,"",11,""],
["c340","",5,"",4,"",6,""],
["c380","",12,"",4,""],
["c440","",5,"",4,"",4,"",5,"",4,""],
["c480","",7,"",5,"",6,""],
["c540","",14,"",4,"",5,"",4,"",5,""],
["c580","",7,"",7,""],
["c640",""],
["c680","",4,"",9,""],
["c740","",4,"",4,"",6,"",6,"",6,""],
["c780",""],
["c840","",4,"",5,"",5,"",7,"",5,"",7,""],
["c880","",6,"",4,"",4,""],
["c940","",4,"",7,"",12,""],
["c980","",4,"",4,"",10,""],
["ca40","",8,"",8,"",9,"",4,"",10],
["ca80","",4,"",8,""],
["cb40","",6,"",10,"",6,"",5,"",6,"",6,"",4,""],
["cb80","",5,"",6,"",14,""],
["cc40","",4,"",10,"",15,"",13,""],
["cc80","",11,"",4,"",7,""],
["cd40","",6,"",6,"",4,"",5,"",4,"",4,""],
["cd80",""],
["ce40","",6,"",5,"",7,""],
["ce80","",4,"",6,"",4,""],
["cf40","",4,"",4,"",6,"",9],
["cf80","",5,"",7,"",4,""],
["d040","",13,"",5,"",5,"",5,"",6,""],
["d080","",4,"",4,"",5,""],
["d140","",4,"",4,"",6,"",5],
["d180","",4,"",4,"",4,""],
["d240","",8,"",24,"",5,"",19,""],
["d280","",26,""],
["d340","",30,"",6],
["d380","",4,"",5,"",21,""],
["d440","",31,"",8,"",21],
["d480","",25,"",6,""],
["d540","",7,"",7,"",46],
["d580","",32,""],
["d640","",34,"",27],
["d680","",30,""],
["d740","",31,"",4,"",25],
["d780","",24,""],
["d840","",8,"",7,"",5,"",6,"",6,"",6,""],
["d880","",6,"",20,""],
["d940","",62],
["d980","",32,""],
["da40","",14,"",8,"",4,"",9,""],
["da80","",12,""],
["db40","",6,"",7,"",4,""],
["db80","",4,"",5,"",11,""],
["dc40","",4,"",6,"",6,"",11,"",6,"",7],
["dc80","",10,"",21,""],
["dd40","",62],
["dd80","",32,""],
["de40","",32,""],
["de80","",4,""],
["df40","",5,"",4,"",4,"",5,"",4,"",6,""],
["df80","",4,""],
["e040","",19,""],
["e080","",10,"",6,"",8,""],
["e140","",4,"",6,"",5,"",5,""],
["e180","",10,"",9,"",8,""],
["e240","",62],
["e280","",32,"",5,""],
["e340","",45,"",16],
["e380","",7,"",24,""],
["e440","",5,"",24,"",31],
["e480","",32,""],
["e540","",51,"",10],
["e580","",31,""],
["e640","",34,"",27],
["e680","",29,""],
["e740","",7,"",54],
["e780","",32,"",6,"",4,""],
["e840","",14,"",43,""],
["e880","",20,""],
["e940","",7,"",42],
["e980","",32,""],
["ea40","",27,"",6,""],
["ea80","",4,"",12,""],
["eb40","",9,"",7,"",9,"",6,""],
["eb80","",4,""],
["ec40","",8,"",4,"",18,"",7],
["ec80","",4,"",7,"",4,"",4,""],
["ed40","",6,"",46],
["ed80","",4,"",23,""],
["ee40","",62],
["ee80","",32,"",4,"",6,""],
["ef40","",5,"",37,"",4],
["ef80","",30,"",4,"",8,""],
["f040","",4,"",28,"",26],
["f080","",9,"",12,"",4,"",6,""],
["f140","",10,"",47],
["f180","",32,""],
["f240","",62],
["f280","",32,""],
["f340","",17,"",6,"",4,""],
["f380","",8,"",6,""],
["f440","",5,"",10,"",10,"",7,"",5],
["f480","",32,""],
["f540","",62],
["f580","",32,""],
["f640","",62],
["f680","",32,"",5,"",5,"",4,"",7,""],
["f740","",62],
["f780","",4,"",4,""],
["f840","",62],
["f880","",32],
["f940","",62],
["f980","",32],
["fa40","",62],
["fa80","",32],
["fb40","",27,"",9,""],
["fb80","",5,"",8,"",5,""],
["fc40","",8,"",4,"",8,"",6],
["fc80","",4,"",5,"",8,""],
["fd40","",4,"",4,"",10,"",38],
["fd80","",5,"",11,"",4,""],
["fe40",""]
]

},{}],25:[function(require,module,exports){
module.exports=[
["0","\u0000",127],
["8141","",4,"",6,""],
["8161","",9,"",5,""],
["8181","",18,"",4,"",6,"",5,"",6,"",7,"",7,"",4,"",4,""],
["8241","",7,"",5],
["8261","",6,"",5,""],
["8281","",7,"",7,"",4,"",10,"",5,"",17,"",7,"",6,"",7,"",18],
["8341","",5,"",5,"",7],
["8361","",18,""],
["8381","",4,"",6,"",5,"",5,"",46,"",6,"",5,"",8],
["8441","",5,"",8],
["8461","",18],
["8481","",7,"",6,"",5,"",10,"",5,"",18,"",5,"",6,"",5,"",26,""],
["8541","",5,"",4,"",6,"",4],
["8561","",5,"",5,"",6,""],
["8581","",6,"",6,"",9,"",26,"",29,"",6,"",5,""],
["8641","",6,"",5,""],
["8661","",6,"",10],
["8681","",22,"",4,"",6,"",5,"",6,"",22,"",4,""],
["8741","",9,"",15],
["8761","",18,""],
["8781","",5,"",7,"",7,"",5,"",6,"",5,"",18,"",6,"",26,"",6,"",4],
["8841","",4,"",5,"",6,"",4],
["8861","",4,""],
["8881","",15,"",4,"",6,"",5,"",54,""],
["8941","",6,"",5,""],
["8961","",10,"",5,""],
["8981","",21,"",18,"",18,"",6,"",6,"",7,"",15],
["8a41","",10,"",6,""],
["8a61","",4,"",18,""],
["8a81","",4,"",19,"",5,"",7,"",5,"",6,"",5,"",4,"",5,"",26,""],
["8b41","",5,"",4,"",6,""],
["8b61","",6,"",8],
["8b81","",52,"",4,"",6,"",5,"",18,"",18],
["8c41","",15,"",4],
["8c61","",6,"",5,"",6,"",5],
["8c81","",12,"",26,"",50,"",5,"",16],
["8d41","",16,"",8],
["8d61","",17,""],
["8d81","",4,"",33,"",6,"",7,"",6,"",9,"",6,"",5,"",6,""],
["8e41","",6,"",5,"",8],
["8e61","",4,"",19],
["8e81","",13,"",6,"",4,"",6,"",5,"",6,"",5,"",11,"",7,"",6,"",5,"",7],
["8f41","",7,"",17],
["8f61","",7,"",6,"",4],
["8f81","",5,"",7,"",5,"",6,"",5,"",18,"",6,"",26,"",6,"",5],
["9041","",6,"",5,""],
["9061","",5,"",15],
["9081","",12,"",6,"",5,"",4,"",6,"",4,"",5,"",11,"",33,""],
["9141","",6,"",5],
["9161","",9,"",5],
["9181","",20,"",4,"",5,"",14,"",33,"",7,"",5,"",6],
["9241","",7,"",4,""],
["9261","",7,"",7,"",4],
["9281","",21,"",18,"",6,"",7,"",6,"",35,""],
["9341","",4,""],
["9361","",6,"",8],
["9381","",37,"",4,"",4,"",6,"",5,"",7,"",22,""],
["9441","",5,"",5,"",8],
["9461","",5,"",6,"",12],
["9481","",5,"",6,"",6,"",9,"",22,"",4,"",6,"",10,"",6,"",24],
["9541","",11,"",5,""],
["9561","",6,"",5,""],
["9581","",6,"",35,"",4,"",4,"",4,"",6,"",5,"",13,"",14],
["9641","",23,""],
["9661","",6,"",5,"",8],
["9681","",10,"",5,"",13,"",33,"",6,"",44],
["9741","",16,"",8],
["9761","",17,"",7],
["9781","",11,"",5,"",6,"",89,""],
["9841","",16,"",5,""],
["9861","",6,"",15],
["9881","",21,"",6,"",5,"",4,"",6,"",5,"",6,"",5,"",6,"",5,""],
["9941","",6,"",5,""],
["9961","",6,"",5,""],
["9981","",8,"",5,"",4,"",11,"",5,"",6,"",6,"",6,"",7,"",6,"",5,""],
["9a41","",16],
["9a61","",6,"",6,""],
["9a81","",4,"",6,"",5,"",5,"",6,"",5,"",5,"",33,"",5,"",6,""],
["9b41","",6,"",8],
["9b61","",17,"",7],
["9b81","",25,"",4,"",5,"",50,"",22,""],
["9c41","",4,"",5,"",5],
["9c61","",8,"",6,"",9],
["9c81","",8,"",6,"",6,"",9,"",26,"",6,"",5,"",18,"",6,"",12],
["9d41","",13,"",8],
["9d61","",25],
["9d81","",8,"",5,"",9,"",6,"",10,"",6,"",5,"",6,"",5,""],
["9e41","",7,"",9,""],
["9e61","",4,"",6,""],
["9e81","",6,"",6,"",6,"",5,"",10,"",5,"",6,"",5,"",6,""],
["9f41","",5,"",4,"",5,""],
["9f61","",6,"",5,""],
["9f81","",4,"",5,"",6,"",5,"",6,"",4,"",6,"",7,"",4,"",4,""],
["a041","",5,"",6,""],
["a061","",5,"",13],
["a081","",4,"",4,"",4,"",6,"",5,"",6,"",5,"",26,"",4,"",5,"",7,""],
["a141","",18,""],
["a161","",6,"",5,""],
["a181","",14,"",5,"",4,"",9,""],
["a241","",5,"",18],
["a261","",6,"",18],
["a281","",7,"",6,"",7,""],
["a341","",6,"",10,""],
["a361","",6,"",16],
["a381","",16,"",4,"",58,"",32,""],
["a441","",5,""],
["a461","",5,"",12],
["a481","",28,"",93],
["a541","",4,"",6,"",5,""],
["a561","",17,"",5,""],
["a581","",16,"",14,"",9],
["a5b0","",9],
["a5c1","",16,"",6],
["a5e1","",16,"",6],
["a641","",19,""],
["a661","",5,"",5,"",6],
["a681","",6,"",18,"",7],
["a741","",4,"",6,"",7],
["a761","",22,""],
["a781","",6,"",5,"",7,"",9,"",9,"",4,"",5,"",4,""],
["a841","",10,"",14],
["a861","",18,"",6],
["a881","",19,"",11,""],
["a8a6",""],
["a8a8",""],
["a8b1","",27,"",25,"",14,""],
["a941","",14,"",10],
["a961","",18],
["a981","",14,"",6,"",27,"",25,"",14,""],
["aa41","",6,"",4,""],
["aa61","",4,"",5,"",6,""],
["aa81","",29,"",82],
["ab41","",6,"",5,""],
["ab61","",6,"",5,"",5],
["ab81","",8,"",6,"",12,"",85],
["ac41","",5,"",6,""],
["ac61","",11,"",4],
["ac81","",28,"",5,"",25],
["acd1","",5,"",25],
["ad41","",6,"",5,"",7],
["ad61","",6,"",10,""],
["ad81","",5,"",18,""],
["ae41","",5,"",16],
["ae61","",5,"",6,"",4],
["ae81","",6,"",5,""],
["af41","",19],
["af61","",13,"",5,""],
["af81","",5,"",6,"",5,""],
["b041","",5,"",5,"",12],
["b061","",5,"",19],
["b081","",13,"",6,"",5,"",7,"",4,""],
["b141","",6,"",5,""],
["b161","",6,"",5,"",11],
["b181","",14,"",6,""],
["b241","",6,"",5,""],
["b261","",18,"",5,""],
["b281","",5,"",18,"",6,""],
["b341","",19,""],
["b361","",5,"",5,"",5],
["b381","",5,"",5,"",19,"",4,""],
["b441","",5,"",6,"",5],
["b461","",6,"",10,""],
["b481","",6,"",18,"",4,"",4,""],
["b541","",14,"",5],
["b561","",5,"",5,"",4],
["b581","",6,"",5,"",11,""],
["b641","",7,"",17],
["b661","",15,""],
["b681","",5,"",6,"",5,""],
["b741","",13,"",6,""],
["b761","",20,""],
["b781","",6,"",14,""],
["b841","",7,"",17],
["b861","",8,"",13],
["b881","",5,"",24,"",4,""],
["b941","",6,"",5,""],
["b961","",14,"",6,""],
["b981","",22,"",4,"",4,""],
["ba41","",5,"",6,""],
["ba61","",5,"",4,"",5],
["ba81","",6,"",9,""],
["bb41","",4,"",5,"",4,""],
["bb61","",6,"",5,""],
["bb81","",31,""],
["bc41","",17,""],
["bc61","",5,"",6,""],
["bc81","",4,"",6,"",5,"",5,"",4,""],
["bd41","",7,"",7,""],
["bd61","",5,"",13],
["bd81","",5,"",25,""],
["be41","",7,"",14],
["be61","",7,"",7,""],
["be81","",4,"",4,"",5,"",8,"",6,""],
["bf41","",10,"",14],
["bf61","",18,""],
["bf81","",5,"",7,"",6,"",5,""],
["c041","",5,"",6,"",5],
["c061","",25],
["c081","",6,"",5,"",7,""],
["c141","",5,"",6,""],
["c161","",19,""],
["c181","",31,""],
["c241","",4,"",5,""],
["c261","",4,"",5,"",6,""],
["c281","",5,"",7,"",9,""],
["c341","",4],
["c361","",4,"",5,"",11],
["c381","",5,"",7,"",5,""],
["c441","",7,"",7,""],
["c461","",5,"",4],
["c481","",5,"",11,""],
["c541","",6,"",5,""],
["c561","",6,"",5,"",4],
["c581","",6,"",5,""],
["c641","",6,"",5],
["c6a1",""],
["c7a1",""],
["c8a1",""],
["caa1",""],
["cba1",""],
["cca1",""],
["cda1",""],
["cea1",""],
["cfa1",""],
["d0a1",""],
["d1a1","",5,"",4,""],
["d2a1","",4,"",5,"",10,"",7,"",5,""],
["d3a1",""],
["d4a1",""],
["d5a1",""],
["d6a1",""],
["d7a1",""],
["d8a1",""],
["d9a1",""],
["daa1",""],
["dba1",""],
["dca1",""],
["dda1",""],
["dea1",""],
["dfa1",""],
["e0a1",""],
["e1a1",""],
["e2a1",""],
["e3a1",""],
["e4a1",""],
["e5a1",""],
["e6a1",""],
["e7a1",""],
["e8a1",""],
["e9a1",""],
["eaa1",""],
["eba1",""],
["eca1",""],
["eda1",""],
["eea1",""],
["efa1",""],
["f0a1",""],
["f1a1",""],
["f2a1",""],
["f3a1",""],
["f4a1",""],
["f5a1",""],
["f6a1",""],
["f7a1",""],
["f8a1",""],
["f9a1",""],
["faa1",""],
["fba1",""],
["fca1",""],
["fda1",""]
]

},{}],26:[function(require,module,exports){
module.exports=[
["0","\u0000",127],
["a140",""],
["a1a1","",4,""],
["a240","",7,""],
["a2a1","",9,"",9,"",8,"",25,"",21],
["a340","",16,"",6,"",16,"",6,"",10],
["a3a1","",25,""],
["a3e1",""],
["a440",""],
["a4a1",""],
["a540",""],
["a5a1",""],
["a640",""],
["a6a1",""],
["a740",""],
["a7a1",""],
["a840",""],
["a8a1",""],
["a940",""],
["a9a1",""],
["aa40",""],
["aaa1",""],
["ab40",""],
["aba1",""],
["ac40",""],
["aca1",""],
["ad40",""],
["ada1",""],
["ae40",""],
["aea1",""],
["af40",""],
["afa1",""],
["b040",""],
["b0a1",""],
["b140",""],
["b1a1",""],
["b240",""],
["b2a1",""],
["b340",""],
["b3a1",""],
["b440",""],
["b4a1",""],
["b540",""],
["b5a1",""],
["b640",""],
["b6a1",""],
["b740",""],
["b7a1",""],
["b840",""],
["b8a1",""],
["b940",""],
["b9a1",""],
["ba40",""],
["baa1",""],
["bb40",""],
["bba1",""],
["bc40",""],
["bca1",""],
["bd40",""],
["bda1",""],
["be40",""],
["bea1",""],
["bf40",""],
["bfa1",""],
["c040",""],
["c0a1",""],
["c140",""],
["c1a1",""],
["c240",""],
["c2a1",""],
["c340",""],
["c3a1",""],
["c440",""],
["c4a1",""],
["c540",""],
["c5a1",""],
["c640",""],
["c940",""],
["c9a1",""],
["ca40",""],
["caa1",""],
["cb40",""],
["cba1",""],
["cc40",""],
["cca1",""],
["cd40",""],
["cda1",""],
["ce40",""],
["cea1",""],
["cf40",""],
["cfa1",""],
["d040",""],
["d0a1",""],
["d140",""],
["d1a1",""],
["d240",""],
["d2a1",""],
["d340",""],
["d3a1",""],
["d440",""],
["d4a1",""],
["d540",""],
["d5a1",""],
["d640",""],
["d6a1",""],
["d740",""],
["d7a1",""],
["d840",""],
["d8a1",""],
["d940",""],
["d9a1",""],
["da40",""],
["daa1",""],
["db40",""],
["dba1",""],
["dc40",""],
["dca1",""],
["dd40",""],
["dda1",""],
["de40",""],
["dea1",""],
["df40",""],
["dfa1",""],
["e040",""],
["e0a1",""],
["e140",""],
["e1a1",""],
["e240",""],
["e2a1",""],
["e340",""],
["e3a1",""],
["e440",""],
["e4a1",""],
["e540",""],
["e5a1",""],
["e640",""],
["e6a1",""],
["e740",""],
["e7a1",""],
["e840",""],
["e8a1",""],
["e940",""],
["e9a1",""],
["ea40",""],
["eaa1",""],
["eb40",""],
["eba1",""],
["ec40",""],
["eca1",""],
["ed40",""],
["eda1",""],
["ee40",""],
["eea1",""],
["ef40",""],
["efa1",""],
["f040",""],
["f0a1",""],
["f140",""],
["f1a1",""],
["f240",""],
["f2a1",""],
["f340",""],
["f3a1",""],
["f440",""],
["f4a1",""],
["f540",""],
["f5a1",""],
["f640",""],
["f6a1",""],
["f740",""],
["f7a1",""],
["f840",""],
["f8a1",""],
["f940",""],
["f9a1",""]
]

},{}],27:[function(require,module,exports){
module.exports=[
["0","\u0000",127],
["8ea1","",62],
["a1a1","",9,""],
["a2a1",""],
["a2ba",""],
["a2ca",""],
["a2dc",""],
["a2f2",""],
["a2fe",""],
["a3b0","",9],
["a3c1","",25],
["a3e1","",25],
["a4a1","",82],
["a5a1","",85],
["a6a1","",16,"",6],
["a6c1","",16,"",6],
["a7a1","",5,"",25],
["a7d1","",5,"",25],
["a8a1",""],
["ada1","",19,"",9],
["adc0",""],
["addf","",4,""],
["b0a1",""],
["b1a1",""],
["b2a1",""],
["b3a1",""],
["b4a1",""],
["b5a1",""],
["b6a1",""],
["b7a1",""],
["b8a1",""],
["b9a1",""],
["baa1",""],
["bba1",""],
["bca1",""],
["bda1",""],
["bea1",""],
["bfa1",""],
["c0a1",""],
["c1a1",""],
["c2a1",""],
["c3a1",""],
["c4a1",""],
["c5a1",""],
["c6a1",""],
["c7a1",""],
["c8a1",""],
["c9a1",""],
["caa1",""],
["cba1",""],
["cca1",""],
["cda1",""],
["cea1",""],
["cfa1",""],
["d0a1",""],
["d1a1",""],
["d2a1",""],
["d3a1",""],
["d4a1",""],
["d5a1",""],
["d6a1",""],
["d7a1",""],
["d8a1",""],
["d9a1",""],
["daa1",""],
["dba1",""],
["dca1",""],
["dda1",""],
["dea1",""],
["dfa1",""],
["e0a1",""],
["e1a1",""],
["e2a1",""],
["e3a1",""],
["e4a1",""],
["e5a1",""],
["e6a1",""],
["e7a1",""],
["e8a1",""],
["e9a1",""],
["eaa1",""],
["eba1",""],
["eca1",""],
["eda1",""],
["eea1",""],
["efa1",""],
["f0a1",""],
["f1a1",""],
["f2a1",""],
["f3a1",""],
["f4a1",""],
["f9a1",""],
["faa1",""],
["fba1",""],
["fca1",""],
["fcf1","",9,""],
["8fa2af",""],
["8fa2c2",""],
["8fa2eb",""],
["8fa6e1",""],
["8fa6e7",""],
["8fa6e9",""],
["8fa6ec",""],
["8fa6f1",""],
["8fa7c2","",10,""],
["8fa7f2","",10,""],
["8fa9a1",""],
["8fa9a4",""],
["8fa9a6",""],
["8fa9a8",""],
["8fa9ab",""],
["8fa9af",""],
["8fa9c1",""],
["8faaa1",""],
["8faaba",""],
["8faba1",""],
["8fabbd",""],
["8fabc5",""],
["8fb0a1",""],
["8fb1a1",""],
["8fb2a1","",4,""],
["8fb3a1",""],
["8fb4a1",""],
["8fb5a1",""],
["8fb6a1","",5,"",4,""],
["8fb7a1","",4,""],
["8fb8a1",""],
["8fb9a1",""],
["8fbaa1","",4,""],
["8fbba1",""],
["8fbca1","",4,""],
["8fbda1","",4,""],
["8fbea1","",4,""],
["8fbfa1",""],
["8fc0a1",""],
["8fc1a1",""],
["8fc2a1",""],
["8fc3a1","",4,""],
["8fc4a1",""],
["8fc5a1",""],
["8fc6a1",""],
["8fc7a1",""],
["8fc8a1",""],
["8fc9a1","",4,"",4,""],
["8fcaa1",""],
["8fcba1",""],
["8fcca1","",9,""],
["8fcda1","",5,""],
["8fcea1","",6,""],
["8fcfa1",""],
["8fd0a1",""],
["8fd1a1",""],
["8fd2a1","",5],
["8fd3a1",""],
["8fd4a1","",4,""],
["8fd5a1",""],
["8fd6a1",""],
["8fd7a1",""],
["8fd8a1",""],
["8fd9a1","",4,"",6,""],
["8fdaa1","",4,""],
["8fdba1","",6,""],
["8fdca1","",4,""],
["8fdda1","",4,""],
["8fdea1","",4,""],
["8fdfa1",""],
["8fe0a1",""],
["8fe1a1","",4,""],
["8fe2a1",""],
["8fe3a1","",5,"",4,""],
["8fe4a1","",4,""],
["8fe5a1","",4,""],
["8fe6a1",""],
["8fe7a1",""],
["8fe8a1","",4,""],
["8fe9a1","",4],
["8feaa1","",4,""],
["8feba1","",4,""],
["8feca1",""],
["8feda1","",4,"",4,""]
]

},{}],28:[function(require,module,exports){
module.exports={"uChars":[128,165,169,178,184,216,226,235,238,244,248,251,253,258,276,284,300,325,329,334,364,463,465,467,469,471,473,475,477,506,594,610,712,716,730,930,938,962,970,1026,1104,1106,8209,8215,8218,8222,8231,8241,8244,8246,8252,8365,8452,8454,8458,8471,8482,8556,8570,8596,8602,8713,8720,8722,8726,8731,8737,8740,8742,8748,8751,8760,8766,8777,8781,8787,8802,8808,8816,8854,8858,8870,8896,8979,9322,9372,9548,9588,9616,9622,9634,9652,9662,9672,9676,9680,9702,9735,9738,9793,9795,11906,11909,11913,11917,11928,11944,11947,11951,11956,11960,11964,11979,12284,12292,12312,12319,12330,12351,12436,12447,12535,12543,12586,12842,12850,12964,13200,13215,13218,13253,13263,13267,13270,13384,13428,13727,13839,13851,14617,14703,14801,14816,14964,15183,15471,15585,16471,16736,17208,17325,17330,17374,17623,17997,18018,18212,18218,18301,18318,18760,18811,18814,18820,18823,18844,18848,18872,19576,19620,19738,19887,40870,59244,59336,59367,59413,59417,59423,59431,59437,59443,59452,59460,59478,59493,63789,63866,63894,63976,63986,64016,64018,64021,64025,64034,64037,64042,65074,65093,65107,65112,65127,65132,65375,65510,65536],"gbChars":[0,36,38,45,50,81,89,95,96,100,103,104,105,109,126,133,148,172,175,179,208,306,307,308,309,310,311,312,313,341,428,443,544,545,558,741,742,749,750,805,819,820,7922,7924,7925,7927,7934,7943,7944,7945,7950,8062,8148,8149,8152,8164,8174,8236,8240,8262,8264,8374,8380,8381,8384,8388,8390,8392,8393,8394,8396,8401,8406,8416,8419,8424,8437,8439,8445,8482,8485,8496,8521,8603,8936,8946,9046,9050,9063,9066,9076,9092,9100,9108,9111,9113,9131,9162,9164,9218,9219,11329,11331,11334,11336,11346,11361,11363,11366,11370,11372,11375,11389,11682,11686,11687,11692,11694,11714,11716,11723,11725,11730,11736,11982,11989,12102,12336,12348,12350,12384,12393,12395,12397,12510,12553,12851,12962,12973,13738,13823,13919,13933,14080,14298,14585,14698,15583,15847,16318,16434,16438,16481,16729,17102,17122,17315,17320,17402,17418,17859,17909,17911,17915,17916,17936,17939,17961,18664,18703,18814,18962,19043,33469,33470,33471,33484,33485,33490,33497,33501,33505,33513,33520,33536,33550,37845,37921,37948,38029,38038,38064,38065,38066,38069,38075,38076,38078,39108,39109,39113,39114,39115,39116,39265,39394,189000]}
},{}],29:[function(require,module,exports){
module.exports=[
["a140","",62],
["a180","",32],
["a240","",62],
["a280","",32],
["a2ab","",5],
["a2e3",""],
["a2ef",""],
["a2fd",""],
["a340","",62],
["a380","",31,""],
["a440","",62],
["a480","",32],
["a4f4","",10],
["a540","",62],
["a580","",32],
["a5f7","",7],
["a640","",62],
["a680","",32],
["a6b9","",7],
["a6d9","",6],
["a6ec",""],
["a6f3",""],
["a6f6","",8],
["a740","",62],
["a780","",32],
["a7c2","",14],
["a7f2","",12],
["a896","",10],
["a8bc",""],
["a8bf",""],
["a8c1",""],
["a8ea","",20],
["a958",""],
["a95b",""],
["a95d",""],
["a989","",11],
["a997","",12],
["a9f0","",14],
["aaa1","",93],
["aba1","",93],
["aca1","",93],
["ada1","",93],
["aea1","",93],
["afa1","",93],
["d7fa","",4],
["f8a1","",93],
["f9a1","",93],
["faa1","",93],
["fba1","",93],
["fca1","",93],
["fda1","",93],
["fe50",""],
["fe80","",6,"",93]
]

},{}],30:[function(require,module,exports){
module.exports=[
["0","\u0000",128],
["a1","",62],
["8140","",9,""],
["8180",""],
["81b8",""],
["81c8",""],
["81da",""],
["81f0",""],
["81fc",""],
["824f","",9],
["8260","",25],
["8281","",25],
["829f","",82],
["8340","",62],
["8380","",22],
["839f","",16,"",6],
["83bf","",16,"",6],
["8440","",5,"",25],
["8470","",5,"",7],
["8480","",17],
["849f",""],
["8740","",19,"",9],
["875f",""],
["877e",""],
["8780","",4,""],
["889f",""],
["8940",""],
["8980",""],
["8a40",""],
["8a80",""],
["8b40",""],
["8b80",""],
["8c40",""],
["8c80",""],
["8d40",""],
["8d80",""],
["8e40",""],
["8e80",""],
["8f40",""],
["8f80",""],
["9040",""],
["9080",""],
["9140",""],
["9180",""],
["9240",""],
["9280",""],
["9340",""],
["9380",""],
["9440",""],
["9480",""],
["9540",""],
["9580",""],
["9640",""],
["9680",""],
["9740",""],
["9780",""],
["9840",""],
["989f",""],
["9940",""],
["9980",""],
["9a40",""],
["9a80",""],
["9b40",""],
["9b80",""],
["9c40",""],
["9c80",""],
["9d40",""],
["9d80",""],
["9e40",""],
["9e80",""],
["9f40",""],
["9f80",""],
["e040",""],
["e080",""],
["e140",""],
["e180",""],
["e240",""],
["e280",""],
["e340",""],
["e380",""],
["e440",""],
["e480",""],
["e540",""],
["e580",""],
["e640",""],
["e680",""],
["e740",""],
["e780",""],
["e840",""],
["e880",""],
["e940",""],
["e980",""],
["ea40",""],
["ea80",""],
["ed40",""],
["ed80",""],
["ee40",""],
["ee80",""],
["eeef","",9,""],
["f040","",62],
["f080","",124],
["f140","",62],
["f180","",124],
["f240","",62],
["f280","",124],
["f340","",62],
["f380","",124],
["f440","",62],
["f480","",124],
["f540","",62],
["f580","",124],
["f640","",62],
["f680","",124],
["f740","",62],
["f780","",124],
["f840","",62],
["f880","",124],
["f940",""],
["fa40","",9,"",9,""],
["fa80",""],
["fb40",""],
["fb80",""],
["fc40",""]
]

},{}],31:[function(require,module,exports){
"use strict";
var Buffer = require("safer-buffer").Buffer;

// Note: UTF16-LE (or UCS2) codec is Node.js native. See encodings/internal.js

// == UTF16-BE codec. ==========================================================

exports.utf16be = Utf16BECodec;
function Utf16BECodec() {
}

Utf16BECodec.prototype.encoder = Utf16BEEncoder;
Utf16BECodec.prototype.decoder = Utf16BEDecoder;
Utf16BECodec.prototype.bomAware = true;


// -- Encoding

function Utf16BEEncoder() {
}

Utf16BEEncoder.prototype.write = function(str) {
    var buf = Buffer.from(str, 'ucs2');
    for (var i = 0; i < buf.length; i += 2) {
        var tmp = buf[i]; buf[i] = buf[i+1]; buf[i+1] = tmp;
    }
    return buf;
}

Utf16BEEncoder.prototype.end = function() {
}


// -- Decoding

function Utf16BEDecoder() {
    this.overflowByte = -1;
}

Utf16BEDecoder.prototype.write = function(buf) {
    if (buf.length == 0)
        return '';

    var buf2 = Buffer.alloc(buf.length + 1),
        i = 0, j = 0;

    if (this.overflowByte !== -1) {
        buf2[0] = buf[0];
        buf2[1] = this.overflowByte;
        i = 1; j = 2;
    }

    for (; i < buf.length-1; i += 2, j+= 2) {
        buf2[j] = buf[i+1];
        buf2[j+1] = buf[i];
    }

    this.overflowByte = (i == buf.length-1) ? buf[buf.length-1] : -1;

    return buf2.slice(0, j).toString('ucs2');
}

Utf16BEDecoder.prototype.end = function() {
}


// == UTF-16 codec =============================================================
// Decoder chooses automatically from UTF-16LE and UTF-16BE using BOM and space-based heuristic.
// Defaults to UTF-16LE, as it's prevalent and default in Node.
// http://en.wikipedia.org/wiki/UTF-16 and http://encoding.spec.whatwg.org/#utf-16le
// Decoder default can be changed: iconv.decode(buf, 'utf16', {defaultEncoding: 'utf-16be'});

// Encoder uses UTF-16LE and prepends BOM (which can be overridden with addBOM: false).

exports.utf16 = Utf16Codec;
function Utf16Codec(codecOptions, iconv) {
    this.iconv = iconv;
}

Utf16Codec.prototype.encoder = Utf16Encoder;
Utf16Codec.prototype.decoder = Utf16Decoder;


// -- Encoding (pass-through)

function Utf16Encoder(options, codec) {
    options = options || {};
    if (options.addBOM === undefined)
        options.addBOM = true;
    this.encoder = codec.iconv.getEncoder('utf-16le', options);
}

Utf16Encoder.prototype.write = function(str) {
    return this.encoder.write(str);
}

Utf16Encoder.prototype.end = function() {
    return this.encoder.end();
}


// -- Decoding

function Utf16Decoder(options, codec) {
    this.decoder = null;
    this.initialBytes = [];
    this.initialBytesLen = 0;

    this.options = options || {};
    this.iconv = codec.iconv;
}

Utf16Decoder.prototype.write = function(buf) {
    if (!this.decoder) {
        // Codec is not chosen yet. Accumulate initial bytes.
        this.initialBytes.push(buf);
        this.initialBytesLen += buf.length;
        
        if (this.initialBytesLen < 16) // We need more bytes to use space heuristic (see below)
            return '';

        // We have enough bytes -> detect endianness.
        var buf = Buffer.concat(this.initialBytes),
            encoding = detectEncoding(buf, this.options.defaultEncoding);
        this.decoder = this.iconv.getDecoder(encoding, this.options);
        this.initialBytes.length = this.initialBytesLen = 0;
    }

    return this.decoder.write(buf);
}

Utf16Decoder.prototype.end = function() {
    if (!this.decoder) {
        var buf = Buffer.concat(this.initialBytes),
            encoding = detectEncoding(buf, this.options.defaultEncoding);
        this.decoder = this.iconv.getDecoder(encoding, this.options);

        var res = this.decoder.write(buf),
            trail = this.decoder.end();

        return trail ? (res + trail) : res;
    }
    return this.decoder.end();
}

function detectEncoding(buf, defaultEncoding) {
    var enc = defaultEncoding || 'utf-16le';

    if (buf.length >= 2) {
        // Check BOM.
        if (buf[0] == 0xFE && buf[1] == 0xFF) // UTF-16BE BOM
            enc = 'utf-16be';
        else if (buf[0] == 0xFF && buf[1] == 0xFE) // UTF-16LE BOM
            enc = 'utf-16le';
        else {
            // No BOM found. Try to deduce encoding from initial content.
            // Most of the time, the content has ASCII chars (U+00**), but the opposite (U+**00) is uncommon.
            // So, we count ASCII as if it was LE or BE, and decide from that.
            var asciiCharsLE = 0, asciiCharsBE = 0, // Counts of chars in both positions
                _len = Math.min(buf.length - (buf.length % 2), 64); // Len is always even.

            for (var i = 0; i < _len; i += 2) {
                if (buf[i] === 0 && buf[i+1] !== 0) asciiCharsBE++;
                if (buf[i] !== 0 && buf[i+1] === 0) asciiCharsLE++;
            }

            if (asciiCharsBE > asciiCharsLE)
                enc = 'utf-16be';
            else if (asciiCharsBE < asciiCharsLE)
                enc = 'utf-16le';
        }
    }

    return enc;
}



},{"safer-buffer":51}],32:[function(require,module,exports){
"use strict";
var Buffer = require("safer-buffer").Buffer;

// UTF-7 codec, according to https://tools.ietf.org/html/rfc2152
// See also below a UTF-7-IMAP codec, according to http://tools.ietf.org/html/rfc3501#section-5.1.3

exports.utf7 = Utf7Codec;
exports.unicode11utf7 = 'utf7'; // Alias UNICODE-1-1-UTF-7
function Utf7Codec(codecOptions, iconv) {
    this.iconv = iconv;
};

Utf7Codec.prototype.encoder = Utf7Encoder;
Utf7Codec.prototype.decoder = Utf7Decoder;
Utf7Codec.prototype.bomAware = true;


// -- Encoding

var nonDirectChars = /[^A-Za-z0-9'\(\),-\.\/:\? \n\r\t]+/g;

function Utf7Encoder(options, codec) {
    this.iconv = codec.iconv;
}

Utf7Encoder.prototype.write = function(str) {
    // Naive implementation.
    // Non-direct chars are encoded as "+<base64>-"; single "+" char is encoded as "+-".
    return Buffer.from(str.replace(nonDirectChars, function(chunk) {
        return "+" + (chunk === '+' ? '' : 
            this.iconv.encode(chunk, 'utf16-be').toString('base64').replace(/=+$/, '')) 
            + "-";
    }.bind(this)));
}

Utf7Encoder.prototype.end = function() {
}


// -- Decoding

function Utf7Decoder(options, codec) {
    this.iconv = codec.iconv;
    this.inBase64 = false;
    this.base64Accum = '';
}

var base64Regex = /[A-Za-z0-9\/+]/;
var base64Chars = [];
for (var i = 0; i < 256; i++)
    base64Chars[i] = base64Regex.test(String.fromCharCode(i));

var plusChar = '+'.charCodeAt(0), 
    minusChar = '-'.charCodeAt(0),
    andChar = '&'.charCodeAt(0);

Utf7Decoder.prototype.write = function(buf) {
    var res = "", lastI = 0,
        inBase64 = this.inBase64,
        base64Accum = this.base64Accum;

    // The decoder is more involved as we must handle chunks in stream.

    for (var i = 0; i < buf.length; i++) {
        if (!inBase64) { // We're in direct mode.
            // Write direct chars until '+'
            if (buf[i] == plusChar) {
                res += this.iconv.decode(buf.slice(lastI, i), "ascii"); // Write direct chars.
                lastI = i+1;
                inBase64 = true;
            }
        } else { // We decode base64.
            if (!base64Chars[buf[i]]) { // Base64 ended.
                if (i == lastI && buf[i] == minusChar) {// "+-" -> "+"
                    res += "+";
                } else {
                    var b64str = base64Accum + buf.slice(lastI, i).toString();
                    res += this.iconv.decode(Buffer.from(b64str, 'base64'), "utf16-be");
                }

                if (buf[i] != minusChar) // Minus is absorbed after base64.
                    i--;

                lastI = i+1;
                inBase64 = false;
                base64Accum = '';
            }
        }
    }

    if (!inBase64) {
        res += this.iconv.decode(buf.slice(lastI), "ascii"); // Write direct chars.
    } else {
        var b64str = base64Accum + buf.slice(lastI).toString();

        var canBeDecoded = b64str.length - (b64str.length % 8); // Minimal chunk: 2 quads -> 2x3 bytes -> 3 chars.
        base64Accum = b64str.slice(canBeDecoded); // The rest will be decoded in future.
        b64str = b64str.slice(0, canBeDecoded);

        res += this.iconv.decode(Buffer.from(b64str, 'base64'), "utf16-be");
    }

    this.inBase64 = inBase64;
    this.base64Accum = base64Accum;

    return res;
}

Utf7Decoder.prototype.end = function() {
    var res = "";
    if (this.inBase64 && this.base64Accum.length > 0)
        res = this.iconv.decode(Buffer.from(this.base64Accum, 'base64'), "utf16-be");

    this.inBase64 = false;
    this.base64Accum = '';
    return res;
}


// UTF-7-IMAP codec.
// RFC3501 Sec. 5.1.3 Modified UTF-7 (http://tools.ietf.org/html/rfc3501#section-5.1.3)
// Differences:
//  * Base64 part is started by "&" instead of "+"
//  * Direct characters are 0x20-0x7E, except "&" (0x26)
//  * In Base64, "," is used instead of "/"
//  * Base64 must not be used to represent direct characters.
//  * No implicit shift back from Base64 (should always end with '-')
//  * String must end in non-shifted position.
//  * "-&" while in base64 is not allowed.


exports.utf7imap = Utf7IMAPCodec;
function Utf7IMAPCodec(codecOptions, iconv) {
    this.iconv = iconv;
};

Utf7IMAPCodec.prototype.encoder = Utf7IMAPEncoder;
Utf7IMAPCodec.prototype.decoder = Utf7IMAPDecoder;
Utf7IMAPCodec.prototype.bomAware = true;


// -- Encoding

function Utf7IMAPEncoder(options, codec) {
    this.iconv = codec.iconv;
    this.inBase64 = false;
    this.base64Accum = Buffer.alloc(6);
    this.base64AccumIdx = 0;
}

Utf7IMAPEncoder.prototype.write = function(str) {
    var inBase64 = this.inBase64,
        base64Accum = this.base64Accum,
        base64AccumIdx = this.base64AccumIdx,
        buf = Buffer.alloc(str.length*5 + 10), bufIdx = 0;

    for (var i = 0; i < str.length; i++) {
        var uChar = str.charCodeAt(i);
        if (0x20 <= uChar && uChar <= 0x7E) { // Direct character or '&'.
            if (inBase64) {
                if (base64AccumIdx > 0) {
                    bufIdx += buf.write(base64Accum.slice(0, base64AccumIdx).toString('base64').replace(/\//g, ',').replace(/=+$/, ''), bufIdx);
                    base64AccumIdx = 0;
                }

                buf[bufIdx++] = minusChar; // Write '-', then go to direct mode.
                inBase64 = false;
            }

            if (!inBase64) {
                buf[bufIdx++] = uChar; // Write direct character

                if (uChar === andChar)  // Ampersand -> '&-'
                    buf[bufIdx++] = minusChar;
            }

        } else { // Non-direct character
            if (!inBase64) {
                buf[bufIdx++] = andChar; // Write '&', then go to base64 mode.
                inBase64 = true;
            }
            if (inBase64) {
                base64Accum[base64AccumIdx++] = uChar >> 8;
                base64Accum[base64AccumIdx++] = uChar & 0xFF;

                if (base64AccumIdx == base64Accum.length) {
                    bufIdx += buf.write(base64Accum.toString('base64').replace(/\//g, ','), bufIdx);
                    base64AccumIdx = 0;
                }
            }
        }
    }

    this.inBase64 = inBase64;
    this.base64AccumIdx = base64AccumIdx;

    return buf.slice(0, bufIdx);
}

Utf7IMAPEncoder.prototype.end = function() {
    var buf = Buffer.alloc(10), bufIdx = 0;
    if (this.inBase64) {
        if (this.base64AccumIdx > 0) {
            bufIdx += buf.write(this.base64Accum.slice(0, this.base64AccumIdx).toString('base64').replace(/\//g, ',').replace(/=+$/, ''), bufIdx);
            this.base64AccumIdx = 0;
        }

        buf[bufIdx++] = minusChar; // Write '-', then go to direct mode.
        this.inBase64 = false;
    }

    return buf.slice(0, bufIdx);
}


// -- Decoding

function Utf7IMAPDecoder(options, codec) {
    this.iconv = codec.iconv;
    this.inBase64 = false;
    this.base64Accum = '';
}

var base64IMAPChars = base64Chars.slice();
base64IMAPChars[','.charCodeAt(0)] = true;

Utf7IMAPDecoder.prototype.write = function(buf) {
    var res = "", lastI = 0,
        inBase64 = this.inBase64,
        base64Accum = this.base64Accum;

    // The decoder is more involved as we must handle chunks in stream.
    // It is forgiving, closer to standard UTF-7 (for example, '-' is optional at the end).

    for (var i = 0; i < buf.length; i++) {
        if (!inBase64) { // We're in direct mode.
            // Write direct chars until '&'
            if (buf[i] == andChar) {
                res += this.iconv.decode(buf.slice(lastI, i), "ascii"); // Write direct chars.
                lastI = i+1;
                inBase64 = true;
            }
        } else { // We decode base64.
            if (!base64IMAPChars[buf[i]]) { // Base64 ended.
                if (i == lastI && buf[i] == minusChar) { // "&-" -> "&"
                    res += "&";
                } else {
                    var b64str = base64Accum + buf.slice(lastI, i).toString().replace(/,/g, '/');
                    res += this.iconv.decode(Buffer.from(b64str, 'base64'), "utf16-be");
                }

                if (buf[i] != minusChar) // Minus may be absorbed after base64.
                    i--;

                lastI = i+1;
                inBase64 = false;
                base64Accum = '';
            }
        }
    }

    if (!inBase64) {
        res += this.iconv.decode(buf.slice(lastI), "ascii"); // Write direct chars.
    } else {
        var b64str = base64Accum + buf.slice(lastI).toString().replace(/,/g, '/');

        var canBeDecoded = b64str.length - (b64str.length % 8); // Minimal chunk: 2 quads -> 2x3 bytes -> 3 chars.
        base64Accum = b64str.slice(canBeDecoded); // The rest will be decoded in future.
        b64str = b64str.slice(0, canBeDecoded);

        res += this.iconv.decode(Buffer.from(b64str, 'base64'), "utf16-be");
    }

    this.inBase64 = inBase64;
    this.base64Accum = base64Accum;

    return res;
}

Utf7IMAPDecoder.prototype.end = function() {
    var res = "";
    if (this.inBase64 && this.base64Accum.length > 0)
        res = this.iconv.decode(Buffer.from(this.base64Accum, 'base64'), "utf16-be");

    this.inBase64 = false;
    this.base64Accum = '';
    return res;
}



},{"safer-buffer":51}],33:[function(require,module,exports){
"use strict";

var BOMChar = '\uFEFF';

exports.PrependBOM = PrependBOMWrapper
function PrependBOMWrapper(encoder, options) {
    this.encoder = encoder;
    this.addBOM = true;
}

PrependBOMWrapper.prototype.write = function(str) {
    if (this.addBOM) {
        str = BOMChar + str;
        this.addBOM = false;
    }

    return this.encoder.write(str);
}

PrependBOMWrapper.prototype.end = function() {
    return this.encoder.end();
}


//------------------------------------------------------------------------------

exports.StripBOM = StripBOMWrapper;
function StripBOMWrapper(decoder, options) {
    this.decoder = decoder;
    this.pass = false;
    this.options = options || {};
}

StripBOMWrapper.prototype.write = function(buf) {
    var res = this.decoder.write(buf);
    if (this.pass || !res)
        return res;

    if (res[0] === BOMChar) {
        res = res.slice(1);
        if (typeof this.options.stripBOM === 'function')
            this.options.stripBOM();
    }

    this.pass = true;
    return res;
}

StripBOMWrapper.prototype.end = function() {
    return this.decoder.end();
}


},{}],34:[function(require,module,exports){
(function (process){(function (){
"use strict";

// Some environments don't have global Buffer (e.g. React Native).
// Solution would be installing npm modules "buffer" and "stream" explicitly.
var Buffer = require("safer-buffer").Buffer;

var bomHandling = require("./bom-handling"),
    iconv = module.exports;

// All codecs and aliases are kept here, keyed by encoding name/alias.
// They are lazy loaded in `iconv.getCodec` from `encodings/index.js`.
iconv.encodings = null;

// Characters emitted in case of error.
iconv.defaultCharUnicode = '';
iconv.defaultCharSingleByte = '?';

// Public API.
iconv.encode = function encode(str, encoding, options) {
    str = "" + (str || ""); // Ensure string.

    var encoder = iconv.getEncoder(encoding, options);

    var res = encoder.write(str);
    var trail = encoder.end();
    
    return (trail && trail.length > 0) ? Buffer.concat([res, trail]) : res;
}

iconv.decode = function decode(buf, encoding, options) {
    if (typeof buf === 'string') {
        if (!iconv.skipDecodeWarning) {
            console.error('Iconv-lite warning: decode()-ing strings is deprecated. Refer to https://github.com/ashtuchkin/iconv-lite/wiki/Use-Buffers-when-decoding');
            iconv.skipDecodeWarning = true;
        }

        buf = Buffer.from("" + (buf || ""), "binary"); // Ensure buffer.
    }

    var decoder = iconv.getDecoder(encoding, options);

    var res = decoder.write(buf);
    var trail = decoder.end();

    return trail ? (res + trail) : res;
}

iconv.encodingExists = function encodingExists(enc) {
    try {
        iconv.getCodec(enc);
        return true;
    } catch (e) {
        return false;
    }
}

// Legacy aliases to convert functions
iconv.toEncoding = iconv.encode;
iconv.fromEncoding = iconv.decode;

// Search for a codec in iconv.encodings. Cache codec data in iconv._codecDataCache.
iconv._codecDataCache = {};
iconv.getCodec = function getCodec(encoding) {
    if (!iconv.encodings)
        iconv.encodings = require("../encodings"); // Lazy load all encoding definitions.
    
    // Canonicalize encoding name: strip all non-alphanumeric chars and appended year.
    var enc = iconv._canonicalizeEncoding(encoding);

    // Traverse iconv.encodings to find actual codec.
    var codecOptions = {};
    while (true) {
        var codec = iconv._codecDataCache[enc];
        if (codec)
            return codec;

        var codecDef = iconv.encodings[enc];

        switch (typeof codecDef) {
            case "string": // Direct alias to other encoding.
                enc = codecDef;
                break;

            case "object": // Alias with options. Can be layered.
                for (var key in codecDef)
                    codecOptions[key] = codecDef[key];

                if (!codecOptions.encodingName)
                    codecOptions.encodingName = enc;
                
                enc = codecDef.type;
                break;

            case "function": // Codec itself.
                if (!codecOptions.encodingName)
                    codecOptions.encodingName = enc;

                // The codec function must load all tables and return object with .encoder and .decoder methods.
                // It'll be called only once (for each different options object).
                codec = new codecDef(codecOptions, iconv);

                iconv._codecDataCache[codecOptions.encodingName] = codec; // Save it to be reused later.
                return codec;

            default:
                throw new Error("Encoding not recognized: '" + encoding + "' (searched as: '"+enc+"')");
        }
    }
}

iconv._canonicalizeEncoding = function(encoding) {
    // Canonicalize encoding name: strip all non-alphanumeric chars and appended year.
    return (''+encoding).toLowerCase().replace(/:\d{4}$|[^0-9a-z]/g, "");
}

iconv.getEncoder = function getEncoder(encoding, options) {
    var codec = iconv.getCodec(encoding),
        encoder = new codec.encoder(options, codec);

    if (codec.bomAware && options && options.addBOM)
        encoder = new bomHandling.PrependBOM(encoder, options);

    return encoder;
}

iconv.getDecoder = function getDecoder(encoding, options) {
    var codec = iconv.getCodec(encoding),
        decoder = new codec.decoder(options, codec);

    if (codec.bomAware && !(options && options.stripBOM === false))
        decoder = new bomHandling.StripBOM(decoder, options);

    return decoder;
}


// Load extensions in Node. All of them are omitted in Browserify build via 'browser' field in package.json.
var nodeVer = typeof process !== 'undefined' && process.versions && process.versions.node;
if (nodeVer) {

    // Load streaming support in Node v0.10+
    var nodeVerArr = nodeVer.split(".").map(Number);
    if (nodeVerArr[0] > 0 || nodeVerArr[1] >= 10) {
        require("./streams")(iconv);
    }

    // Load Node primitive extensions.
    require("./extend-node")(iconv);
}

if ("" != "\u0100") {
    console.error("iconv-lite warning: javascript files use encoding different from utf-8. See https://github.com/ashtuchkin/iconv-lite/wiki/Javascript-source-file-encodings for more info.");
}

}).call(this)}).call(this,require('_process'))
},{"../encodings":18,"./bom-handling":33,"./extend-node":3,"./streams":3,"_process":7,"safer-buffer":51}],35:[function(require,module,exports){
(function (global, factory) {
typeof exports === 'object' && typeof module !== 'undefined' ? module.exports = factory() :
typeof define === 'function' && define.amd ? define(factory) :
(global.KDBush = factory());
}(this, (function () { 'use strict';

function sortKD(ids, coords, nodeSize, left, right, depth) {
    if (right - left <= nodeSize) { return; }

    var m = (left + right) >> 1;

    select(ids, coords, m, left, right, depth % 2);

    sortKD(ids, coords, nodeSize, left, m - 1, depth + 1);
    sortKD(ids, coords, nodeSize, m + 1, right, depth + 1);
}

function select(ids, coords, k, left, right, inc) {

    while (right > left) {
        if (right - left > 600) {
            var n = right - left + 1;
            var m = k - left + 1;
            var z = Math.log(n);
            var s = 0.5 * Math.exp(2 * z / 3);
            var sd = 0.5 * Math.sqrt(z * s * (n - s) / n) * (m - n / 2 < 0 ? -1 : 1);
            var newLeft = Math.max(left, Math.floor(k - m * s / n + sd));
            var newRight = Math.min(right, Math.floor(k + (n - m) * s / n + sd));
            select(ids, coords, k, newLeft, newRight, inc);
        }

        var t = coords[2 * k + inc];
        var i = left;
        var j = right;

        swapItem(ids, coords, left, k);
        if (coords[2 * right + inc] > t) { swapItem(ids, coords, left, right); }

        while (i < j) {
            swapItem(ids, coords, i, j);
            i++;
            j--;
            while (coords[2 * i + inc] < t) { i++; }
            while (coords[2 * j + inc] > t) { j--; }
        }

        if (coords[2 * left + inc] === t) { swapItem(ids, coords, left, j); }
        else {
            j++;
            swapItem(ids, coords, j, right);
        }

        if (j <= k) { left = j + 1; }
        if (k <= j) { right = j - 1; }
    }
}

function swapItem(ids, coords, i, j) {
    swap(ids, i, j);
    swap(coords, 2 * i, 2 * j);
    swap(coords, 2 * i + 1, 2 * j + 1);
}

function swap(arr, i, j) {
    var tmp = arr[i];
    arr[i] = arr[j];
    arr[j] = tmp;
}

function range(ids, coords, minX, minY, maxX, maxY, nodeSize) {
    var stack = [0, ids.length - 1, 0];
    var result = [];
    var x, y;

    while (stack.length) {
        var axis = stack.pop();
        var right = stack.pop();
        var left = stack.pop();

        if (right - left <= nodeSize) {
            for (var i = left; i <= right; i++) {
                x = coords[2 * i];
                y = coords[2 * i + 1];
                if (x >= minX && x <= maxX && y >= minY && y <= maxY) { result.push(ids[i]); }
            }
            continue;
        }

        var m = Math.floor((left + right) / 2);

        x = coords[2 * m];
        y = coords[2 * m + 1];

        if (x >= minX && x <= maxX && y >= minY && y <= maxY) { result.push(ids[m]); }

        var nextAxis = (axis + 1) % 2;

        if (axis === 0 ? minX <= x : minY <= y) {
            stack.push(left);
            stack.push(m - 1);
            stack.push(nextAxis);
        }
        if (axis === 0 ? maxX >= x : maxY >= y) {
            stack.push(m + 1);
            stack.push(right);
            stack.push(nextAxis);
        }
    }

    return result;
}

function within(ids, coords, qx, qy, r, nodeSize) {
    var stack = [0, ids.length - 1, 0];
    var result = [];
    var r2 = r * r;

    while (stack.length) {
        var axis = stack.pop();
        var right = stack.pop();
        var left = stack.pop();

        if (right - left <= nodeSize) {
            for (var i = left; i <= right; i++) {
                if (sqDist(coords[2 * i], coords[2 * i + 1], qx, qy) <= r2) { result.push(ids[i]); }
            }
            continue;
        }

        var m = Math.floor((left + right) / 2);

        var x = coords[2 * m];
        var y = coords[2 * m + 1];

        if (sqDist(x, y, qx, qy) <= r2) { result.push(ids[m]); }

        var nextAxis = (axis + 1) % 2;

        if (axis === 0 ? qx - r <= x : qy - r <= y) {
            stack.push(left);
            stack.push(m - 1);
            stack.push(nextAxis);
        }
        if (axis === 0 ? qx + r >= x : qy + r >= y) {
            stack.push(m + 1);
            stack.push(right);
            stack.push(nextAxis);
        }
    }

    return result;
}

function sqDist(ax, ay, bx, by) {
    var dx = ax - bx;
    var dy = ay - by;
    return dx * dx + dy * dy;
}

var defaultGetX = function (p) { return p[0]; };
var defaultGetY = function (p) { return p[1]; };

var KDBush = function KDBush(points, getX, getY, nodeSize, ArrayType) {
    if ( getX === void 0 ) getX = defaultGetX;
    if ( getY === void 0 ) getY = defaultGetY;
    if ( nodeSize === void 0 ) nodeSize = 64;
    if ( ArrayType === void 0 ) ArrayType = Float64Array;

    this.nodeSize = nodeSize;
    this.points = points;

    var IndexArrayType = points.length < 65536 ? Uint16Array : Uint32Array;

    var ids = this.ids = new IndexArrayType(points.length);
    var coords = this.coords = new ArrayType(points.length * 2);

    for (var i = 0; i < points.length; i++) {
        ids[i] = i;
        coords[2 * i] = getX(points[i]);
        coords[2 * i + 1] = getY(points[i]);
    }

    sortKD(ids, coords, nodeSize, 0, ids.length - 1, 0);
};

KDBush.prototype.range = function range$1 (minX, minY, maxX, maxY) {
    return range(this.ids, this.coords, minX, minY, maxX, maxY, this.nodeSize);
};

KDBush.prototype.within = function within$1 (x, y, r) {
    return within(this.ids, this.coords, x, y, r, this.nodeSize);
};

return KDBush;

})));

},{}],36:[function(require,module,exports){
(function (process,setImmediate,__dirname){(function (){
(function () {

  var VERSION = "0.5.79";


  var utils = /*#__PURE__*/Object.freeze({
    __proto__: null,
    get default () { return utils; },
    get getUniqueName () { return getUniqueName; },
    get isFunction () { return isFunction; },
    get isObject () { return isObject; },
    get clamp () { return clamp; },
    get isArray () { return isArray; },
    get isNumber () { return isNumber; },
    get isValidNumber () { return isValidNumber; },
    get isFiniteNumber () { return isFiniteNumber; },
    get isNonNegNumber () { return isNonNegNumber; },
    get isInteger () { return isInteger; },
    get isEven () { return isEven; },
    get isOdd () { return isOdd; },
    get isString () { return isString; },
    get isDate () { return isDate; },
    get isBoolean () { return isBoolean; },
    get formatDateISO () { return formatDateISO; },
    get toArray () { return toArray; },
    get isArrayLike () { return isArrayLike; },
    get addslashes () { return addslashes; },
    get regexEscape () { return regexEscape; },
    get htmlEscape () { return htmlEscape; },
    get defaults () { return defaults; },
    get extend () { return extend; },
    get inherit () { return inherit; },
    get reduceAsync () { return reduceAsync; },
    get merge () { return merge; },
    get difference () { return difference; },
    get intersection () { return intersection; },
    get indexOf () { return indexOf; },
    get contains () { return contains; },
    get some () { return some; },
    get every () { return every; },
    get find () { return find; },
    get range () { return range; },
    get repeat () { return repeat; },
    get sum () { return sum$1; },
    get getArrayBounds () { return getArrayBounds; },
    get uniq () { return uniq; },
    get pluck () { return pluck; },
    get countValues () { return countValues; },
    get indexOn () { return indexOn; },
    get groupBy () { return groupBy; },
    get arrayToIndex () { return arrayToIndex; },
    get forEach () { return forEach; },
    get forEachProperty () { return forEachProperty; },
    get initializeArray () { return initializeArray; },
    get replaceArray () { return replaceArray; },
    get repeatString () { return repeatString; },
    get splitLines () { return splitLines; },
    get pluralSuffix () { return pluralSuffix; },
    get endsWith () { return endsWith; },
    get lpad () { return lpad; },
    get rpad () { return rpad; },
    get trim () { return trim; },
    get ltrim () { return ltrim; },
    get rtrim () { return rtrim; },
    get addThousandsSep () { return addThousandsSep; },
    get numToStr () { return numToStr; },
    get formatNumber () { return formatNumber; },
    get formatIntlNumber () { return formatIntlNumber; },
    get formatNumberForDisplay () { return formatNumberForDisplay; },
    get shuffle () { return shuffle; },
    get sortOn () { return sortOn; },
    get genericSort () { return genericSort; },
    get getSortedIds () { return getSortedIds; },
    get sortArrayIndex () { return sortArrayIndex; },
    get reorderArray () { return reorderArray; },
    get getKeyComparator () { return getKeyComparator; },
    get getGenericComparator () { return getGenericComparator; },
    get quicksort () { return quicksort$1; },
    get quicksortPartition () { return quicksortPartition; },
    get findRankByValue () { return findRankByValue; },
    get findValueByPct () { return findValueByPct; },
    get findValueByRank () { return findValueByRank; },
    get findMedian () { return findMedian; },
    get mean () { return mean; },
    get format () { return format; },
    get formatter () { return formatter; },
    get wildcardToRegExp () { return wildcardToRegExp; },
    get createBuffer () { return createBuffer; },
    get expandoBuffer () { return expandoBuffer; },
    get copyElements () { return copyElements; },
    get extendBuffer () { return extendBuffer; },
    get mergeNames () { return mergeNames; },
    get findStringPrefix () { return findStringPrefix; },
    get parsePercent () { return parsePercent; },
    get formatVersionedName () { return formatVersionedName; },
    get uniqifyNames () { return uniqifyNames; },
    get parseString () { return parseString; },
    get parseNumber () { return parseNumber; },
    get parseIntlNumber () { return parseIntlNumber; },
    get cleanNumericString () { return cleanNumericString; },
    get trimQuotes () { return trimQuotes; }
  });

  var Buffer = require('buffer').Buffer; // works with browserify

  var uniqCount = 0;
  function getUniqueName(prefix) {
    return (prefix || "__id_") + (++uniqCount);
  }

  function isFunction(obj) {
    return typeof obj == 'function';
  }

  function isObject(obj) {
    return obj === Object(obj); // via underscore
  }

  function clamp(val, min, max) {
    return val < min ? min : (val > max ? max : val);
  }

  function isArray(obj) {
    return Array.isArray(obj);
  }

  // Is obj a valid number or NaN? (test if obj is type number)
  function isNumber(obj) {
    return obj != null && obj.constructor == Number;
  }

  function isValidNumber(val) {
    return isNumber(val) && !isNaN(val);
  }

  // Similar to isFinite() but does not coerce strings or other types
  function isFiniteNumber(val) {
    return isValidNumber(val) && val !== Infinity && val !== -Infinity;
  }

  // This uses type conversion
  // export function isFiniteNumber(val) {
  //   return val > -Infinity && val < Infinity;
  // }

  function isNonNegNumber(val) {
    return isNumber(val) && val >= 0;
  }

  function isInteger(obj) {
    return isNumber(obj) && ((obj | 0) === obj);
  }

  function isEven(obj) {
    return (obj % 2) === 0;
  }

  function isOdd(obj) {
    return (obj % 2) === 1;
  }

  function isString(obj) {
    return obj != null && obj.toString === String.prototype.toString;
    // TODO: replace w/ something better.
  }

  function isDate(obj) {
    return !!obj && obj.getTime === Date.prototype.getTime;
  }

  function isBoolean(obj) {
    return obj === true || obj === false;
  }

  function formatDateISO(d) {
    if (!isDate(d)) return '';
    return d.toISOString().replace(':00.000Z', 'Z');
  }

  // Convert an array-like object to an Array, or make a copy if @obj is an Array
  function toArray(obj) {
    var arr;
    if (!isArrayLike(obj)) error("toArray() requires an array-like object");
    try {
      arr = Array.prototype.slice.call(obj, 0); // breaks in ie8
    } catch(e) {
      // support ie8
      arr = [];
      for (var i=0, n=obj.length; i<n; i++) {
        arr[i] = obj[i];
      }
    }
    return arr;
  }

  // Array like: has length property, is numerically indexed and mutable.
  // TODO: try to detect objects with length property but no indexed data elements
  function isArrayLike(obj) {
    if (!obj) return false;
    if (isArray(obj)) return true;
    if (isString(obj)) return false;
    if (obj.length === 0) return true;
    if (obj.length > 0) return true;
    return false;
  }

  // See https://raw.github.com/kvz/phpjs/master/functions/strings/addslashes.js
  function addslashes(str) {
    return (str + '').replace(/[\\"']/g, '\\$&').replace(/\u0000/g, '\\0');
  }

  // Escape a literal string to use in a regexp.
  // Ref.: http://simonwillison.net/2006/Jan/20/escape/
  function regexEscape(str) {
    return str.replace(/[-[\]{}()*+?.,\\^$|#\s]/g, '\\$&');
  }


  // See https://github.com/janl/mustache.js/blob/master/mustache.js
  var entityMap = {
    '&': '&amp;',
    '<': '&lt;',
    '>': '&gt;',
    '"': '&quot;',
    "'": '&#39;',
    '/': '&#x2F;'
  };
  function htmlEscape(s) {
    return String(s).replace(/[&<>"'\/]/g, function(s) {
      return entityMap[s];
    });
  }

  function defaults(dest) {
    for (var i=1, n=arguments.length; i<n; i++) {
      var src = arguments[i] || {};
      for (var key in src) {
        if (key in dest === false && src.hasOwnProperty(key)) {
          dest[key] = src[key];
        }
      }
    }
    return dest;
  }

  function extend(o) {
    var dest = o || {},
        n = arguments.length,
        key, i, src;
    for (i=1; i<n; i++) {
      src = arguments[i] || {};
      for (key in src) {
        if (src.hasOwnProperty(key)) {
          dest[key] = src[key];
        }
      }
    }
    return dest;
  }

  // Pseudoclassical inheritance
  //
  // Inherit from a Parent function:
  //    inherit(Child, Parent);
  // Call parent's constructor (inside child constructor):
  //    this.__super__([args...]);
  function inherit(targ, src) {
    var f = function() {
      if (this.__super__ == f) {
        // add __super__ of parent to front of lookup chain
        // so parent class constructor can call its parent using this.__super__
        this.__super__ = src.prototype.__super__;
        // call parent constructor function. this.__super__ now points to parent-of-parent
        src.apply(this, arguments);
        // remove temp __super__, expose targ.prototype.__super__ again
        delete this.__super__;
      }
    };

    f.prototype = src.prototype || src; // added || src to allow inheriting from objects as well as functions
    // Extend targ prototype instead of wiping it out --
    //   in case inherit() is called after targ.prototype = {stuff}; statement
    targ.prototype = extend(new f(), targ.prototype); //
    targ.prototype.constructor = targ;
    targ.prototype.__super__ = f;
  }


  // Call @iter on each member of an array (similar to Array#reduce(iter))
  //    iter: function(memo, item, callback)
  // Call @done when all members have been processed or if an error occurs
  //    done: function(err, memo)
  // @memo: Initial value
  //
  function reduceAsync(arr, memo, iter, done) {
    var call = typeof setImmediate == 'undefined' ? setTimeout : setImmediate;
    var i=0;
    next(null, memo);

    function next(err, memo) {
      // Detach next operation from call stack to prevent overflow
      // Don't use setTimeout(, 0) if setImmediate is available
      // (setTimeout() can introduce a long delay if previous operation was slow,
      //    as of Node 0.10.32 -- a bug?)
      if (err) {
        return done(err, null);
      }
      call(function() {
        if (i < arr.length === false) {
          done(null, memo);
        } else {
          iter(memo, arr[i++], next);
        }
      }, 0);
    }
  }


  // Append elements of @src array to @dest array
  function merge(dest, src) {
    if (!isArray(dest) || !isArray(src)) {
      error("Usage: merge(destArray, srcArray);");
    }
    for (var i=0, n=src.length; i<n; i++) {
      dest.push(src[i]);
    }
    return dest;
  }

  // Returns elements in arr and not in other
  // (similar to underscore diff)
  function difference(arr, other) {
    var index = arrayToIndex(other);
    return arr.filter(function(el) {
      return !Object.prototype.hasOwnProperty.call(index, el);
    });
  }

  // Return the intersection of two arrays
  function intersection(a, b) {
    return a.filter(function(el) {
      return b.includes(el);
    });
  }

  function indexOf(arr, item) {
    var nan = item !== item;
    for (var i = 0, len = arr.length || 0; i < len; i++) {
      if (arr[i] === item) return i;
      if (nan && arr[i] !== arr[i]) return i;
    }
    return -1;
  }

  // Test a string or array-like object for existence of substring or element
  function contains(container, item) {
    if (isString(container)) {
      return container.indexOf(item) != -1;
    }
    else if (isArrayLike(container)) {
      return indexOf(container, item) != -1;
    }
    error("Expected Array or String argument");
  }

  function some(arr, test) {
    return arr.reduce(function(val, item) {
      return val || test(item); // TODO: short-circuit?
    }, false);
  }

  function every(arr, test) {
    return arr.reduce(function(val, item) {
      return val && test(item);
    }, true);
  }

  function find(arr, test, ctx) {
    var matches = arr.filter(test, ctx);
    return matches.length === 0 ? null : matches[0];
  }

  function range(len, start, inc) {
    var arr = [],
        v = start === void 0 ? 0 : start,
        i = inc === void 0 ? 1 : inc;
    while(len--) {
      arr.push(v);
      v += i;
    }
    return arr;
  }

  function repeat(times, func) {
    var values = [],
        val;
    for (var i=0; i<times; i++) {
      val = func(i);
      if (val !== void 0) {
        values[i] = val;
      }
    }
    return values.length > 0 ? values : void 0;
  }

  // Calc sum, skip falsy and NaN values
  // Assumes: no other non-numeric objects in array
  //
  function sum$1(arr, info) {
    if (!isArrayLike(arr)) error ("sum() expects an array, received:", arr);
    var tot = 0,
        nan = 0,
        val;
    for (var i=0, n=arr.length; i<n; i++) {
      val = arr[i];
      if (val) {
        tot += val;
      } else if (isNaN(val)) {
        nan++;
      }
    }
    if (info) {
      info.nan = nan;
    }
    return tot;
  }

  // Calculate min and max values of an array, ignoring NaN values
  function getArrayBounds(arr) {
    var min = Infinity,
      max = -Infinity,
      nan = 0, val;
    for (var i=0, len=arr.length; i<len; i++) {
      val = arr[i];
      if (val !== val) nan++;
      if (val < min) min = val;
      if (val > max) max = val;
    }
    return {
      min: min,
      max: max,
      nan: nan
    };
  }

  // export function uniq(src) {
  //   var index = {};
  //   return src.reduce(function(memo, el) {
  //     if (el in index === false) {
  //       index[el] = true;
  //       memo.push(el);
  //     }
  //     return memo;
  //   }, []);
  // }

  function uniq(src) {
    var index = new Set();
    var arr = [];
    var item;
    for (var i=0, n=src.length; i<n; i++) {
      item = src[i];
      if (!index.has(item)) {
        arr.push(item);
        index.add(item);
      }
    }
    return arr;
  }

  function pluck(arr, key) {
    return arr.map(function(obj) {
      return obj[key];
    });
  }

  function countValues(arr) {
    return arr.reduce(function(memo, val) {
      memo[val] = (val in memo) ? memo[val] + 1 : 1;
      return memo;
    }, {});
  }

  function indexOn(arr, k) {
    return arr.reduce(function(index, o) {
      index[o[k]] = o;
      return index;
    }, {});
  }

  function groupBy(arr, k) {
    return arr.reduce(function(index, o) {
      var keyval = o[k];
      if (keyval in index) {
        index[keyval].push(o);
      } else {
        index[keyval] = [o];
      }
      return index;
    }, {});
  }

  function arrayToIndex(arr, val) {
    var init = arguments.length > 1;
    return arr.reduce(function(index, key) {
      index[key] = init ? val : true;
      return index;
    }, {});
  }

  // Support for iterating over array-like objects, like typed arrays
  function forEach(arr, func, ctx) {
    if (!isArrayLike(arr)) {
      throw new Error("#forEach() takes an array-like argument. " + arr);
    }
    for (var i=0, n=arr.length; i < n; i++) {
      func.call(ctx, arr[i], i);
    }
  }

  function forEachProperty(o, func, ctx) {
    Object.keys(o).forEach(function(key) {
      func.call(ctx, o[key], key);
    });
  }

  function initializeArray(arr, init) {
    for (var i=0, len=arr.length; i<len; i++) {
      arr[i] = init;
    }
    return arr;
  }

  function replaceArray(arr, arr2) {
    arr.splice(0, arr.length);
    for (var i=0, n=arr2.length; i<n; i++) {
      arr.push(arr2[i]);
    }
  }

  function repeatString(src, n) {
    var str = "";
    for (var i=0; i<n; i++)
      str += src;
    return str;
  }

  function splitLines(str) {
    return str.split(/\r?\n/);
  }

  function pluralSuffix(count) {
    return count != 1 ? 's' : '';
  }

  function endsWith(str, ending) {
      return str.indexOf(ending, str.length - ending.length) !== -1;
  }

  function lpad(str, size, pad) {
    pad = pad || ' ';
    str = String(str);
    return repeatString(pad, size - str.length) + str;
  }

  function rpad(str, size, pad) {
    pad = pad || ' ';
    str = String(str);
    return str + repeatString(pad, size - str.length);
  }

  function trim(str) {
    return ltrim(rtrim(str));
  }

  var ltrimRxp = /^\s+/;
  function ltrim(str) {
    return str.replace(ltrimRxp, '');
  }

  var rtrimRxp = /\s+$/;
  function rtrim(str) {
    return str.replace(rtrimRxp, '');
  }

  function addThousandsSep(str) {
    var fmt = '',
        start = str[0] == '-' ? 1 : 0,
        dec = str.indexOf('.'),
        end = str.length,
        ins = (dec == -1 ? end : dec) - 3;
    while (ins > start) {
      fmt = ',' + str.substring(ins, end) + fmt;
      end = ins;
      ins -= 3;
    }
    return str.substring(0, end) + fmt;
  }

  function numToStr(num, decimals) {
    return decimals >= 0 ? num.toFixed(decimals) : String(num);
  }

  function formatNumber(val) {
    return val + '';
  }

  function formatIntlNumber(val) {
    var str = formatNumber(val);
    return '"' + str.replace('.', ',') + '"'; // need to quote if comma-delimited
  }

  function formatNumberForDisplay(num, decimals, nullStr, showPos) {
    var fmt;
    if (isNaN(num)) {
      fmt = nullStr || '-';
    } else {
      fmt = numToStr(num, decimals);
      fmt = addThousandsSep(fmt);
      if (showPos && parseFloat(fmt) > 0) {
        fmt = "+" + fmt;
      }
    }
    return fmt;
  }

  function shuffle(arr) {
    var tmp, i, j;
    for (i = arr.length - 1; i > 0; i--) {
      j = Math.floor(Math.random() * (i + 1));
      tmp = arr[i];
      arr[i] = arr[j];
      arr[j] = tmp;
    }
  }

  // Sort an array of objects based on one or more properties.
  // Usage: sortOn(array, key1, asc?[, key2, asc? ...])
  //
  function sortOn(arr) {
    var comparators = [];
    for (var i=1; i<arguments.length; i+=2) {
      comparators.push(getKeyComparator(arguments[i], arguments[i+1]));
    }
    arr.sort(function(a, b) {
      var cmp = 0,
          i = 0,
          n = comparators.length;
      while (i < n && cmp === 0) {
        cmp = comparators[i](a, b);
        i++;
      }
      return cmp;
    });
    return arr;
  }

  // Sort array of values that can be compared with < > operators (strings, numbers)
  // null, undefined and NaN are sorted to the end of the array
  // default order is ascending
  //
  function genericSort(arr, ascending) {
    var compare = getGenericComparator(ascending);
    Array.prototype.sort.call(arr, compare);
    return arr;
  }

  function getSortedIds(arr, asc) {
    var ids = range(arr.length);
    sortArrayIndex(ids, arr, asc);
    return ids;
  }

  function sortArrayIndex(ids, arr, asc) {
    var compare = getGenericComparator(asc);
    ids.sort(function(i, j) {
      // added i, j comparison to guarantee that sort is stable
      var cmp = compare(arr[i], arr[j]);
      return cmp > 0 || cmp === 0 && i > j ? 1 : -1;
    });
  }

  function reorderArray(arr, idxs) {
    var len = idxs.length;
    var arr2 = [];
    for (var i=0; i<len; i++) {
      var idx = idxs[i];
      if (idx < 0 || idx >= len) error("Out-of-bounds array idx");
      arr2[i] = arr[idx];
    }
    replaceArray(arr, arr2);
  }

  function getKeyComparator(key, asc) {
    var compare = getGenericComparator(asc);
    return function(a, b) {
      return compare(a[key], b[key]);
    };
  }

  function getGenericComparator(asc) {
    asc = asc !== false;
    return function(a, b) {
      var retn = 0;
      if (b == null) {
        retn = a == null ? 0 : -1;
      } else if (a == null) {
        retn = 1;
      } else if (a < b) {
        retn = asc ? -1 : 1;
      } else if (a > b) {
        retn = asc ? 1 : -1;
      } else if (a !== a) {
        retn = 1;
      } else if (b !== b) {
        retn = -1;
      }
      return retn;
    };
  }


  // Generic in-place sort (null, NaN, undefined not handled)
  function quicksort$1(arr, asc) {
    quicksortPartition(arr, 0, arr.length-1);
    if (asc === false) Array.prototype.reverse.call(arr); // Works with typed arrays
    return arr;
  }

  // Moved out of quicksort() (saw >100% speedup in Chrome with deep recursion)
  function quicksortPartition (a, lo, hi) {
    var i = lo,
        j = hi,
        pivot, tmp;
    while (i < hi) {
      pivot = a[lo + hi >> 1]; // avoid n^2 performance on sorted arrays
      while (i <= j) {
        while (a[i] < pivot) i++;
        while (a[j] > pivot) j--;
        if (i <= j) {
          tmp = a[i];
          a[i] = a[j];
          a[j] = tmp;
          i++;
          j--;
        }
      }
      if (lo < j) quicksortPartition(a, lo, j);
      lo = i;
      j = hi;
    }
  }


  function findRankByValue(arr, value) {
    if (isNaN(value)) return arr.length;
    var rank = 1;
    for (var i=0, n=arr.length; i<n; i++) {
      if (value > arr[i]) rank++;
    }
    return rank;
  }

  function findValueByPct(arr, pct) {
    var rank = Math.ceil((1-pct) * (arr.length));
    return findValueByRank(arr, rank);
  }

  // See http://ndevilla.free.fr/median/median/src/wirth.c
  // Elements of @arr are reordered
  //
  function findValueByRank(arr, rank) {
    if (!arr.length || rank < 1 || rank > arr.length) error("[findValueByRank()] invalid input");

    rank = clamp(rank | 0, 1, arr.length);
    var k = rank - 1, // conv. rank to array index
        n = arr.length,
        l = 0,
        m = n - 1,
        i, j, val, tmp;

    while (l < m) {
      val = arr[k];
      i = l;
      j = m;
      do {
        while (arr[i] < val) {i++;}
        while (val < arr[j]) {j--;}
        if (i <= j) {
          tmp = arr[i];
          arr[i] = arr[j];
          arr[j] = tmp;
          i++;
          j--;
        }
      } while (i <= j);
      if (j < k) l = i;
      if (k < i) m = j;
    }
    return arr[k];
  }

  //
  //
  function findMedian(arr) {
    var n = arr.length,
        rank = Math.floor(n / 2) + 1,
        median = findValueByRank(arr, rank);
    if ((n & 1) == 0) {
      median = (median + findValueByRank(arr, rank - 1)) / 2;
    }
    return median;
  }


  function mean(arr) {
    var count = 0,
        avg = NaN,
        val;
    for (var i=0, n=arr.length; i<n; i++) {
      val = arr[i];
      if (isNaN(val)) continue;
      avg = ++count == 1 ? val : val / count + (count - 1) / count * avg;
    }
    return avg;
  }


  /*
  A simplified version of printf formatting
  Format codes: %[flags][width][.precision]type

  supported flags:
    +   add '+' before positive numbers
    0   left-pad with '0'
    '   Add thousands separator
  width: 1 to many
  precision: .(1 to many)
  type:
    s     string
    di    integers
    f     decimal numbers
    xX    hexidecimal (unsigned)
    %     literal '%'

  Examples:
    code    val    formatted
    %+d     1      '+1'
    %4i     32     '  32'
    %04i    32     '0032'
    %x      255    'ff'
    %.2f    0.125  '0.13'
    %'f     1000   '1,000'
  */

  // Usage: format(formatString, [values])
  // Tip: When reusing the same format many times, use formatter() for 5x - 10x better performance
  //
  function format(fmt) {
    var fn = formatter(fmt);
    var str = fn.apply(null, Array.prototype.slice.call(arguments, 1));
    return str;
  }

  function formatValue(val, matches) {
    var flags = matches[1];
    var padding = matches[2];
    var decimals = matches[3] ? parseInt(matches[3].substr(1)) : void 0;
    var type = matches[4];
    var isString = type == 's',
        isHex = type == 'x' || type == 'X',
        isInt = type == 'd' || type == 'i',
        isFloat = type == 'f',
        isNumber = !isString;

    var sign = "",
        padDigits = 0,
        isZero = false,
        isNeg = false;

    var str, padChar, padStr;
    if (isString) {
      str = String(val);
    }
    else if (isHex) {
      str = val.toString(16);
      if (type == 'X')
        str = str.toUpperCase();
    }
    else if (isNumber) {
      // str = formatNumberForDisplay(val, isInt ? 0 : decimals);
      str = numToStr(val, decimals);
      if (str[0] == '-') {
        isNeg = true;
        str = str.substr(1);
      }
      isZero = parseFloat(str) == 0;
      if (flags.indexOf("'") != -1 || flags.indexOf(',') != -1) {
        str = addThousandsSep(str);
      }
      if (!isZero) { // BUG: sign is added when num rounds to 0
        if (isNeg) {
          sign = "\u2212"; // U+2212
        } else if (flags.indexOf('+') != -1) {
          sign = '+';
        }
      }
    }

    if (padding) {
      var strLen = str.length + sign.length;
      var minWidth = parseInt(padding, 10);
      if (strLen < minWidth) {
        padDigits = minWidth - strLen;
        padChar = flags.indexOf('0') == -1 ? ' ' : '0';
        padStr = repeatString(padChar, padDigits);
      }
    }

    if (padDigits == 0) {
      str = sign + str;
    } else if (padChar == '0') {
      str = sign + padStr + str;
    } else {
      str = padStr + sign + str;
    }
    return str;
  }

  // Get a function for interpolating formatted values into a string.
  function formatter(fmt) {
    var codeRxp = /%([\',+0]*)([1-9]?)((?:\.[1-9])?)([sdifxX%])/g;
    var literals = [],
        formatCodes = [],
        startIdx = 0,
        prefix = "",
        matches = codeRxp.exec(fmt),
        literal;

    while (matches) {
      literal = fmt.substring(startIdx, codeRxp.lastIndex - matches[0].length);
      if (matches[0] == '%%') {
        prefix += literal + '%';
      } else {
        literals.push(prefix + literal);
        prefix = '';
        formatCodes.push(matches);
      }
      startIdx = codeRxp.lastIndex;
      matches = codeRxp.exec(fmt);
    }
    literals.push(prefix + fmt.substr(startIdx));

    return function() {
      var str = literals[0],
          n = arguments.length;
      if (n != formatCodes.length) {
        error("[format()] Data does not match format string; format:", fmt, "data:", arguments);
      }
      for (var i=0; i<n; i++) {
        str += formatValue(arguments[i], formatCodes[i]) + literals[i+1];
      }
      return str;
    };
  }

  function wildcardToRegExp(name) {
    var rxp = name.split('*').map(function(str) {
      return regexEscape(str);
    }).join('.*');
    return new RegExp('^' + rxp + '$');
  }

  function createBuffer(arg, arg2) {
    if (isInteger(arg)) {
      return Buffer.allocUnsafe ? Buffer.allocUnsafe(arg) : new Buffer(arg);
    } else {
      // check allocUnsafe to make sure Buffer.from() will accept strings (it didn't before Node v5.10)
      return Buffer.from && Buffer.allocUnsafe ? Buffer.from(arg, arg2) : new Buffer(arg, arg2);
    }
  }

  function expandoBuffer(constructor, rate) {
    var capacity = 0,
        k = rate >= 1 ? rate : 1.2,
        buf;
    return function(size) {
      if (size > capacity) {
        capacity = Math.ceil(size * k);
        buf = constructor ? new constructor(capacity) : createBuffer(capacity);
      }
      return buf;
    };
  }

  function copyElements(src, i, dest, j, n, rev) {
    if (src === dest && j > i) error ("copy error");
    var inc = 1,
        offs = 0;
    if (rev) {
      inc = -1;
      offs = n - 1;
    }
    for (var k=0; k<n; k++, offs += inc) {
      dest[k + j] = src[i + offs];
    }
  }

  function extendBuffer(src, newLen, copyLen) {
    var len = Math.max(src.length, newLen);
    var n = copyLen || src.length;
    var dest = new src.constructor(len);
    copyElements(src, 0, dest, 0, n);
    return dest;
  }

  function mergeNames(name1, name2) {
    var merged;
    if (name1 && name2) {
      merged = findStringPrefix(name1, name2).replace(/[-_]$/, '');
    }
    return merged || '';
  }

  function findStringPrefix(a, b) {
    var i = 0;
    for (var n=a.length; i<n; i++) {
      if (a[i] !== b[i]) break;
    }
    return a.substr(0, i);
  }

  function parsePercent(o) {
    var str = String(o);
    var isPct = str.indexOf('%') > 0;
    var pct;
    if (isPct) {
      pct = Number(str.replace('%', '')) / 100;
    } else {
      pct = Number(str);
    }
    if (!(pct >= 0 && pct <= 1)) {
      stop(format("Invalid percentage: %s", str));
    }
    return pct;
  }

  function formatVersionedName(name, i) {
    var suffix = String(i);
    if (/[0-9]$/.test(name)) {
      suffix = '-' + suffix;
    }
    return name + suffix;
  }

  function uniqifyNames(names, formatter) {
    var counts = countValues(names),
        format = formatter || formatVersionedName,
        names2 = [];

    names.forEach(function(name) {
      var i = 0,
          candidate = name,
          versionedName;
      while (
          names2.indexOf(candidate) > -1 || // candidate name has already been used
          candidate == name && counts[candidate] > 1 || // duplicate unversioned names
          candidate != name && counts[candidate] > 0) { // versioned name is a preexisting name
        i++;
        versionedName = format(name, i);
        if (!versionedName || versionedName == candidate) {
          throw new Error("Naming error"); // catch buggy versioning function
        }
        candidate = versionedName;
      }
      names2.push(candidate);
    });
    return names2;
  }


  // Assume: @raw is string, undefined or null
  function parseString(raw) {
    return raw ? raw : "";
  }

  // Assume: @raw is string, undefined or null
  // Use null instead of NaN for unparsable values
  // (in part because if NaN is used, empty strings get converted to "NaN"
  // when re-exported).
  function parseNumber(raw) {
    return parseToNum(raw, cleanNumericString);
  }

  function parseIntlNumber(raw) {
    return parseToNum(raw, convertIntlNumString);
  }

  function parseToNum(raw, clean) {
    var str = String(raw).trim();
    var parsed = str ? Number(clean(str)) : NaN;
    return isNaN(parsed) ? null : parsed;
  }

  // Remove comma separators from strings
  function cleanNumericString(str) {
    return (str.indexOf(',') > 0) ? str.replace(/,([0-9]{3})/g, '$1') : str;
  }

  function convertIntlNumString(str) {
    str = str.replace(/[ .]([0-9]{3})/g, '$1');
    return str.replace(',', '.');
  }

  function trimQuotes(raw) {
    var len = raw.length, first, last;
    if (len >= 2) {
      first = raw.charAt(0);
      last = raw.charAt(len-1);
      if (first == '"' && last == '"' && !raw.includes('","') ||
          first == "'" && last == "'" && !raw.includes("','")) {
        return raw.substr(1, len-2);
      }
    }
    return raw;
  }

  var context = createContext(); // command context (persist for the current command cycle)

  function runningInBrowser() {
    return typeof window !== 'undefined' && typeof window.document !== 'undefined';
  }

  function getStateVar(key) {
    return context[key];
  }

  function setStateVar(key, val) {
    context[key] = val;
  }

  function createContext() {
    return {
      DEBUG: false,
      QUIET: false,
      VERBOSE: false,
      defs: {},
      input_files: []
    };
  }

  // Install a new set of context variables, clear them when an async callback is called.
  // @cb callback function to wrap
  // returns wrapped callback function
  function createAsyncContext(cb) {
    context = createContext();
    return function() {
      cb.apply(null, utils.toArray(arguments));
      // clear context after cb(), so output/errors can be handled in current context
      context = createContext();
    };
  }

  // Save the current context, restore it when an async callback is called
  // @cb callback function to wrap
  // returns wrapped callback function
  function preserveContext(cb) {
    var ctx = context;
    return function() {
      context = ctx;
      cb.apply(null, utils.toArray(arguments));
    };
  }

  var State = /*#__PURE__*/Object.freeze({
    __proto__: null,
    runningInBrowser: runningInBrowser,
    getStateVar: getStateVar,
    setStateVar: setStateVar,
    createAsyncContext: createAsyncContext,
    preserveContext: preserveContext
  });

  var LOGGING = false;
  var STDOUT = false; // use stdout for status messages

  // These three functions can be reset by GUI using setLoggingFunctions();
  var _error = function() {
    var msg = utils.toArray(arguments).join(' ');
    throw new Error(msg);
  };

  var _stop = function() {
    throw new UserError(formatLogArgs(arguments));
  };

  var _interrupt = function() {
    throw new NonFatalError(formatLogArgs(arguments));
  };

  var _message = function() {
    logArgs(arguments);
  };

  function enableLogging() {
    LOGGING = true;
  }

  function loggingEnabled() {
    return !!LOGGING;
  }

  // Handle an unexpected condition (internal error)
  function error() {
    _error.apply(null, utils.toArray(arguments));
  }

  // Handle an error caused by invalid input or misuse of API
  function stop() {
    _stop.apply(null, utils.toArray(arguments));
  }

  function interrupt() {
    _interrupt.apply(null, utils.toArray(arguments));
  }

  // Print a status message
  function message() {
    _message.apply(null, messageArgs(arguments));
  }

  // A way for the GUI to replace the CLI logging functions
  function setLoggingFunctions(message, error, stop) {
    _message = message;
    _error = error;
    _stop = stop;
  }


  // print a message to stdout
  function print() {
    STDOUT = true; // tell logArgs() to print to stdout, not stderr
    message.apply(null, arguments);
    STDOUT = false;
  }

  function verbose() {
    // verbose can be set globally with the -verbose command or separately for each command
    if (getStateVar('VERBOSE') || getStateVar('verbose')) {
      message.apply(null, arguments);
    }
  }

  function debug() {
    if (getStateVar('DEBUG') || getStateVar('debug')) {
      logArgs(arguments);
    }
  }

  function printError(err) {
    var msg;
    if (!LOGGING) return;
    if (utils.isString(err)) {
      err = new UserError(err);
    }
    if (err.name == 'NonFatalError') {
      console.error(messageArgs([err.message]).join(' '));
    } else if (err.name == 'UserError') {
      msg = err.message;
      if (!/Error/.test(msg)) {
        msg = "Error: " + msg;
      }
      console.error(messageArgs([msg]).join(' '));
      console.error("Run mapshaper -h to view help");
    } else {
      // not a user error (i.e. a bug in mapshaper)
      console.error(err);
      // throw err;
    }
  }

  function UserError(msg) {
    var err = new Error(msg);
    err.name = 'UserError';
    return err;
  }

  function NonFatalError(msg) {
    var err = new Error(msg);
    err.name = 'NonFatalError';
    return err;
  }

  function formatColumns(arr, alignments) {
    var widths = arr.reduce(function(memo, line) {
      return line.map(function(str, i) {
        return memo ? Math.max(memo[i], str.length) : str.length;
      });
    }, null);
    return arr.map(function(line) {
      line = line.map(function(str, i) {
        var rt = alignments && alignments[i] == 'right';
        var pad = (rt ? str.padStart : str.padEnd).bind(str);
        return pad(widths[i], ' ');
      });
      return '  ' + line.join(' ');
    }).join('\n');
  }

  // Format an array of (preferably short) strings in columns for console logging.
  function formatStringsAsGrid(arr) {
    // TODO: variable column width
    var longest = arr.reduce(function(len, str) {
          return Math.max(len, str.length);
        }, 0),
        colWidth = longest + 2,
        perLine = Math.floor(80 / colWidth) || 1;
    return arr.reduce(function(memo, name, i) {
      var col = i % perLine;
      if (i > 0 && col === 0) memo += '\n';
      if (col < perLine - 1) { // right-pad all but rightmost column
        name = utils.rpad(name, colWidth - 2, ' ');
      }
      return memo +  '  ' + name;
    }, '');
  }

  // expose so GUI can use it
  function formatLogArgs(args) {
    return utils.toArray(args).join(' ');
  }

  function messageArgs(args) {
    var arr = utils.toArray(args);
    var cmd = getStateVar('current_command');
    if (cmd && cmd != 'help') {
      arr.unshift('[' + cmd + ']');
    }
    return arr;
  }

  function logArgs(args) {
    if (!LOGGING || getStateVar('QUIET') || !utils.isArrayLike(args)) return;
    var msg = formatLogArgs(args);
    if (STDOUT) console.log(msg);
    else console.error(msg);
  }

  var Logging = /*#__PURE__*/Object.freeze({
    __proto__: null,
    enableLogging: enableLogging,
    loggingEnabled: loggingEnabled,
    error: error,
    stop: stop,
    interrupt: interrupt,
    message: message,
    setLoggingFunctions: setLoggingFunctions,
    print: print,
    verbose: verbose,
    debug: debug,
    printError: printError,
    UserError: UserError,
    NonFatalError: NonFatalError,
    formatColumns: formatColumns,
    formatStringsAsGrid: formatStringsAsGrid,
    formatLogArgs: formatLogArgs,
    logArgs: logArgs
  });

  function Transform() {
    this.mx = this.my = 1;
    this.bx = this.by = 0;
  }

  Transform.prototype.isNull = function() {
    return !this.mx || !this.my || isNaN(this.bx) || isNaN(this.by);
  };

  Transform.prototype.invert = function() {
    var inv = new Transform();
    inv.mx = 1 / this.mx;
    inv.my = 1 / this.my;
    //inv.bx = -this.bx * inv.mx;
    //inv.by = -this.by * inv.my;
    inv.bx = -this.bx / this.mx;
    inv.by = -this.by / this.my;
    return inv;
  };


  Transform.prototype.transform = function(x, y, xy) {
    xy = xy || [];
    xy[0] = x * this.mx + this.bx;
    xy[1] = y * this.my + this.by;
    return xy;
  };

  Transform.prototype.toString = function() {
    return JSON.stringify(Object.assign({}, this));
  };

  function Bounds() {
    if (arguments.length > 0) {
      this.setBounds.apply(this, arguments);
    }
  }

  Bounds.from = function() {
    var b = new Bounds();
    return b.setBounds.apply(b, arguments);
  };

  Bounds.prototype.toString = function() {
    return JSON.stringify({
      xmin: this.xmin,
      xmax: this.xmax,
      ymin: this.ymin,
      ymax: this.ymax
    });
  };

  Bounds.prototype.toArray = function() {
    return this.hasBounds() ? [this.xmin, this.ymin, this.xmax, this.ymax] : [];
  };

  Bounds.prototype.hasBounds = function() {
    return this.xmin <= this.xmax && this.ymin <= this.ymax;
  };

  Bounds.prototype.sameBounds =
  Bounds.prototype.equals = function(bb) {
    return bb && this.xmin === bb.xmin && this.xmax === bb.xmax &&
      this.ymin === bb.ymin && this.ymax === bb.ymax;
  };

  Bounds.prototype.width = function() {
    return (this.xmax - this.xmin) || 0;
  };

  Bounds.prototype.height = function() {
    return (this.ymax - this.ymin) || 0;
  };

  Bounds.prototype.area = function() {
    return this.width() * this.height() || 0;
  };

  Bounds.prototype.empty = function() {
    this.xmin = this.ymin = this.xmax = this.ymax = void 0;
    return this;
  };

  Bounds.prototype.setBounds = function(a, b, c, d) {
    if (arguments.length == 1) {
      // assume first arg is a Bounds or array
      if (utils.isArrayLike(a)) {
        b = a[1];
        c = a[2];
        d = a[3];
        a = a[0];
      } else {
        b = a.ymin;
        c = a.xmax;
        d = a.ymax;
        a = a.xmin;
      }
    }

    this.xmin = a;
    this.ymin = b;
    this.xmax = c;
    this.ymax = d;
    if (a > c || b > d) this.update();
    // error("Bounds#setBounds() min/max reversed:", a, b, c, d);
    return this;
  };


  Bounds.prototype.centerX = function() {
    var x = (this.xmin + this.xmax) * 0.5;
    return x;
  };

  Bounds.prototype.centerY = function() {
    var y = (this.ymax + this.ymin) * 0.5;
    return y;
  };

  Bounds.prototype.containsPoint = function(x, y) {
    if (x >= this.xmin && x <= this.xmax &&
      y <= this.ymax && y >= this.ymin) {
      return true;
    }
    return false;
  };

  // intended to speed up slightly bubble symbol detection; could use intersects() instead
  // TODO: fix false positive where circle is just outside a corner of the box
  Bounds.prototype.containsBufferedPoint =
  Bounds.prototype.containsCircle = function(x, y, buf) {
    if ( x + buf > this.xmin && x - buf < this.xmax ) {
      if ( y - buf < this.ymax && y + buf > this.ymin ) {
        return true;
      }
    }
    return false;
  };

  Bounds.prototype.intersects = function(bb) {
    if (bb.xmin <= this.xmax && bb.xmax >= this.xmin &&
      bb.ymax >= this.ymin && bb.ymin <= this.ymax) {
      return true;
    }
    return false;
  };

  Bounds.prototype.contains = function(bb) {
    if (bb.xmin >= this.xmin && bb.ymax <= this.ymax &&
      bb.xmax <= this.xmax && bb.ymin >= this.ymin) {
      return true;
    }
    return false;
  };

  Bounds.prototype.shift = function(x, y) {
    this.setBounds(this.xmin + x,
      this.ymin + y, this.xmax + x, this.ymax + y);
  };

  Bounds.prototype.padBounds = function(a, b, c, d) {
    this.xmin -= a;
    this.ymin -= b;
    this.xmax += c;
    this.ymax += d;
  };

  // Rescale the bounding box by a fraction. TODO: implement focus.
  // @param {number} pct Fraction of original extents
  // @param {number} pctY Optional amount to scale Y
  //
  Bounds.prototype.scale = function(pct, pctY) { /*, focusX, focusY*/
    var halfWidth = (this.xmax - this.xmin) * 0.5;
    var halfHeight = (this.ymax - this.ymin) * 0.5;
    var kx = pct - 1;
    var ky = pctY === undefined ? kx : pctY - 1;
    this.xmin -= halfWidth * kx;
    this.ymin -= halfHeight * ky;
    this.xmax += halfWidth * kx;
    this.ymax += halfHeight * ky;
  };

  // Return a bounding box with the same extent as this one.
  Bounds.prototype.cloneBounds = // alias so child classes can override clone()
  Bounds.prototype.clone = function() {
    return new Bounds(this.xmin, this.ymin, this.xmax, this.ymax);
  };

  Bounds.prototype.clearBounds = function() {
    this.setBounds(new Bounds());
  };

  Bounds.prototype.mergePoint = function(x, y) {
    if (this.xmin === void 0) {
      this.setBounds(x, y, x, y);
    } else {
      // this works even if x,y are NaN
      if (x < this.xmin)  this.xmin = x;
      else if (x > this.xmax)  this.xmax = x;

      if (y < this.ymin) this.ymin = y;
      else if (y > this.ymax) this.ymax = y;
    }
  };

  // expands either x or y dimension to match @aspect (width/height ratio)
  // @focusX, @focusY (optional): expansion focus, as a fraction of width and height
  Bounds.prototype.fillOut = function(aspect, focusX, focusY) {
    if (arguments.length < 3) {
      focusX = 0.5;
      focusY = 0.5;
    }
    var w = this.width(),
        h = this.height(),
        currAspect = w / h,
        pad;
    if (isNaN(aspect) || aspect <= 0) {
      // error condition; don't pad
    } else if (currAspect < aspect) { // fill out x dimension
      pad = h * aspect - w;
      this.xmin -= (1 - focusX) * pad;
      this.xmax += focusX * pad;
    } else {
      pad = w / aspect - h;
      this.ymin -= (1 - focusY) * pad;
      this.ymax += focusY * pad;
    }
    return this;
  };

  Bounds.prototype.update = function() {
    var tmp;
    if (this.xmin > this.xmax) {
      tmp = this.xmin;
      this.xmin = this.xmax;
      this.xmax = tmp;
    }
    if (this.ymin > this.ymax) {
      tmp = this.ymin;
      this.ymin = this.ymax;
      this.ymax = tmp;
    }
  };

  Bounds.prototype.transform = function(t) {
    this.xmin = this.xmin * t.mx + t.bx;
    this.xmax = this.xmax * t.mx + t.bx;
    this.ymin = this.ymin * t.my + t.by;
    this.ymax = this.ymax * t.my + t.by;
    this.update();
    return this;
  };

  // Returns a Transform object for mapping this onto Bounds @b2
  // @flipY (optional) Flip y-axis coords, for converting to/from pixel coords
  //
  Bounds.prototype.getTransform = function(b2, flipY) {
    var t = new Transform();
    t.mx = b2.width() / this.width() || 1; // TODO: better handling of 0 w,h
    t.bx = b2.xmin - t.mx * this.xmin;
    if (flipY) {
      t.my = -b2.height() / this.height() || 1;
      t.by = b2.ymax - t.my * this.ymin;
    } else {
      t.my = b2.height() / this.height() || 1;
      t.by = b2.ymin - t.my * this.ymin;
    }
    return t;
  };

  Bounds.prototype.mergeCircle = function(x, y, r) {
    if (r < 0) r = -r;
    this.mergeBounds([x - r, y - r, x + r, y + r]);
  };

  Bounds.prototype.mergeBounds = function(bb) {
    var a, b, c, d;
    if (bb instanceof Bounds) {
      a = bb.xmin;
      b = bb.ymin;
      c = bb.xmax;
      d = bb.ymax;
    } else if (arguments.length == 4) {
      a = arguments[0];
      b = arguments[1];
      c = arguments[2];
      d = arguments[3];
    } else if (bb.length == 4) {
      // assume array: [xmin, ymin, xmax, ymax]
      a = bb[0];
      b = bb[1];
      c = bb[2];
      d = bb[3];
    } else {
      error("Bounds#mergeBounds() invalid argument:", bb);
    }

    if (this.xmin === void 0) {
      this.setBounds(a, b, c, d);
    } else {
      if (a < this.xmin) this.xmin = a;
      if (b < this.ymin) this.ymin = b;
      if (c > this.xmax) this.xmax = c;
      if (d > this.ymax) this.ymax = d;
    }
    return this;
  };

  function countPointsInLayer(lyr) {
    var count = 0;
    if (layerHasPoints(lyr)) {
      forEachPoint(lyr.shapes, function() {count++;});
    }
    return count;
  }

  function getPointBounds$1(shapes) {
    var bounds = new Bounds();
    forEachPoint(shapes, function(p) {
      bounds.mergePoint(p[0], p[1]);
    });
    return bounds;
  }

  function getPointFeatureBounds(shape, bounds) {
    var n = shape ? shape.length : 0;
    var p;
    if (!bounds) bounds = new Bounds();
    for (var i=0; i<n; i++) {
      p = shape[i];
      bounds.mergePoint(p[0], p[1]);
    }
    return bounds;
  }

  // NOTE: layers can have multipoint features and null features
  function getPointsInLayer(lyr) {
    var coords = [];
    forEachPoint(lyr.shapes, function(p) {
      coords.push(p);
    });
    return coords;
  }

  // Iterate over each [x,y] point in a layer
  // shapes: one layer's "shapes" array
  function forEachPoint(shapes, cb) {
    var i, n, j, m, shp;
    for (i=0, n=shapes.length; i<n; i++) {
      shp = shapes[i];
      for (j=0, m=shp ? shp.length : 0; j<m; j++) {
        cb(shp[j], i);
      }
    }
  }

  var PointUtils = /*#__PURE__*/Object.freeze({
    __proto__: null,
    countPointsInLayer: countPointsInLayer,
    getPointBounds: getPointBounds$1,
    getPointFeatureBounds: getPointFeatureBounds,
    getPointsInLayer: getPointsInLayer,
    forEachPoint: forEachPoint
  });

  function absArcId(arcId) {
    return arcId >= 0 ? arcId : ~arcId;
  }

  function calcArcBounds(xx, yy, start, len) {
    var i = start | 0,
        n = isNaN(len) ? xx.length - i : len + i,
        x, y, xmin, ymin, xmax, ymax;
    if (n > 0) {
      xmin = xmax = xx[i];
      ymin = ymax = yy[i];
    }
    for (i++; i<n; i++) {
      x = xx[i];
      y = yy[i];
      if (x < xmin) xmin = x;
      if (x > xmax) xmax = x;
      if (y < ymin) ymin = y;
      if (y > ymax) ymax = y;
    }
    return [xmin, ymin, xmax, ymax];
  }

  var WGS84 = {
    // https://en.wikipedia.org/wiki/Earth_radius
    SEMIMAJOR_AXIS: 6378137,
    SEMIMINOR_AXIS: 6356752.3142,
    AUTHALIC_RADIUS: 6371007.2,
    VOLUMETRIC_RADIUS: 6371000.8
  };

  // TODO: remove this constant, use actual data from dataset CRS,
  // also consider using ellipsoidal formulas where greater accuracy might be important.
  var R$1 = WGS84.SEMIMAJOR_AXIS;
  var D2R = Math.PI / 180;
  var R2D = 180 / Math.PI;

  // Equirectangular projection
  function degreesToMeters(deg) {
    return deg * D2R * R$1;
  }

  function distance3D(ax, ay, az, bx, by, bz) {
    var dx = ax - bx,
      dy = ay - by,
      dz = az - bz;
    return Math.sqrt(dx * dx + dy * dy + dz * dz);
  }

  function distanceSq(ax, ay, bx, by) {
    var dx = ax - bx,
        dy = ay - by;
    return dx * dx + dy * dy;
  }

  function distance2D(ax, ay, bx, by) {
    var dx = ax - bx,
        dy = ay - by;
    return Math.sqrt(dx * dx + dy * dy);
  }

  function distanceSq3D(ax, ay, az, bx, by, bz) {
    var dx = ax - bx,
        dy = ay - by,
        dz = az - bz;
    return dx * dx + dy * dy + dz * dz;
  }

  // atan2() makes this function fairly slow, replaced by ~2x faster formula
  function innerAngle2(ax, ay, bx, by, cx, cy) {
    var a1 = Math.atan2(ay - by, ax - bx),
        a2 = Math.atan2(cy - by, cx - bx),
        a3 = Math.abs(a1 - a2);
    if (a3 > Math.PI) {
      a3 = 2 * Math.PI - a3;
    }
    return a3;
  }

  // Return angle abc in range [0, 2PI) or NaN if angle is invalid
  // (e.g. if length of ab or bc is 0)
  /*
  function signedAngle2(ax, ay, bx, by, cx, cy) {
    var a1 = Math.atan2(ay - by, ax - bx),
        a2 = Math.atan2(cy - by, cx - bx),
        a3 = a2 - a1;

    if (ax == bx && ay == by || bx == cx && by == cy) {
      a3 = NaN; // Use NaN for invalid angles
    } else if (a3 >= Math.PI * 2) {
      a3 = 2 * Math.PI - a3;
    } else if (a3 < 0) {
      a3 = a3 + 2 * Math.PI;
    }
    return a3;
  }
  */

  function standardAngle(a) {
    var twoPI = Math.PI * 2;
    while (a < 0) {
      a += twoPI;
    }
    while (a >= twoPI) {
      a -= twoPI;
    }
    return a;
  }

  function signedAngle(ax, ay, bx, by, cx, cy) {
    if (ax == bx && ay == by || bx == cx && by == cy) {
      return NaN; // Use NaN for invalid angles
    }
    var abx = ax - bx,
        aby = ay - by,
        cbx = cx - bx,
        cby = cy - by,
        dotp = abx * cbx + aby * cby,
        crossp = abx * cby - aby * cbx,
        a = Math.atan2(crossp, dotp);
    return standardAngle(a);
  }

  function bearing2D(x1, y1, x2, y2) {
    var val = Math.PI/2 - Math.atan2(y2 - y1, x2 - x1);
    return val > Math.PI ? val - 2 * Math.PI : val;
  }

  // Calc bearing in radians at lng1, lat1
  function bearing(lng1, lat1, lng2, lat2) {
    var D2R = Math.PI / 180;
    lng1 *= D2R;
    lng2 *= D2R;
    lat1 *= D2R;
    lat2 *= D2R;
    var y = Math.sin(lng2-lng1) * Math.cos(lat2),
        x = Math.cos(lat1)*Math.sin(lat2) - Math.sin(lat1)*Math.cos(lat2)*Math.cos(lng2-lng1);
    return Math.atan2(y, x);
  }

  // Calc angle of turn from ab to bc, in range [0, 2PI)
  // Receive lat-lng values in degrees
  function signedAngleSph(alng, alat, blng, blat, clng, clat) {
    if (alng == blng && alat == blat || blng == clng && blat == clat) {
      return NaN;
    }
    var b1 = bearing(blng, blat, alng, alat), // calc bearing at b
        b2 = bearing(blng, blat, clng, clat),
        a = Math.PI * 2 + b1 - b2;
    return standardAngle(a);
  }

  /*
  // Convert arrays of lng and lat coords (xsrc, ysrc) into
  // x, y, z coords (meters) on the most common spherical Earth model.
  //
  function convLngLatToSph(xsrc, ysrc, xbuf, ybuf, zbuf) {
    var deg2rad = Math.PI / 180,
        r = R;
    for (var i=0, len=xsrc.length; i<len; i++) {
      var lng = xsrc[i] * deg2rad,
          lat = ysrc[i] * deg2rad,
          cosLat = Math.cos(lat);
      xbuf[i] = Math.cos(lng) * cosLat * r;
      ybuf[i] = Math.sin(lng) * cosLat * r;
      zbuf[i] = Math.sin(lat) * r;
    }
  }
  */

  // Convert arrays of lng and lat coords (xsrc, ysrc) into
  // x, y, z coords (meters) on the most common spherical Earth model.
  //
  function convLngLatToSph(xsrc, ysrc, xbuf, ybuf, zbuf) {
    var p = [];
    for (var i=0, len=xsrc.length; i<len; i++) {
      lngLatToXYZ(xsrc[i], ysrc[i], p);
      xbuf[i] = p[0];
      ybuf[i] = p[1];
      zbuf[i] = p[2];
    }
  }

  function xyzToLngLat(x, y, z, p) {
    var d = distance3D(0, 0, 0, x, y, z); // normalize
    var lat = Math.asin(z / d) / D2R;
    var lng = Math.atan2(y / d, x / d) / D2R;
    p[0] = lng;
    p[1] = lat;
  }

  function lngLatToXYZ(lng, lat, p) {
    var cosLat;
    lng *= D2R;
    lat *= D2R;
    cosLat = Math.cos(lat);
    p[0] = Math.cos(lng) * cosLat * R$1;
    p[1] = Math.sin(lng) * cosLat * R$1;
    p[2] = Math.sin(lat) * R$1;
  }

  // Haversine formula (well conditioned at small distances)
  function sphericalDistance(lam1, phi1, lam2, phi2) {
    var dlam = lam2 - lam1,
        dphi = phi2 - phi1,
        a = Math.sin(dphi / 2) * Math.sin(dphi / 2) +
            Math.cos(phi1) * Math.cos(phi2) *
            Math.sin(dlam / 2) * Math.sin(dlam / 2),
        c = 2 * Math.atan2(Math.sqrt(a), Math.sqrt(1 - a));
    return c;
  }

  // Receive: coords in decimal degrees;
  // Return: distance in meters on spherical earth
  function greatCircleDistance(lng1, lat1, lng2, lat2) {
    var D2R = Math.PI / 180,
        dist = sphericalDistance(lng1 * D2R, lat1 * D2R, lng2 * D2R, lat2 * D2R);
    return dist * R$1;
  }

  // TODO: make this safe for small angles
  function innerAngle(ax, ay, bx, by, cx, cy) {
    var ab = distance2D(ax, ay, bx, by),
        bc = distance2D(bx, by, cx, cy),
        theta, dotp;
    if (ab === 0 || bc === 0) {
      theta = 0;
    } else {
      dotp = ((ax - bx) * (cx - bx) + (ay - by) * (cy - by)) / (ab * bc);
      if (dotp >= 1 - 1e-14) {
        theta = 0;
      } else if (dotp <= -1 + 1e-14) {
        theta = Math.PI;
      } else {
        theta = Math.acos(dotp); // consider using other formula at small dp
      }
    }
    return theta;
  }

  function innerAngle3D(ax, ay, az, bx, by, bz, cx, cy, cz) {
    var ab = distance3D(ax, ay, az, bx, by, bz),
        bc = distance3D(bx, by, bz, cx, cy, cz),
        theta, dotp;
    if (ab === 0 || bc === 0) {
      theta = 0;
    } else {
      dotp = ((ax - bx) * (cx - bx) + (ay - by) * (cy - by) + (az - bz) * (cz - bz)) / (ab * bc);
      if (dotp >= 1) {
        theta = 0;
      } else if (dotp <= -1) {
        theta = Math.PI;
      } else {
        theta = Math.acos(dotp); // consider using other formula at small dp
      }
    }
    return theta;
  }

  function triangleArea(ax, ay, bx, by, cx, cy) {
    var area = Math.abs(((ay - cy) * (bx - cx) + (by - cy) * (cx - ax)) / 2);
    return area;
  }

  function detSq(ax, ay, bx, by, cx, cy) {
    var det = ax * by - ax * cy + bx * cy - bx * ay + cx * ay - cx * by;
    return det * det;
  }

  function cosine(ax, ay, bx, by, cx, cy) {
    var den = distance2D(ax, ay, bx, by) * distance2D(bx, by, cx, cy),
        cos = 0;
    if (den > 0) {
      cos = ((ax - bx) * (cx - bx) + (ay - by) * (cy - by)) / den;
      if (cos > 1) cos = 1; // handle fp rounding error
      else if (cos < -1) cos = -1;
    }
    return cos;
  }

  function cosine3D(ax, ay, az, bx, by, bz, cx, cy, cz) {
    var den = distance3D(ax, ay, az, bx, by, bz) * distance3D(bx, by, bz, cx, cy, cz),
        cos = 0;
    if (den > 0) {
      cos = ((ax - bx) * (cx - bx) + (ay - by) * (cy - by) + (az - bz) * (cz - bz)) / den;
      if (cos > 1) cos = 1; // handle fp rounding error
      else if (cos < -1) cos = -1;
    }
    return cos;
  }

  function triangleArea3D(ax, ay, az, bx, by, bz, cx, cy, cz) {
    var area = 0.5 * Math.sqrt(detSq(ax, ay, bx, by, cx, cy) +
      detSq(ax, az, bx, bz, cx, cz) + detSq(ay, az, by, bz, cy, cz));
    return area;
  }

  // Given point B and segment AC, return the squared distance from B to the
  // nearest point on AC
  // Receive the squared length of segments AB, BC, AC
  // TODO: analyze rounding error. Returns 0 for these coordinates:
  //    P: [2, 3 - 1e-8]  AB: [[1, 3], [3, 3]]
  //
  function apexDistSq(ab2, bc2, ac2) {
    var dist2;
    if (ac2 === 0) {
      dist2 = ab2;
    } else if (ab2 >= bc2 + ac2) {
      dist2 = bc2;
    } else if (bc2 >= ab2 + ac2) {
      dist2 = ab2;
    } else {
      var dval = (ab2 + ac2 - bc2);
      dist2 = ab2 -  dval * dval / ac2  * 0.25;
    }
    if (dist2 < 0) {
      dist2 = 0;
    }
    return dist2;
  }

  function pointSegDistSq(ax, ay, bx, by, cx, cy) {
    var ab2 = distanceSq(ax, ay, bx, by),
        ac2 = distanceSq(ax, ay, cx, cy),
        bc2 = distanceSq(bx, by, cx, cy);
    return apexDistSq(ab2, ac2, bc2);
  }

  function pointSegDistSq3D(ax, ay, az, bx, by, bz, cx, cy, cz) {
    var ab2 = distanceSq3D(ax, ay, az, bx, by, bz),
        ac2 = distanceSq3D(ax, ay, az, cx, cy, cz),
        bc2 = distanceSq3D(bx, by, bz, cx, cy, cz);
    return apexDistSq(ab2, ac2, bc2);
  }

  // Apparently better conditioned for some inputs than pointSegDistSq()
  //
  function pointSegDistSq2(px, py, ax, ay, bx, by) {
    var ab2 = distanceSq(ax, ay, bx, by);
    var t = ((px - ax) * (bx - ax) + (py - ay) * (by - ay)) / ab2;
    if (ab2 === 0) return distanceSq(px, py, ax, ay);
    if (t < 0) t = 0;
    if (t > 1) t = 1;
    return distanceSq(px, py, ax + t * (bx - ax), ay + t * (by - ay));
  }


  // internal.reversePathCoords = function(arr, start, len) {
  //   var i = start,
  //       j = start + len - 1,
  //       tmp;
  //   while (i < j) {
  //     tmp = arr[i];
  //     arr[i] = arr[j];
  //     arr[j] = tmp;
  //     i++;
  //     j--;
  //   }
  // };

  // merge B into A
  // function mergeBounds(a, b) {
  //   if (b[0] < a[0]) a[0] = b[0];
  //   if (b[1] < a[1]) a[1] = b[1];
  //   if (b[2] > a[2]) a[2] = b[2];
  //   if (b[3] > a[3]) a[3] = b[3];
  // }

  function containsBounds(a, b) {
    return a[0] <= b[0] && a[2] >= b[2] && a[1] <= b[1] && a[3] >= b[3];
  }

  // function boundsArea(b) {
  //   return (b[2] - b[0]) * (b[3] - b[1]);
  // }

  var Geom = /*#__PURE__*/Object.freeze({
    __proto__: null,
    R: R$1,
    D2R: D2R,
    R2D: R2D,
    degreesToMeters: degreesToMeters,
    distance3D: distance3D,
    distanceSq: distanceSq,
    distance2D: distance2D,
    distanceSq3D: distanceSq3D,
    innerAngle2: innerAngle2,
    standardAngle: standardAngle,
    signedAngle: signedAngle,
    bearing2D: bearing2D,
    bearing: bearing,
    signedAngleSph: signedAngleSph,
    convLngLatToSph: convLngLatToSph,
    xyzToLngLat: xyzToLngLat,
    lngLatToXYZ: lngLatToXYZ,
    sphericalDistance: sphericalDistance,
    greatCircleDistance: greatCircleDistance,
    innerAngle: innerAngle,
    innerAngle3D: innerAngle3D,
    triangleArea: triangleArea,
    cosine: cosine,
    cosine3D: cosine3D,
    triangleArea3D: triangleArea3D,
    pointSegDistSq: pointSegDistSq,
    pointSegDistSq3D: pointSegDistSq3D,
    pointSegDistSq2: pointSegDistSq2,
    containsBounds: containsBounds
  });

  function pathIsClosed(ids, arcs) {
    var firstArc = ids[0];
    var lastArc = ids[ids.length - 1];
    var p1 = arcs.getVertex(firstArc, 0);
    var p2 = arcs.getVertex(lastArc, -1);
    var closed = p1.x === p2.x && p1.y === p2.y;
    return closed;
  }

  function getPointToPathDistance(px, py, ids, arcs) {
    return getPointToPathInfo(px, py, ids, arcs).distance;
  }

  function getPointToPathInfo(px, py, ids, arcs) {
    var iter = arcs.getShapeIter(ids);
    var pPathSq = Infinity;
    var ax, ay, bx, by, axmin, aymin, bxmin, bymin, pabSq;
    if (iter.hasNext()) {
      ax = axmin = bxmin = iter.x;
      ay = aymin = bymin = iter.y;
    }
    while (iter.hasNext()) {
      bx = iter.x;
      by = iter.y;
      pabSq = pointSegDistSq2(px, py, ax, ay, bx, by);
      if (pabSq < pPathSq) {
        pPathSq = pabSq;
        axmin = ax;
        aymin = ay;
        bxmin = bx;
        bymin = by;
      }
      ax = bx;
      ay = by;
    }
    if (pPathSq == Infinity) return {distance: Infinity};
    return {
      segment: [[axmin, aymin], [bxmin, bymin]],
      distance: Math.sqrt(pPathSq)
    };
  }


  // Return unsigned distance of a point to the nearest point on a polygon or polyline path
  //
  function getPointToShapeDistance(x, y, shp, arcs) {
    var minDist = (shp || []).reduce(function(minDist, ids) {
      var pathDist = getPointToPathDistance(x, y, ids, arcs);
      return Math.min(minDist, pathDist);
    }, Infinity);
    return minDist;
  }

  // @ids array of arc ids
  // @arcs ArcCollection
  function getAvgPathXY(ids, arcs) {
    var iter = arcs.getShapeIter(ids);
    if (!iter.hasNext()) return null;
    var x0 = iter.x,
        y0 = iter.y,
        count = 0,
        sumX = 0,
        sumY = 0;
    while (iter.hasNext()) {
      count++;
      sumX += iter.x;
      sumY += iter.y;
    }
    if (count === 0 || iter.x !== x0 || iter.y !== y0) {
      sumX += x0;
      sumY += y0;
      count++;
    }
    return {
      x: sumX / count,
      y: sumY / count
    };
  }

  // Return path with the largest (area) bounding box
  // @shp array of array of arc ids
  // @arcs ArcCollection
  function getMaxPath(shp, arcs) {
    var maxArea = 0;
    return (shp || []).reduce(function(maxPath, path) {
      var bbArea = arcs.getSimpleShapeBounds(path).area();
      if (bbArea > maxArea) {
        maxArea = bbArea;
        maxPath = path;
      }
      return maxPath;
    }, null);
  }

  function countVerticesInPath(ids, arcs) {
    var iter = arcs.getShapeIter(ids),
        count = 0;
    while (iter.hasNext()) count++;
    return count;
  }

  function getPathBounds$1(points) {
    var bounds = new Bounds();
    for (var i=0, n=points.length; i<n; i++) {
      bounds.mergePoint(points[i][0], points[i][1]);
    }
    return bounds;
  }

  var calcPathLen;
  calcPathLen = (function() {
    var len, calcLen;
    function addSegLen(i, j, xx, yy) {
      len += calcLen(xx[i], yy[i], xx[j], yy[j]);
    }
    // @spherical (optional bool) calculate great circle length in meters
    return function(path, arcs, spherical) {
      if (spherical && arcs.isPlanar()) {
        error("Expected lat-long coordinates");
      }
      calcLen = spherical ? greatCircleDistance : distance2D;
      len = 0;
      for (var i=0, n=path.length; i<n; i++) {
        arcs.forEachArcSegment(path[i], addSegLen);
      }
      return len;
    };
  }());

  var PathGeom = /*#__PURE__*/Object.freeze({
    __proto__: null,
    pathIsClosed: pathIsClosed,
    getPointToPathDistance: getPointToPathDistance,
    getPointToPathInfo: getPointToPathInfo,
    getPointToShapeDistance: getPointToShapeDistance,
    getAvgPathXY: getAvgPathXY,
    getMaxPath: getMaxPath,
    countVerticesInPath: countVerticesInPath,
    getPathBounds: getPathBounds$1,
    get calcPathLen () { return calcPathLen; }
  });

  // Get the centroid of the largest ring of a polygon
  // TODO: Include holes in the calculation
  // TODO: Add option to find centroid of all rings, not just the largest
  function getShapeCentroid(shp, arcs) {
    var maxPath = getMaxPath(shp, arcs);
    return maxPath ? getPathCentroid(maxPath, arcs) : null;
  }

  function getPathCentroid(ids, arcs) {
    var iter = arcs.getShapeIter(ids),
        sum = 0,
        sumX = 0,
        sumY = 0,
        dx, dy, ax, ay, bx, by, tmp, area;
    if (!iter.hasNext()) return null;
    // reduce effect of fp errors by shifting shape origin to 0,0 (issue #304)
    ax = 0;
    ay = 0;
    dx = -iter.x;
    dy = -iter.y;
    while (iter.hasNext()) {
      bx = ax;
      by = ay;
      ax = iter.x + dx;
      ay = iter.y + dy;
      tmp = bx * ay - by * ax;
      sum += tmp;
      sumX += tmp * (bx + ax);
      sumY += tmp * (by + ay);
    }
    area = sum / 2;
    if (area === 0) {
      return getAvgPathXY(ids, arcs);
    } else return {
      x: sumX / (6 * area) - dx,
      y: sumY / (6 * area) - dy
    };
  }

  var PolygonCentroid = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getShapeCentroid: getShapeCentroid,
    getPathCentroid: getPathCentroid
  });

  // A compactness measure designed for testing electoral districts for gerrymandering.
  // Returns value in [0-1] range. 1 = perfect circle, 0 = collapsed polygon
  function calcPolsbyPopperCompactness(area, perimeter) {
    if (perimeter <= 0) return 0;
    return Math.abs(area) * Math.PI * 4 / (perimeter * perimeter);
  }

  // Larger values (less severe penalty) than Polsby Popper
  function calcSchwartzbergCompactness(area, perimeter) {
    if (perimeter <= 0) return 0;
    return 2 * Math.PI * Math.sqrt(Math.abs(area) / Math.PI) / perimeter;
  }

  // Returns: 1 if CW, -1 if CCW, 0 if collapsed
  function getPathWinding(ids, arcs) {
    var area = getPathArea(ids, arcs);
    return area > 0 && 1 || area < 0 && -1 || 0;
  }

  function getShapeArea(shp, arcs) {
    // return (arcs.isPlanar() ? geom.getPlanarShapeArea : geom.getSphericalShapeArea)(shp, arcs);
    return (shp || []).reduce(function(area, ids) {
      return area + getPathArea(ids, arcs);
    }, 0);
  }

  function getPlanarShapeArea(shp, arcs) {
    return (shp || []).reduce(function(area, ids) {
      return area + getPlanarPathArea(ids, arcs);
    }, 0);
  }

  function getSphericalShapeArea(shp, arcs, R) {
    if (arcs.isPlanar()) {
      error("[getSphericalShapeArea()] Function requires decimal degree coordinates");
    }
    return (shp || []).reduce(function(area, ids) {
      return area + getSphericalPathArea(ids, arcs, R);
    }, 0);
  }

  // export function getEllipsoidalShapeArea(shp, arcs, crs) {
  //   return (shp || []).reduce(function(area, ids) {
  //     return area + getEllipsoidalPathArea(ids, arcs, crs);
  //   }, 0);
  // }

  // Return true if point is inside or on boundary of a shape
  //
  function testPointInPolygon(x, y, shp, arcs) {
    var isIn = false,
        isOn = false;
    if (shp) {
      shp.forEach(function(ids) {
        var inRing = testPointInRing(x, y, ids, arcs);
        if (inRing == 1) {
          isIn = !isIn;
        } else if (inRing == -1) {
          isOn = true;
        }
      });
    }
    return isOn || isIn;
  }

  function getYIntercept(x, ax, ay, bx, by) {
    return ay + (x - ax) * (by - ay) / (bx - ax);
  }

  function getXIntercept(y, ax, ay, bx, by) {
    return ax + (y - ay) * (bx - ax) / (by - ay);
  }

  // Test if point (x, y) is inside, outside or on the boundary of a polygon ring
  // Return 0: outside; 1: inside; -1: on boundary
  //
  function testPointInRing(x, y, ids, arcs) {
    /*
    // arcs.getSimpleShapeBounds() doesn't apply simplification, can't use here
    //// wait, why not? simplifcation shoudn't expand bounds, so this test makes sense
    if (!arcs.getSimpleShapeBounds(ids).containsPoint(x, y)) {
      return false;
    }
    */
    var isIn = false,
        isOn = false;
    forEachSegmentInPath(ids, arcs, function(a, b, xx, yy) {
      var result = testRayIntersection(x, y, xx[a], yy[a], xx[b], yy[b]);
      if (result == 1) {
        isIn = !isIn;
      } else if (isNaN(result)) {
        isOn = true;
      }
    });
    return isOn ? -1 : (isIn ? 1 : 0);
  }

  // test if a vertical ray originating at (x, y) intersects a segment
  // returns 1 if intersection, 0 if no intersection, NaN if point touches segment
  // (Special rules apply to endpoint intersections, to support point-in-polygon testing.)
  function testRayIntersection(x, y, ax, ay, bx, by) {
    var val = getRayIntersection(x, y, ax, ay, bx, by);
    if (val != val) {
      return NaN;
    }
    return val == -Infinity ? 0 : 1;
  }

  function getRayIntersection(x, y, ax, ay, bx, by) {
    var hit = -Infinity, // default: no hit
        yInt;

    // case: p is entirely above, left or right of segment
    if (x < ax && x < bx || x > ax && x > bx || y > ay && y > by) {
        // no intersection
    }
    // case: px aligned with a segment vertex
    else if (x === ax || x === bx) {
      // case: vertical segment or collapsed segment
      if (x === ax && x === bx) {
        // p is on segment
        if (y == ay || y == by || y > ay != y > by) {
          hit = NaN;
        }
        // else: no hit
      }
      // case: px equal to ax (only)
      else if (x === ax) {
        if (y === ay) {
          hit = NaN;
        } else if (bx < ax && y < ay) {
          // only score hit if px aligned to rightmost endpoint
          hit = ay;
        }
      }
      // case: px equal to bx (only)
      else {
        if (y === by) {
          hit = NaN;
        } else if (ax < bx && y < by) {
          // only score hit if px aligned to rightmost endpoint
          hit = by;
        }
      }
    // case: px is between endpoints
    } else {
      yInt = getYIntercept(x, ax, ay, bx, by);
      if (yInt > y) {
        hit = yInt;
      } else if (yInt == y) {
        hit = NaN;
      }
    }
    return hit;
  }

  function getPathArea(ids, arcs) {
    return (arcs.isPlanar() ? getPlanarPathArea : getSphericalPathArea)(ids, arcs);
  }

  function getSphericalPathArea(ids, arcs, R) {
    var iter = arcs.getShapeIter(ids);
    return getSphericalPathArea2(iter, R);
  }

  function getSphericalPathArea2(iter, R) {
    var sum = 0,
        started = false,
        deg2rad = Math.PI / 180,
        x, y, xp, yp;
    R = R || WGS84.SEMIMAJOR_AXIS;
    while (iter.hasNext()) {
      x = iter.x * deg2rad;
      y = Math.sin(iter.y * deg2rad);
      if (started) {
        sum += (x - xp) * (2 + y + yp);
      } else {
        started = true;
      }
      xp = x;
      yp = y;
    }
    return sum / 2 * R * R;
  }

  // Get path area from an array of [x, y] points
  // TODO: consider removing duplication with getPathArea(), e.g. by
  //   wrapping points in an iterator.
  //
  function getPlanarPathArea2(points) {
    var sum = 0,
        ax, ay, bx, by, dx, dy, p;
    for (var i=0, n=points.length; i<n; i++) {
      p = points[i];
      if (i === 0) {
        ax = 0;
        ay = 0;
        dx = -p[0];
        dy = -p[1];
      } else {
        ax = p[0] + dx;
        ay = p[1] + dy;
        sum += ax * by - bx * ay;
      }
      bx = ax;
      by = ay;
    }
    return sum / 2;
  }

  function getPlanarPathArea(ids, arcs) {
    var iter = arcs.getShapeIter(ids),
        sum = 0,
        ax, ay, bx, by, dx, dy;
    if (iter.hasNext()) {
      ax = 0;
      ay = 0;
      dx = -iter.x;
      dy = -iter.y;
      while (iter.hasNext()) {
        bx = ax;
        by = ay;
        ax = iter.x + dx;
        ay = iter.y + dy;
        sum += ax * by - bx * ay;
      }
    }
    return sum / 2;
  }

  function getPathPerimeter(ids, arcs) {
    return (arcs.isPlanar() ? getPlanarPathPerimeter : getSphericalPathPerimeter)(ids, arcs);
  }

  function getShapePerimeter(shp, arcs) {
    return (shp || []).reduce(function(len, ids) {
      return len + getPathPerimeter(ids, arcs);
    }, 0);
  }

  function getSphericalShapePerimeter(shp, arcs) {
    if (arcs.isPlanar()) {
      error("[getSphericalShapePerimeter()] Function requires decimal degree coordinates");
    }
    return (shp || []).reduce(function(len, ids) {
      return len + getSphericalPathPerimeter(ids, arcs);
    }, 0);
  }

  function getPlanarPathPerimeter(ids, arcs) {
    return calcPathLen(ids, arcs, false);
  }

  function getSphericalPathPerimeter(ids, arcs) {
    return calcPathLen(ids, arcs, true);
  }

  var PolygonGeom = /*#__PURE__*/Object.freeze({
    __proto__: null,
    calcPolsbyPopperCompactness: calcPolsbyPopperCompactness,
    calcSchwartzbergCompactness: calcSchwartzbergCompactness,
    getPathWinding: getPathWinding,
    getShapeArea: getShapeArea,
    getPlanarShapeArea: getPlanarShapeArea,
    getSphericalShapeArea: getSphericalShapeArea,
    testPointInPolygon: testPointInPolygon,
    testPointInRing: testPointInRing,
    testRayIntersection: testRayIntersection,
    getRayIntersection: getRayIntersection,
    getPathArea: getPathArea,
    getSphericalPathArea: getSphericalPathArea,
    getSphericalPathArea2: getSphericalPathArea2,
    getPlanarPathArea2: getPlanarPathArea2,
    getPlanarPathArea: getPlanarPathArea,
    getPathPerimeter: getPathPerimeter,
    getShapePerimeter: getShapePerimeter,
    getSphericalShapePerimeter: getSphericalShapePerimeter,
    getPlanarPathPerimeter: getPlanarPathPerimeter,
    getSphericalPathPerimeter: getSphericalPathPerimeter
  });

  // Returns an interval for snapping together coordinates that be co-incident bug
  // have diverged because of floating point rounding errors. Intended to be small
  // enought not not to snap points that should be distinct.
  // This is not a robust method... e.g. some formulas for some inputs may produce
  // errors that are larger than this interval.
  // @coords: Array of relevant coordinates (e.g. bbox coordinates of vertex coordinates
  //   of two intersecting segments).
  //
  function getHighPrecisionSnapInterval(coords) {
    var maxCoord = Math.max.apply(null, coords.map(Math.abs));
    return maxCoord * 1e-14;
  }

  function snapCoords(arcs, threshold) {
      var avgDist = getAvgSegment(arcs),
          autoSnapDist = avgDist * 0.0025,
          snapDist = autoSnapDist;

    if (threshold > 0) {
      snapDist = threshold;
      message(utils.format("Applying snapping threshold of %s -- %.6f times avg. segment length", threshold, threshold / avgDist));
    }
    var snapCount = snapCoordsByInterval(arcs, snapDist);
    if (snapCount > 0) arcs.dedupCoords();
    message(utils.format("Snapped %s point%s", snapCount, utils.pluralSuffix(snapCount)));
  }

  // Snap together points within a small threshold
  //
  function snapCoordsByInterval(arcs, snapDist) {
    var snapCount = 0,
        data = arcs.getVertexData(),
        ids;

    if (snapDist > 0) {
      // Get sorted coordinate ids
      // Consider: speed up sorting -- try bucket sort as first pass.
      //
      ids = sortCoordinateIds(data.xx);
      for (var i=0, n=ids.length; i<n; i++) {
        snapCount += snapPoint(i, snapDist, ids, data.xx, data.yy);
      }
    }
    return snapCount;

    function snapPoint(i, limit, ids, xx, yy) {
      var j = i,
          n = ids.length,
          x = xx[ids[i]],
          y = yy[ids[i]],
          snaps = 0,
          id2, dx, dy;

      while (++j < n) {
        id2 = ids[j];
        dx = xx[id2] - x;
        if (dx > limit) break;
        dy = yy[id2] - y;
        if (dx === 0 && dy === 0 || dx * dx + dy * dy > limit * limit) continue;
        xx[id2] = x;
        yy[id2] = y;
        snaps++;
      }
      return snaps;
    }
  }

  function sortCoordinateIds(a) {
    var n = a.length,
        ids = new Uint32Array(n);
    for (var i=0; i<n; i++) {
      ids[i] = i;
    }
    quicksortIds(a, ids, 0, ids.length-1);
    return ids;
  }

  /*
  // Returns array of array ids, in ascending order.
  // @a array of numbers
  //
  utils.sortCoordinateIds = function(a) {
    return utils.bucketSortIds(a);
  };

  // This speeds up sorting of large datasets (~2x faster for 1e7 values)
  // worth the additional code?
  utils.bucketSortIds = function(a, n) {
    var len = a.length,
        ids = new Uint32Array(len),
        bounds = utils.getArrayBounds(a),
        buckets = Math.ceil(n > 0 ? n : len / 10),
        counts = new Uint32Array(buckets),
        offsets = new Uint32Array(buckets),
        i, j, offs, count;

    // get bucket sizes
    for (i=0; i<len; i++) {
      j = bucketId(a[i], bounds.min, bounds.max, buckets);
      counts[j]++;
    }

    // convert counts to offsets
    offs = 0;
    for (i=0; i<buckets; i++) {
      offsets[i] = offs;
      offs += counts[i];
    }

    // assign ids to buckets
    for (i=0; i<len; i++) {
      j = bucketId(a[i], bounds.min, bounds.max, buckets);
      offs = offsets[j]++;
      ids[offs] = i;
    }

    // sort each bucket with quicksort
    for (i = 0; i<buckets; i++) {
      count = counts[i];
      if (count > 1) {
        offs = offsets[i] - count;
        utils.quicksortIds(a, ids, offs, offs + count - 1);
      }
    }
    return ids;

    function bucketId(val, min, max, buckets) {
      var id = (buckets * (val - min) / (max - min)) | 0;
      return id < buckets ? id : buckets - 1;
    }
  };
  */

  function quicksortIds(a, ids, lo, hi) {
    if (hi - lo > 24) {
      var pivot = a[ids[lo + hi >> 1]],
          i = lo,
          j = hi,
          tmp;
      while (i <= j) {
        while (a[ids[i]] < pivot) i++;
        while (a[ids[j]] > pivot) j--;
        if (i <= j) {
          tmp = ids[i];
          ids[i] = ids[j];
          ids[j] = tmp;
          i++;
          j--;
        }
      }
      if (j > lo) quicksortIds(a, ids, lo, j);
      if (i < hi) quicksortIds(a, ids, i, hi);
    } else {
      insertionSortIds(a, ids, lo, hi);
    }
  }

  function insertionSortIds(arr, ids, start, end) {
    var id, i, j;
    for (j = start + 1; j <= end; j++) {
      id = ids[j];
      for (i = j - 1; i >= start && arr[id] < arr[ids[i]]; i--) {
        ids[i+1] = ids[i];
      }
      ids[i+1] = id;
    }
  }

  var Snapping = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getHighPrecisionSnapInterval: getHighPrecisionSnapInterval,
    snapCoords: snapCoords,
    snapCoordsByInterval: snapCoordsByInterval,
    sortCoordinateIds: sortCoordinateIds
  });

  // Find the intersection between two 2D segments
  // Returns 0, 1 or 2 [x, y] locations as null, [x, y], or [x1, y1, x2, y2]
  // Special cases:
  // Endpoint-to-endpoint touches are not treated as intersections.
  // If the segments touch at a T-intersection, it is treated as an intersection.
  // If the segments are collinear and partially overlapping, each subsumed endpoint
  //    is counted as an intersection (there will be either one or two)
  //
  function segmentIntersection(ax, ay, bx, by, cx, cy, dx, dy, epsArg) {
    // Use a small tolerance interval, so collinear segments and T-intersections
    // are detected (floating point rounding often causes exact functions to fail)
    var eps = epsArg >= 0 ? epsArg :
        getHighPrecisionSnapInterval([ax, ay, bx, by, cx, cy, dx, dy]);
    var epsSq = eps * eps;
    var touches, cross;
    // Detect 0, 1 or 2 'touch' intersections, where a vertex of one segment
    // is very close to the other segment's linear portion.
    // One touch indicates either a T-intersection or two overlapping collinear
    // segments that share an endpoint. Two touches indicates overlapping
    // collinear segments that do not share an endpoint.
    touches = findPointSegTouches(epsSq, ax, ay, bx, by, cx, cy, dx, dy);
    // if (touches) return touches;
    // Ignore endpoint-only intersections
    if (!touches && testEndpointHit(epsSq, ax, ay, bx, by, cx, cy, dx, dy)) {
      return null;
    }
    // Detect cross intersection
    cross = findCrossIntersection(ax, ay, bx, by, cx, cy, dx, dy, eps);
    if (cross && touches) {
      // Removed this call -- using multiple snap/cut passes seems more
      // effective for repairing real-world datasets.
      // return reconcileCrossAndTouches(cross, touches, eps);
    }
    return touches || cross || null;
  }

  function reconcileCrossAndTouches(cross, touches, eps) {
    var hits;
    eps = eps || 0;
    if (touches.length > 2) {
      // two touches and a cross: cross should be between the touches, intersection at touches
      hits = touches;
    } else if (distance2D(cross[0], cross[1], touches[0], touches[1]) <= eps) {
      // cross is very close to touch point (e.g. small overshoot): intersection at touch point
      hits = touches;
    } else {
      // one touch and one cross: use both points
      hits = touches.concat(cross);
    }
    return hits;
  }


  // Find the intersection point of two segments that cross each other,
  // or return null if the segments do not cross.
  // Assumes endpoint intersections have already been detected
  function findCrossIntersection(ax, ay, bx, by, cx, cy, dx, dy, eps) {
    if (!segmentHit(ax, ay, bx, by, cx, cy, dx, dy)) return null;
    var den = determinant2D(bx - ax, by - ay, dx - cx, dy - cy);
    var m = orient2D(cx, cy, dx, dy, ax, ay) / den;
    var p = [ax + m * (bx - ax), ay + m * (by - ay)];
    if (Math.abs(den) < 1e-18) {
      // assume that collinear and near-collinear segment intersections have been
      // accounted for already.
      // TODO: is this a valid assumption?
      return null;
    }

    // Snap p to a vertex if very close to one
    // This avoids tiny segments caused by T-intersection overshoots and prevents
    //   pathfinder errors related to f-p rounding.
    // (NOTE: this may no longer be needed, since T-intersections are now detected
    // first)
    if (eps > 0) {
      snapIntersectionPoint(p, ax, ay, bx, by, cx, cy, dx, dy, eps);
    }
    // Clamp point to x range and y range of both segments
    // (This may occur due to fp rounding, if one segment is vertical or horizontal)
    clampIntersectionPoint(p, ax, ay, bx, by, cx, cy, dx, dy);
    return p;
  }

  function testEndpointHit(epsSq, ax, ay, bx, by, cx, cy, dx, dy) {
    return distanceSq(ax, ay, cx, cy) <= epsSq || distanceSq(ax, ay, dx, dy) <= epsSq ||
      distanceSq(bx, by, cx, cy) <= epsSq || distanceSq(bx, by, dx, dy) <= epsSq;
  }

  function findPointSegTouches(epsSq, ax, ay, bx, by, cx, cy, dx, dy) {
    var touches = [];
    collectPointSegTouch(touches, epsSq, ax, ay, cx, cy, dx, dy);
    collectPointSegTouch(touches, epsSq, bx, by, cx, cy, dx, dy);
    collectPointSegTouch(touches, epsSq, cx, cy, ax, ay, bx, by);
    collectPointSegTouch(touches, epsSq, dx, dy, ax, ay, bx, by);
    if (touches.length === 0) return null;
    if (touches.length > 4) {
      // Geometrically, more than two touch intersections can not occur.
      // Is it possible that fp rounding or a bug might result in >2 touches?
      debug('Intersection detection error');
    }
    return touches;
  }

  function collectPointSegTouch(arr, epsSq, px, py, ax, ay, bx, by) {
    // The original point-seg distance function caused errors in test data.
    // (probably because of large rounding errors with some inputs).
    // var pab = pointSegDistSq(px, py, ax, ay, bx, by);
    var pab = pointSegDistSq2(px, py, ax, ay, bx, by);
    if (pab > epsSq) return; // point is too far from segment to touch
    var pa = distanceSq(ax, ay, px, py);
    var pb = distanceSq(bx, by, px, py);
    if (pa <= epsSq || pb <= epsSq) return; // ignore endpoint hits
    arr.push(px, py); // T intersection at P and AB
  }


  // Used by mapshaper-undershoots.js
  // TODO: make more robust, make sure result is compatible with segmentIntersection()
  // (rounding errors currently must be handled downstream)
  function findClosestPointOnSeg(px, py, ax, ay, bx, by) {
    var dx = bx - ax,
        dy = by - ay,
        dotp = (px - ax) * dx + (py - ay) * dy,
        abSq = dx * dx + dy * dy,
        k = abSq === 0 ? -1 : dotp / abSq,
        eps = 0.1, // 1e-6, // snap to endpoint
        p;
    if (k <= eps) {
      p = [ax, ay];
    } else if (k >= 1 - eps) {
      p = [bx, by];
    } else {
      p = [ax + k * dx, ay + k * dy];
    }
    return p;
  }

  function snapIfCloser(p, minDist, x, y, x2, y2) {
    var dist = distance2D(x, y, x2, y2);
    if (dist < minDist) {
      minDist = dist;
      p[0] = x2;
      p[1] = y2;
    }
    return minDist;
  }

  function snapIntersectionPoint(p, ax, ay, bx, by, cx, cy, dx, dy, eps) {
    var x = p[0],
        y = p[1],
        snapDist = eps;
    snapDist = snapIfCloser(p, snapDist, x, y, ax, ay);
    snapDist = snapIfCloser(p, snapDist, x, y, bx, by);
    snapDist = snapIfCloser(p, snapDist, x, y, cx, cy);
    snapDist = snapIfCloser(p, snapDist, x, y, dx, dy);
  }

  function clampIntersectionPoint(p, ax, ay, bx, by, cx, cy, dx, dy) {
    // Handle intersection points that fall outside the x-y range of either
    // segment by snapping to nearest endpoint coordinate. Out-of-range
    // intersection points can be caused by floating point rounding errors
    // when a segment is vertical or horizontal. This has caused problems when
    // repeatedly applying bbox clipping along the same segment
    var x = p[0],
        y = p[1];
    // assumes that segment ranges intersect
    x = clampToCloseRange(x, ax, bx);
    x = clampToCloseRange(x, cx, dx);
    y = clampToCloseRange(y, ay, by);
    y = clampToCloseRange(y, cy, dy);
    p[0] = x;
    p[1] = y;
  }

  // a: coordinate of point
  // b: endpoint coordinate of segment
  // c: other endpoint of segment
  function outsideRange(a, b, c) {
    var out;
    if (b < c) {
      out = a < b || a > c;
    } else if (b > c) {
      out = a > b || a < c;
    } else {
      out = a != b;
    }
    return out;
  }

  function clampToCloseRange(a, b, c) {
    var lim;
    if (outsideRange(a, b, c)) {
      lim = Math.abs(a - b) < Math.abs(a - c) ? b : c;
      if (Math.abs(a - lim) > 1e-15) {
        debug("[clampToCloseRange()] large clamping interval", a, b, c);
      }
      a = lim;
    }
    return a;
  }

  // Determinant of matrix
  //  | a  b |
  //  | c  d |
  function determinant2D(a, b, c, d) {
    return a * d - b * c;
  }

  // returns a positive value if the points a, b, and c are arranged in
  // counterclockwise order, a negative value if the points are in clockwise
  // order, and zero if the points are collinear.
  // Source: Jonathan Shewchuk http://www.cs.berkeley.edu/~jrs/meshpapers/robnotes.pdf
  function orient2D(ax, ay, bx, by, cx, cy) {
    return determinant2D(ax - cx, ay - cy, bx - cx, by - cy);
  }

  // Source: Sedgewick, _Algorithms in C_
  // (Other functions were tried that were more sensitive to floating point errors
  //  than this function)
  function segmentHit(ax, ay, bx, by, cx, cy, dx, dy) {
    return orient2D(ax, ay, bx, by, cx, cy) *
        orient2D(ax, ay, bx, by, dx, dy) <= 0 &&
        orient2D(cx, cy, dx, dy, ax, ay) *
        orient2D(cx, cy, dx, dy, bx, by) <= 0;
  }

  // Useful for determining if a segment that intersects another segment is
  // entering or leaving an enclosed buffer area
  // returns -1 if angle of p1p2 -> p3p4 is counter-clockwise (left turn)
  // returns 1 if angle is clockwise
  // return 0 if segments are collinear
  function segmentTurn(p1, p2, p3, p4) {
    var ax = p1[0],
        ay = p1[1],
        bx = p2[0],
        by = p2[1],
        // shift p3p4 segment to start at p2
        dx = bx - p3[0],
        dy = by - p3[1],
        cx = p4[0] + dx,
        cy = p4[1] + dy,
        orientation = orient2D(ax, ay, bx, by, cx, cy);
      if (!orientation) return 0;
      return orientation < 0 ? 1 : -1;
  }

  var SegmentGeom = /*#__PURE__*/Object.freeze({
    __proto__: null,
    segmentIntersection: segmentIntersection,
    findClosestPointOnSeg: findClosestPointOnSeg,
    orient2D: orient2D,
    segmentHit: segmentHit,
    segmentTurn: segmentTurn
  });

  var geom = Object.assign({}, Geom, PolygonGeom, PathGeom, SegmentGeom, PolygonCentroid);

  // Utility functions for working with ArcCollection and arrays of arc ids.

  // Return average segment length (with simplification)
  function getAvgSegment(arcs) {
    var sum = 0;
    var count = arcs.forEachSegment(function(i, j, xx, yy) {
      var dx = xx[i] - xx[j],
          dy = yy[i] - yy[j];
      sum += Math.sqrt(dx * dx + dy * dy);
    });
    return sum / count || 0;
  }

  // Return average magnitudes of dx, dy (with simplification)
  function getAvgSegment2(arcs) {
    var dx = 0, dy = 0;
    var count = arcs.forEachSegment(function(i, j, xx, yy) {
      dx += Math.abs(xx[i] - xx[j]);
      dy += Math.abs(yy[i] - yy[j]);
    });
    return [dx / count || 0, dy / count || 0];
  }

  /*
  this.getAvgSegmentSph2 = function() {
    var sumx = 0, sumy = 0;
    var count = this.forEachSegment(function(i, j, xx, yy) {
      var lat1 = yy[i],
          lat2 = yy[j];
      sumy += geom.degreesToMeters(Math.abs(lat1 - lat2));
      sumx += geom.degreesToMeters(Math.abs(xx[i] - xx[j]) *
          Math.cos((lat1 + lat2) * 0.5 * geom.D2R);
    });
    return [sumx / count || 0, sumy / count || 0];
  };
  */

  function getDirectedArcPresenceTest(shapes, n) {
    var flags = new Uint8Array(n);
    forEachArcId(shapes, function(id) {
      var absId = absArcId(id);
      if (absId < n === false) error('index error');
      flags[absId] |= id < 0 ? 2 : 1;
    });
    return function(arcId) {
      var absId = absArcId(arcId);
      return arcId < 0 ? (flags[absId] & 2) == 2 : (flags[absId] & 1) == 1;
    };
  }

  function getArcPresenceTest(shapes, arcs) {
    var counts = new Uint8Array(arcs.size());
    countArcsInShapes(shapes, counts);
    return function(id) {
      if (id < 0) id = ~id;
      return counts[id] > 0;
    };
  }

  // @counts A typed array for accumulating count of each abs arc id
  //   (assume it won't overflow)
  function countArcsInShapes(shapes, counts) {
    traversePaths(shapes, null, function(obj) {
      var arcs = obj.arcs,
          id;
      for (var i=0; i<arcs.length; i++) {
        id = arcs[i];
        if (id < 0) id = ~id;
        counts[id]++;
      }
    });
  }

  function getPathBounds(shapes, arcs) {
    var bounds = new Bounds();
    forEachArcId(shapes, function(id) {
      arcs.mergeArcBounds(id, bounds);
    });
    return bounds;
  }

  // Returns subset of shapes in @shapes that contain one or more arcs in @arcIds
  function findShapesByArcId(shapes, arcIds, numArcs) {
    var index = numArcs ? new Uint8Array(numArcs) : [],
        found = [];
    arcIds.forEach(function(id) {
      index[absArcId(id)] = 1;
    });
    shapes.forEach(function(shp, shpId) {
      var isHit = false;
      forEachArcId(shp || [], function(id) {
        isHit = isHit || index[absArcId(id)] == 1;
      });
      if (isHit) {
        found.push(shpId);
      }
    });
    return found;
  }

  function reversePath(ids) {
    ids.reverse();
    for (var i=0, n=ids.length; i<n; i++) {
      ids[i] = ~ids[i];
    }
    return ids;
  }

  function clampIntervalByPct(z, pct) {
    if (pct <= 0) z = Infinity;
    else if (pct >= 1) z = 0;
    return z;
  }

  // Return id of the vertex between @start and @end with the highest
  // threshold that is less than @zlim, or -1 if none
  //
  function findNextRemovableVertex(zz, zlim, start, end) {
    var tmp, jz = 0, j = -1, z;
    if (start > end) {
      tmp = start;
      start = end;
      end = tmp;
    }
    for (var i=start+1; i<end; i++) {
      z = zz[i];
      if (z < zlim && z > jz) {
        j = i;
        jz = z;
      }
    }
    return j;
  }

  // Visit each arc id in a path, shape or array of shapes
  // Use non-undefined return values of callback @cb as replacements.
  function forEachArcId(arr, cb) {
    var item;
    for (var i=0; i<arr.length; i++) {
      item = arr[i];
      if (item instanceof Array) {
        forEachArcId(item, cb);
      } else if (utils.isInteger(item)) {
        var val = cb(item);
        if (val !== void 0) {
          arr[i] = val;
        }
      } else if (item) {
        error("Non-integer arc id in:", arr);
      }
    }
  }

  function forEachSegmentInShape(shape, arcs, cb) {
    for (var i=0, n=shape ? shape.length : 0; i<n; i++) {
      forEachSegmentInPath(shape[i], arcs, cb);
    }
  }

  function forEachSegmentInPath(ids, arcs, cb) {
    for (var i=0, n=ids.length; i<n; i++) {
      arcs.forEachArcSegment(ids[i], cb);
    }
  }

  function traversePaths(shapes, cbArc, cbPart, cbShape) {
    var segId = 0;
    shapes.forEach(function(parts, shapeId) {
      if (!parts || parts.length === 0) return; // null shape
      var arcIds, arcId;
      if (cbShape) {
        cbShape(shapeId);
      }
      for (var i=0, m=parts.length; i<m; i++) {
        arcIds = parts[i];
        if (cbPart) {
          cbPart({
            i: i,
            shapeId: shapeId,
            shape: parts,
            arcs: arcIds
          });
        }

        if (cbArc) {
          for (var j=0, n=arcIds.length; j<n; j++, segId++) {
            arcId = arcIds[j];
            cbArc({
              i: j,
              shapeId: shapeId,
              partId: i,
              arcId: arcId,
              segId: segId
            });
          }
        }
      }
    });
  }

  function arcHasLength(id, coords) {
    var iter = coords.getArcIter(id), x, y;
    if (iter.hasNext()) {
      x = iter.x;
      y = iter.y;
      while (iter.hasNext()) {
        if (iter.x != x || iter.y != y) return true;
      }
    }
    return false;
  }

  function filterEmptyArcs(shape, coords) {
    if (!shape) return null;
    var shape2 = [];
    shape.forEach(function(ids) {
      var path = [];
      for (var i=0; i<ids.length; i++) {
        if (arcHasLength(ids[i], coords)) {
          path.push(ids[i]);
        }
      }
      if (path.length > 0) shape2.push(path);
    });
    return shape2.length > 0 ? shape2 : null;
  }

  // Return an array of information about each part/ring in a polygon or polyline shape
  function getPathMetadata(shape, arcs, type) {
    var data = [],
        ids;
    for (var i=0, n=shape && shape.length; i<n; i++) {
      ids = shape[i];
      data.push({
        ids: ids,
        area: type == 'polygon' ? geom.getPlanarPathArea(ids, arcs) : 0,
        bounds: arcs.getSimpleShapeBounds(ids)
      });
    }
    return data;
  }

  function quantizeArcs(arcs, quanta) {
    // Snap coordinates to a grid of @quanta locations on both axes
    // This may snap nearby points to the same coordinates.
    // Consider a cleanup pass to remove dupes, make sure collapsed arcs are
    //   removed on export.
    //
    var bb1 = arcs.getBounds(),
        bb2 = new Bounds(0, 0, quanta-1, quanta-1),
        fw = bb1.getTransform(bb2),
        inv = fw.invert();

    arcs.transformPoints(function(x, y) {
      var p = fw.transform(x, y);
      return inv.transform(Math.round(p[0]), Math.round(p[1]));
    });
  }

  var PathUtils = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getAvgSegment: getAvgSegment,
    getAvgSegment2: getAvgSegment2,
    getDirectedArcPresenceTest: getDirectedArcPresenceTest,
    getArcPresenceTest: getArcPresenceTest,
    countArcsInShapes: countArcsInShapes,
    getPathBounds: getPathBounds,
    findShapesByArcId: findShapesByArcId,
    reversePath: reversePath,
    clampIntervalByPct: clampIntervalByPct,
    findNextRemovableVertex: findNextRemovableVertex,
    forEachArcId: forEachArcId,
    forEachSegmentInShape: forEachSegmentInShape,
    forEachSegmentInPath: forEachSegmentInPath,
    traversePaths: traversePaths,
    filterEmptyArcs: filterEmptyArcs,
    getPathMetadata: getPathMetadata,
    quantizeArcs: quantizeArcs
  });

  // Utility functions for both paths and points

  // @shp An element of the layer.shapes array
  //   (may be null, or, depending on layer type, an array of points or an array of arrays of arc ids)
  function cloneShape(shp) {
    if (!shp) return null;
    return shp.map(function(part) {
      return part.concat();
    });
  }

  function cloneShapes(arr) {
    return utils.isArray(arr) ? arr.map(cloneShape) : null;
  }

  function forEachShapePart(paths, cb) {
    editShapeParts(paths, cb);
  }

  // Updates shapes array in-place.
  // editPart: callback function
  function editShapes(shapes, editPart) {
    for (var i=0, n=shapes.length; i<n; i++) {
      shapes[i] = editShapeParts(shapes[i], editPart);
    }
  }

  // @parts: geometry of a feature (array of paths, array of points or null)
  // @cb: function(part, i, parts)
  //    If @cb returns an array, it replaces the existing value
  //    If @cb returns null, the path is removed from the feature
  //
  function editShapeParts(parts, cb) {
    if (!parts) return null; // null geometry not edited
    if (!utils.isArray(parts)) error("Expected an array, received:", parts);
    var nulls = 0,
        n = parts.length,
        retn;

    for (var i=0; i<n; i++) {
      retn = cb(parts[i], i, parts);
      if (retn === null) {
        nulls++;
        parts[i] = null;
      } else if (utils.isArray(retn)) {
        parts[i] = retn;
      }
    }
    if (nulls == n) {
      return null;
    } else if (nulls > 0) {
      return parts.filter(function(part) {return !!part;});
    } else {
      return parts;
    }
  }

  // Get max number of parts in a single shape from an array of shapes.
  // Caveat: polygon holes are counted as separate parts.
  function findMaxPartCount(shapes) {
    var maxCount = 0, shp;
    for (var i=0, n=shapes.length; i<n; i++) {
      shp = shapes[i];
      if (shp && shp.length > maxCount) {
        maxCount = shp.length;
      }
    }
    return maxCount;
  }

  var ShapeUtils = /*#__PURE__*/Object.freeze({
    __proto__: null,
    cloneShape: cloneShape,
    cloneShapes: cloneShapes,
    forEachShapePart: forEachShapePart,
    editShapes: editShapes,
    editShapeParts: editShapeParts,
    findMaxPartCount: findMaxPartCount
  });

  // List of encodings supported by iconv-lite:
  // https://github.com/ashtuchkin/iconv-lite/wiki/Supported-Encodings

  var iconv = require('iconv-lite');
  var toUtf8 = getNativeEncoder('utf8');
  var fromUtf8 = getNativeDecoder('utf8');

  // Return list of supported encodings
  function getEncodings() {
    iconv.encodingExists('ascii'); // make iconv load its encodings
    return Object.keys(iconv.encodings);
  }

  function validateEncoding(enc) {
    if (!encodingIsSupported(enc)) {
      stop("Unknown encoding:", enc, "\nRun the -encodings command see a list of supported encodings");
    }
    return enc;
  }

  function stringsAreAscii(arr) {
    return stringIsAscii(arr.join(''));
  }

  function stringIsAscii(str) {
    var c;
    for (var i=0, n=str.length; i<n; i++) {
      c = str.charCodeAt(i);
      if (c >= 128) return false;
    }
    return true;
  }

  function encodingIsUtf8(enc) {
    // treating utf-8 as default
    return !enc || /^utf-?8$/i.test(String(enc));
  }

  // Identify the most common encodings that are supersets of ascii at the
  // single-byte level (meaning that bytes in 0 - 0x7f range must be ascii)
  // (this allows identifying line breaks and other ascii patterns in buffers)
  function encodingIsAsciiCompat(enc) {
    enc = standardizeEncodingName(enc);
    // gb.* selects the Guo Biao encodings
    // big5 in not compatible -- second byte starts at 0x40
    return !enc || /^(win|latin|utf8|ascii|iso88|gb)/.test(enc);
  }

  // Ex. convert UTF-8 to utf8
  function standardizeEncodingName(enc) {
    return (enc || '').toLowerCase().replace(/[_-]/g, '');
  }

  // Similar to Buffer#toString(); tries to speed up utf8 conversion in
  // web browser (when using browserify Buffer shim)
  function bufferToString(buf, enc, start, end) {
    if (start >= 0) {
      buf = buf.slice(start, end);
    }
    return decodeString(buf, enc);
  }

  function getNativeEncoder(enc) {
    var encoder = null;
    enc = standardizeEncodingName(enc);
    if (enc != 'utf8') {
      // TODO: support more encodings if TextEncoder is available
      return null;
    }
    if (typeof TextEncoder != 'undefined') {
      encoder = new TextEncoder(enc);
    }
    return function(str) {
      // Convert Uint8Array from encoder to Buffer (fix for issue #216)
      return encoder ? Buffer.from(encoder.encode(str).buffer) : utils.createBuffer(str, enc);
    };
  }

  function encodeString(str, enc) {
    // TODO: faster ascii encoding?
    var buf;
    if (encodingIsUtf8(enc)) {
      buf = toUtf8(str);
    } else {
      buf = iconv.encode(str, enc);
    }
    return buf;
  }

  function getNativeDecoder(enc) {
    var decoder = null;
    enc = standardizeEncodingName(enc);
    if (enc != 'utf8') {
      // TODO: support more encodings if TextDecoder is available
      return null;
    }
    if (typeof TextDecoder != 'undefined') {
      decoder = new TextDecoder(enc);
    }
    return function(buf) {
      return decoder ? decoder.decode(buf) : buf.toString(enc);
    };
  }

  // @buf a Node Buffer
  function decodeString(buf, enc) {
    var str;
    if (encodingIsUtf8(enc)) {
      str = fromUtf8(buf);
    } else {
      str = iconv.decode(buf, enc);
    }
    return str;
  }

  function encodingIsSupported(raw) {
    var enc = standardizeEncodingName(raw);
    return getEncodings().includes(enc);
  }

  function trimBOM(str) {
    // remove BOM if present
    if (str.charCodeAt(0) == 0xfeff) {
      str = str.substr(1);
    }
    return str;
  }

  function printEncodings() {
    var encodings = getEncodings().filter(function(name) {
      // filter out some aliases and non-applicable encodings
      return !/^(_|cs|internal|ibm|isoir|singlebyte|table|[0-9]|l[0-9]|windows)/.test(name);
    });
    encodings.sort();
    print("Supported encodings:\n" + formatStringsAsGrid(encodings));
  }

  var Encodings = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getEncodings: getEncodings,
    validateEncoding: validateEncoding,
    stringsAreAscii: stringsAreAscii,
    stringIsAscii: stringIsAscii,
    encodingIsUtf8: encodingIsUtf8,
    encodingIsAsciiCompat: encodingIsAsciiCompat,
    standardizeEncodingName: standardizeEncodingName,
    bufferToString: bufferToString,
    encodeString: encodeString,
    decodeString: decodeString,
    encodingIsSupported: encodingIsSupported,
    trimBOM: trimBOM,
    printEncodings: printEncodings
  });

  // Not a general-purpose deep copy function
  function copyRecord(o) {
    var o2 = {}, key, val;
    if (!o) return null;
    for (key in o) {
      if (o.hasOwnProperty(key)) {
        val = o[key];
        if (val == o) {
          // avoid infinite recursion if val is a circular reference, by copying all properties except key
          val = utils.extend({}, val);
          delete val[key];
        }
        o2[key] = val && val.constructor === Object ? copyRecord(val) : val;
      }
    }
    return o2;
  }

  function getValueType(val) {
    var type = null;
    if (utils.isString(val)) {
      type = 'string';
    } else if (utils.isNumber(val)) {
      type = 'number';
    } else if (utils.isBoolean(val)) {
      type = 'boolean';
    } else if (utils.isDate(val)) {
      type = 'date';
    } else if (utils.isObject(val)) {
      type = 'object';
    }
    return type;
  }

  // Fill out a data table with undefined values
  // The undefined members will disappear when records are exported as JSON,
  // but will show up when fields are listed using Object.keys()
  function fixInconsistentFields(records) {
    var fields = findIncompleteFields(records);
    patchMissingFields(records, fields);
  }

  function findIncompleteFields(records) {
    var counts = {},
        i, j, keys;
    for (i=0; i<records.length; i++) {
      keys = Object.keys(records[i] || {});
      for (j=0; j<keys.length; j++) {
        counts[keys[j]] = (counts[keys[j]] | 0) + 1;
      }
    }
    return Object.keys(counts).filter(function(k) {return counts[k] < records.length;});
  }

  function patchMissingFields(records, fields) {
    var rec, i, j, f;
    for (i=0; i<records.length; i++) {
      rec = records[i] || (records[i] = {});
      for (j=0; j<fields.length; j++) {
        f = fields[j];
        if (f in rec === false) {
          rec[f] = undefined;
        }
      }
    }
  }

  function fieldListContainsAll(list, fields) {
    return list.indexOf('*') > -1 || utils.difference(fields, list).length === 0;
  }

  function getColumnType(key, records) {
    var type = null,
        rec;
    for (var i=0, n=records.length; i<n; i++) {
      rec = records[i];
      type = rec ? getValueType(rec[key]) : null;
      if (type) break;
    }
    return type;
  }

  function deleteFields(table, test) {
    table.getFields().forEach(function(name) {
      if (test(name)) {
        table.deleteField(name);
      }
    });
  }

  function isInvalidFieldName(f) {
    // Reject empty and all-whitespace strings. TODO: consider other criteria
    return /^\s*$/.test(f);
  }

  // Resolve name conflicts in field names by appending numbers
  // @fields Array of field names
  // @maxLen (optional) Maximum chars in name
  //
  function getUniqFieldNames(fields, maxLen, encoding) {
    var used = {};
    return fields.map(function(name) {
      var i = 0,
          validName;
      do {
        validName = encoding && encoding != 'ascii' ?
          adjustEncodedFieldName(name, maxLen, i, encoding) :
          adjustFieldName(name, maxLen, i);
        i++;
      } while ((validName in used) ||
        // don't replace an existing valid field name with a truncated name
        name != validName && utils.contains(fields, validName));
      used[validName] = true;
      return validName;
    });
  }

  function getFieldValues(records, field) {
    return records.map(function(rec) {
      return rec ? rec[field] : undefined;
    });
  }

  function getUniqFieldValues(records, field) {
    var index = {};
    var values = [];
    records.forEach(function(rec) {
      var val = rec[field];
      if (val in index === false) {
        index[val] = true;
        values.push(val);
      }
    });
    return values;
  }

  // Truncate and/or uniqify a name (if relevant params are present)
  function adjustFieldName(name, maxLen, i) {
    var name2, suff;
    maxLen = maxLen || 256;
    if (!i) {
      name2 = name.substr(0, maxLen);
    } else {
      suff = String(i);
      if (suff.length == 1) {
        suff = '_' + suff;
      }
      name2 = name.substr(0, maxLen - suff.length) + suff;
    }
    return name2;
  }

  // Truncate and/or uniqify a name (if relevant params are present)
  function adjustEncodedFieldName(name, maxLen, i, encoding) {
    var suff = i ? String(i) : '';
    var name2 = name + suff;
    var buf = encodeString(name2, encoding);
    if (buf.length > (maxLen || 256)) {
      name = name.substr(0, name.length - 1);
      return adjustEncodedFieldName(name, maxLen, i, encoding);
    }
    return name2;
  }

  function applyFieldOrder(arr, option) {
    if (option == 'ascending') {
      arr.sort(function(a, b) {
        return a.toLowerCase() < b.toLowerCase() ? -1 : 1;
      });
    }
    return arr;
  }

  function getFirstNonEmptyRecord(records) {
    for (var i=0, n=records ? records.length : 0; i<n; i++) {
      if (records[i]) return records[i];
    }
    return null;
  }

  function findFieldNames(records, order) {
    var first = getFirstNonEmptyRecord(records);
    var names = first ? Object.keys(first) : [];
    return applyFieldOrder(names, order);
  }

  var DataUtils = /*#__PURE__*/Object.freeze({
    __proto__: null,
    copyRecord: copyRecord,
    getValueType: getValueType,
    fixInconsistentFields: fixInconsistentFields,
    fieldListContainsAll: fieldListContainsAll,
    getColumnType: getColumnType,
    deleteFields: deleteFields,
    isInvalidFieldName: isInvalidFieldName,
    getUniqFieldNames: getUniqFieldNames,
    getFieldValues: getFieldValues,
    getUniqFieldValues: getUniqFieldValues,
    applyFieldOrder: applyFieldOrder,
    getFirstNonEmptyRecord: getFirstNonEmptyRecord,
    findFieldNames: findFieldNames
  });

  function DataTable(obj) {
    var records;
    if (utils.isArray(obj)) {
      records = obj;
    } else {
      records = [];
      // integer object: create empty records
      if (utils.isInteger(obj)) {
        for (var i=0; i<obj; i++) {
          records.push({});
        }
      } else if (obj) {
        error("Invalid DataTable constructor argument:", obj);
      }
    }

    this.getRecords = function() {
      return records;
    };

    // Same-name method in ShapefileTable doesn't require parsing the entire DBF file
    this.getReadOnlyRecordAt = function(i) {
      return copyRecord(records[i]); // deep-copies plain objects but not other constructed objects
    };
  }

  DataTable.prototype = {

    fieldExists: function(name) {
      return utils.contains(this.getFields(), name);
    },

    toString: function() {return JSON.stringify(this);},

    toJSON: function() {
      return this.getRecords();
    },

    addField: function(name, init) {
      var useFunction = utils.isFunction(init);
      if (!utils.isNumber(init) && !utils.isString(init) && !useFunction) {
        error("DataTable#addField() requires a string, number or function for initialization");
      }
      if (this.fieldExists(name)) error("DataTable#addField() tried to add a field that already exists:", name);
      // var dataFieldRxp = /^[a-zA-Z_][a-zA-Z_0-9]*$/;
      // if (!dataFieldRxp.test(name)) error("DataTable#addField() invalid field name:", name);

      this.getRecords().forEach(function(obj, i) {
        obj[name] = useFunction ? init(obj, i) : init;
      });
    },

    getRecordAt: function(i) {
      return this.getRecords()[i];
    },

    addIdField: function() {
      this.addField('FID', function(obj, i) {
        return i;
      });
    },

    deleteField: function(f) {
      this.getRecords().forEach(function(o) {
        delete o[f];
      });
    },

    getFields: function() {
      return findFieldNames(this.getRecords());
    },

    isEmpty: function() {
      return this.getFields().length === 0 || this.size() === 0;
    },

    update: function(f) {
      var records = this.getRecords();
      for (var i=0, n=records.length; i<n; i++) {
        records[i] = f(records[i], i);
      }
    },

    clone: function() {
      // TODO: this could be sped up using a record constructor function
      // (see getRecordConstructor() in DbfReader)
      var records2 = this.getRecords().map(copyRecord);
      return new DataTable(records2);
    },

    size: function() {
      return this.getRecords().length;
    }
  };

  // Insert a column of values into a (new or existing) data field
  function insertFieldValues(lyr, fieldName, values) {
    var size = getFeatureCount(lyr) || values.length,
        table = lyr.data = (lyr.data || new DataTable(size)),
        records = table.getRecords(),
        rec, val;

    for (var i=0, n=records.length; i<n; i++) {
      rec = records[i];
      val = values[i];
      if (!rec) rec = records[i] = {};
      rec[fieldName] = val === undefined ? null : val;
    }
  }

  function getLayerDataTable(lyr) {
    var data = lyr.data;
    if (!data) {
      data = lyr.data = new DataTable(lyr.shapes ? lyr.shapes.length : 0);
    }
    return data;
  }

  function layerHasNonNullData(lyr) {
    return lyr.data && getFirstNonEmptyRecord(lyr.data.getRecords()) ? true : false;
  }

  function layerHasGeometry(lyr) {
    return layerHasPaths(lyr) || layerHasPoints(lyr);
  }

  function layerHasPaths(lyr) {
    return (lyr.geometry_type == 'polygon' || lyr.geometry_type == 'polyline') &&
      layerHasNonNullShapes(lyr);
  }

  function layerHasPoints(lyr) {
    return lyr.geometry_type == 'point' && layerHasNonNullShapes(lyr);
  }

  function layerHasNonNullShapes(lyr) {
    return utils.some(lyr.shapes || [], function(shp) {
      return !!shp;
    });
  }

  function deleteFeatureById(lyr, i) {
    if (lyr.shapes) lyr.shapes.splice(i, 1);
    if (lyr.data) lyr.data.getRecords().splice(i, 1);
  }

  // TODO: move elsewhere (moved here from mapshaper-point-utils to avoid circular dependency)
  function transformPointsInLayer(lyr, f) {
    if (layerHasPoints(lyr)) {
      forEachPoint(lyr.shapes, function(p) {
        var p2 = f(p[0], p[1]);
        p[0] = p2[0];
        p[1] = p2[1];
      });
    }
  }

  function getFeatureCount(lyr) {
    var count = 0;
    if (lyr.data) {
      count = lyr.data.size();
    } else if (lyr.shapes) {
      count = lyr.shapes.length;
    }
    return count;
  }

  function layerIsEmpty(lyr) {
    return getFeatureCount(lyr) == 0;
  }

  function requireDataField(obj, field, msg) {
    var data = obj.fieldExists ? obj : obj.data; // accept layer or DataTable
    if (!field) stop('Missing a field parameter');
    if (!data || !data.fieldExists(field)) {
      stop(msg || 'Missing a field named:', field);
    }
  }

  function requireDataFields(table, fields) {
    if (!fields || !fields.length) return;
    if (!table) {
      stop("Missing attribute data");
    }
    var dataFields = table.getFields(),
        missingFields = utils.difference(fields, dataFields);
    if (missingFields.length > 0) {
      stop("Table is missing one or more fields:\n",
          missingFields, "\nExisting fields:", '\n' + formatStringsAsGrid(dataFields));
    }
  }

  function layerTypeMessage(lyr, defaultMsg, customMsg) {
    var msg;
    // check that custom msg is a string (could be an index if require function is called by forEach)
    if (customMsg && utils.isString(customMsg)) {
      msg = customMsg;
    } else {
      msg = defaultMsg + ', ';
      if (!lyr || !lyr.geometry_type) {
        msg += 'received a layer with no geometry';
      } else {
        msg += 'received a ' + lyr.geometry_type + ' layer';
      }
    }
    return msg;
  }

  function requirePointLayer(lyr, msg) {
    if (!lyr || lyr.geometry_type !== 'point')
      stop(layerTypeMessage(lyr, "Expected a point layer", msg));
  }

  function requireSinglePointLayer(lyr, msg) {
    requirePointLayer(lyr);
    if (countMultiPartFeatures(lyr) > 0) {
      stop(msg || 'This command requires single points; layer contains multi-point features.');
    }
  }

  function requirePolylineLayer(lyr, msg) {
    if (!lyr || lyr.geometry_type !== 'polyline')
      stop(layerTypeMessage(lyr, "Expected a polyline layer", msg));
  }

  function requirePolygonLayer(lyr, msg) {
    if (!lyr || lyr.geometry_type !== 'polygon')
      stop(layerTypeMessage(lyr, "Expected a polygon layer", msg));
  }

  function requirePathLayer(lyr, msg) {
    if (!lyr || !layerHasPaths(lyr))
      stop(layerTypeMessage(lyr, "Expected a polygon or polyline layer", msg));
  }

  // Used by info command and gui layer menu
  function getLayerSourceFile(lyr, dataset) {
    var inputs = dataset.info && dataset.info.input_files;
    return inputs && inputs[0] || '';
  }

  // Divide a collection of features with mixed types into layers of a single type
  // (Used for importing TopoJSON and GeoJSON features)
  function divideFeaturesByType(shapes, properties, types) {
    var typeSet = utils.uniq(types);
    var layers = typeSet.map(function(geoType) {
      var p = [],
          s = [],
          dataNulls = 0,
          rec;
      for (var i=0, n=shapes.length; i<n; i++) {
        if (types[i] != geoType) continue;
        if (geoType) s.push(shapes[i]);
        rec = properties[i];
        p.push(rec);
        if (!rec) dataNulls++;
      }
      return {
        geometry_type: geoType,
        shapes: s,
        data: dataNulls < s.length ? new DataTable(p) : null
      };
    });
    return layers;
  }

  // make a stub copy if the no_replace option is given, else pass thru src layer
  function getOutputLayer(src, opts) {
    return opts && opts.no_replace ? {geometry_type: src.geometry_type} : src;
  }

  //
  function setOutputLayerName(dest, src, defName, opts) {
    opts = opts || {};
    if (opts.name) {
      dest.name = opts.name;
    } else if (opts.no_replace) {
      dest.name = defName || undefined;
    } else {
      dest.name = src && src.name || defName || undefined;
    }
  }

  // Make a deep copy of a layer
  function copyLayer(lyr) {
    var copy = copyLayerShapes(lyr);
    if (copy.data) {
      copy.data = copy.data.clone();
    }
    return copy;
  }

  // Make a shallow copy of a path layer; replace layer.shapes with an array that is
  // filtered to exclude paths containing any of the arc ids contained in arcIds.
  // arcIds: an array of (non-negative) arc ids to exclude
  function filterPathLayerByArcIds(pathLyr, arcIds) {
    var index = arcIds.reduce(function(memo, id) {
      memo[id] = true;
      return memo;
    }, {});
    // deep copy shapes; this could be optimized to only copy shapes that are modified
    var shapes = cloneShapes(pathLyr.shapes);
    editShapes(shapes, onPath); // remove paths that are missing shapes
    return utils.defaults({shapes: shapes}, pathLyr);

    function onPath(path) {
      for (var i=0; i<path.length; i++) {
        if (absArcId(path[i]) in index) {
          return null;
        }
      }
      return path;
    }
  }

  function copyLayerShapes(lyr) {
    var copy = utils.extend({}, lyr);
    if (lyr.shapes) {
      copy.shapes = cloneShapes(lyr.shapes);
    }
    return copy;
  }

  function countMultiPartFeatures(shapes) {
    var count = 0;
    for (var i=0, n=shapes.length; i<n; i++) {
      if (shapes[i] && shapes[i].length > 1) count++;
    }
    return count;
  }

  // moving this here from mapshaper-path-utils to avoid circular dependency
  function getArcPresenceTest2(layers, arcs) {
    var counts = countArcsInLayers(layers, arcs);
    return function(arcId) {
      return counts[absArcId(arcId)] > 0;
    };
  }

  // Count arcs in a collection of layers
  function countArcsInLayers(layers, arcs) {
    var counts = new Uint32Array(arcs.size());
    layers.filter(layerHasPaths).forEach(function(lyr) {
      countArcsInShapes(lyr.shapes, counts);
    });
    return counts;
  }

  // Returns a Bounds object
  function getLayerBounds(lyr, arcs) {
    var bounds = null;
    if (lyr.geometry_type == 'point') {
      bounds = getPointBounds$1(lyr.shapes);
    } else if (lyr.geometry_type == 'polygon' || lyr.geometry_type == 'polyline') {
      bounds = getPathBounds(lyr.shapes, arcs);
    } else {
      // just return null if layer has no bounds
      // error("Layer is missing a valid geometry type");
    }
    return bounds;
  }

  function isolateLayer(layer, dataset) {
    return utils.defaults({
      layers: dataset.layers.filter(function(lyr) {return lyr == layer;})
    }, dataset);
  }

  function initDataTable(lyr) {
    lyr.data = new DataTable(getFeatureCount(lyr));
  }

  var LayerUtils = /*#__PURE__*/Object.freeze({
    __proto__: null,
    insertFieldValues: insertFieldValues,
    getLayerDataTable: getLayerDataTable,
    layerHasNonNullData: layerHasNonNullData,
    layerHasGeometry: layerHasGeometry,
    layerHasPaths: layerHasPaths,
    layerHasPoints: layerHasPoints,
    layerHasNonNullShapes: layerHasNonNullShapes,
    deleteFeatureById: deleteFeatureById,
    transformPointsInLayer: transformPointsInLayer,
    getFeatureCount: getFeatureCount,
    layerIsEmpty: layerIsEmpty,
    requireDataField: requireDataField,
    requireDataFields: requireDataFields,
    layerTypeMessage: layerTypeMessage,
    requirePointLayer: requirePointLayer,
    requireSinglePointLayer: requireSinglePointLayer,
    requirePolylineLayer: requirePolylineLayer,
    requirePolygonLayer: requirePolygonLayer,
    requirePathLayer: requirePathLayer,
    getLayerSourceFile: getLayerSourceFile,
    divideFeaturesByType: divideFeaturesByType,
    getOutputLayer: getOutputLayer,
    setOutputLayerName: setOutputLayerName,
    copyLayer: copyLayer,
    filterPathLayerByArcIds: filterPathLayerByArcIds,
    copyLayerShapes: copyLayerShapes,
    countMultiPartFeatures: countMultiPartFeatures,
    getArcPresenceTest2: getArcPresenceTest2,
    countArcsInLayers: countArcsInLayers,
    getLayerBounds: getLayerBounds,
    isolateLayer: isolateLayer,
    initDataTable: initDataTable
  });

  // A matrix class that supports affine transformations (scaling, translation, rotation).
  // Elements:
  //   a  c  tx
  //   b  d  ty
  //   0  0  1  (u v w are not used)
  //
  function Matrix2D() {
    this.a = 1;
    this.c = 0;
    this.tx = 0;
    this.b = 0;
    this.d = 1;
    this.ty = 0;
  }

  Matrix2D.prototype.transformXY = function(x, y, p) {
    p = p || {};
    p.x = x * this.a + y * this.c + this.tx;
    p.y = x * this.b + y * this.d + this.ty;
    return p;
  };

  Matrix2D.prototype.translate = function(dx, dy) {
    this.tx += dx;
    this.ty += dy;
  };

  // x, y: optional origin
  Matrix2D.prototype.rotate = function(q, x, y) {
    var cos = Math.cos(q);
    var sin = Math.sin(q);
    x = x || 0;
    y = y || 0;
    this.a = cos;
    this.c = -sin;
    this.b = sin;
    this.d = cos;
    this.tx += x - x * cos + y * sin;
    this.ty += y - x * sin - y * cos;
  };

  // cx, cy: optional origin
  Matrix2D.prototype.scale = function(sx, sy, cx, cy) {
    cx = cx || 0;
    cy = cy || 0;
    this.a *= sx;
    this.c *= sx;
    this.b *= sy;
    this.d *= sy;
    this.tx -= cx * (sx - 1);
    this.ty -= cy * (sy - 1);
  };

  // A compound projection, consisting of a default projection and one or more rectangular frames
  // that are projected separately and affine transformed.
  // @mainParams: parameters for main projection, including:
  //    proj: Proj string
  //    bbox: lat-lon bounding box
  function MixedProjection(mainParams, options) {
    var mproj = require('mproj');
    var mainFrame = initFrame(mainParams);
    var mainP = mainFrame.crs;
    var frames = [mainFrame];
    var mixedP = initMixedProjection(mproj);

    // This CRS masquerades as the main projection... the version with
    // custom insets is exposed to savvy users
    mainP.__mixed_crs = mixedP;

    // required opts:
    //    origin: [lng, lat] origin of frame (unprojected)
    //    placement: [x, y] location (in projected coordinates) to shift the origin
    //    proj: Proj.4 string for projecting data within the frame
    //    bbox: Lat-long bounding box of frame area
    //
    // optional:
    //    dx: x shift (meters)
    //    dy: y shift (meters)
    //    scale: scale factor (1 = no scaling)
    //    rotation: rotation in degrees (0 = no rotation)
    //
    mainP.addFrame = function(paramsArg) {
      var params = getFrameParams(paramsArg, options); // apply defaults and overrides
      var frame = initFrame(params);
      var m = new Matrix2D();
      //  originXY: the projected coordinates of the frame origin
      var originXY = params.origin ? projectFrameOrigin(params.origin, frame.crs) : [0, 0];
      var placementXY = params.placement || [0, 0];
      var dx = placementXY[0] - originXY[0] + (+params.dx || 0);
      var dy = placementXY[1] - originXY[1] + (+params.dy || 0);

      if (params.rotation) {
        m.rotate(params.rotation * Math.PI / 180.0, originXY[0], originXY[1]);
      }
      if (params.scale) {
        m.scale(params.scale, params.scale, originXY[0], originXY[1]);
      }
      m.translate(dx, dy);

      frame.matrix = m;
      frames.push(frame);
      return this;
    };

    function initFrame(params) {
      return {
        bounds: new Bounds(bboxToRadians(params.bbox)),
        crs:  mproj.pj_init(params.proj)
      };
    }

    function bboxToRadians(bbox) {
      var D2R = Math.PI / 180;
      return bbox.map(function(deg) {
        return deg * D2R;
      });
    }

    function projectFrameOrigin(origin, P) {
      var xy = mproj.pj_fwd_deg({lam: origin[0], phi: origin[1]}, P);
      return [xy.x, xy.y];
    }

    mixedP.fwd = function(lp, xy) {
      var frame, xy2;
      for (var i=0, n=frames.length; i<n; i++) {
        frame = frames[i];
        if (frame.bounds.containsPoint(lp.lam, lp.phi)) {
          xy2 = mproj.pj_fwd(lp, frame.crs);
          if (frame.matrix) {
            frame.matrix.transformXY(xy2.x, xy2.y, xy2);
          }
          break;
        }
      }
      xy.x = xy2 ? xy2.x : Infinity;
      xy.y = xy2 ? xy2.y : Infinity;
    };

    return mainP;
  }

  function initMixedProjection(mproj) {
    if (!mproj.internal.pj_list.mixed) {
      mproj.pj_add(function(P) {
        P.a = 1;
      }, 'mixed', 'Mapshaper Mixed Projection');
    }
    return mproj.pj_init('+proj=mixed');
  }

  function getFrameParams (params, options) {
    var opts = options[params.name];
    utils.defaults(params, {scale: 1, dx: 0, dy: 0, rotation: 0}); // add defaults
    if (!opts) return params;
    Object.keys(opts).forEach(function(key) {
      var val = opts[key];
      if (key in params) {
        params[key] = opts[key];
      } else {
        params.proj = replaceProjParam(params.proj, key, val);
      }
    });
    return params;
  }

  function replaceProjParam(proj, key, val) {
    var param = '+' + key + '=';
    return proj.split(' ').map(function(str) {
      if (str.indexOf(param) === 0) {
        str = str.substr(0, param.length) + val;
      }
      return str;
    }).join(' ');
  }

  // str: a custom projection string, e.g.: "albersusa +PR"
  function parseCustomProjection(str) {
    var parts = str.trim().split(/ +/);
    var params = [];
    var names = parts.filter(function(part) {
      if (/^\+/.test(part)) {
        params.push(part.substr(1)); // strip '+'
        return false;
      }
      return true;
    });
    var name = names[0];
    var opts = parseCustomParams(params);
    if (names.length != 1) return null; // parse error if other than one name found
    return getCustomProjection(name, opts);
  }

  // returns a custom projection object
  function getCustomProjection(name, opts) {
    if (name == 'albersusa') {
      return new AlbersUSA(opts);
    }
    return null;
  }

  function AlbersUSA(optsArg) {
    var opts = optsArg || {};
    var main = {
      proj: '+proj=aea +lon_0=-96 +lat_0=37.5 +lat_1=29.5 +lat_2=45.5',
      bbox: [-129,23,-62,52]
    };
    var AK = {
      name: 'AK',
      proj: '+proj=aea +lat_1=55 +lat_2=70 +lat_0=65 +lon_0=-148 +x_0=0 +y_0=0',
      bbox: [-172.26,50.89,-127.00,73.21],
      origin: [-152, 63],
      placement: [-1882782,-969242],
      scale: 0.37
    };
    var HI = {
      name: 'HI',
      proj: '+proj=aea +lat_1=19 +lat_2=24 +lat_0=20.9 +lon_0=-156.5 +x_0=0 +y_0=0',
      bbox: [-160.50,18.72,-154.57,22.58],
      origin: [-157, 21],
      placement: [-1050326,-1055362]
    };
    var PR = {
      name: 'PR',
      proj: '+proj=aea +lat_1=18 +lat_2=18.43 +lat_0=17.83 +lon_0=-66.43 +x_0=0 +y_0=0',
      bbox: [-68.092,17.824,-65.151,18.787],
      origin: [-66.431, 18.228],
      placement: [1993101,-1254517]
    };
    var VI = {
      name: 'VI',
      // same projection and origin as PR, so they maintain their true geographical relationship
      proj: '+proj=aea +lat_1=18 +lat_2=18.43 +lat_0=17.83 +lon_0=-66.43 +x_0=0 +y_0=0',
      bbox: [-65.104,17.665,-64.454,18.505],
      origin: [-66.431, 18.228],
      placement: [1993101,-1254517]
    };
    var mixed = new MixedProjection(main, opts)
      .addFrame(AK)
      .addFrame(HI);
    if (opts.PR) {
      mixed.addFrame(PR);
    }
    if (opts.VI) {
      mixed.addFrame(VI);
    }
    return mixed;
  }


  function parseCustomParams(arr) {
    var opts = {};
    arr.forEach(function(str) {
      parseCustomParam(str, opts);
    });
    return opts;
  }

  function parseCustomParam(str, opts) {
    var parts = str.split('=');
    var path = parts[0].split('.');
    var key = path.pop();
    var obj = path.reduce(function(memo, name) {
      if (name in memo === false) {
        memo[name] = {};
      } else if (!utils.isObject(memo[name])) {
        return {};// error condition, could display a warning
      }
      return memo[name];
    }, opts);
    if (parts.length > 1) {
      obj[key] = parseCustomParamValue(parts[1]);
    } else if (key in obj === false && !path.length) {
      // e.g. convert string 'PR' into {PR: {}} (empty object),
      // to show PR with default properties
      obj[key] = {};
    }
  }

  function parseCustomParamValue(str) {
    var val;
    if (str.indexOf(',') > 0) {
      val = str.split(',').map(parseFloat);
      // TODO: validate
      return val;
    }
    val = utils.parseNumber(str);
    if (val === null) {
      val = str;
    }
    return val;
  }

  var CustomProjections = /*#__PURE__*/Object.freeze({
    __proto__: null,
    parseCustomProjection: parseCustomProjection,
    AlbersUSA: AlbersUSA,
    parseCustomParams: parseCustomParams
  });

  function getWorldBounds(e) {
    e = utils.isFiniteNumber(e) ? e : 1e-10;
    return [-180 + e, -90 + e, 180 - e, 90 - e];
  }

  function probablyDecimalDegreeBounds(b) {
    var world = getWorldBounds(-1), // add a bit of excess
        bbox = (b instanceof Bounds) ? b.toArray() : b;
    return geom.containsBounds(world, bbox);
  }

  function clampToWorldBounds(b) {
    var bbox = (b instanceof Bounds) ? b.toArray() : b;
    return new Bounds().setBounds(Math.max(bbox[0], -180), Math.max(bbox[1], -90),
        Math.min(bbox[2], 180), Math.min(bbox[3], 90));
  }

  function getAntimeridian(lon0) {
    var anti = lon0 - 180;
    while (anti <= -180) anti += 360;
    return anti;
  }

  var LatLon = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getWorldBounds: getWorldBounds,
    probablyDecimalDegreeBounds: probablyDecimalDegreeBounds,
    clampToWorldBounds: clampToWorldBounds,
    getAntimeridian: getAntimeridian
  });

  var asyncLoader = null;

  var projectionAliases = {
    robinson: '+proj=robin +datum=WGS84',
    webmercator: '+proj=merc +a=6378137 +b=6378137',
    wgs84: '+proj=longlat +datum=WGS84',
    albersusa: new AlbersUSA() // with default parameters
  };

  // This stub is replaced when loaded in GUI, which may need to load some files
  function initProjLibrary(opts, done) {
    if (!asyncLoader) return done();
    asyncLoader(opts, done);
  }

  function setProjectionLoader(loader) {
    asyncLoader = loader;
  }

  // Find Proj.4 definition file names in strings like "+init=epsg:3000"
  // (Used by GUI, defined here for testing)
  function findProjLibs(str) {
    var matches = str.match(/\b(esri|epsg|nad83|nad27)(?=:[0-9]+\b)/ig) || [];
    return utils.uniq(matches.map(function(str) {return str.toLowerCase();}));
  }

  // Returns a function for reprojecting [x, y] points; function throws an error
  // if the transformation fails
  // src, dest: proj4 objects
  function getProjTransform(src, dest) {
    var mproj = require('mproj');
    var clampSrc = isLatLngCRS(src);
    dest = dest.__mixed_crs || dest;
    return function(x, y) {
      var xy;
      if (clampSrc) {
        // snap lng to bounds
        if (x < -180) x = -180;
        else if (x > 180) x = 180;
      }
      xy = [x, y];
      mproj.pj_transform_point(src, dest, xy);
      return xy;
    };
  }

  // Same as getProjTransform(), but return null if projection fails
  // (also faster)
  function getProjTransform2(src, dest) {
    var mproj = require('mproj'),
        xx = [0],
        yy = [0],
        preK = src.is_latlong ? mproj.internal.DEG_TO_RAD : 1,
        postK = dest.is_latlong ? mproj.internal.RAD_TO_DEG : 1,
        clampSrc = isLatLngCRS(src);

    return function(x, y) {
      var fail;
      if (clampSrc) {
        // snap lng to bounds
        if (x < -180) x = -180;
        else if (x > 180) x = 180;
      }
      xx[0] = x * preK;
      yy[0] = y * preK;
      try {
        dest = dest.__mixed_crs || dest;
        mproj.pj_transform(src, dest, xx, yy);
        fail = xx[0] == Infinity; // mproj invalid coord value
      } catch(e) {
        fail = true;
      }
      return fail ? null : [xx[0] * postK, yy[0] * postK];
    };
  }

  function toLngLat(xy, P) {
    var proj;
    if (isLatLngCRS(P)) {
      return xy.concat();
    }
    proj = getProjInfo(P, getCRS('wgs84'));
    return proj(xy);
  }

  function getProjInfo(dataset) {
    var P, info;
    try {
      P = getDatasetCRS(dataset);
      if (P) {
        info = crsToProj4(P);
      }
    } catch(e) {}
    return info || "[unknown]";
  }

  function crsToProj4(P) {
    return require('mproj').internal.get_proj_defn(P);
  }

  function crsToPrj(P) {
    var wkt;
    try {
      wkt = require('mproj').internal.wkt_from_proj4(P);
    } catch(e) {
      // console.log(e)
    }
    return wkt;
  }

  function crsAreEqual(a, b) {
    var str = crsToProj4(a);
    return !!str && str == crsToProj4(b);
  }

  function getProjDefn(str) {
    var mproj = require('mproj');
    var defn;
    // prepend '+proj=' to bare proj names
    str = str.replace(/(^| )([\w]+)($| )/, function(a, b, c, d) {
      if (c in mproj.internal.pj_list) {
        return b + '+proj=' + c + d;
      }
      return a;
    });
    if (looksLikeProj4String(str)) {
      defn = str;
    } else if (str in projectionAliases) {
      defn = projectionAliases[str];  // defn is a function
    } else if (looksLikeInitString(str)) {
      defn = '+init=' + str.toLowerCase();
    } else if (str in getStateVar('defs')) {
      // a proj4 alias could be dynamically created in a -calc expression
      defn = getStateVar('defs')[str];
    } else {
      defn = parseCustomProjection(str);
    }
    if (!defn) {
      stop("Unknown projection definition:", str);
    }
    return defn;
  }

  function looksLikeInitString(str) {
    return /^(esri|epsg|nad83|nad27):[0-9]+$/i.test(String(str));
  }

  function looksLikeProj4String(str) {
    return /^(\+[^ ]+ *)+$/.test(str);
  }

  function getCRS(str) {
    var defn = getProjDefn(str);  // defn is a string or a Proj object
    var P;
    if (!utils.isString(defn)) {
      P = defn;
    } else {
      try {
        P = require('mproj').pj_init(defn);
      } catch(e) {
        stop('Unable to use projection', defn, '(' + e.message + ')');
      }
    }
    return P || null;
  }

  function requireProjectedDataset(dataset) {
    if (isLatLngCRS(getDatasetCRS(dataset))) {
      stop("Command requires a target with projected coordinates (not lat-long)");
    }
  }

  // @info: info property of source dataset (instead of crs object, so wkt string
  //        can be preserved if present)
  function setDatasetCRS(dataset, info) {
    dataset.info = dataset.info || {};
    // Assumes that proj4 object is never mutated.
    // TODO: assign a copy of crs (if present)
    dataset.info.crs = info.crs;
    dataset.info.prj = info.prj;
  }

  function getDatasetCRS(dataset) {
    var info = dataset.info || {},
        P = info.crs;
    if (!P && info.prj) {
      P = parsePrj(info.prj);
    }
    if (!P && probablyDecimalDegreeBounds(getDatasetBounds(dataset))) {
      // use wgs84 for probable latlong datasets with unknown datums
      P = getCRS('wgs84');
    }
    return P;
  }

  function requireDatasetsHaveCompatibleCRS(arr) {
    arr.reduce(function(memo, dataset) {
      var P = getDatasetCRS(dataset);
      if (memo && P) {
        if (isLatLngCRS(memo) != isLatLngCRS(P)) {
          stop("Unable to combine projected and unprojected datasets");
        }
      }
      return P || memo;
    }, null);
  }

  // Assumes conformal projections; consider returning average of vertical and
  // horizontal scale factors.
  // x, y: a point location in projected coordinates
  // Returns k, the ratio of coordinate distance to distance on the ground
  function getScaleFactorAtXY(x, y, crs) {
    var proj = require('mproj');
    var dist = 1;
    var lp = proj.pj_inv_deg({x: x, y: y}, crs);
    var lp2 = proj.pj_inv_deg({x: x + dist, y: y}, crs);
    var k = dist / geom.greatCircleDistance(lp.lam, lp.phi, lp2.lam, lp2.phi);
    return k;
  }

  function isProjectedCRS(P) {
    return !isLatLngCRS(P);
  }

  function isLatLngCRS(P) {
    return P && P.is_latlong || false;
  }

  function isLatLngDataset(dataset) {
    return isLatLngCRS(getDatasetCRS(dataset));
  }

  function printProjections() {
    var index = require('mproj').internal.pj_list;
    var msg = 'Proj4 projections\n';
    Object.keys(index).sort().forEach(function(id) {
      msg += '  ' + utils.rpad(id, 7, ' ') + '  ' + index[id].name + '\n';
    });
    msg += '\nAliases';
    Object.keys(projectionAliases).sort().forEach(function(n) {
      msg += '\n  ' + n;
    });
    print(msg);
  }

  function translatePrj(str) {
    var proj4;
    try {
      proj4 = require('mproj').internal.wkt_to_proj4(str);
    } catch(e) {
      stop('Unusable .prj file (' + e.message + ')');
    }
    return proj4;
  }

  // Convert contents of a .prj file to a projection object
  function parsePrj(str) {
    return getCRS(translatePrj(str));
  }

  var Projections = /*#__PURE__*/Object.freeze({
    __proto__: null,
    initProjLibrary: initProjLibrary,
    setProjectionLoader: setProjectionLoader,
    findProjLibs: findProjLibs,
    getProjTransform: getProjTransform,
    getProjTransform2: getProjTransform2,
    toLngLat: toLngLat,
    getProjInfo: getProjInfo,
    crsToProj4: crsToProj4,
    crsToPrj: crsToPrj,
    crsAreEqual: crsAreEqual,
    getProjDefn: getProjDefn,
    looksLikeProj4String: looksLikeProj4String,
    getCRS: getCRS,
    requireProjectedDataset: requireProjectedDataset,
    setDatasetCRS: setDatasetCRS,
    getDatasetCRS: getDatasetCRS,
    requireDatasetsHaveCompatibleCRS: requireDatasetsHaveCompatibleCRS,
    getScaleFactorAtXY: getScaleFactorAtXY,
    isProjectedCRS: isProjectedCRS,
    isLatLngCRS: isLatLngCRS,
    isLatLngDataset: isLatLngDataset,
    printProjections: printProjections,
    translatePrj: translatePrj,
    parsePrj: parsePrj
  });

  // Coordinate iterators
  //
  // Interface:
  //   properties: x, y
  //   method: hasNext()
  //
  // Usage:
  //   while (iter.hasNext()) {
  //     iter.x, iter.y; // do something w/ x & y
  //   }

  // Iterate over an array of [x, y] points
  //
  function PointIter(points) {
    var n = points.length,
        i = 0,
        iter = {
          x: 0,
          y: 0,
          hasNext: hasNext
        };
    function hasNext() {
      if (i >= n) return false;
      iter.x = points[i][0];
      iter.y = points[i][1];
      i++;
      return true;
    }
    return iter;
  }


  // Constructor takes arrays of coords: xx, yy, zz (optional)
  //
  function ArcIter(xx, yy) {
    this._i = 0;
    this._n = 0;
    this._inc = 1;
    this._xx = xx;
    this._yy = yy;
    this.i = 0;
    this.x = 0;
    this.y = 0;
  }

  ArcIter.prototype.init = function(i, len, fw) {
    if (fw) {
      this._i = i;
      this._inc = 1;
    } else {
      this._i = i + len - 1;
      this._inc = -1;
    }
    this._n = len;
    return this;
  };

  ArcIter.prototype.hasNext = function() {
    var i = this._i;
    if (this._n > 0) {
      this._i = i + this._inc;
      this.x = this._xx[i];
      this.y = this._yy[i];
      this.i = i;
      this._n--;
      return true;
    }
    return false;
  };

  function FilteredArcIter(xx, yy, zz) {
    var _zlim = 0,
        _i = 0,
        _inc = 1,
        _stop = 0;

    this.init = function(i, len, fw, zlim) {
      _zlim = zlim || 0;
      if (fw) {
        _i = i;
        _inc = 1;
        _stop = i + len;
      } else {
        _i = i + len - 1;
        _inc = -1;
        _stop = i - 1;
      }
      return this;
    };

    this.hasNext = function() {
      // using local vars is significantly faster when skipping many points
      var zarr = zz,
          i = _i,
          j = i,
          zlim = _zlim,
          stop = _stop,
          inc = _inc;
      if (i == stop) return false;
      do {
        j += inc;
      } while (j != stop && zarr[j] < zlim);
      _i = j;
      this.x = xx[i];
      this.y = yy[i];
      this.i = i;
      return true;
    };
  }

  // Iterate along a path made up of one or more arcs.
  //
  function ShapeIter(arcs) {
    this._arcs = arcs;
    this._i = 0;
    this._n = 0;
    this.x = 0;
    this.y = 0;
  }

  ShapeIter.prototype.hasNext = function() {
    var arc = this._arc;
    if (this._i < this._n === false) {
      return false;
    }
    if (arc.hasNext()) {
      this.x = arc.x;
      this.y = arc.y;
      return true;
    }
    this.nextArc();
    return this.hasNext();
  };

  ShapeIter.prototype.init = function(ids) {
    this._ids = ids;
    this._n = ids.length;
    this.reset();
    return this;
  };

  ShapeIter.prototype.nextArc = function() {
    var i = this._i + 1;
    if (i < this._n) {
      this._arc = this._arcs.getArcIter(this._ids[i]);
      if (i > 0) this._arc.hasNext(); // skip first point
    }
    this._i = i;
  };

  ShapeIter.prototype.reset = function() {
    this._i = -1;
    this.nextArc();
  };

  var ShapeIter$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    PointIter: PointIter,
    ArcIter: ArcIter,
    FilteredArcIter: FilteredArcIter,
    ShapeIter: ShapeIter
  });

  // Returns a function for converting simplification ratio [0-1] to an interval value.
  // If the dataset is large, the value is an approximation (for speed while using slider)
  function getThresholdFunction(arcs) {
    var size = arcs.getPointCount(),
        nth = Math.ceil(size / 5e5),
        sortedThresholds = arcs.getRemovableThresholds(nth);
        // Sort simplification thresholds for all non-endpoint vertices
        // for quick conversion of simplification percentage to threshold value.
        // For large datasets, use every nth point, for faster sorting.
        // utils.quicksort(sortedThresholds, false); // descending
        utils.quicksort(sortedThresholds, true); // ascending

    return function(pct) {
      var n = sortedThresholds.length;
      var rank = retainedPctToRank(pct, sortedThresholds.length);
      if (rank < 1) return 0;
      if (rank > n) return Infinity;
      return sortedThresholds[rank-1];
    };
  }

  // Return integer rank of n (1-indexed) or 0 if pct <= 0 or n+1 if pct >= 1
  function retainedPctToRank(pct, n) {
    var rank;
    if (n === 0 || pct >= 1) {
      rank = 0;
    } else if (pct <= 0) {
      rank = n + 1;
    } else {
      rank = Math.floor((1 - pct) * (n + 2));
    }
    return rank;
  }

  // nth (optional): sample every nth threshold (use estimate for speed)
  function getThresholdByPct(pct, arcs, nth) {
    var tmp = arcs.getRemovableThresholds(nth),
        rank = retainedPctToRank(pct, tmp.length);
    if (rank < 1) return 0;
    if (rank > tmp.length) return Infinity;
    return utils.findValueByRank(tmp, rank);
  }

  var SimplifyPct = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getThresholdFunction: getThresholdFunction,
    getThresholdByPct: getThresholdByPct
  });

  // An interface for managing a collection of paths.
  // Constructor signatures:
  //
  // ArcCollection(arcs)
  //    arcs is an array of polyline arcs; each arc is an array of points: [[x0, y0], [x1, y1], ... ]
  //
  // ArcCollection(nn, xx, yy)
  //    nn is an array of arc lengths; xx, yy are arrays of concatenated coords;
  function ArcCollection() {
    var _xx, _yy,  // coordinates data
        _ii, _nn,  // indexes, sizes
        _zz, _zlimit = 0, // simplification
        _bb, _allBounds, // bounding boxes
        _arcIter, _filteredArcIter; // path iterators

    if (arguments.length == 1) {
      initLegacyArcs(arguments[0]);  // want to phase this out
    } else if (arguments.length == 3) {
      initXYData.apply(this, arguments);
    } else {
      error("ArcCollection() Invalid arguments");
    }

    function initLegacyArcs(arcs) {
      var xx = [], yy = [];
      var nn = arcs.map(function(points) {
        var n = points ? points.length : 0;
        for (var i=0; i<n; i++) {
          xx.push(points[i][0]);
          yy.push(points[i][1]);
        }
        return n;
      });
      initXYData(nn, xx, yy);
    }

    function initXYData(nn, xx, yy) {
      var size = nn.length;
      if (nn instanceof Array) nn = new Uint32Array(nn);
      if (xx instanceof Array) xx = new Float64Array(xx);
      if (yy instanceof Array) yy = new Float64Array(yy);
      _xx = xx;
      _yy = yy;
      _nn = nn;
      _zz = null;
      _zlimit = 0;
      _filteredArcIter = null;

      // generate array of starting idxs of each arc
      _ii = new Uint32Array(size);
      for (var idx = 0, j=0; j<size; j++) {
        _ii[j] = idx;
        idx += nn[j];
      }

      if (idx != _xx.length || _xx.length != _yy.length) {
        error("ArcCollection#initXYData() Counting error");
      }

      initBounds();
      // Pre-allocate some path iterators for repeated use.
      _arcIter = new ArcIter(_xx, _yy);
      return this;
    }

    function initZData(zz) {
      if (!zz) {
        _zz = null;
        _zlimit = 0;
        _filteredArcIter = null;
      } else {
        if (zz.length != _xx.length) error("ArcCollection#initZData() mismatched arrays");
        if (zz instanceof Array) zz = new Float64Array(zz);
        _zz = zz;
        _filteredArcIter = new FilteredArcIter(_xx, _yy, _zz);
      }
    }

    function initBounds() {
      var data = calcArcBounds2(_xx, _yy, _nn);
      _bb = data.bb;
      _allBounds = data.bounds;
    }

    function calcArcBounds2(xx, yy, nn) {
      var numArcs = nn.length,
          bb = new Float64Array(numArcs * 4),
          bounds = new Bounds(),
          arcOffs = 0,
          arcLen,
          j, b;
      for (var i=0; i<numArcs; i++) {
        arcLen = nn[i];
        if (arcLen > 0) {
          j = i * 4;
          b = calcArcBounds(xx, yy, arcOffs, arcLen);
          bb[j++] = b[0];
          bb[j++] = b[1];
          bb[j++] = b[2];
          bb[j] = b[3];
          arcOffs += arcLen;
          bounds.mergeBounds(b);
        }
      }
      return {
        bb: bb,
        bounds: bounds
      };
    }

    this.updateVertexData = function(nn, xx, yy, zz) {
      initXYData(nn, xx, yy);
      initZData(zz || null);
    };

    // Give access to raw data arrays...
    this.getVertexData = function() {
      return {
        xx: _xx,
        yy: _yy,
        zz: _zz,
        bb: _bb,
        nn: _nn,
        ii: _ii
      };
    };

    this.getCopy = function() {
      var copy = new ArcCollection(new Int32Array(_nn), new Float64Array(_xx),
          new Float64Array(_yy));
      if (_zz) {
        copy.setThresholds(new Float64Array(_zz));
        copy.setRetainedInterval(_zlimit);
      }
      return copy;
    };

    function getFilteredPointCount() {
      var zz = _zz, z = _zlimit;
      if (!zz || !z) return this.getPointCount();
      var count = 0;
      for (var i=0, n = zz.length; i<n; i++) {
        if (zz[i] >= z) count++;
      }
      return count;
    }

    function getFilteredVertexData() {
      var len2 = getFilteredPointCount();
      var arcCount = _nn.length;
      var xx2 = new Float64Array(len2),
          yy2 = new Float64Array(len2),
          zz2 = new Float64Array(len2),
          nn2 = new Int32Array(arcCount),
          i=0, i2 = 0,
          n, n2;

      for (var arcId=0; arcId < arcCount; arcId++) {
        n2 = 0;
        n = _nn[arcId];
        for (var end = i+n; i < end; i++) {
          if (_zz[i] >= _zlimit) {
            xx2[i2] = _xx[i];
            yy2[i2] = _yy[i];
            zz2[i2] = _zz[i];
            i2++;
            n2++;
          }
        }
        if (n2 == 1) {
          error("Collapsed arc");
          // This should not happen (endpoints should be z == Infinity)
          // Could handle like this, instead of throwing an error:
          // n2 = 0;
          // xx2.pop();
          // yy2.pop();
          // zz2.pop();
        } else if (n2 === 0) {
          // collapsed arc... ignoring
        }
        nn2[arcId] = n2;
      }
      return {
        xx: xx2,
        yy: yy2,
        zz: zz2,
        nn: nn2
      };
    }

    this.getFilteredCopy = function() {
      if (!_zz || _zlimit === 0) return this.getCopy();
      var data = getFilteredVertexData();
      var copy = new ArcCollection(data.nn, data.xx, data.yy);
      copy.setThresholds(data.zz);
      return copy;
    };

    // Return arcs as arrays of [x, y] points (intended for testing).
    this.toArray = function() {
      var arr = [];
      this.forEach(function(iter) {
        var arc = [];
        while (iter.hasNext()) {
          arc.push([iter.x, iter.y]);
        }
        arr.push(arc);
      });
      return arr;
    };

    this.toJSON = function() {
      return this.toArray();
    };

    // @cb function(i, j, xx, yy)
    this.forEachArcSegment = function(arcId, cb) {
      var fw = arcId >= 0,
          absId = fw ? arcId : ~arcId,
          zlim = this.getRetainedInterval(),
          n = _nn[absId],
          step = fw ? 1 : -1,
          v1 = fw ? _ii[absId] : _ii[absId] + n - 1,
          v2 = v1,
          xx = _xx, yy = _yy, zz = _zz,
          count = 0;

      for (var j = 1; j < n; j++) {
        v2 += step;
        if (zlim === 0 || zz[v2] >= zlim) {
          cb(v1, v2, xx, yy);
          v1 = v2;
          count++;
        }
      }
      return count;
    };

    // @cb function(i, j, xx, yy)
    this.forEachSegment = function(cb) {
      var count = 0;
      for (var i=0, n=this.size(); i<n; i++) {
        count += this.forEachArcSegment(i, cb);
      }
      return count;
    };

    this.transformPoints = function(f) {
      var xx = _xx, yy = _yy, arcId = -1, n = 0, p;
      for (var i=0, len=xx.length; i<len; i++, n--) {
        while (n === 0) {
          n = _nn[++arcId];
        }
        p = f(xx[i], yy[i], arcId);
        if (p) {
          xx[i] = p[0];
          yy[i] = p[1];
        }
      }
      initBounds();
    };

    // Return an ArcIter object for each path in the dataset
    //
    this.forEach = function(cb) {
      for (var i=0, n=this.size(); i<n; i++) {
        cb(this.getArcIter(i), i);
      }
    };

    // Iterate over arcs with access to low-level data
    //
    this.forEach2 = function(cb) {
      for (var arcId=0, n=this.size(); arcId<n; arcId++) {
        cb(_ii[arcId], _nn[arcId], _xx, _yy, _zz, arcId);
      }
    };

    this.forEach3 = function(cb) {
      var start, end, xx, yy, zz;
      for (var arcId=0, n=this.size(); arcId<n; arcId++) {
        start = _ii[arcId];
        end = start + _nn[arcId];
        xx = _xx.subarray(start, end);
        yy = _yy.subarray(start, end);
        if (_zz) zz = _zz.subarray(start, end);
        cb(xx, yy, zz, arcId);
      }
    };

    // Remove arcs that don't pass a filter test and re-index arcs
    // Return array mapping original arc ids to re-indexed ids. If arr[n] == -1
    // then arc n was removed. arr[n] == m indicates that the arc at n was
    // moved to index m.
    // Return null if no arcs were re-indexed (and no arcs were removed)
    //
    this.filter = function(cb) {
      var test = function(i) {
        return cb(this.getArcIter(i), i);
      }.bind(this);
      return this.deleteArcs(test);
    };

    this.deleteArcs = function(test) {
      var n = this.size(),
          map = new Int32Array(n),
          goodArcs = 0,
          goodPoints = 0;
      for (var i=0; i<n; i++) {
        if (test(i)) {
          map[i] = goodArcs++;
          goodPoints += _nn[i];
        } else {
          map[i] = -1;
        }
      }
      if (goodArcs < n) {
        condenseArcs(map);
      }
      return map;
    };

    function condenseArcs(map) {
      var goodPoints = 0,
          goodArcs = 0,
          copyElements = utils.copyElements,
          k, arcLen;
      for (var i=0, n=map.length; i<n; i++) {
        k = map[i];
        arcLen = _nn[i];
        if (k > -1) {
          copyElements(_xx, _ii[i], _xx, goodPoints, arcLen);
          copyElements(_yy, _ii[i], _yy, goodPoints, arcLen);
          if (_zz) copyElements(_zz, _ii[i], _zz, goodPoints, arcLen);
          _nn[k] = arcLen;
          goodPoints += arcLen;
          goodArcs++;
        }
      }

      initXYData(_nn.subarray(0, goodArcs), _xx.subarray(0, goodPoints),
          _yy.subarray(0, goodPoints));
      if (_zz) initZData(_zz.subarray(0, goodPoints));
    }

    this.dedupCoords = function() {
      var arcId = 0, i = 0, i2 = 0,
          arcCount = this.size(),
          zz = _zz,
          arcLen, arcLen2;
      while (arcId < arcCount) {
        arcLen = _nn[arcId];
        arcLen2 = dedupArcCoords(i, i2, arcLen, _xx, _yy, zz);
        _nn[arcId] = arcLen2;
        i += arcLen;
        i2 += arcLen2;
        arcId++;
      }
      if (i > i2) {
        initXYData(_nn, _xx.subarray(0, i2), _yy.subarray(0, i2));
        if (zz) initZData(zz.subarray(0, i2));
      }
      return i - i2;
    };

    this.getVertex = function(arcId, nth) {
      var i = this.indexOfVertex(arcId, nth);
      return {
        x: _xx[i],
        y: _yy[i]
      };
    };

    // @nth: index of vertex. ~(idx) starts from the opposite endpoint
    this.indexOfVertex = function(arcId, nth) {
      var absId = arcId < 0 ? ~arcId : arcId,
          len = _nn[absId];
      if (nth < 0) nth = len + nth;
      if (absId != arcId) nth = len - nth - 1;
      if (nth < 0 || nth >= len) error("[ArcCollection] out-of-range vertex id");
      return _ii[absId] + nth;
    };

    // Tests if arc endpoints have same x, y coords
    // (arc may still have collapsed);
    this.arcIsClosed = function(arcId) {
      var i = this.indexOfVertex(arcId, 0),
          j = this.indexOfVertex(arcId, -1);
      return i != j && _xx[i] == _xx[j] && _yy[i] == _yy[j];
    };

    // Tests if first and last segments mirror each other
    // A 3-vertex arc with same endpoints tests true
    this.arcIsLollipop = function(arcId) {
      var len = this.getArcLength(arcId),
          i, j;
      if (len <= 2 || !this.arcIsClosed(arcId)) return false;
      i = this.indexOfVertex(arcId, 1);
      j = this.indexOfVertex(arcId, -2);
      return _xx[i] == _xx[j] && _yy[i] == _yy[j];
    };

    this.arcIsDegenerate = function(arcId) {
      var iter = this.getArcIter(arcId);
      var i = 0,
          x, y;
      while (iter.hasNext()) {
        if (i > 0) {
          if (x != iter.x || y != iter.y) return false;
        }
        x = iter.x;
        y = iter.y;
        i++;
      }
      return true;
    };

    this.getArcLength = function(arcId) {
      return _nn[absArcId(arcId)];
    };

    this.getArcIter = function(arcId) {
      var fw = arcId >= 0,
          i = fw ? arcId : ~arcId,
          iter = _zz && _zlimit ? _filteredArcIter : _arcIter;
      if (i >= _nn.length) {
        error("#getArcId() out-of-range arc id:", arcId);
      }
      return iter.init(_ii[i], _nn[i], fw, _zlimit);
    };

    this.getShapeIter = function(ids) {
      return new ShapeIter(this).init(ids);
    };

    // Add simplification data to the dataset
    // @thresholds is either a single typed array or an array of arrays of removal thresholds for each arc;
    //
    this.setThresholds = function(thresholds) {
      var n = this.getPointCount(),
          zz = null;
      if (!thresholds) {
        // nop
      } else if (thresholds.length == n) {
        zz = thresholds;
      } else if (thresholds.length == this.size()) {
        zz = flattenThresholds(thresholds, n);
      } else {
        error("Invalid threshold data");
      }
      initZData(zz);
      return this;
    };

    function flattenThresholds(arr, n) {
      var zz = new Float64Array(n),
          i = 0;
      arr.forEach(function(arr) {
        for (var j=0, n=arr.length; j<n; i++, j++) {
          zz[i] = arr[j];
        }
      });
      if (i != n) error("Mismatched thresholds");
      return zz;
    }

    // bake in current simplification level, if any
    this.flatten = function() {
      if (_zlimit > 0) {
        var data = getFilteredVertexData();
        this.updateVertexData(data.nn, data.xx, data.yy);
        _zlimit = 0;
      } else {
        _zz = null;
      }
    };

    this.getRetainedInterval = function() {
      return _zlimit;
    };

    this.setRetainedInterval = function(z) {
      _zlimit = z;
      return this;
    };

    this.getRetainedPct = function() {
      return this.getPctByThreshold(_zlimit);
    };

    this.setRetainedPct = function(pct) {
      if (pct >= 1) {
        _zlimit = 0;
      } else {
        _zlimit = this.getThresholdByPct(pct);
        _zlimit = clampIntervalByPct(_zlimit, pct);
      }
      return this;
    };

    // Return array of z-values that can be removed for simplification
    //
    this.getRemovableThresholds = function(nth) {
      if (!_zz) error("[arcs] Missing simplification data.");
      var skip = nth | 1,
          arr = new Float64Array(Math.ceil(_zz.length / skip)),
          z;
      for (var i=0, j=0, n=this.getPointCount(); i<n; i+=skip) {
        z = _zz[i];
        if (z != Infinity) {
          arr[j++] = z;
        }
      }
      return arr.subarray(0, j);
    };

    this.getArcThresholds = function(arcId) {
      if (!(arcId >= 0 && arcId < this.size())) {
        error("[arcs] Invalid arc id:", arcId);
      }
      var start = _ii[arcId],
          end = start + _nn[arcId];
      return _zz.subarray(start, end);
    };

    // nth (optional): sample every nth threshold (use estimate for speed)
    this.getPctByThreshold = function(val, nth) {
      var arr, rank, pct;
      if (val > 0) {
        arr = this.getRemovableThresholds(nth);
        rank = utils.findRankByValue(arr, val);
        pct = arr.length > 0 ? 1 - (rank - 1) / arr.length : 1;
      } else {
        pct = 1;
      }
      return pct;
    };

    // nth (optional): sample every nth threshold (use estimate for speed)
    this.getThresholdByPct = function(pct, nth) {
      return getThresholdByPct(pct, this, nth);
    };

    this.arcIntersectsBBox = function(i, b1) {
      var b2 = _bb,
          j = i * 4;
      return b2[j] <= b1[2] && b2[j+2] >= b1[0] && b2[j+3] >= b1[1] && b2[j+1] <= b1[3];
    };

    this.arcIsContained = function(i, b1) {
      var b2 = _bb,
          j = i * 4;
      return b2[j] >= b1[0] && b2[j+2] <= b1[2] && b2[j+1] >= b1[1] && b2[j+3] <= b1[3];
    };

    this.arcIsSmaller = function(i, units) {
      var bb = _bb,
          j = i * 4;
      return bb[j+2] - bb[j] < units && bb[j+3] - bb[j+1] < units;
    };

    // TODO: allow datasets in lat-lng coord range to be flagged as planar
    this.isPlanar = function() {
      return !probablyDecimalDegreeBounds(this.getBounds());
    };

    this.size = function() {
      return _ii && _ii.length || 0;
    };

    this.getPointCount = function() {
      return _xx && _xx.length || 0;
    };

    this.getFilteredPointCount = getFilteredPointCount;

    this.getBounds = function() {
      return _allBounds.clone();
    };

    this.getSimpleShapeBounds = function(arcIds, bounds) {
      bounds = bounds || new Bounds();
      for (var i=0, n=arcIds.length; i<n; i++) {
        this.mergeArcBounds(arcIds[i], bounds);
      }
      return bounds;
    };

    this.getSimpleShapeBounds2 = function(arcIds, arr) {
      var bbox = arr || [],
          bb = _bb,
          id = absArcId(arcIds[0]) * 4;
      bbox[0] = bb[id];
      bbox[1] = bb[++id];
      bbox[2] = bb[++id];
      bbox[3] = bb[++id];
      for (var i=1, n=arcIds.length; i<n; i++) {
        id = absArcId(arcIds[i]) * 4;
        if (bb[id] < bbox[0]) bbox[0] = bb[id];
        if (bb[++id] < bbox[1]) bbox[1] = bb[id];
        if (bb[++id] > bbox[2]) bbox[2] = bb[id];
        if (bb[++id] > bbox[3]) bbox[3] = bb[id];
      }
      return bbox;
    };

    // TODO: move this and similar methods out of ArcCollection
    this.getMultiShapeBounds = function(shapeIds, bounds) {
      bounds = bounds || new Bounds();
      if (shapeIds) { // handle null shapes
        for (var i=0, n=shapeIds.length; i<n; i++) {
          this.getSimpleShapeBounds(shapeIds[i], bounds);
        }
      }
      return bounds;
    };

    this.mergeArcBounds = function(arcId, bounds) {
      if (arcId < 0) arcId = ~arcId;
      var offs = arcId * 4;
      bounds.mergeBounds(_bb[offs], _bb[offs+1], _bb[offs+2], _bb[offs+3]);
    };
  }

  // Remove duplicate coords and NaNs
  function dedupArcCoords(src, dest, arcLen, xx, yy, zz) {
    var n = 0, n2 = 0; // counters
    var x, y, i, j, keep;
    while (n < arcLen) {
      j = src + n;
      x = xx[j];
      y = yy[j];
      keep = x == x && y == y && (n2 === 0 || x != xx[j-1] || y != yy[j-1]);
      if (keep) {
        i = dest + n2;
        xx[i] = x;
        yy[i] = y;
        n2++;
      }
      if (zz && n2 > 0 && (keep || zz[j] > zz[i])) {
        zz[i] = zz[j];
      }
      n++;
    }
    return n2 > 1 ? n2 : 0;
  }

  // Get function to Hash an x, y point to a non-negative integer
  function getXYHash(size) {
    var buf = new ArrayBuffer(16),
        floats = new Float64Array(buf),
        uints = new Uint32Array(buf),
        lim = size | 0;
    if (lim > 0 === false) {
      throw new Error("Invalid size param: " + size);
    }

    return function(x, y) {
      var u = uints, h;
      floats[0] = x;
      floats[1] = y;
      h = u[0] ^ u[1];
      h = h << 5 ^ h >> 7 ^ u[2] ^ u[3];
      return (h & 0x7fffffff) % lim;
    };
  }

  // Get function to Hash a single coordinate to a non-negative integer
  function getXHash(size) {
    var buf = new ArrayBuffer(8),
        floats = new Float64Array(buf),
        uints = new Uint32Array(buf),
        lim = size | 0;
    if (lim > 0 === false) {
      throw new Error("Invalid size param: " + size);
    }

    return function(x) {
      var h;
      floats[0] = x;
      h = uints[0] ^ uints[1];
      h = h << 5 ^ h >> 7;
      return (h & 0x7fffffff) % lim;
    };
  }

  // Used for building topology
  //
  function ArcIndex(pointCount) {
    var hashTableSize = Math.floor(pointCount * 0.25 + 1),
        hash = getXYHash(hashTableSize),
        hashTable = new Int32Array(hashTableSize),
        chainIds = [],
        arcs = [],
        arcPoints = 0;

    utils.initializeArray(hashTable, -1);

    this.addArc = function(xx, yy) {
      var end = xx.length - 1,
          key = hash(xx[end], yy[end]),
          chainId = hashTable[key],
          arcId = arcs.length;
      hashTable[key] = arcId;
      arcs.push([xx, yy]);
      arcPoints += xx.length;
      chainIds.push(chainId);
      return arcId;
    };

    // Look for a previously generated arc with the same sequence of coords, but in the
    // opposite direction. (This program uses the convention of CW for space-enclosing rings, CCW for holes,
    // so coincident boundaries should contain the same points in reverse sequence).
    //
    this.findDuplicateArc = function(xx, yy, start, end, getNext, getPrev) {
      // First, look for a reverse match
      var arcId = findArcNeighbor(xx, yy, start, end, getNext);
      if (arcId === null) {
        // Look for forward match
        // (Abnormal topology, but we're accepting it because in-the-wild
        // Shapefiles sometimes have duplicate paths)
        arcId = findArcNeighbor(xx, yy, end, start, getPrev);
      } else {
        arcId = ~arcId;
      }
      return arcId;
    };

    function findArcNeighbor(xx, yy, start, end, getNext) {
      var next = getNext(start),
          key = hash(xx[start], yy[start]),
          arcId = hashTable[key],
          arcX, arcY, len;

      while (arcId != -1) {
        // check endpoints and one segment...
        // it would be more rigorous but slower to identify a match
        // by comparing all segments in the coordinate sequence
        arcX = arcs[arcId][0];
        arcY = arcs[arcId][1];
        len = arcX.length;
        if (arcX[0] === xx[end] && arcX[len-1] === xx[start] && arcX[len-2] === xx[next] &&
            arcY[0] === yy[end] && arcY[len-1] === yy[start] && arcY[len-2] === yy[next]) {
          return arcId;
        }
        arcId = chainIds[arcId];
      }
      return null;
    }

    this.getVertexData = function() {
      var xx = new Float64Array(arcPoints),
          yy = new Float64Array(arcPoints),
          nn = new Uint32Array(arcs.length),
          copied = 0,
          arc, len;
      for (var i=0, n=arcs.length; i<n; i++) {
        arc = arcs[i];
        len = arc[0].length;
        utils.copyElements(arc[0], 0, xx, copied, len);
        utils.copyElements(arc[1], 0, yy, copied, len);
        nn[i] = len;
        copied += len;
      }
      return {
        xx: xx,
        yy: yy,
        nn: nn
      };
    };
  }

  function initPointChains(xx, yy) {
    var chainIds = initHashChains(xx, yy),
        j, next, prevMatchId, prevUnmatchId;

    // disentangle, reverse and close the chains created by initHashChains()
    for (var i = xx.length-1; i>=0; i--) {
      next = chainIds[i];
      if (next >= i) continue;
      prevMatchId = i;
      prevUnmatchId = -1;
      do {
        j = next;
        next = chainIds[j];
        if (yy[j] == yy[i] && xx[j] == xx[i]) {
          chainIds[j] = prevMatchId;
          prevMatchId = j;
        } else {
          if (prevUnmatchId > -1) {
            chainIds[prevUnmatchId] = j;
          }
          prevUnmatchId = j;
        }
      } while (next < j);
      if (prevUnmatchId > -1) {
        // Make sure last unmatched entry is terminated
        chainIds[prevUnmatchId] = prevUnmatchId;
      }
      chainIds[i] = prevMatchId; // close the chain
    }
    return chainIds;
  }

  function initHashChains(xx, yy) {
    // Performance doesn't improve much above ~1.3 * point count
    var n = xx.length,
        m = Math.floor(n * 1.3) || 1,
        hash = getXYHash(m),
        hashTable = new Int32Array(m),
        chainIds = new Int32Array(n), // Array to be filled with chain data
        key, j, i, x, y;

    for (i=0; i<n; i++) {
      x = xx[i];
      y = yy[i];
      if (x != x || y != y) {
        j = -1; // NaN coord: no hash entry, one-link chain
      } else {
        key = hash(x, y);
        j = hashTable[key] - 1; // coord ids are 1-based in hash table; 0 used as null value.
        hashTable[key] = i + 1;
      }
      chainIds[i] = j >= 0 ? j : i; // first item in a chain points to self
    }
    return chainIds;
  }

  // Converts all polygon and polyline paths in a dataset to a topological format
  // (in-place)
  function buildTopology(dataset) {
    if (!dataset.arcs) return;
    var raw = dataset.arcs.getVertexData(),
        cooked = buildPathTopology(raw.nn, raw.xx, raw.yy);
    dataset.arcs.updateVertexData(cooked.nn, cooked.xx, cooked.yy);
    dataset.layers.forEach(function(lyr) {
      if (lyr.geometry_type == 'polyline' || lyr.geometry_type == 'polygon') {
        lyr.shapes = replaceArcIds(lyr.shapes, cooked.paths);
      }
    });
  }

  // buildPathTopology() converts non-topological paths into
  // a topological format
  //
  // Arguments:
  //    xx: [Array|Float64Array],   // x coords of each point in the dataset
  //    yy: [Array|Float64Array],   // y coords ...
  //    nn: [Array]  // length of each path
  //
  // (x- and y-coords of all paths are concatenated into two arrays)
  //
  // Returns:
  // {
  //    xx, yy (array)   // coordinate data
  //    nn: (array)      // points in each arc
  //    paths: (array)   // Paths are arrays of one or more arc id.
  // }
  //
  // Negative arc ids in the paths array indicate a reversal of arc -(id + 1)
  //
  function buildPathTopology(nn, xx, yy) {
    var pointCount = xx.length,
        chainIds = initPointChains(xx, yy),
        pathIds = initPathIds(pointCount, nn),
        index = new ArcIndex(pointCount),
        slice = usingTypedArrays() ? xx.subarray : Array.prototype.slice,
        paths, retn;
    paths = convertPaths(nn);
    retn = index.getVertexData();
    retn.paths = paths;
    return retn;

    function usingTypedArrays() {
      return !!(xx.subarray && yy.subarray);
    }

    function convertPaths(nn) {
      var paths = [],
          pointId = 0,
          pathLen;
      for (var i=0, len=nn.length; i<len; i++) {
        pathLen = nn[i];
        paths.push(pathLen < 2 ? null : convertPath(pointId, pointId + pathLen - 1));
        pointId += pathLen;
      }
      return paths;
    }

    function nextPoint(id) {
      var partId = pathIds[id],
          nextId = id + 1;
      if (nextId < pointCount && pathIds[nextId] === partId) {
        return id + 1;
      }
      var len = nn[partId];
      return sameXY(id, id - len + 1) ? id - len + 2 : -1;
    }

    function prevPoint(id) {
      var partId = pathIds[id],
          prevId = id - 1;
      if (prevId >= 0 && pathIds[prevId] === partId) {
        return id - 1;
      }
      var len = nn[partId];
      return sameXY(id, id + len - 1) ? id + len - 2 : -1;
    }

    function sameXY(a, b) {
      return xx[a] == xx[b] && yy[a] == yy[b];
    }

    // Convert a non-topological path to one or more topological arcs
    // @start, @end are ids of first and last points in the path
    // TODO: don't allow id ~id pairs
    //
    function convertPath(start, end) {
      var arcIds = [],
          firstNodeId = -1,
          arcStartId;

      // Visit each point in the path, up to but not including the last point
      for (var i = start; i < end; i++) {
        if (pointIsArcEndpoint(i)) {
          if (firstNodeId > -1) {
            arcIds.push(addEdge(arcStartId, i));
          } else {
            firstNodeId = i;
          }
          arcStartId = i;
        }
      }

      // Identify the final arc in the path
      if (firstNodeId == -1) {
        // Not in an arc, i.e. no nodes have been found...
        // Assuming that path is either an island or is congruent with one or more rings
        arcIds.push(addRing(start, end));
      }
      else if (firstNodeId == start) {
        // path endpoint is a node;
        if (!pointIsArcEndpoint(end)) {
          error("Topology error"); // TODO: better error handling
        }
        arcIds.push(addEdge(arcStartId, i));
      } else {
        // final arc wraps around
        arcIds.push(addSplitEdge(arcStartId, end, start + 1, firstNodeId));
      }
      return arcIds;
    }

    // Test if a point @id is an endpoint of a topological path
    function pointIsArcEndpoint(id) {
      var id2 = chainIds[id],
          prev = prevPoint(id),
          next = nextPoint(id),
          prev2, next2;
      if (prev == -1 || next == -1) {
        // @id is an endpoint if it is the start or end of an open path
        return true;
      }
      while (id != id2) {
        prev2 = prevPoint(id2);
        next2 = nextPoint(id2);
        if (prev2 == -1 || next2 == -1 || brokenEdge(prev, next, prev2, next2)) {
          // there is a discontinuity at @id -- point is arc endpoint
          return true;
        }
        id2 = chainIds[id2];
      }
      return false;
    }

    // a and b are two vertices with the same x, y coordinates
    // test if the segments on either side of them are also identical
    function brokenEdge(aprev, anext, bprev, bnext) {
      var apx = xx[aprev],
          anx = xx[anext],
          bpx = xx[bprev],
          bnx = xx[bnext],
          apy = yy[aprev],
          any = yy[anext],
          bpy = yy[bprev],
          bny = yy[bnext];
      if (apx == bnx && anx == bpx && apy == bny && any == bpy ||
          apx == bpx && anx == bnx && apy == bpy && any == bny) {
        return false;
      }
      return true;
    }

    function mergeArcParts(src, startId, endId, startId2, endId2) {
      var len = endId - startId + endId2 - startId2 + 2,
          ArrayClass = usingTypedArrays() ? Float64Array : Array,
          dest = new ArrayClass(len),
          j = 0, i;
      for (i=startId; i <= endId; i++) {
        dest[j++] = src[i];
      }
      for (i=startId2; i <= endId2; i++) {
        dest[j++] = src[i];
      }
      return dest;
    }

    function addSplitEdge(start1, end1, start2, end2) {
      var arcId = index.findDuplicateArc(xx, yy, start1, end2, nextPoint, prevPoint);
      if (arcId === null) {
        arcId = index.addArc(mergeArcParts(xx, start1, end1, start2, end2),
            mergeArcParts(yy, start1, end1, start2, end2));
      }
      return arcId;
    }

    function addEdge(start, end) {
      // search for a matching edge that has already been generated
      var arcId = index.findDuplicateArc(xx, yy, start, end, nextPoint, prevPoint);
      if (arcId === null) {
        arcId = index.addArc(slice.call(xx, start, end + 1),
            slice.call(yy, start, end + 1));
      }
      return arcId;
    }

    function addRing(startId, endId) {
      var chainId = chainIds[startId],
          pathId = pathIds[startId],
          arcId;

      while (chainId != startId) {
        if (pathIds[chainId] < pathId) {
          break;
        }
        chainId = chainIds[chainId];
      }

      if (chainId == startId) {
        return addEdge(startId, endId);
      }

      for (var i=startId; i<endId; i++) {
        arcId = index.findDuplicateArc(xx, yy, i, i, nextPoint, prevPoint);
        if (arcId !== null) return arcId;
      }
      error("Unmatched ring; id:", pathId, "len:", nn[pathId]);
    }
  }


  // Create a lookup table for path ids; path ids are indexed by point id
  //
  function initPathIds(size, pathSizes) {
    var pathIds = new Int32Array(size),
        j = 0;
    for (var pathId=0, pathCount=pathSizes.length; pathId < pathCount; pathId++) {
      for (var i=0, n=pathSizes[pathId]; i<n; i++, j++) {
        pathIds[j] = pathId;
      }
    }
    return pathIds;
  }

  function replaceArcIds(src, replacements) {
    return src.map(function(shape) {
      return replaceArcsInShape(shape, replacements);
    });

    function replaceArcsInShape(shape, replacements) {
      if (!shape) return null;
      return shape.map(function(path) {
        return replaceArcsInPath(path, replacements);
      });
    }

    function replaceArcsInPath(path, replacements) {
      return path.reduce(function(memo, id) {
        var abs = absArcId(id);
        var topoPath = replacements[abs];
        if (topoPath) {
          if (id < 0) {
            topoPath = topoPath.concat(); // TODO: need to copy?
            reversePath(topoPath);
          }
          for (var i=0, n=topoPath.length; i<n; i++) {
            memo.push(topoPath[i]);
          }
        }
        return memo;
      }, []);
    }
  }

  var Topology = /*#__PURE__*/Object.freeze({
    __proto__: null,
    buildTopology: buildTopology,
    buildPathTopology: buildPathTopology
  });

  // Merge arcs from one or more source datasets into target dataset
  // return array of layers from the source dataset (instead of adding them to the target dataset)
  function mergeDatasetsIntoDataset(dataset, datasets) {
    var merged = mergeDatasets([dataset].concat(datasets));
    var mergedLayers = datasets.reduce(function(memo, dataset) {
      return memo.concat(dataset.layers);
    }, []);
    dataset.arcs = merged.arcs;
    return mergedLayers;
  }

  // Don't modify input layers (mergeDatasets() updates arc ids in-place)
  function mergeDatasetsForExport(arr) {
    // copy layers but not arcs, which get copied in mergeDatasets()
    var copy = arr.map(function(dataset) {
      return utils.defaults({
        layers: dataset.layers.map(copyLayerShapes)
      }, dataset);
    });
    return mergeDatasets(copy);
  }

  function mergeCommandTargets(targets, catalog) {
    var targetLayers = [];
    var targetDatasets = [];
    var datasetsWithArcs = 0;
    var merged;

    targets.forEach(function(target) {
      targetLayers = targetLayers.concat(target.layers);
      targetDatasets = targetDatasets.concat(target.dataset);
      if (target.dataset.arcs && target.dataset.arcs.size() > 0) datasetsWithArcs++;
    });

    merged = mergeDatasets(targetDatasets);

    // Rebuild topology, if multiple datasets contain arcs
    if (datasetsWithArcs > 1) {
      buildTopology(merged);
    }

    // remove old datasets after merging, so catalog is not affected if merge throws an error
    targetDatasets.forEach(catalog.removeDataset);
    catalog.addDataset(merged); // sets default target to all layers in merged dataset
    catalog.setDefaultTarget(targetLayers, merged); // reset default target
    return [{
      layers: targetLayers,
      dataset: merged
    }];
  }

  // Combine multiple datasets into one using concatenation
  // (any shared topology is ignored)
  function mergeDatasets(arr) {
    var arcSources = [],
        arcCount = 0,
        mergedLayers = [],
        mergedInfo = {},
        mergedArcs;

    // Error if incompatible CRS
    requireDatasetsHaveCompatibleCRS(arr);

    arr.forEach(function(dataset) {
      var n = dataset.arcs ? dataset.arcs.size() : 0;
      if (n > 0) {
        arcSources.push(dataset.arcs);
      }

      mergeDatasetInfo(mergedInfo, dataset);
      dataset.layers.forEach(function(lyr) {
        if (lyr.geometry_type == 'polygon' || lyr.geometry_type == 'polyline') {
          forEachArcId(lyr.shapes, function(id) {
            return id < 0 ? id - arcCount : id + arcCount;
          });
        }
        mergedLayers.push(lyr);
      });
      arcCount += n;
    });

    if (arcSources.length > 0) {
      mergedArcs = mergeArcs(arcSources);
      if (mergedArcs.size() != arcCount) {
        error("[mergeDatasets()] Arc indexing error");
      }
    }

    return {
      info: mergedInfo,
      arcs: mergedArcs,
      layers: mergedLayers
    };
  }

  function mergeDatasetInfo(merged, dataset) {
    var info = dataset.info || {};
    merged.input_files = utils.uniq((merged.input_files || []).concat(info.input_files || []));
    merged.input_formats = utils.uniq((merged.input_formats || []).concat(info.input_formats || []));
    // merge other info properties (e.g. input_geojson_crs, input_delimiter, prj, crs)
    utils.defaults(merged, info);
  }

  function mergeArcs(arr) {
    // Returning the original causes a test to fail
    // if (arr.length < 2) return arr[0];
    var dataArr = arr.map(function(arcs) {
      if (arcs.getRetainedInterval() > 0) {
        verbose("Baking-in simplification setting.");
        arcs.flatten();
      }
      return arcs.getVertexData();
    });
    var xx = mergeArrays(utils.pluck(dataArr, 'xx'), Float64Array),
        yy = mergeArrays(utils.pluck(dataArr, 'yy'), Float64Array),
        nn = mergeArrays(utils.pluck(dataArr, 'nn'), Int32Array);

    return new ArcCollection(nn, xx, yy);
  }

  function countElements(arrays) {
    return arrays.reduce(function(memo, arr) {
      return memo + (arr.length || 0);
    }, 0);
  }

  function mergeArrays(arrays, TypedArr) {
    var size = countElements(arrays),
        Arr = TypedArr || Array,
        merged = new Arr(size),
        offs = 0;
    arrays.forEach(function(src) {
      var n = src.length;
      for (var i = 0; i<n; i++) {
        merged[i + offs] = src[i];
      }
      offs += n;
    });
    return merged;
  }

  var Merging = /*#__PURE__*/Object.freeze({
    __proto__: null,
    mergeDatasetsIntoDataset: mergeDatasetsIntoDataset,
    mergeDatasetsForExport: mergeDatasetsForExport,
    mergeCommandTargets: mergeCommandTargets,
    mergeDatasets: mergeDatasets,
    mergeArcs: mergeArcs
  });

  // Test if the second endpoint of an arc is the endpoint of any path in any layer
  function getPathEndpointTest(layers, arcs) {
    var index = new Uint8Array(arcs.size());
    layers.forEach(function(lyr) {
      if (layerHasPaths(lyr)) {
        lyr.shapes.forEach(addShape);
      }
    });

    function addShape(shape) {
      forEachShapePart(shape, addPath);
    }

    function addPath(path) {
      addEndpoint(~path[0]);
      addEndpoint(path[path.length - 1]);
    }

    function addEndpoint(arcId) {
      var absId = absArcId(arcId);
      var fwd = absId == arcId;
      index[absId] |= fwd ? 1 : 2;
    }

    return function(arcId) {
      var absId = absArcId(arcId);
      var fwd = absId == arcId;
      var code = index[absId];
      return fwd ? (code & 1) == 1 : (code & 2) == 2;
    };
  }

  var PathEndpoints = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getPathEndpointTest: getPathEndpointTest
  });

  // @arcs ArcCollection
  // @filter Optional filter function, arcIds that return false are excluded
  //
  function NodeCollection(arcs, filter) {
    if (Array.isArray(arcs)) {
      arcs = new ArcCollection(arcs);
    }
    var arcData = arcs.getVertexData(),
        nn = arcData.nn,
        xx = arcData.xx,
        yy = arcData.yy,
        nodeData;

    // Accessor function for arcs
    Object.defineProperty(this, 'arcs', {value: arcs});

    var toArray = this.toArray = function() {
      var chains = getNodeChains(),
          flags = new Uint8Array(chains.length),
          arr = [];
      utils.forEach(chains, function(nextIdx, thisIdx) {
        var node, x, y, p;
        if (flags[thisIdx] == 1) return;
        p = getEndpoint(thisIdx);
        if (!p) return; // endpoints of an excluded arc
        node = {coordinates: p, arcs: []};
        arr.push(node);
        while (flags[thisIdx] != 1) {
          node.arcs.push(chainToArcId(thisIdx));
          flags[thisIdx] = 1;
          thisIdx = chains[thisIdx];
        }
      });
      return arr;
    };

    this.size = function() {
      return this.toArray().length;
    };

    this.findDanglingEndpoints = function() {
      var chains = getNodeChains(),
          arr = [], p;
      for (var i=0, n=chains.length; i<n; i++) {
        if (chains[i] != i) continue; // endpoint attaches to a node
        p = getEndpoint(i);
        if (!p) continue; // endpoint belongs to an excluded arc
        arr.push({
          point: p,
          arc: chainToArcId(i)
        });
      }
      return arr;
    };

    this.detachAcyclicArcs = function() {
      var chains = getNodeChains(),
          count = 0,
          fwd, rev;
      for (var i=0, n=chains.length; i<n; i+= 2) {
        fwd = i == chains[i];
        rev = i + 1 == chains[i + 1];
        // detach arcs that are disconnected at one end or the other
        if ((fwd || rev) && !linkIsDetached(i)) {
          this.detachArc(chainToArcId(i));
          count++;
        }
      }
      if (count > 0) {
        // removing one acyclic arc could expose another -- need another pass
        count += this.detachAcyclicArcs();
      }
      return count;
    };

    this.detachArc = function(arcId) {
      unlinkDirectedArc(arcId);
      unlinkDirectedArc(~arcId);
    };

    this.forEachConnectedArc = function(arcId, cb) {
      var nextId = nextConnectedArc(arcId),
          i = 0;
      while (nextId != arcId) {
        cb(nextId, i++);
        nextId = nextConnectedArc(nextId);
      }
    };

    // Receives an arc id for an arc that enters a node.
    // Returns an array of ids of all other arcs that are connected to the same node.
    //    Returned ids lead into the node (as opposed to outwards from it)
    // An optional filter function receives the directed id (positive or negative)
    //    of each connected arc and excludes arcs for which the filter returns false.
    //    The filter is also applied to the initial arc; if false, no arcs are returned.
    //
    this.getConnectedArcs = function(arcId, filter) {
      var ids = [];
      var filtered = !!filter;
      var nextId = nextConnectedArc(arcId);
      if (filtered && !filter(arcId)) {
        // return ids;
      }
      while (nextId != arcId) {
        if (!filtered || filter(nextId)) {
          ids.push(nextId);
        }
        nextId = nextConnectedArc(nextId);
      }
      return ids;
    };

    // Returns the id of the first identical arc or @arcId if none found
    // TODO: find a better function name
    this.findDuplicateArc = function(arcId) {
      var nextId = nextConnectedArc(arcId),
          match = arcId;
      while (nextId != arcId) {
        if (testArcMatch(arcId, nextId)) {
          if (absArcId(nextId) < absArcId(match)) match = nextId;
        }
        nextId = nextConnectedArc(nextId);
      }
      return match;
    };

    // returns null if link has been removed from node collection
    function getEndpoint(chainId) {
      return linkIsDetached(chainId) ? null : [nodeData.xx[chainId], nodeData.yy[chainId]];
    }

    function linkIsDetached(chainId) {
      return isNaN(nodeData.xx[chainId]);
    }

    function unlinkDirectedArc(arcId) {
      var chainId = arcToChainId(arcId),
          chains = getNodeChains(),
          nextId = chains[chainId],
          prevId = prevChainId(chainId);
      nodeData.xx[chainId] = NaN;
      nodeData.yy[chainId] = NaN;
      chains[chainId] = chainId;
      chains[prevId] = nextId;
    }

    function chainToArcId(chainId) {
      var absId = chainId >> 1;
      return chainId & 1 == 1 ? absId : ~absId;
    }

    function arcToChainId(arcId) {
      var fw = arcId >= 0;
      return fw ? arcId * 2 + 1 : (~arcId) * 2; // if fw, use end, if rev, use start
    }

    function getNodeChains() {
      if (!nodeData) {
        nodeData = findNodeTopology(arcs, filter);
        if (nn.length * 2 != nodeData.chains.length) error("[NodeCollection] count error");
      }
      return nodeData.chains;
    }

    function testArcMatch(a, b) {
      var absA = a >= 0 ? a : ~a,
          absB = b >= 0 ? b : ~b,
          lenA = nn[absA];
      if (lenA < 2) {
        // Don't throw error on collapsed arcs -- assume they will be handled
        //   appropriately downstream.
        // error("[testArcMatch() defective arc; len:", lenA);
        return false;
      }
      if (lenA != nn[absB]) return false;
      if (testVertexMatch(a, b, -1) &&
          testVertexMatch(a, b, 1) &&
          testVertexMatch(a, b, -2)) {
        return true;
      }
      return false;
    }

    function testVertexMatch(a, b, i) {
      var ai = arcs.indexOfVertex(a, i),
          bi = arcs.indexOfVertex(b, i);
      return xx[ai] == xx[bi] && yy[ai] == yy[bi];
    }

    // return arcId of next arc in the chain, pointed towards the shared vertex
    function nextConnectedArc(arcId) {
      var chainId = arcToChainId(arcId),
          chains =  getNodeChains(),
          nextChainId = chains[chainId];
      if (!(nextChainId >= 0 && nextChainId < chains.length)) {
        // console.log('arcId:', arcId, 'chainId:', chainId, 'next chain id:', nextChainId)
        error("out-of-range chain id");
      }
      return chainToArcId(nextChainId);
    }

    function prevChainId(chainId) {
      var chains = getNodeChains(),
          prevId = chainId,
          nextId = chains[chainId];
      while (nextId != chainId) {
        prevId = nextId;
        nextId = chains[nextId];
        if (nextId == prevId) error("Node indexing error");
      }
      return prevId;
    }

    // expose functions for testing
    this.internal = {
      testArcMatch: testArcMatch,
      testVertexMatch: testVertexMatch
    };
  }

  function findNodeTopology(arcs, filter) {
    var n = arcs.size() * 2,
        xx2 = new Float64Array(n),
        yy2 = new Float64Array(n),
        ids2 = new Int32Array(n);

    arcs.forEach2(function(i, n, xx, yy, zz, arcId) {
      var start = i,
          end = i + n - 1,
          start2 = arcId * 2,
          end2 = start2 + 1,
          ax = xx[start],
          ay = yy[start],
          bx = xx[end],
          by = yy[end];
      if (filter && !filter(arcId)) {
        ax = ay = bx = by = NaN;
      }

      xx2[start2] = ax;
      yy2[start2] = ay;
      ids2[start2] = arcId;
      xx2[end2] = bx;
      yy2[end2] = by;
      ids2[end2] = arcId;
    });

    var chains = initPointChains(xx2, yy2);
    return {
      xx: xx2,
      yy: yy2,
      ids: ids2,
      chains: chains
    };
  }

  // Dissolve arcs that can be merged without affecting topology of layers
  // remove arcs that are not referenced by any layer; remap arc ids
  // in layers. (dataset.arcs is replaced).
  function dissolveArcs(dataset) {
    var arcs = dataset.arcs,
        layers = dataset.layers.filter(layerHasPaths);

    if (!arcs || !layers.length) {
      dataset.arcs = null;
      return;
    }

    var arcsCanDissolve = getArcDissolveTest(layers, arcs),
        newArcs = [],
        totalPoints = 0,
        arcIndex = new Int32Array(arcs.size()), // maps old arc ids to new ids
        arcStatus = new Uint8Array(arcs.size());
        // arcStatus: 0 = unvisited, 1 = dropped, 2 = remapped, 3 = remapped + reversed
    layers.forEach(function(lyr) {
      // modify copies of the original shapes; original shapes should be unmodified
      // (need to test this)
      lyr.shapes = lyr.shapes.map(function(shape) {
        return editShapeParts(shape && shape.concat(), translatePath);
      });
    });
    dataset.arcs = dissolveArcCollection(arcs, newArcs, totalPoints);

    function translatePath(path) {
      var pointCount = 0;
      var newPath = [];
      var newArc, arcId, absId, arcLen, fw, newArcId;

      for (var i=0, n=path.length; i<n; i++) {
        arcId = path[i];
        absId = absArcId(arcId);
        fw = arcId === absId;

        if (arcs.arcIsDegenerate(arcId)) {
          // arc has collapsed -- skip
        } else if (arcStatus[absId] !== 0) {
          // arc has already been translated -- skip
          newArc = null;
        } else {
          arcLen = arcs.getArcLength(arcId);

          if (newArc && arcsCanDissolve(path[i-1], arcId)) {
            if (arcLen > 0) {
              arcLen--; // shared endpoint not counted;
            }
            newArc.push(arcId);  // arc data is appended to previous arc
            arcStatus[absId] = 1; // arc is dropped from output
          } else {
            // start a new dissolved arc
            newArc = [arcId];
            arcIndex[absId] = newArcs.length;
            newArcs.push(newArc);
            arcStatus[absId] = fw ? 2 : 3; // 2: unchanged; 3: reversed
          }
          pointCount += arcLen;
        }

        if (arcStatus[absId] > 1) {
          // arc is retained (and renumbered) in the dissolved path -- add to path
          newArcId = arcIndex[absId];
          if (fw && arcStatus[absId] == 3 || !fw && arcStatus[absId] == 2) {
            newArcId = ~newArcId;
          }
          newPath.push(newArcId);
        }
      }
      totalPoints += pointCount;
      return newPath;
    }
  }

  function dissolveArcCollection(arcs, newArcs, newLen) {
    var nn2 = new Uint32Array(newArcs.length),
        xx2 = new Float64Array(newLen),
        yy2 = new Float64Array(newLen),
        src = arcs.getVertexData(),
        zz2 = src.zz ? new Float64Array(newLen) : null,
        interval = arcs.getRetainedInterval(),
        offs = 0;

    newArcs.forEach(function(newArc, newId) {
      newArc.forEach(function(oldId, i) {
        extendDissolvedArc(oldId, newId);
      });
    });

    return new ArcCollection(nn2, xx2, yy2).setThresholds(zz2).setRetainedInterval(interval);

    function extendDissolvedArc(oldId, newId) {
      var absId = absArcId(oldId),
          rev = oldId < 0,
          n = src.nn[absId],
          i = src.ii[absId],
          n2 = nn2[newId];

      if (n > 0) {
        if (n2 > 0) {
          n--;
          if (!rev) i++;
        }
        utils.copyElements(src.xx, i, xx2, offs, n, rev);
        utils.copyElements(src.yy, i, yy2, offs, n, rev);
        if (zz2) utils.copyElements(src.zz, i, zz2, offs, n, rev);
        nn2[newId] += n;
        offs += n;
      }
    }
  }

  // Test whether two arcs can be merged together
  function getArcDissolveTest(layers, arcs) {
    var nodes = new NodeCollection(arcs, getArcPresenceTest2(layers, arcs)),
        // don't allow dissolving through endpoints of polyline paths
        lineLayers = layers.filter(function(lyr) {return lyr.geometry_type == 'polyline';}),
        testLineEndpoint = getPathEndpointTest(lineLayers, arcs),
        linkCount, lastId;

    return function(id1, id2) {
      if (id1 == id2 || id1 == ~id2) {
        verbose("Unexpected arc sequence:", id1, id2);
        return false; // This is unexpected; don't try to dissolve, anyway
      }
      linkCount = 0;
      nodes.forEachConnectedArc(id1, countLink);
      return linkCount == 1 && lastId == ~id2 && !testLineEndpoint(id1) && !testLineEndpoint(~id2);
    };

    function countLink(arcId, i) {
      linkCount++;
      lastId = arcId;
    }
  }

  var ArcDissolve = /*#__PURE__*/Object.freeze({
    __proto__: null,
    dissolveArcs: dissolveArcs,
    getArcDissolveTest: getArcDissolveTest
  });

  // utility functions for datasets

  // Split into datasets with one layer each
  function splitDataset(dataset) {
    return dataset.layers.map(function(lyr) {
      var split = {
        arcs: dataset.arcs,
        layers: [lyr],
        info: utils.extend({}, dataset.info)
      };
      dissolveArcs(split); // replace arcs with filtered + dissolved copy
      return split;
    });
  }

  function splitApartLayers(dataset, layers) {
    var datasets = [];
    dataset.layers = dataset.layers.filter(function(lyr) {
      if (!layers.includes(lyr)) {
        return true;
      }
      var split = {
        arcs: dataset.arcs,
        layers: [lyr],
        info: utils.extend({}, dataset.info)
      };
      dissolveArcs(split); // replace arcs with filtered + dissolved copy
      datasets.push(split);
      return false;
    });
    if (dataset.layers.length) {
      dissolveArcs(dataset);
      datasets.push(dataset);
    }
    return datasets;
  }

  // clone all layers, make a filtered copy of arcs
  function copyDataset(dataset) {
    var d2 = utils.extend({}, dataset);
    d2.layers = d2.layers.map(copyLayer);
    if (d2.arcs) {
      d2.arcs = d2.arcs.getFilteredCopy();
    }
    return d2;
  }

  // clone coordinate data, shallow-copy attribute data
  function copyDatasetForExport(dataset) {
    var d2 = utils.extend({}, dataset);
    d2.layers = d2.layers.map(copyLayerShapes);
    if (d2.arcs) {
      d2.arcs = d2.arcs.getFilteredCopy();
    }
    return d2;
  }

  // shallow-copy layers, so they can be renamed (for export)
  function copyDatasetForRenaming(dataset) {
    return utils.defaults({
      layers: dataset.layers.map(function(lyr) {return utils.extend({}, lyr);})
    }, dataset);
  }

  function getDatasetBounds(dataset) {
    var bounds = new Bounds();
    dataset.layers.forEach(function(lyr) {
      var lyrbb = getLayerBounds(lyr, dataset.arcs);
      if (lyrbb) bounds.mergeBounds(lyrbb);
    });
    return bounds;
  }

  function datasetHasGeometry(dataset) {
    return utils.some(dataset.layers, function(lyr) {
      return layerHasGeometry(lyr);
    });
  }

  function datasetHasPaths(dataset) {
    return utils.some(dataset.layers, function(lyr) {
      return layerHasPaths(lyr);
    });
  }

  // Remove ArcCollection of a dataset if not referenced by any layer
  // TODO: consider doing arc dissolve, or just removing unreferenced arcs
  // (currently cleanupArcs() is run after every command, so be mindful of performance)
  function cleanupArcs(dataset) {
    if (dataset.arcs && !utils.some(dataset.layers, layerHasPaths)) {
      dataset.arcs = null;
      return true;
    }
  }

  // Remove unused arcs from a dataset
  // Warning: using dissolveArcs() means that adjacent arcs are combined when possible
  function pruneArcs(dataset) {
    cleanupArcs(dataset);
    if (dataset.arcs) {
      dissolveArcs(dataset);
    }
  }

  // replace cut layers in-sequence (to maintain layer indexes)
  // append any additional new layers
  function replaceLayers(dataset, cutLayers, newLayers) {
    // modify a copy in case cutLayers == dataset.layers
    var currLayers = dataset.layers.concat();
    utils.repeat(Math.max(cutLayers.length, newLayers.length), function(i) {
      var cutLyr = cutLayers[i],
          newLyr = newLayers[i],
          idx = cutLyr ? currLayers.indexOf(cutLyr) : currLayers.length;

      if (cutLyr) {
        currLayers.splice(idx, 1);
      }
      if (newLyr) {
        currLayers.splice(idx, 0, newLyr);
      }
    });
    dataset.layers = currLayers;
  }

  // Replace a layer with a layer from a second dataset
  // (in-place)
  // (Typically, the second dataset is imported from dynamically generated GeoJSON and contains one layer)
  function replaceLayerContents(lyr, dataset, dataset2) {
    var lyr2 = mergeOutputLayerIntoDataset(lyr, dataset, dataset2, {});
    if (layerHasPaths(lyr2)) {
      buildTopology(dataset);
    }
  }

  function mergeOutputLayerIntoDataset(lyr, dataset, dataset2, opts) {
    if (!dataset2 || dataset2.layers.length != 1) {
      error('Invalid source dataset');
    }
    if (dataset.layers.includes(lyr) === false) {
      error('Invalid target layer');
    }
    // this command returns merged layers instead of adding them to target dataset
    var outputLayers = mergeDatasetsIntoDataset(dataset, [dataset2]);
    var lyr2 = outputLayers[0];

    // TODO: find a more reliable way of knowing when to copy data
    var copyData = !lyr2.data && lyr.data && getFeatureCount(lyr2) == lyr.data.size();

    if (copyData) {
      lyr2.data = opts.no_replace ? lyr.data.clone() : lyr.data;
    }
    if (opts.no_replace) {
      // dataset.layers.push(lyr2);

    } else {
      lyr2 = Object.assign(lyr, {data: null, shapes: null}, lyr2);
      if (layerHasPaths(lyr)) {
        // Remove unused arcs from replaced layer
        // TODO: consider using clean insead of this
        dissolveArcs(dataset);
      }
    }

    lyr2.name = opts.name || lyr2.name;
    return lyr2;
  }

  // Transform the points in a dataset in-place; don't clean up corrupted shapes
  function transformPoints(dataset, f) {
    if (dataset.arcs) {
      dataset.arcs.transformPoints(f);
    }
    dataset.layers.forEach(function(lyr) {
      if (layerHasPoints(lyr)) {
        transformPointsInLayer(lyr, f);
      }
    });
  }

  var DatasetUtils = /*#__PURE__*/Object.freeze({
    __proto__: null,
    splitDataset: splitDataset,
    splitApartLayers: splitApartLayers,
    copyDataset: copyDataset,
    copyDatasetForExport: copyDatasetForExport,
    copyDatasetForRenaming: copyDatasetForRenaming,
    getDatasetBounds: getDatasetBounds,
    datasetHasGeometry: datasetHasGeometry,
    datasetHasPaths: datasetHasPaths,
    cleanupArcs: cleanupArcs,
    pruneArcs: pruneArcs,
    replaceLayers: replaceLayers,
    replaceLayerContents: replaceLayerContents,
    mergeOutputLayerIntoDataset: mergeOutputLayerIntoDataset,
    transformPoints: transformPoints
  });

  function getPathSep(path) {
    // TODO: improve
    return path.indexOf('/') == -1 && path.indexOf('\\') != -1 ? '\\' : '/';
  }

  // Parse the path to a file without using Node
  // Guess if the path is a directory or file
  function parseLocalPath(path) {
    var obj = {
          filename: '',
          directory: '',
          basename: '',
          extension: ''
        },
        sep = getPathSep(path),
        parts = path.split(sep),
        lastPart = parts.pop(),
        // try to match typical extensions but reject directory names with dots
        extRxp = /\.([a-z][a-z0-9]*)$/i,
        extMatch = extRxp.test(lastPart) ? extRxp.exec(lastPart)[0] : '';

    if (extMatch || lastPart.includes('*')) {
      obj.filename = lastPart;
      obj.extension = extMatch ? extMatch.slice(1) : '';
      obj.basename = lastPart.slice(0, lastPart.length - extMatch.length);
      obj.directory = parts.join(sep);
    } else if (!lastPart) { // path ends with separator
      obj.directory = parts.join(sep);
    } else {
      obj.directory = path;
    }
    return obj;
  }

  function getFileBase(path) {
    return parseLocalPath(path).basename;
  }

  function getFileExtension(path) {
    return parseLocalPath(path).extension;
  }

  function getPathBase(path) {
    var info =  parseLocalPath(path);
    if (!info.extension) return path;
    return path.slice(0, path.length - info.extension.length - 1);
  }

  function replaceFileExtension(path, ext) {
    return getPathBase(path) + '.' + ext;
  }

  function getCommonFileBase(names) {
    return names.reduce(function(memo, name, i) {
      if (i === 0) {
        memo = getFileBase(name);
      } else {
        memo = utils.mergeNames(memo, name);
      }
      return memo;
    }, "");
  }

  function getOutputFileBase(dataset) {
    var inputFiles = dataset.info && dataset.info.input_files;
    return inputFiles && getCommonFileBase(inputFiles) || 'output';
  }

  var FilenameUtils = /*#__PURE__*/Object.freeze({
    __proto__: null,
    parseLocalPath: parseLocalPath,
    getFileBase: getFileBase,
    getFileExtension: getFileExtension,
    getPathBase: getPathBase,
    replaceFileExtension: replaceFileExtension,
    getCommonFileBase: getCommonFileBase,
    getOutputFileBase: getOutputFileBase
  });

  var cli = {};

  cli.isFile = function(path, cache) {
    if (cache && (path in cache)) return true;
    if (runningInBrowser()) return false;
    var ss = cli.statSync(path);
    return ss && ss.isFile() || false;
  };

  // cli.fileSize = function(path) {
  //   var ss = cli.statSync(path);
  //   return ss && ss.size || 0;
  // };

  cli.isDirectory = function(path) {
    if (runningInBrowser()) return false;
    var ss = cli.statSync(path);
    return ss && ss.isDirectory() || false;
  };

  // @encoding (optional) e.g. 'utf8'
  cli.readFile = function(fname, encoding, cache) {
    var content;
    if (cache && (fname in cache)) {
      content = cache[fname];
      delete cache[fname];
    } else if (fname == '/dev/stdin') {
      content = require('rw').readFileSync(fname);
    } else {
      getStateVar('input_files').push(fname);
      content = require('fs').readFileSync(fname);
    }
    if (encoding && Buffer.isBuffer(content)) {
      content = trimBOM(decodeString(content, encoding));
    }
    return content;
  };

  cli.createDirIfNeeded = function(fname) {
    var odir = parseLocalPath(fname).directory;
    if (!odir || cli.isDirectory(odir) || fname == '/dev/stdout') return;
    try {
      require('fs').mkdirSync(odir, {recursive: true});
      message('Created output directory:', odir);
    } catch(e) {
      stop('Unable to create output directory:', odir);
    }
  };

  // content: Buffer or string
  cli.writeFile = function(fname, content, cb) {
    var fs = require('rw');
    cli.createDirIfNeeded(fname);
    if (cb) {
      fs.writeFile(fname, content, preserveContext(cb));
    } else {
      fs.writeFileSync(fname, content);
    }
  };

  // Returns Node Buffer
  cli.convertArrayBuffer = function(buf) {
    var src = new Uint8Array(buf),
        dest = utils.createBuffer(src.length);
    for (var i = 0, n=src.length; i < n; i++) {
      dest[i] = src[i];
    }
    return dest;
  };

  // Expand any "*" wild cards in file name
  // (For the Windows command line; unix shells do this automatically)
  cli.expandFileName = function(name) {
    var info = parseLocalPath(name),
        rxp = utils.wildcardToRegExp(info.filename),
        dir = info.directory || '.',
        files = [];

    try {
      require('fs').readdirSync(dir).forEach(function(item) {
        var path = require('path').join(dir, item);
        if (rxp.test(item) && cli.isFile(path)) {
          files.push(path);
        }
      });
    } catch(e) {}

    if (files.length === 0) {
      stop('No files matched (' + name + ')');
    }
    return files;
  };

  // Expand any wildcards.
  cli.expandInputFiles = function(files) {
    return files.reduce(function(memo, name) {
      if (name.indexOf('*') > -1) {
        memo = memo.concat(cli.expandFileName(name));
      } else {
        memo.push(name);
      }
      return memo;
    }, []);
  };

  cli.validateOutputDir = function(name) {
    if (!cli.isDirectory(name) && !runningInBrowser()) {
      error("Output directory not found:", name);
    }
  };

  // TODO: rename and improve
  // Want to test if a path is something readable (e.g. file or stdin)
  cli.checkFileExists = function(path, cache) {
    if (!cli.isFile(path, cache) && path != '/dev/stdin') {
      stop("File not found (" + path + ")");
    }
  };

  cli.statSync = function(fpath) {
    var obj = null;
    try {
      obj = require('fs').statSync(fpath);
    } catch(e) {}
    return obj;
  };

  function writeFiles(exports, opts, cb) {
    cb = cb || function() {};
    return _writeFiles(exports, opts, cb);
  }

  // Used by GUI to replace the CLI version of writeFiles()
  // (so -o can work in the browser console)
  function replaceWriteFiles(func) {
    _writeFiles = func;
  }

  var _writeFiles = function(exports, opts, cb) {
    if (exports.length > 0 === false) {
      message("No files to save");
    } else if (opts.dry_run) {
      // no output
    } else if (opts.stdout) {
      // Pass callback for asynchronous output (synchronous output to stdout can
      // trigger EAGAIN error, e.g. when piped to less)
      return cli.writeFile('/dev/stdout', exports[0].content, cb);
    } else {
      var paths = getOutputPaths(utils.pluck(exports, 'filename'), opts);
      var inputFiles = getStateVar('input_files');
      exports.forEach(function(obj, i) {
        var path = paths[i];
        if (obj.content instanceof ArrayBuffer) {
          // replacing content so ArrayBuffers can be gc'd
          obj.content = cli.convertArrayBuffer(obj.content); // convert to Buffer
        }
        if (opts.output) {
          opts.output.push({filename: path, content: obj.content});
        } else {
          if (!opts.force && inputFiles.indexOf(path) > -1) {
            stop('Need to use the "-o force" option to overwrite input files.');
          }
          cli.writeFile(path, obj.content);
          message("Wrote " + path);
        }
      });
    }
    if (cb) cb(null);
  };

  function getOutputPaths(files, opts) {
    var odir = opts.directory;
    if (odir) {
      files = files.map(function(file) {
        return require('path').join(odir, file);
      });
    }
    return files;
  }

  var FileExport = /*#__PURE__*/Object.freeze({
    __proto__: null,
    writeFiles: writeFiles,
    replaceWriteFiles: replaceWriteFiles,
    getOutputPaths: getOutputPaths
  });

  // Returns a search function
  // Receives array of objects to index; objects must have a 'bounds' member
  //    that is a Bounds object.
  function getBoundsSearchFunction(boxes) {
    var index, Flatbush;
    if (!boxes.length) {
      // Unlike rbush, flatbush doesn't allow size 0 indexes; workaround
      return function() {return [];};
    }
    Flatbush = require('flatbush');
    index = new Flatbush(boxes.length);
    boxes.forEach(function(ring) {
      var b = ring.bounds;
      index.add(b.xmin, b.ymin, b.xmax, b.ymax);
    });
    index.finish();

    function idxToObj(i) {
      return boxes[i];
    }

    // Receives xmin, ymin, xmax, ymax parameters
    // Returns subset of original @bounds array
    return function(a, b, c, d) {
      return index.search(a, b, c, d).map(idxToObj);
    };
  }

  // @xx array of x coords
  // @ids an array of segment endpoint ids [a0, b0, a1, b1, ...]
  // Sort @ids in place so that xx[a(n)] <= xx[b(n)] and xx[a(n)] <= xx[a(n+1)]
  function sortSegmentIds(xx, ids) {
    orderSegmentIds(xx, ids);
    quicksortSegmentIds(xx, ids, 0, ids.length-2);
  }

  function orderSegmentIds(xx, ids, spherical) {
    function swap(i, j) {
      var tmp = ids[i];
      ids[i] = ids[j];
      ids[j] = tmp;
    }
    for (var i=0, n=ids.length; i<n; i+=2) {
      if (xx[ids[i]] > xx[ids[i+1]]) {
        swap(i, i+1);
      }
    }
  }

  function insertionSortSegmentIds(arr, ids, start, end) {
    var id, id2;
    for (var j = start + 2; j <= end; j+=2) {
      id = ids[j];
      id2 = ids[j+1];
      for (var i = j - 2; i >= start && arr[id] < arr[ids[i]]; i-=2) {
        ids[i+2] = ids[i];
        ids[i+3] = ids[i+1];
      }
      ids[i+2] = id;
      ids[i+3] = id2;
    }
  }

  function quicksortSegmentIds (a, ids, lo, hi) {
    var i = lo,
        j = hi,
        pivot, tmp;
    while (i < hi) {
      pivot = a[ids[(lo + hi >> 2) << 1]]; // avoid n^2 performance on sorted arrays
      while (i <= j) {
        while (a[ids[i]] < pivot) i+=2;
        while (a[ids[j]] > pivot) j-=2;
        if (i <= j) {
          tmp = ids[i];
          ids[i] = ids[j];
          ids[j] = tmp;
          tmp = ids[i+1];
          ids[i+1] = ids[j+1];
          ids[j+1] = tmp;
          i+=2;
          j-=2;
        }
      }

      if (j - lo < 40) insertionSortSegmentIds(a, ids, lo, j);
      else quicksortSegmentIds(a, ids, lo, j);
      if (hi - i < 40) {
        insertionSortSegmentIds(a, ids, i, hi);
        return;
      }
      lo = i;
      j = hi;
    }
  }

  // PolygonIndex indexes the coordinates in one polygon feature for efficient
  // point-in-polygon tests

  function PolygonIndex(shape, arcs, opts) {
    var data = arcs.getVertexData(),
        polygonBounds = arcs.getMultiShapeBounds(shape),
        boundsLeft,
        xminIds, xmaxIds, // vertex ids of segment endpoints
        bucketCount,
        bucketOffsets,
        bucketWidth;

    init();

    // Return 0 if outside, 1 if inside, -1 if on boundary
    this.pointInPolygon = function(x, y) {
      if (!polygonBounds.containsPoint(x, y)) {
        return false;
      }
      var bucketId = getBucketId(x);
      var count = countCrosses(x, y, bucketId);
      if (bucketId > 0) {
        count += countCrosses(x, y, bucketId - 1);
      }
      count += countCrosses(x, y, bucketCount); // check oflo bucket
      if (isNaN(count)) return -1;
      return count % 2 == 1 ? 1 : 0;
    };

    function countCrosses(x, y, bucketId) {
      var offs = bucketOffsets[bucketId],
          count = 0,
          xx = data.xx,
          yy = data.yy,
          n, a, b;
      if (bucketId == bucketCount) { // oflo bucket
        n = xminIds.length - offs;
      } else {
        n = bucketOffsets[bucketId + 1] - offs;
      }
      for (var i=0; i<n; i++) {
        a = xminIds[i + offs];
        b = xmaxIds[i + offs];
        count += geom.testRayIntersection(x, y, xx[a], yy[a], xx[b], yy[b]);
      }
      return count;
    }

    function getBucketId(x) {
      var i = Math.floor((x - boundsLeft) / bucketWidth);
      if (i < 0) i = 0;
      if (i >= bucketCount) i = bucketCount - 1;
      return i;
    }

    function getBucketCount(segCount) {
      // default is this many segs per bucket (average)
      // var buckets = opts && opts.buckets > 0 ? opts.buckets : segCount / 200;
      // using more segs/bucket for more complex shapes, based on trial and error
      var buckets = Math.pow(segCount, 0.75) / 10;
      return Math.ceil(buckets);
    }

    function init() {
      var xx = data.xx,
          segCount = 0,
          segId = 0,
          bucketId = -1,
          prevBucketId,
          segments,
          head, tail,
          a, b, i, j, xmin, xmax;

      // get array of segments as [s0p0, s0p1, s1p0, s1p1, ...], sorted by xmin coordinate
      forEachSegmentInShape(shape, arcs, function() {
        segCount++;
      });
      segments = new Uint32Array(segCount * 2);
      i = 0;
      forEachSegmentInShape(shape, arcs, function(a, b, xx, yy) {
        segments[i++] = a;
        segments[i++] = b;
      });
      sortSegmentIds(xx, segments);

      // assign segments to buckets according to xmin coordinate
      xminIds = new Uint32Array(segCount);
      xmaxIds = new Uint32Array(segCount);
      bucketCount = getBucketCount(segCount);
      bucketOffsets = new Uint32Array(bucketCount + 1); // add an oflo bucket
      boundsLeft = xx[segments[0]]; // xmin of first segment
      bucketWidth = (xx[segments[segments.length - 2]] - boundsLeft) / bucketCount;
      head = 0; // insertion index for next segment in the current bucket
      tail = segCount - 1; // insertion index for next segment in oflo bucket

      while (segId < segCount) {
        j = segId * 2;
        a = segments[j];
        b = segments[j+1];
        xmin = xx[a];
        xmax = xx[b];
        prevBucketId = bucketId;
        bucketId = getBucketId(xmin);

        while (bucketId > prevBucketId) {
          prevBucketId++;
          bucketOffsets[prevBucketId] = head;
        }

        if (xmax - xmin >= 0 === false) error("Invalid segment");
        if (getBucketId(xmax) - bucketId > 1) {
          // if segment extends to more than two buckets, put it in the oflo bucket
          xminIds[tail] = a;
          xmaxIds[tail] = b;
          tail--; // oflo bucket fills from right to left
        } else {
          // else place segment in a bucket based on x coord of leftmost endpoint
          xminIds[head] = a;
          xmaxIds[head] = b;
          head++;
        }
        segId++;
      }
      bucketOffsets[bucketCount] = head;
      if (head != tail + 1) error("Segment indexing error");
    }
  }

  // PathIndex supports several kinds of spatial query on a layer of polyline or polygon shapes
  function PathIndex(shapes, arcs) {
    var boundsQuery = getBoundsSearchFunction(getRingData(shapes, arcs));
    var totalArea = getPathBounds(shapes, arcs).area();

    function getRingData(shapes, arcs) {
      var arr = [];
      shapes.forEach(function(shp, shpId) {
        var n = shp ? shp.length : 0;
        for (var i=0; i<n; i++) {
          arr.push({
            ids: shp[i],
            id: shpId,
            bounds: arcs.getSimpleShapeBounds(shp[i])
          });
        }
      });
      return arr;
    }

    // Returns shape ids of all polygons that intersect point p
    // (p is inside a ring or on the boundary)
    this.findEnclosingShapes = function(p) {
      var ids = [];
      var cands = findPointHitCandidates(p);
      var groups = groupItemsByShapeId(cands);
      groups.forEach(function(group) {
        if (testPointInRings(p, group)) {
          ids.push(group[0].id);
        }
      });
      return ids;
    };

    // Returns shape id of a polygon that intersects p or -1
    // (If multiple intersections, returns one of the polygons)
    this.findEnclosingShape = function(p) {
      var shpId = -1;
      var groups = groupItemsByShapeId(findPointHitCandidates(p));
      groups.forEach(function(group) {
        if (testPointInRings(p, group)) {
          shpId = group[0].id;
        }
      });
      return shpId;
    };

    // Returns shape ids of polygons that contain an arc
    // (arcs that are )
    // Assumes that input arc is either inside, outside or coterminous with indexed
    // arcs (i.e. input arc does not cross an indexed arc)
    this.findShapesEnclosingArc = function(arcId) {
      var p = getTestPoint([arcId]);
      return this.findEnclosingShapes(p);
    };

    this.findPointEnclosureCandidates = function(p, buffer) {
      var items = findPointHitCandidates(p, buffer);
      return utils.pluck(items, 'id');
    };

    this.pointIsEnclosed = function(p) {
      return testPointInRings(p, findPointHitCandidates(p));
    };

    // Finds the polygon containing the smallest ring that entirely contains @ring
    // Assumes ring boundaries do not cross.
    // Unhandled edge case:
    //   two rings share at least one segment but are not congruent.
    // @ring: array of arc ids
    // Returns id of enclosing polygon or -1 if none found
    this.findSmallestEnclosingPolygon = function(ring) {
      var bounds = arcs.getSimpleShapeBounds(ring);
      var p = getTestPoint(ring);
      var smallest;
      var cands = findPointHitCandidates(p);
      cands.forEach(function(cand) {
        if (cand.bounds.contains(bounds) && // skip partially intersecting bboxes (can't be enclosures)
          !cand.bounds.sameBounds(bounds) && // skip self, congruent and reversed-congruent rings
          !(smallest && smallest.bounds.area() < cand.bounds.area())) {
              if (testPointInRing(p, cand)) {
                smallest = cand;
              }
            }
      });

      return smallest ? smallest.id : -1;
    };

    this.arcIsEnclosed = function(arcId) {
      return this.pointIsEnclosed(getTestPoint([arcId]));
    };

    // Test if a polygon ring is contained within an indexed ring
    // Not a true polygon-in-polygon test
    // Assumes that the target ring does not cross an indexed ring at any point
    // or share a segment with an indexed ring. (Intersecting rings should have
    // been detected previously).
    //
    this.pathIsEnclosed = function(pathIds) {
      return this.pointIsEnclosed(getTestPoint(pathIds));
    };

    // return array of paths that are contained within a path, or null if none
    // @pathIds Array of arc ids comprising a closed path
    this.findEnclosedPaths = function(pathIds) {
      var b = arcs.getSimpleShapeBounds(pathIds),
          cands = boundsQuery(b.xmin, b.ymin, b.xmax, b.ymax),
          paths = [],
          index;

      if (cands.length > 6) {
        index = new PolygonIndex([pathIds], arcs);
      }
      cands.forEach(function(cand) {
        var p = getTestPoint(cand.ids);
        var isEnclosed = b.containsPoint(p[0], p[1]) && (index ?
          index.pointInPolygon(p[0], p[1]) : geom.testPointInRing(p[0], p[1], pathIds, arcs));
        if (isEnclosed) {
          paths.push(cand.ids);
        }
      });
      return paths.length > 0 ? paths : null;
    };

    this.findPathsInsideShape = function(shape) {
      var paths = []; // list of enclosed paths
      shape.forEach(function(ids) {
        var enclosed = this.findEnclosedPaths(ids);
        if (enclosed) {
          // any paths that are enclosed by an even number of rings are removed from list
          // (given normal topology, such paths are inside holes)
          paths = xorArrays(paths, enclosed);
        }
      }, this);
      return paths.length > 0 ? paths : null;
    };

    function testPointInRing(p, cand) {
      if (!cand.bounds.containsPoint(p[0], p[1])) return false;
      if (!cand.index && cand.bounds.area() > totalArea * 0.01) {
        // index larger polygons (because they are slower to test via pointInRing()
        //    and they are more likely to be involved in repeated hit tests).
        cand.index = new PolygonIndex([cand.ids], arcs);
      }
      return cand.index ?
          cand.index.pointInPolygon(p[0], p[1]) :
          geom.testPointInRing(p[0], p[1], cand.ids, arcs);
    }

    //
    function testPointInRings(p, cands) {
      var isOn = false,
          isIn = false;
      cands.forEach(function(cand) {
        var inRing = testPointInRing(p, cand);
        if (inRing == -1) {
          isOn = true;
        } else if (inRing == 1) {
          isIn = !isIn;
        }
      });
      return isOn || isIn;
    }

    function groupItemsByShapeId(items) {
      var groups = [],
          group, item;
      if (items.length > 0) {
        items.sort(function(a, b) {return a.id - b.id;});
        for (var i=0; i<items.length; i++) {
          item = items[i];
          if (i === 0 || item.id != items[i-1].id) {
            groups.push(group=[]);
          }
          group.push(item);
        }
      }
      return groups;
    }

    function findPointHitCandidates(p, buffer) {
      var b = buffer > 0 ? buffer : 0;
      var x = p[0], y = p[1];
      return boundsQuery(p[0] - b, p[1] - b, p[0] + b, p[1] + b);
    }

    // Find a point on a ring to use for point-in-polygon testing
    function getTestPoint(ring) {
      // Use the point halfway along first segment rather than an endpoint
      // (because ring might still be enclosed if a segment endpoint touches an indexed ring.)
      // The returned point should work for point-in-polygon testing if two rings do not
      // share any common segments (which should be true for topological datasets)
      // TODO: consider alternative of finding an internal point of @ring (slower but
      //   potentially more reliable).
      var arcId = ring[0],
          p0 = arcs.getVertex(arcId, 0),
          p1 = arcs.getVertex(arcId, 1);
      return [(p0.x + p1.x) / 2, (p0.y + p1.y) / 2];
    }

    // concatenate arrays, removing elements that are in both
    function xorArrays(a, b) {
      var xor = [], i;
      for (i=0; i<a.length; i++) {
        if (b.indexOf(a[i]) == -1) xor.push(a[i]);
      }
      for (i=0; i<b.length; i++) {
        if (a.indexOf(b[i]) == -1) xor.push(b[i]);
      }
      return xor;
    }
  }

  // Delete rings that are nested directly inside an enclosing ring with the same winding direction
  // Does not remove unenclosed CCW rings (currently this causes problems when
  //   rounding coordinates for SVG and TopoJSON output)
  // Assumes ring boundaries do not overlap (should be true after e.g. dissolving)
  //
  function fixNestingErrors(rings, arcs) {
    if (rings.length <= 1) return rings;
    var ringData = getPathMetadata(rings, arcs, 'polygon');
    // convert rings to shapes for PathIndex
    var shapes = rings.map(function(ids) {return [ids];});
    var index = new PathIndex(shapes, arcs);
    return rings.filter(ringIsValid);

    function ringIsValid(ids, i) {
      var containerId = index.findSmallestEnclosingPolygon(ids);
      var ringIsCW, containerIsCW;
      var valid = true;
      if (containerId > -1) {
        ringIsCW = ringData[i].area > 0;
        containerIsCW = ringData[containerId].area > 0;
        if (containerIsCW == ringIsCW) {
          // reject rings with same chirality as their containing ring
          valid = false;
        }
      }
      return valid;
    }
  }

  // Set winding order of polygon rings so that outer rings are CW, first-order
  // nested rings are CCW, etc.
  function rewindPolygons(lyr, arcs) {
    lyr.shapes = lyr.shapes.map(function(shp) {
      if (!shp) return null;
      return rewindPolygon(shp, arcs);
    });
  }

  // Update winding order of rings in a polygon so that outermost rings are
  // CW and nested rings alternate between CCW and CW.
  function rewindPolygon(rings, arcs) {
    var ringData = getPathMetadata(rings, arcs, 'polygon');

    // Sort rings by area, from large to small
    ringData.sort(function(a, b) {
      return Math.abs(b.area) - Math.abs(a.area);
    });
    // If a ring is contained by one or more rings, set it to the opposite
    //   direction as its immediate parent
    // If a ring is not contained, make it CW.
    ringData.forEach(function(ring, i) {
      var shouldBeCW = true;
      var j = i;
      var largerRing;
      while (--j >= 0) {
        largerRing = ringData[j];
        if (testRingInRing(ring, largerRing, arcs)) {
          // set to opposite of containing ring
          shouldBeCW = largerRing.area > 0 ? false : true;
          break;
        }
      }
      setRingWinding(ring, shouldBeCW);
    });
    return ringData.map(function(data) { return data.ids; });
  }

  // data: a ring data object
  function setRingWinding(data, cw) {
    var isCW = data.area > 0;
    if (isCW != cw) {
      data.area = -data.area;
      reversePath(data.ids);
    }
  }

  // a, b: two ring data objects (from getPathMetadata);
  function testRingInRing(a, b, arcs) {
    if (b.bounds.contains(a.bounds) === false) return false;
    var p = arcs.getVertex(a.ids[0], 0); // test with first point in the ring
    return geom.testPointInRing(p.x, p.y, b.ids, arcs) == 1;
  }

  // Bundle holes with their containing rings for Topo/GeoJSON polygon export.
  // Assumes outer rings are CW and inner (hole) rings are CCW, unless
  //   the reverseWinding flag is set.
  // @paths array of objects with path metadata -- see internal.exportPathData()
  //
  function groupPolygonRings(paths, arcs, reverseWinding) {
    var holes = [],
        groups = [],
        sign = reverseWinding ? -1 : 1,
        boundsQuery;

    (paths || []).forEach(function(path) {
      if (path.area * sign > 0) {
        groups.push([path]);
      } else if (path.area * sign < 0) {
        holes.push(path);
      } else {
        // Zero-area ring, skipping
      }
    });

    if (holes.length === 0) {
      return groups;
    }

    // Using a spatial index to improve performance when the current feature
    // contains many holes and space-filling rings.
    // (Thanks to @simonepri for providing an example implementation in PR #248)
    boundsQuery = getBoundsSearchFunction(groups.map(function(group, i) {
      return {
        bounds: group[0].bounds,
        idx: i
      };
    }));

    // Group each hole with its containing ring
    holes.forEach(function(hole) {
      var containerId = -1,
          containerArea = 0,
          holeArea = hole.area * -sign,
          b = hole.bounds,
          // Find rings that might contain this hole
          candidates = boundsQuery(b.xmin, b.ymin, b.xmax, b.ymax),
          ring, ringId, ringArea, isContained;

      // Group this hole with the smallest-area ring that contains it.
      // (Assumes that if a ring's bbox contains a hole, then the ring also
      //  contains the hole).
      for (var i=0, n=candidates.length; i<n; i++) {
        ringId = candidates[i].idx;
        ring = groups[ringId][0];
        ringArea = ring.area * sign;
        isContained = ring.bounds.contains(hole.bounds) && ringArea > holeArea;
        if (isContained && candidates.length > 1 && !testRingInRing(hole, ring, arcs)) {
          // Using a more precise ring-in-ring test in the unusual case that
          // this hole is contained within the bounding box of multiple rings.
          // TODO: consider doing a ring-in-ring test even when there is only one
          // candidate ring, based on bbox-in-bbox test (this may affect performance
          // with some datasets).
          continue;
        }
        if (isContained && (containerArea === 0 || ringArea < containerArea)) {
          containerArea = ringArea;
          containerId = ringId;
        }
      }
      if (containerId == -1) {
        debug("[groupPolygonRings()] polygon hole is missing a containing ring, dropping.");
      } else {
        groups[containerId].push(hole);
      }
    });

    return groups;
  }

  function exportPointData(points) {
    var data, path;
    if (!points || points.length === 0) {
      data = {partCount: 0, pointCount: 0};
    } else {
      path = {
        points: points,
        pointCount: points.length,
        bounds: geom.getPathBounds(points)
      };
      data = {
        bounds: path.bounds,
        pathData: [path],
        partCount: 1,
        pointCount: path.pointCount
      };
    }
    return data;
  }

  // TODO: remove duplication with internal.getPathMetadata()
  function exportPathData(shape, arcs, type) {
    // kludge until Shapefile exporting is refactored
    if (type == 'point') return exportPointData(shape);

    var pointCount = 0,
        bounds = new Bounds(),
        paths = [];

    if (shape && (type == 'polyline' || type == 'polygon')) {
      shape.forEach(function(arcIds, i) {
        var iter = arcs.getShapeIter(arcIds),
            path = exportPathCoords(iter),
            valid = true;
        path.ids = arcIds;
        if (type == 'polygon') {
          path.area = geom.getPlanarPathArea2(path.points);
          valid = path.pointCount > 3 && path.area !== 0;
        } else if (type == 'polyline') {
          valid = path.pointCount > 1;
        }
        if (valid) {
          pointCount += path.pointCount;
          path.bounds = geom.getPathBounds(path.points);
          bounds.mergeBounds(path.bounds);
          paths.push(path);
        } else {
          verbose("Skipping a collapsed", type, "path");
        }
      });
    }

    return {
      pointCount: pointCount,
      pathData: paths,
      pathCount: paths.length,
      bounds: bounds
    };
  }

  function exportPathCoords(iter) {
    var points = [],
        i = 0,
        x, y, prevX, prevY;
    while (iter.hasNext()) {
      x = iter.x;
      y = iter.y;
      if (i === 0 || prevX != x || prevY != y) {
        points.push([x, y]);
        i++;
      }
      prevX = x;
      prevY = y;
    }
    return {
      points: points,
      pointCount: points.length
    };
  }

  var PathExport = /*#__PURE__*/Object.freeze({
    __proto__: null,
    exportPointData: exportPointData,
    exportPathData: exportPathData
  });

  function stringifyAsNDJSON(o) {
    var str = JSON.stringify(o);
    return str.replace(/\n/g, '\n').replace(/\r/g, '\r');
  }

  function getFormattedStringify(numArrayKeys) {
    var keyIndex = utils.arrayToIndex(numArrayKeys);
    var sentinel = '\u1000\u2FD5\u0310';
    var stripRxp = new RegExp('"' + sentinel + '|' + sentinel + '"', 'g');
    var indentChars = '  ';

    function replace(key, val) {
      // We want to format numerical arrays like [1, 2, 3] instead of
      // the way JSON.stringify() behaves when applying indentation.
      // This kludge converts arrays to strings with sentinel strings inside the
      // surrounding quotes. At the end, the sentinel strings and quotes
      // are replaced by array brackets.
      if (key in keyIndex && utils.isArray(val)) {
        var str = JSON.stringify(val);
        // make sure the array does not contain any strings
        if (str.indexOf('"' == -1)) {
          return sentinel + str.replace(/,/g, ', ') + sentinel;
        }
      }
      return val;
    }

    return function(obj) {
      var json = JSON.stringify(obj, replace, indentChars);
      return json.replace(stripRxp, '');
    };
  }

  var Stringify = /*#__PURE__*/Object.freeze({
    __proto__: null,
    stringifyAsNDJSON: stringifyAsNDJSON,
    getFormattedStringify: getFormattedStringify
  });

  // Return id of rightmost connected arc in relation to @arcId
  // Return @arcId if no arcs can be found
  function getRightmostArc(arcId, nodes, filter) {
    var ids = nodes.getConnectedArcs(arcId);
    if (filter) {
      ids = ids.filter(filter);
    }
    if (ids.length === 0) {
      return arcId; // error condition, handled by caller
    }
    return getRighmostArc2(arcId, ids, nodes.arcs);
  }

  function getRighmostArc2 (fromId, ids, arcs) {
    var coords = arcs.getVertexData(),
        xx = coords.xx,
        yy = coords.yy,
        inode = arcs.indexOfVertex(fromId, -1),
        nodeX = xx[inode],
        nodeY = yy[inode],
        ifrom = arcs.indexOfVertex(fromId, -2),
        fromX = xx[ifrom],
        fromY = yy[ifrom],
        toId = fromId, // initialize to from-arc -- an error
        ito, candId, icand, code, j;

    /*if (x == ax && y == ay) {
      error("Duplicate point error");
    }*/
    if (ids.length > 0) {
      toId = ids[0];
      ito = arcs.indexOfVertex(toId, -2);
    }

    for (j=1; j<ids.length; j++) {
      candId = ids[j];
      icand = arcs.indexOfVertex(candId, -2);
      code = chooseRighthandPath(fromX, fromY, nodeX, nodeY, xx[ito], yy[ito], xx[icand], yy[icand]);
      // code = internal.chooseRighthandPath(0, 0, nodeX - fromX, nodeY - fromY, xx[ito] - fromX, yy[ito] - fromY, xx[icand] - fromX, yy[icand] - fromY);
      if (code == 2) {
        toId = candId;
        ito = icand;
      }
    }
    if (toId == fromId) {
      // This shouldn't occur, assuming that other arcs are present
      error("Pathfinder error");
    }
    return toId;
  }

  function chooseRighthandPath2(fromX, fromY, nodeX, nodeY, ax, ay, bx, by) {
    return chooseRighthandVector(ax - nodeX, ay - nodeY, bx - nodeX, by - nodeY);
  }

  // TODO: consider using simpler internal.chooseRighthandPath2()
  // Returns 1 if node->a, return 2 if node->b, else return 0
  // TODO: better handling of identical angles (better -- avoid creating them)
  function chooseRighthandPath(fromX, fromY, nodeX, nodeY, ax, ay, bx, by) {
    var angleA = geom.signedAngle(fromX, fromY, nodeX, nodeY, ax, ay);
    var angleB = geom.signedAngle(fromX, fromY, nodeX, nodeY, bx, by);
    var code;
    if (angleA <= 0 || angleB <= 0) {
      debug("[chooseRighthandPath()] 0 angle(s):", angleA, angleB);
      if (angleA <= 0) {
        debug('  A orient2D:', geom.orient2D(fromX, fromY, nodeX, nodeY, ax, ay));
      }
      if (angleB <= 0) {
        debug('  B orient2D:', geom.orient2D(fromX, fromY, nodeX, nodeY, bx, by));
      }
      // TODO: test against "from" segment
      if (angleA > 0) {
        code = 1;
      } else if (angleB > 0) {
        code = 2;
      } else {
        code = 0;
      }
    } else if (angleA < angleB) {
      code = 1;
    } else if (angleB < angleA) {
      code = 2;
    } else if (isNaN(angleA) || isNaN(angleB)) {
      // probably a duplicate point, which should not occur
      error('Invalid node geometry');
    } else {
      // Equal angles: use fallback test that is less sensitive to rounding error
      code = chooseRighthandVector(ax - nodeX, ay - nodeY, bx - nodeX, by - nodeY);
      debug('[chooseRighthandPath()] equal angles:', angleA, 'fallback test:', code);
    }
    return code;
  }

  function chooseRighthandVector(ax, ay, bx, by) {
    var orient = geom.orient2D(ax, ay, 0, 0, bx, by);
    var code;
    if (orient > 0) {
      code = 2;
    } else if (orient < 0) {
      code = 1;
    } else {
      code = 0;
    }
    return code;
  }

  var PathfinderUtils = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getRightmostArc: getRightmostArc,
    chooseRighthandVector: chooseRighthandVector
  });

  // Functions for redrawing polygons for clipping / erasing / flattening / division
  // These functions use 8 bit codes to control forward and reverse traversal of each arc.
  //
  // Function of path bits 0-7:
  // 0: is fwd path hidden or visible? (0=hidden, 1=visible)
  // 1: is fwd path open or closed for traversal? (0=closed, 1=open)
  // 2: unused
  // 3: unused
  // 4: is rev path hidden or visible?
  // 5: is rev path open or closed for traversal?
  // 6: unused
  // 7: unused
  //
  // Example codes:
  // 0x3 (3): forward path is visible and open, reverse path is hidden and closed
  // 0x10 (16): forward path is hidden and closed, reverse path is visible and closed
  //

  var FWD_VISIBLE = 0x1;
  var FWD_OPEN = 0x2;
  var REV_VISIBLE = 0x10;
  var REV_OPEN = 0x20;

  function setBits(bits, arcBits, mask) {
    return (bits & ~mask) | (arcBits & mask);
  }

  function andBits(bits, arcBits, mask) {
    return bits & (~mask | arcBits);
  }

  function setRouteBits(arcBits, arcId, routesArr) {
    var idx = absArcId(arcId), // get index of path in
        mask;
    if (idx == arcId) { // arcBits controls fwd path
      mask = ~3; // target fwd bits
    } else { // arcBits controls rev. path
      mask = ~0x30; // target rev bits
      arcBits = arcBits << 4; // shift code to target rev path
    }
    routesArr[idx] &= (arcBits | mask);
  }

  function getRouteBits(arcId, routesArr) {
    var idx = absArcId(arcId),
        bits = routesArr[idx];
    if (idx != arcId) bits = bits >> 4;
    return bits & 7;
  }

  // Open arc pathways in a single shape or array of shapes
  //
  function openArcRoutes(paths, arcColl, routesArr, fwd, rev, dissolve, orBits) {
    forEachArcId(paths, function(arcId) {
      var isInv = arcId < 0,
          idx = isInv ? ~arcId : arcId,
          currBits = routesArr[idx],
          openFwd = isInv ? rev : fwd,
          openRev = isInv ? fwd : rev,
          newBits = currBits;

      // error condition: lollipop arcs can cause problems; ignore these
      if (arcColl.arcIsLollipop(arcId)) {
        debug('lollipop');
        newBits = 0; // unset (i.e. make invisible)
      } else {
        if (openFwd) {
          newBits |= 3; // set fwd path to visible and open
        }
        if (openRev) {
          newBits |= 0x30; // set rev. path to visible and open
        }

        // placing this in front of dissolve - dissolve has to be able to hide
        // pathways that are made visible by orBits
        if (orBits > 0) {
          newBits |= orBits;
        }

        // dissolve hides arcs that have both fw and rev pathways open
        // (these arcs represent shared borders and will not be part of the dissolved path)
        //
        if (dissolve && (newBits & 0x22) === 0x22) {
          newBits &= ~0x11; // make invisible
        }
      }

      routesArr[idx] = newBits;
    });
  }

  function closeArcRoutes(arcIds, arcs, routesArr, fwd, rev, hide) {
    forEachArcId(arcIds, function(arcId) {
      var isInv = arcId < 0,
          idx = isInv ? ~arcId : arcId,
          currBits = routesArr[idx],
          mask = 0xff,
          closeFwd = isInv ? rev : fwd,
          closeRev = isInv ? fwd : rev;

      if (closeFwd) {
        if (hide) mask &= ~1;
        mask ^= 0x2;
      }
      if (closeRev) {
        if (hide) mask &= ~0x10;
        mask ^= 0x20;
      }
      routesArr[idx] = currBits & mask;
    });
  }

  // Return a function for generating a path across a graph of connected arcs
  // useRoute: function(arcId) {}
  //           Tries to extend path to the given arc
  //           Returns true and extends path by one arc on success
  //           Returns false and rejects the entire path on failure
  // routeIsUsable (optional): function(arcId) {}
  //           An optional filter function; pathfinder ignores the given arc if
  //           this function returns false;
  // TODO: add option to use spherical geometry for lat-lng coords
  //
  function getPathFinder(nodes, useRoute, routeIsUsable) {
    var testArc = null;
    if (routeIsUsable) {
      testArc = function(arcId) {
        return routeIsUsable(~arcId); // outward path must be traversable
      };
    }

    function getNextArc(prevId) {
      // reverse arc to point onwards
      return ~getRightmostArc(prevId, nodes, testArc);
    }

    return function(startId) {
      var path = [],
          nextId, msg,
          candId = startId;

      do {
        if (useRoute(candId)) {
          path.push(candId);
          nextId = candId;
          candId = getNextArc(nextId);
        } else {
          return null;
        }

        if (candId == ~nextId) {
          // TODO: handle or prevent this error condition
          debug("Pathfinder warning: dead-end path");
          return null;
        }
      } while (candId != startId);
      return path.length === 0 ? null : path;
    };
  }

  // Returns a function for flattening or dissolving a collection of rings
  // Assumes rings are oriented in CW direction
  //
  function getRingIntersector(nodes, flagsArr) {
    var arcs = nodes.arcs;
    var findPath = getPathFinder(nodes, useRoute, routeIsActive);
    flagsArr = flagsArr || new Uint8Array(arcs.size());

    // types: "dissolve" "flatten"
    return function(rings, type) {
      var dissolve = type == 'dissolve',
          openFwd = true,
          openRev = type == 'flatten',
          output;
      // even single rings get transformed (e.g. to remove spikes)
      if (rings.length > 0) {
        output = [];
        openArcRoutes(rings, arcs, flagsArr, openFwd, openRev, dissolve);
        forEachShapePart(rings, function(ids) {
          var path;
          for (var i=0, n=ids.length; i<n; i++) {
            path = findPath(ids[i]);
            if (path) {
              output.push(path);
            }
          }
        });
        closeArcRoutes(rings, arcs, flagsArr, openFwd, openRev, true);
      } else {
        output = rings;
      }
      return output;
    };

    function routeIsActive(arcId) {
      var bits = getRouteBits(arcId, flagsArr);
      return (bits & 1) == 1;
    }

    function useRoute(arcId) {
      var route = getRouteBits(arcId, flagsArr),
          isOpen = false;
      if (route == 3) {
        isOpen = true;
        setRouteBits(1, arcId, flagsArr); // close the path, leave visible
      }
      return isOpen;
    }
  }

  // function debugFlags(flags) {
  //   var arr = [];
  //   utils.forEach(flags, function(flag) {
  //     arr.push(bitsToString(flag));
  //   });
  //   message(arr);

  //   function bitsToString(bits) {
  //     var str = "";
  //     for (var i=0; i<8; i++) {
  //       str += (bits & (1 << i)) > 0 ? "1" : "0";
  //       if (i < 7) str += ' ';
  //       if (i == 3) str += ' ';
  //     }
  //     return str;
  //   }
  // }

  var Pathfinder = /*#__PURE__*/Object.freeze({
    __proto__: null,
    setBits: setBits,
    andBits: andBits,
    setRouteBits: setRouteBits,
    getRouteBits: getRouteBits,
    openArcRoutes: openArcRoutes,
    closeArcRoutes: closeArcRoutes,
    getPathFinder: getPathFinder,
    getRingIntersector: getRingIntersector
  });

  function roundToSignificantDigits(n, d) {
    return +n.toPrecision(d);
  }

  function roundToDigits(n, d) {
    return +n.toFixed(d); // string conversion makes this slow
  }

  function roundToTenths(n) {
    return (Math.round(n * 10)) / 10;
  }

  // inc: Rounding increment (e.g. 0.001 rounds to thousandths)
  function getRoundingFunction(inc) {
    if (!utils.isNumber(inc) || inc === 0) {
      error("Rounding increment must be a non-zero number.");
    }
    var inv = 1 / inc;
    if (inv > 1) inv = Math.round(inv);
    return function(x) {
      return Math.round(x * inv) / inv;
      // these alternatives show rounding error after JSON.stringify()
      // return Math.round(x / inc) / inv;
      // return Math.round(x / inc) * inc;
      // return Math.round(x * inv) * inc;
    };
  }

  function getBoundsPrecisionForDisplay(bbox) {
    var w = bbox[2] - bbox[0],
        h = bbox[3] - bbox[1],
        range = Math.min(w, h) + 1e-8,
        digits = 0;
    while (range < 2000) {
      range *= 10;
      digits++;
    }
    return digits;
  }

  function getRoundedCoordString(coords, decimals) {
    return coords.map(function(n) {return n.toFixed(decimals);}).join(',');
  }

  function getRoundedCoords(coords, decimals) {
    return getRoundedCoordString(coords, decimals).split(',').map(parseFloat);
  }

  function roundPoints(lyr, round) {
    forEachPoint(lyr.shapes, function(p) {
      p[0] = round(p[0]);
      p[1] = round(p[1]);
    });
  }

  function setCoordinatePrecision(dataset, precision) {
    var round = getRoundingFunction(precision);
    // var dissolvePolygon, nodes;
    transformPoints(dataset, function(x, y) {
      return [round(x), round(y)];
    });
    // v0.4.52 removing polygon dissolve - see issue #219
    /*
    if (dataset.arcs) {
      nodes = internal.addIntersectionCuts(dataset);
      dissolvePolygon = internal.getPolygonDissolver(nodes);
    }
    dataset.layers.forEach(function(lyr) {
      if (lyr.geometry_type == 'polygon' && dissolvePolygon) {
        // clean each polygon -- use dissolve function to remove spikes
        // TODO: better handling of corrupted polygons
        lyr.shapes = lyr.shapes.map(dissolvePolygon);
      }
    });
    */
    return dataset;
  }

  var Rounding = /*#__PURE__*/Object.freeze({
    __proto__: null,
    roundToSignificantDigits: roundToSignificantDigits,
    roundToDigits: roundToDigits,
    roundToTenths: roundToTenths,
    getRoundingFunction: getRoundingFunction,
    getBoundsPrecisionForDisplay: getBoundsPrecisionForDisplay,
    getRoundedCoordString: getRoundedCoordString,
    getRoundedCoords: getRoundedCoords,
    roundPoints: roundPoints,
    setCoordinatePrecision: setCoordinatePrecision
  });

  var UNITS_LOOKUP = {
    m: 'meters',
    meter: 'meters',
    meters: 'meters',
    mi: 'miles',
    mile: 'miles',
    miles: 'miles',
    km: 'kilometers',
    ft: 'feet',
    feet: 'feet'
  };

  // From pj_units.js in mapshaper-proj
  var TO_METERS = {
    meters: 1,
    kilometers: 1000,
    feet: 0.3048, // International Standard Foot
    miles: 1609.344 // International Statute Mile
  };

  // Return coeff. for converting a distance measure to dataset coordinates
  // @paramUnits: units code of distance param, or null if units are not specified
  // @crs: Proj.4 CRS object, or null (unknown latlong CRS);
  //
  function getIntervalConversionFactor(paramUnits, crs) {
    var fromParam = 0,
        fromCRS = 0,
        k;

    if (crs) {
      if (crs.is_latlong) {
        // calculations on latlong coordinates typically use meters
        fromCRS = 1;
      } else if (crs.to_meter > 0) {
        fromCRS = crs.to_meter;
      } else {
        error('Invalid CRS');
      }
    }
    if (paramUnits) {
      fromParam = TO_METERS[paramUnits];
      if (!fromParam) error('Unknown units:', paramUnits);
    }

    if (fromParam && fromCRS) {
      // known param units, known CRS conversion
      k = fromParam / fromCRS;
    } else if (!fromParam && !fromCRS) {
      // unknown param units, unknown (projected) CRS -- no scaling
      k = 1;
    } else if (fromParam && !fromCRS) {
      // known param units, unknown CRS -- error condition, not convertible
      stop('Unable to convert', paramUnits, 'to unknown coordinates');
    } else if (!fromParam && fromCRS) {
      // unknown param units, known CRS -- assume param in meters (bw compatibility)
      k = 1 / fromCRS;
    }
    return k;
  }

  // throws an error if measure is non-parsable
  function parseMeasure(m) {
    var o = parseMeasure2(m);
    if (isNaN(o.value)) {
      stop('Invalid parameter:', m);
    }
    return o;
  }

  // returns NaN value if value is non-parsable
  function parseMeasure2(m) {
    var s = utils.isString(m) ? m : '';
    var match = /(sq|)([a-z]+)(2|)$/i.exec(s); // units rxp
    var o = {};
    if (utils.isNumber(m)) {
      o.value = m;
    } else if (s === '') {
      o.value = NaN;
    } else if (match) {
      o.units = UNITS_LOOKUP[match[2].toLowerCase()];
      o.areal = !!(match[1] || match[3]);
      o.value = Number(s.substring(0, s.length - match[0].length));
      if (!o.units && !isNaN(o.value)) {
        // throw error if string contains a number followed by unrecognized units string
        stop('Unknown units: ' + match[0]);
      }
    } else {
      o.value = Number(s);
    }
    return o;
  }

  function convertAreaParam(opt, crs) {
    var o = parseMeasure(opt);
    var k = getIntervalConversionFactor(o.units, crs);
    return o.value * k * k;
  }

  function convertDistanceParam(opt, crs) {
    var o = parseMeasure(opt);
    var k = getIntervalConversionFactor(o.units, crs);
    if (o.areal) {
      stop('Expected a distance, received an area:', opt);
    }
    return o.value * k;
  }

  // Same as convertDistanceParam(), except:
  //   in the case of latlong datasets, coordinates are unitless (instead of meters),
  //   and parameters with units trigger an error
  function convertIntervalParam(opt, crs) {
    var o = parseMeasure(opt);
    var k = getIntervalConversionFactor(o.units, crs);
    if (o.units && crs && crs.is_latlong) {
      stop('Parameter does not support distance units with latlong datasets');
    }
    if (o.areal) {
      stop('Expected a distance, received an area:', opt);
    }
    return o.value * k;
  }

  function convertIntervalPair(opt, crs) {
    var a, b;
    if (!Array.isArray(opt) || opt.length != 2) {
      stop('Expected two distance parameters, received', opt);
    }
    a = parseMeasure(opt[0]);
    b = parseMeasure(opt[1]);
    if (a.units && !b.units || b.units && !a.units) {
      stop('Both parameters should have units:', opt);
    }
    return [convertIntervalParam(opt[0], crs),
            convertIntervalParam(opt[1], crs)];
  }

  // Accepts a single value or a list of four values. List order is l,b,t,r
  function convertFourSides(opt, crs, bounds) {
    var arr = opt.split(',');
    if (arr.length == 1) {
      arr = [arr[0], arr[0], arr[0], arr[0]];
    } else if (arr.length != 4) {
      stop("Expected a distance parameter or a list of four params");
    }
    return arr.map(function(param, i) {
      var tmp;
      if (param.indexOf('%') > 0) {
        tmp = parseFloat(param) / 100 || 0;
        return tmp * (i == 1 || i == 3 ? bounds.height() : bounds.width());
      }
      return convertIntervalParam(opt, crs);
    });
  }

  // Convert an area measure to a label in sqkm or sqm
  function getAreaLabel(area, crs) {
    var sqm = crs && crs.to_meter ? area * crs.to_meter * crs.to_meter : area;
    var sqkm = sqm / 1e6;
    return sqkm < 0.01 ? Math.round(sqm) + ' sqm' : sqkm + ' sqkm';
  }

  var Units = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getIntervalConversionFactor: getIntervalConversionFactor,
    parseMeasure: parseMeasure,
    parseMeasure2: parseMeasure2,
    convertAreaParam: convertAreaParam,
    convertDistanceParam: convertDistanceParam,
    convertIntervalParam: convertIntervalParam,
    convertIntervalPair: convertIntervalPair,
    convertFourSides: convertFourSides,
    getAreaLabel: getAreaLabel
  });

  // Used by -clean -dissolve2 -filter-slivers -filter-islands to generate area filters
  // for removing small polygon rings.
  // Assumes lyr is a polygon layer.
  function getSliverFilter(lyr, dataset, opts) {
    var areaArg = opts.min_gap_area || opts.min_area || opts.gap_fill_area;
    if (+areaArg == 0) {
      return {
        filter: function() {return false;}, // don't fill any gaps
        threshold: 0
      };
    }
    var sliverControl = opts.sliver_control >= 0 ? opts.sliver_control : 0; // 0 is default
    var crs = getDatasetCRS(dataset);
    var threshold = areaArg ?
        convertAreaParam(areaArg, crs) :
        getDefaultSliverThreshold(lyr, dataset.arcs);
    var filter = sliverControl > 0 ?
        getSliverTest(dataset.arcs, threshold, sliverControl) :
        getMinAreaTest(threshold, dataset);
    var label = getSliverLabel(getAreaLabel(threshold, crs), sliverControl > 0);
    return {
      threshold: threshold,
      filter: filter,
      label: label
    };
  }

  function getSliverLabel(areaStr, variable) {
    if (variable) {
      areaStr = areaStr.replace(' ', '+ ') + ' variable';
    }
    return areaStr + ' threshold';
  }

  function getMinAreaTest(minArea, dataset) {
    var pathArea = dataset.arcs.isPlanar() ? geom.getPlanarPathArea : geom.getSphericalPathArea;
    return function(path) {
      var area = pathArea(path, dataset.arcs);
      return Math.abs(area) < minArea;
    };
  }

  function getSliverTest(arcs, threshold, strength) {
    if (strength >= 0 === false) {
      strength = 1; // default is 1 (full-strength)
    }
    if (strength > 1 || threshold >= 0 === false) {
      error('Invalid parameter');
    }
    var calcEffectiveArea = getSliverAreaFunction(arcs, strength);
    return function(ring) {
      return Math.abs(calcEffectiveArea(ring)) < threshold;
    };
  }

  // Strength: 0-1
  function getSliverAreaFunction(arcs, strength) {
    var k = Math.sqrt(strength); // more sensible than linear weighted avg.
    return function(ring) {
      var area = geom.getPathArea(ring, arcs);
      var perim = geom.getPathPerimeter(ring, arcs);
      var compactness = geom.calcPolsbyPopperCompactness(area, perim);
      var effectiveArea = area * (k * compactness + 1 - k);
      return effectiveArea;
    };
  }

  // Calculate a default area threshold using average segment length,
  // but increase the threshold for high-detail datasets and decrease it for
  // low-detail datasets (using segments per ring as a measure of detail).
  //
  function getDefaultSliverThreshold(lyr, arcs) {
    var ringCount = 0;
    var calcLen = arcs.isPlanar() ? geom.distance2D : geom.greatCircleDistance;
    var avgSegLen = 0;
    var segCount = 0;
    var onSeg = function(i, j, xx, yy) {
      var len = calcLen(xx[i], yy[i], xx[j], yy[j]);
      segCount++;
      avgSegLen += (len - avgSegLen) / segCount;
    };
    editShapes(lyr.shapes, function(path) {
      ringCount++;
      forEachSegmentInPath(path, arcs, onSeg);
    });
    var segPerRing = segCount / ringCount || 0;
    var complexityFactor = Math.pow(segPerRing, 0.75); // use seg/ring as a proxy for complexity
    var threshold = avgSegLen * avgSegLen / 50 * complexityFactor;
    threshold = roundToSignificantDigits(threshold, 2); // round for display
    return threshold;
  }


  // Original function for calculating default area threshold
  function calcMaxSliverArea(arcs) {
    var k = 2,
        dxMax = arcs.getBounds().width() / k,
        dyMax = arcs.getBounds().height() / k,
        count = 0,
        mean = 0;
    arcs.forEachSegment(function(i, j, xx, yy) {
      var dx = Math.abs(xx[i] - xx[j]),
          dy = Math.abs(yy[i] - yy[j]);
      if (dx < dxMax && dy < dyMax) {
        // TODO: write utility function for calculating mean this way
        mean += (Math.sqrt(dx * dx + dy * dy) - mean) / ++count;
      }
    });
    return mean * mean;
  }

  var Slivers = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getSliverFilter: getSliverFilter,
    getSliverTest: getSliverTest,
    getSliverAreaFunction: getSliverAreaFunction,
    getDefaultSliverThreshold: getDefaultSliverThreshold,
    calcMaxSliverArea: calcMaxSliverArea
  });

  // Returns undefined if not found
  function lookupColorName(str) {
    return colors[str.toLowerCase().replace(/[ -]+/g, '')];
  }

  var colors = {
    aliceblue: '#f0f8ff',
    antiquewhite: '#faebd7',
    aqua: '#00ffff',
    aquamarine: '#7fffd4',
    azure: '#f0ffff',
    beige: '#f5f5dc',
    bisque: '#ffe4c4',
    black: '#000000',
    blanchedalmond: '#ffebcd',
    blue: '#0000ff',
    blueviolet: '#8a2be2',
    brown: '#a52a2a',
    burlywood: '#deb887',
    cadetblue: '#5f9ea0',
    chartreuse: '#7fff00',
    chocolate: '#d2691e',
    coral: '#ff7f50',
    cornflowerblue: '#6495ed',
    cornsilk: '#fff8dc',
    crimson: '#dc143c',
    cyan: '#00ffff',
    darkblue: '#00008b',
    darkcyan: '#008b8b',
    darkgoldenrod: '#b8860b',
    darkgray: '#a9a9a9',
    darkgreen: '#006400',
    darkgrey: '#a9a9a9',
    darkkhaki: '#bdb76b',
    darkmagenta: '#8b008b',
    darkolivegreen: '#556b2f',
    darkorange: '#ff8c00',
    darkorchid: '#9932cc',
    darkred: '#8b0000',
    darksalmon: '#e9967a',
    darkseagreen: '#8fbc8f',
    darkslateblue: '#483d8b',
    darkslategray: '#2f4f4f',
    darkslategrey: '#2f4f4f',
    darkturquoise: '#00ced1',
    darkviolet: '#9400d3',
    deeppink: '#ff1493',
    deepskyblue: '#00bfff',
    dimgray: '#696969',
    dimgrey: '#696969',
    dodgerblue: '#1e90ff',
    firebrick: '#b22222',
    floralwhite: '#fffaf0',
    forestgreen: '#228b22',
    fuchsia: '#ff00ff',
    gainsboro: '#dcdcdc',
    ghostwhite: '#f8f8ff',
    gold: '#ffd700',
    goldenrod: '#daa520',
    gray: '#808080',
    green: '#008000',
    greenyellow: '#adff2f',
    grey: '#808080',
    honeydew: '#f0fff0',
    hotpink: '#ff69b4',
    indianred: '#cd5c5c',
    indigo: '#4b0082',
    ivory: '#fffff0',
    khaki: '#f0e68c',
    lavender: '#e6e6fa',
    lavenderblush: '#fff0f5',
    lawngreen: '#7cfc00',
    lemonchiffon: '#fffacd',
    lightblue: '#add8e6',
    lightcoral: '#f08080',
    lightcyan: '#e0ffff',
    lightgoldenrodyellow: '#fafad2',
    lightgray: '#d3d3d3',
    lightgreen: '#90ee90',
    lightgrey: '#d3d3d3',
    lightpink: '#ffb6c1',
    lightsalmon: '#ffa07a',
    lightseagreen: '#20b2aa',
    lightskyblue: '#87cefa',
    lightslategray: '#778899',
    lightslategrey: '#778899',
    lightsteelblue: '#b0c4de',
    lightyellow: '#ffffe0',
    lime: '#00ff00',
    limegreen: '#32cd32',
    linen: '#faf0e6',
    magenta: '#ff00ff',
    maroon: '#800000',
    mediumaquamarine: '#66cdaa',
    mediumblue: '#0000cd',
    mediumorchid: '#ba55d3',
    mediumpurple: '#9370db',
    mediumseagreen: '#3cb371',
    mediumslateblue: '#7b68ee',
    mediumspringgreen: '#00fa9a',
    mediumturquoise: '#48d1cc',
    mediumvioletred: '#c71585',
    midnightblue: '#191970',
    mintcream: '#f5fffa',
    mistyrose: '#ffe4e1',
    moccasin: '#ffe4b5',
    navajowhite: '#ffdead',
    navy: '#000080',
    oldlace: '#fdf5e6',
    olive: '#808000',
    olivedrab: '#6b8e23',
    orange: '#ffa500',
    orangered: '#ff4500',
    orchid: '#da70d6',
    palegoldenrod: '#eee8aa',
    palegreen: '#98fb98',
    paleturquoise: '#afeeee',
    palevioletred: '#db7093',
    papayawhip: '#ffefd5',
    peachpuff: '#ffdab9',
    peru: '#cd853f',
    pink: '#ffc0cb',
    plum: '#dda0dd',
    powderblue: '#b0e0e6',
    purple: '#800080',
    rebeccapurple: '#663399',
    red: '#ff0000',
    rosybrown: '#bc8f8f',
    royalblue: '#4169e1',
    saddlebrown: '#8b4513',
    salmon: '#fa8072',
    sandybrown: '#f4a460',
    seagreen: '#2e8b57',
    seashell: '#fff5ee',
    sienna: '#a0522d',
    silver: '#c0c0c0',
    skyblue: '#87ceeb',
    slateblue: '#6a5acd',
    slategray: '#708090',
    slategrey: '#708090',
    snow: '#fffafa',
    springgreen: '#00ff7f',
    steelblue: '#4682b4',
    tan: '#d2b48c',
    teal: '#008080',
    thistle: '#d8bfd8',
    tomato: '#ff6347',
    turquoise: '#40e0d0',
    violet: '#ee82ee',
    wheat: '#f5deb3',
    white: '#ffffff',
    whitesmoke: '#f5f5f5',
    yellow: '#ffff00',
    yellowgreen: '#9acd32'
  };

  var rgbaRxp = /^rgba?\(([^)]+)\)/;
  var hexRxp = /^#([a-f0-9]{3,8})/i;

  function parseColor(arg) {
    arg = arg ? String(arg) : '';
    var hexStr = hexRxp.test(arg) ? arg : lookupColorName(arg);
    var rgb = null;
    if (hexStr) rgb = parseHexColor(hexStr);
    else if (rgbaRxp.test(arg)) rgb = parseRGBA(arg);
    if (!testRGB(rgb)) stop("Unsupported color:", arg);
    return rgb;
  }

  function testRGB(o) {
    return !!o && testChannel(o.r) && testChannel(o.g) && testChannel(o.b) &&
      testAlpha(o.a);
  }

  function testAlpha(a) {
    return a >= 0 && a <= 1;
  }

  function testChannel(c) {
    return c >= 0 && c < 256; // allow fractional values
  }

  function parseRGBA(arg) {
    var str = rgbaRxp.exec(arg)[1];
    var parts = str.split(',').map(function(part) { return parseFloat(part); });
    return {
      r: parts[0],
      g: parts[1],
      b: parts[2],
      a: parts[3] >= 0 ? parts[3] : 1
    };
  }

  function formatColor(o) {
    return o.a < 1 ? formatRGBA(o) : formatHexColor(o);
  }

  function formatHexColor(o) {
    return "#" + formatHexChannel(o.r) + formatHexChannel(o.g) + formatHexChannel(o.b);

  }

  function formatRGBA(o) {
    var rgb = snapHexChannel(o.r) + ',' + snapHexChannel(o.g) + ',' + snapHexChannel(o.b);
    return o.a < 1 ?
      'rgba(' + rgb + ',' + snapAlpha(o.a) + ')' :
      'rgb(' + rgb + ')';
  }

  function snapAlpha(a) {
    a = +a || 0;
    a = Math.round(a * 1000) / 1000; // round to thousandths
    return utils.clamp(a, 0, 1);
  }

  function snapHexChannel(arg) {
    return Math.round(utils.clamp(+arg || 0, 0, 255));
  }

  // arg: should be number in 0-255 range
  function formatHexChannel(arg) {
    return snapHexChannel(arg).toString(16).padStart(2, '0');
  }

  // returns {r, g, b} object
  function parseHexColor(str) {
    var hex = hexRxp.exec(str)[1];
    if (hex.length == 3 || hex.length == 4) {
      hex = hex.split('').map(function(c) { return c + c; });
    }
    if (hex.length != 6 && hex.length != 8) return null;
    return {
      r: parseInt(hex.substr(0, 2), 16),
      g: parseInt(hex.substr(2, 2), 16),
      b: parseInt(hex.substr(4, 2), 16),
      a: hex.length == 8 ? parseInt(hex.substr(7, 2), 16) / 255 : 1
    };
  }

  function toHSV(rgb) {
    var r = rgb.r,
        g = rgb.g,
        b = rgb.b,
        max = Math.max(r, g, b),
        min = Math.min(r, g, b),
        diff = max - min,
        h;
    if (diff === 0) {
      h = 0;
    } else if (r == max) {
      h = (g - b) / diff;
    } else if (g == max) {
      h = (b - r) / diff + 2;
    } else {
      h = (r - g) / diff + 4;
    }
    h *= 60;
    if (h < 0) h += 360;
    return {
      h: h,
      s: max == 0 ? 0 : 255 * (1 - min / max),
      v: max,
      a: rgb.a
    };
  }

  function fromHSV(hsv) {
    var h = hsv.h,
        s = hsv.s / 255,
        v = hsv.v,
        hi = Math.floor(h / 60) % 6,
        f = h / 60 - Math.floor(h / 60),
        p = (v * (1 - s)),
        q = (v * (1 - f * s)),
        t = (v * (1 - (1 - f) * s)),
        r, g, b;
    if (hi === 0) {
      r = v; g = t; b = p;
    } else if (hi == 1) {
      r = q; g = v; b = p;
    } else if (hi == 2) {
      r = p; g = v; b = t;
    } else if (hi == 3) {
      r = p; g = q; b = v;
    } else if (hi == 4) {
      r = t; g = p; b = v;
    } else {
      r = v; g = p; b = q;
    }
    return {
      r: r,
      g: g,
      b: b,
      a: hsv.a
    };
  }

  function blend(a, b) {
    var colors, weights, args;
    if (Array.isArray(a)) {
      colors = a;
      weights = b;
    } else {
      colors = [];
      weights = [];
      args = Array.from(arguments);
      for (var i=0; i<args.length; i+= 2) {
        colors.push(args[i]);
        weights.push(args[i + 1]);
      }
    }
    weights = normalizeWeights(weights);
    if (!weights) return '#eee';
    var blended = colors.reduce(function(memo, col, i) {
      var rgb = parseColor(col);
      var w = +weights[i] || 0;
      memo.r += rgb.r * w;
      memo.g += rgb.g * w;
      memo.b += rgb.b * w;
      return memo;
    }, {r: 0, g: 0, b: 0});
    return formatColor(blended);
  }


  function normalizeWeights(weights) {
    var sum = utils.sum(weights);
    if (sum > 0 === false) {
      return null;
    }
    return weights.map(function(w) {
      return w / sum;
    });
  }

  function addUtils(env) {
    Object.assign(env, {
      round: function(val, dig) {
        var k = 1;
        if (!val && val !== 0) return val; // don't coerce null to 0
        dig = dig | 0;
        while(dig-- > 0) k *= 10;
        return Math.round(val * k) / k;
      },
      int_median: interpolated_median,
      sprintf: utils.format,
      blend: blend
    });
  }

  // piecewise linear interpolation (for a special project)
  function interpolated_median(counts, breaks) {
    if (!counts || !breaks || counts.length != breaks.length - 1) return null;
    var total = utils.sum(counts);
    var medianIdx = Math.floor(total / 2);
    var lowerCount = 0, upperCount, lowerValue, upperValue, t;
    for (var i=1; i<breaks.length; i++) {
      lowerValue = breaks[i-1];
      upperValue = breaks[i];
      upperCount = lowerCount + counts[i-1];
      if (medianIdx <= upperCount) {
        t = (medianIdx - lowerCount) / (upperCount - lowerCount);
        return lowerValue + t * (upperValue - lowerValue);
      }
      lowerCount = upperCount;
    }
    return null;
  }

  function addGetters(obj, getters) {
    Object.keys(getters).forEach(function(name) {
      var val = getters[name];
      var o = typeof val == 'function' ?
        {get: val} :
        {value: val, writable: false};
      Object.defineProperty(obj, name, o);
    });
  }

  function simplifyArcsFast(arcs, dist) {
    var xx = [],
        yy = [],
        nn = [],
        count;
    for (var i=0, n=arcs.size(); i<n; i++) {
      count = simplifyPathFast([i], arcs, dist, xx, yy);
      if (count == 1) {
        count = 0;
        xx.pop();
        yy.pop();
      }
      nn.push(count);
    }
    return new ArcCollection(nn, xx, yy);
  }

  function simplifyPolygonFast(shp, arcs, dist) {
    if (!shp || !dist) return null;
    var xx = [],
        yy = [],
        nn = [],
        shp2 = [];

    shp.forEach(function(path) {
      var count = simplifyPathFast(path, arcs, dist, xx, yy);
      while (count < 4 && count > 0) {
        xx.pop();
        yy.pop();
        count--;
      }
      if (count > 0) {
        shp2.push([nn.length]);
        nn.push(count);
      }
    });
    return {
      shape: shp2.length > 0 ? shp2 : null,
      arcs: new ArcCollection(nn, xx, yy)
    };
  }

  function simplifyPathFast(path, arcs, dist, xx, yy) {
    var iter = arcs.getShapeIter(path),
        count = 0,
        prevX, prevY, x, y;
    while (iter.hasNext()) {
      x = iter.x;
      y = iter.y;
      if (count === 0 || geom.distance2D(x, y, prevX, prevY) > dist) {
        xx.push(x);
        yy.push(y);
        prevX = x;
        prevY = y;
        count++;
      }
    }
    if (x != prevX || y != prevY) {
      xx.push(x);
      yy.push(y);
      count++;
    }
    return count;
  }

  var SimplifyFast = /*#__PURE__*/Object.freeze({
    __proto__: null,
    simplifyArcsFast: simplifyArcsFast,
    simplifyPolygonFast: simplifyPolygonFast
  });

  // Find a point inside a polygon and located away from the polygon edge
  // Method:
  // - get the largest ring of the polygon
  // - get an array of x-values distributed along the horizontal extent of the ring
  // - for each x:
  //     intersect a vertical line with the polygon at x
  //     find midpoints of each intersecting segment
  // - for each midpoint:
  //     adjust point vertically to maximize weighted distance from polygon edge
  // - return the adjusted point having the maximum weighted distance from the edge
  //
  // (distance is weighted to slightly favor points near centroid)
  //
  function findAnchorPoint(shp, arcs) {
    var maxPath = shp && geom.getMaxPath(shp, arcs),
        pathBounds = maxPath && arcs.getSimpleShapeBounds(maxPath),
        thresh, simple;
    if (!pathBounds || !pathBounds.hasBounds() || pathBounds.area() === 0) {
      return null;
    }
    // Optimization: quickly simplify using a relatively small distance threshold.
    // (testing multiple candidate points can be very slow for large and detailed
    //   polgons; simplification alleviates this)
    // Caveat: In rare cases this could cause poor point placement, e.g. if
    //   simplification causes small holes to be removed.
    thresh = Math.sqrt(pathBounds.area()) * 0.01;
    simple = simplifyPolygonFast(shp, arcs, thresh);
    if (!simple.shape) {
      return null; // collapsed shape
    }
    return findAnchorPoint2(simple.shape, simple.arcs);
  }

  // Assumes: shp is a polygon with at least one space-enclosing ring
  function findAnchorPoint2(shp, arcs) {
    var maxPath = geom.getMaxPath(shp, arcs);
    var pathBounds = arcs.getSimpleShapeBounds(maxPath);
    var centroid = geom.getPathCentroid(maxPath, arcs);
    var weight = getPointWeightingFunction(centroid, pathBounds);
    var area = geom.getPlanarPathArea(maxPath, arcs);
    var hrange, lbound, rbound, focus, htics, hstep, p, p2;

    // Limit test area if shape is simple and squarish
    if (shp.length == 1 && area * 1.2 > pathBounds.area()) {
      htics = 5;
      focus = 0.2;
    } else if (shp.length == 1 && area * 1.7 > pathBounds.area()) {
      htics = 7;
      focus = 0.4;
    } else {
      htics = 11;
      focus = 0.5;
    }
    hrange = pathBounds.width() * focus;
    lbound = centroid.x - hrange / 2;
    rbound = lbound + hrange;
    hstep = hrange / htics;

    // Find a best-fit point
    p = probeForBestAnchorPoint(shp, arcs, lbound, rbound, htics, weight);
    if (!p) {
      verbose("[points inner] failed, falling back to centroid");
     p = centroid;
    } else {
      // Look for even better fit close to best-fit point
      p2 = probeForBestAnchorPoint(shp, arcs, p.x - hstep / 2,
          p.x + hstep / 2, 2, weight);
      if (p2.distance > p.distance) {
        p = p2;
      }
    }
    return p;
  }

  function getPointWeightingFunction(centroid, pathBounds) {
    // Get a factor for weighting a candidate point
    // Points closer to the centroid are slightly preferred
    var referenceDist = Math.max(pathBounds.width(), pathBounds.height()) / 2;
    return function(x, y) {
      var offset = geom.distance2D(centroid.x, centroid.y, x, y);
      return 1 - Math.min(0.6 * offset / referenceDist, 0.25);
    };
  }

  function findAnchorPointCandidates(shp, arcs, xx) {
    var ymin = arcs.getBounds().ymin - 1;
    return xx.reduce(function(memo, x) {
      var cands = findHitCandidates(x, ymin, shp, arcs);
      return memo.concat(cands);
    }, []);
  }

  function probeForBestAnchorPoint(shp, arcs, lbound, rbound, htics, weight) {
    var tics = getInnerTics(lbound, rbound, htics);
    var interval = (rbound - lbound) / htics;
    // Get candidate points, distributed along x-axis
    var candidates = findAnchorPointCandidates(shp, arcs, tics);
    var bestP, adjustedP, candP;

    // Sort candidates so points at the center of longer segments are tried first
    candidates.forEach(function(p) {
      p.interval *= weight(p.x, p.y);
    });
    candidates.sort(function(a, b) {
      return b.interval - a.interval;
    });

    for (var i=0; i<candidates.length; i++) {
      candP = candidates[i];
      // Optimization: Stop searching if weighted half-segment length of remaining
      //   points is less than the weighted edge distance of the best candidate
      if (bestP && bestP.distance > candP.interval) {
        break;
      }
      adjustedP = getAdjustedPoint(candP.x, candP.y, shp, arcs, interval, weight);

      if (!bestP || adjustedP.distance > bestP.distance) {
        bestP = adjustedP;
      }
    }
    return bestP;
  }

  // [x, y] is a point assumed to be inside a polygon @shp
  // Try to move the point farther from the polygon edge
  function getAdjustedPoint(x, y, shp, arcs, vstep, weight) {
    var p = {
      x: x,
      y: y,
      distance: geom.getPointToShapeDistance(x, y, shp, arcs) * weight(x, y)
    };
    scanForBetterPoint(p, shp, arcs, vstep, weight); // scan up
    scanForBetterPoint(p, shp, arcs, -vstep, weight); // scan down
    return p;
  }

  // Try to find a better-fit point than @p by scanning vertically
  // Modify p in-place
  function scanForBetterPoint(p, shp, arcs, vstep, weight) {
    var x = p.x,
        y = p.y,
        dmax = p.distance,
        d;

    while (true) {
      y += vstep;
      d = geom.getPointToShapeDistance(x, y, shp, arcs) * weight(x, y);
      // overcome vary small local minima
      if (d > dmax * 0.90 && geom.testPointInPolygon(x, y, shp, arcs)) {
        if (d > dmax) {
          p.distance = dmax = d;
          p.y = y;
        }
      } else {
        break;
      }
    }
  }

  // Return array of points at the midpoint of each line segment formed by the
  //   intersection of a vertical ray at [x, y] and a polygon shape
  function findHitCandidates(x, y, shp, arcs) {
    var yy = findRayShapeIntersections(x, y, shp, arcs);
    var cands = [], y1, y2, interval;

    // sorting by y-coord organizes y-intercepts into interior segments
    utils.genericSort(yy);
    for (var i=0; i<yy.length; i+=2) {
      y1 = yy[i];
      y2 = yy[i+1];
      interval = (y2 - y1) / 2;
      if (interval > 0) {
        cands.push({
          y: (y1 + y2) / 2,
          x: x,
          interval: interval
        });
      }
    }
    return cands;
  }

  // Return array of y-intersections between vertical ray with origin at [x, y]
  //   and a polygon
  function findRayShapeIntersections(x, y, shp, arcs) {
    if (!shp) return [];
    return shp.reduce(function(memo, path) {
      var yy = findRayRingIntersections(x, y, path, arcs);
      return memo.concat(yy);
    }, []);
  }

  // Return array of y-intersections between vertical ray and a polygon ring
  function findRayRingIntersections(x, y, path, arcs) {
    var yints = [];
    forEachSegmentInPath(path, arcs, function(a, b, xx, yy) {
      var result = geom.getRayIntersection(x, y, xx[a], yy[a], xx[b], yy[b]);
      if (result > -Infinity) {
        yints.push(result);
      }
    });
    // Ignore odd number of intersections -- probably caused by a ray that touches
    //   but doesn't cross the ring
    // TODO: improve method to handle edge case with two touches and no crosses.
    if (yints.length % 2 === 1) {
      yints = [];
    }
    return yints;
  }

  // TODO: find better home + name for this
  function getInnerTics(min, max, steps) {
    var range = max - min,
        step = range / (steps + 1),
        arr = [];
    for (var i = 1; i<=steps; i++) {
      arr.push(min + step * i);
    }
    return arr;
  }

  var AnchorPoints = /*#__PURE__*/Object.freeze({
    __proto__: null,
    findAnchorPoint: findAnchorPoint
  });

  // Returns a function for calculating the percentage of a shape's perimeter by length that
  // is composed of inner (shared) boundaries
  function getInnerPctCalcFunction(arcs, shapes) {
    var calcSegLen = arcs.isPlanar() ? geom.distance2D : geom.greatCircleDistance;
    var arcIndex = new ArcTopologyIndex(arcs, shapes);
    var outerLen, innerLen, arcLen; // temp variables

    return function(shp) {
      outerLen = 0;
      innerLen = 0;
      if (shp) shp.forEach(procRing);
      return innerLen > 0 ? innerLen / (innerLen + outerLen) : 0;
    };

    function procRing(ids) {
      ids.forEach(procArc);
    }

    function procArc(id) {
      arcLen = 0;
      arcs.forEachArcSegment(id, addSegLen);
      if (arcIndex.isInnerArc(id)) {
        innerLen += arcLen;
      } else {
        outerLen += arcLen;
      }
    }

    function addSegLen(i, j, xx, yy) {
      arcLen += calcSegLen(xx[i], yy[i], xx[j], yy[j]);
    }
  }

  function ArcTopologyIndex(arcs, shapes) {
    var index = new Uint8Array(arcs.size());
    forEachArcId(shapes, function(arcId) {
      if (arcId < 0) index[~arcId] |= 2;
      else (index[arcId] |= 1);
    });

    this.isInnerArc = function(arcId) {
      var i = absArcId(arcId);
      return index[i] == 3;
    };
  }

  function addBBoxGetter(obj, lyr, arcs) {
    var bbox;
    addGetters(obj, {
      bbox: function() {
        if (!bbox) {
          bbox = getBBox$1(lyr, arcs);
        }
        return bbox;
      }
    });
  }

  function getBBox$1(lyr, arcs) {
    var bounds = getLayerBounds(lyr, arcs); // TODO: avoid this overhead if bounds is not used
    if (!bounds) return null;
    var bbox = bounds.toArray();
    Object.assign(bbox, {
      cx: bounds.centerX(),
      cy: bounds.centerY(),
      height: bounds.height(),
      width: bounds.width(),
      left: bounds.xmin,
      bottom: bounds.ymin,
      top: bounds.ymax,
      right: bounds.xmax
    });
    return bbox;
  }

  // Returns an object representing a layer in a JS expression
  function getLayerProxy(lyr, arcs) {
    var obj = {};
    var records = lyr.data ? lyr.data.getRecords() : null;
    var getters = {
      name: lyr.name,
      data: records
    };
    addGetters(obj, getters);
    addBBoxGetter(obj, lyr, arcs);
    return obj;
  }

  function addLayerGetters(ctx, lyr, arcs) {
    var layerProxy;
    addGetters(ctx, {
      layer_name: lyr.name || '', // consider removing this
      layer: function() {
        // init on first access (to avoid overhead if not used)
        if (!layerProxy) layerProxy = getLayerProxy(lyr, arcs);
        return layerProxy;
      }
    });
    return ctx;
  }

  // Returns a function to return a feature proxy by id
  // (the proxy appears as "this" or "$" in a feature expression)
  function initFeatureProxy(lyr, arcs, optsArg) {
    var opts = optsArg || {},
        hasPoints = layerHasPoints(lyr),
        hasPaths = arcs && layerHasPaths(lyr),
        _records = lyr.data ? lyr.data.getRecords() : null,
        _isPlanar = hasPaths && arcs.isPlanar(),
        ctx = {},
        calcInnerPct,
        _bounds, _centroid, _innerXY, _xy, _ids, _id;

    // all contexts have this.id and this.layer
    addGetters(ctx, {
      id: function() { return _id; }
    });
    addLayerGetters(ctx, lyr, arcs);

    if (opts.geojson_editor) {
      Object.defineProperty(ctx, 'geojson', {
        set: function(o) {
          opts.geojson_editor.set(o, _id);
        },
        get: function() {
          return opts.geojson_editor.get(_id);
        }
      });
    }

    if (_records) {
      // add r/w member "properties"
      Object.defineProperty(ctx, 'properties',
        {set: function(obj) {
          if (utils.isObject(obj)) {
            _records[_id] = obj;
          } else {
            stop("Can't assign non-object to $.properties");
          }
        }, get: function() {
          var rec = _records[_id];
          if (!rec) {
            rec = _records[_id] = {};
          }
          return rec;
        }});
    }

    if (hasPaths) {
      addGetters(ctx, {
        // TODO: count hole/s + containing ring as one part
        partCount: function() {
          return _ids ? _ids.length : 0;
        },
        isNull: function() {
          return ctx.partCount === 0;
        },
        bounds: function() {
          return shapeBounds().toArray();
        },
        height: function() {
          return shapeBounds().height();
        },
        width: function() {
          return shapeBounds().width();
        }
      });

      if (lyr.geometry_type == 'polyline') {
        addGetters(ctx, {
          'length': function() {
            return geom.getShapePerimeter(_ids, arcs);
          }
        });
      }

      if (lyr.geometry_type == 'polygon') {
        addGetters(ctx, {
          area: function() {
            return _isPlanar ? ctx.planarArea : geom.getSphericalShapeArea(_ids, arcs);
          },
          // area2: function() {
          //   return _isPlanar ? ctx.planarArea : geom.getSphericalShapeArea(_ids, arcs, WGS84.SEMIMINOR_RADIUS);
          // },
          // area3: function() {
          //   return _isPlanar ? ctx.planarArea : geom.getSphericalShapeArea(_ids, arcs, WGS84.AUTHALIC_RADIUS);
          // },
          perimeter: function() {
            return geom.getShapePerimeter(_ids, arcs);
          },
          compactness: function() {
            return geom.calcPolsbyPopperCompactness(ctx.area, ctx.perimeter);
          },
          planarArea: function() {
            return geom.getPlanarShapeArea(_ids, arcs);
          },
          innerPct: function() {
            if (!calcInnerPct) calcInnerPct = getInnerPctCalcFunction(arcs, lyr.shapes);
            return calcInnerPct(_ids);
          },
          originalArea: function() {
            // Get area
            var i = arcs.getRetainedInterval(),
                area;
            arcs.setRetainedInterval(0);
            area = ctx.area;
            arcs.setRetainedInterval(i);
            return area;
          },
          centroidX: function() {
            var p = centroid();
            return p ? p.x : null;
          },
          centroidY: function() {
            var p = centroid();
            return p ? p.y : null;
          },
          innerX: function() {
            var p = innerXY();
            return p ? p.x : null;
          },
          innerY: function() {
            var p = innerXY();
            return p ? p.y : null;
          }
        });
      }

    } else if (hasPoints) {
      // TODO: add functions like bounds, isNull, pointCount
      Object.defineProperty(ctx, 'coordinates',
        {set: function(obj) {
          if (!obj || utils.isArray(obj)) {
            lyr.shapes[_id] = obj || null;
          } else {
            stop("Can't assign non-array to $.coordinates");
          }
        }, get: function() {
          return lyr.shapes[_id] || null;
        }});
      Object.defineProperty(ctx, 'x', {
        get: function() { xy(); return _xy ? _xy[0] : null;},
        set: function(val) { xy(); if (_xy) _xy[0] = Number(val);}
      });
      Object.defineProperty(ctx, 'y', {
        get: function() { xy(); return _xy ? _xy[1] : null;},
        set: function(val) { xy(); if (_xy) _xy[1] = Number(val);}
      });
    }

    function xy() {
      var shape = lyr.shapes[_id];
      if (!_xy) {
        _xy = shape && shape[0] || null;
      }
    }

    function centroid() {
      _centroid = _centroid || geom.getShapeCentroid(_ids, arcs);
      return _centroid;
    }

    function innerXY() {
      _innerXY = _innerXY || findAnchorPoint(_ids, arcs);
      return _innerXY;
    }

    function shapeBounds() {
      if (!_bounds) {
        _bounds = arcs.getMultiShapeBounds(_ids);
      }
      return _bounds;
    }

    return function(id) {
      _id = id;
      // reset stored values
      if (hasPaths) {
        _bounds = null;
        _centroid = null;
        _innerXY = null;
        _ids = lyr.shapes[id];
      }
      if (hasPoints) {
        _xy = null;
      }
      return ctx;
    };
  }

  // Compiled expression returns a value
  function compileValueExpression(exp, lyr, arcs, opts) {
    opts = opts || {};
    opts.returns = true;
    return compileFeatureExpression(exp, lyr, arcs, opts);
  }

  function cleanExpression(exp) {
    // workaround for problem in GNU Make v4: end-of-line backslashes inside
    // quoted strings are left in the string (other shell environments remove them)
    return exp.replace(/\\\n/g, ' ');
  }

  function compileFeaturePairFilterExpression(exp, lyr, arcs) {
    var func = compileFeaturePairExpression(exp, lyr, arcs);
    return function(idA, idB) {
      var val = func(idA, idB);
      if (val !== true && val !== false) {
        stop("where expression must return true or false");
      }
      return val;
    };
  }

  function compileFeaturePairExpression(rawExp, lyr, arcs) {
    var exp = cleanExpression(rawExp);
    // don't add layer data to the context
    // (fields are not added to the pair expression context)
    var ctx = getExpressionContext({});
    var getA = getProxyFactory(lyr, arcs);
    var getB = getProxyFactory(lyr, arcs);
    var vars = getAssignedVars(exp);
    var functionBody = "with($$env){with($$record){return " + exp + "}}";
    var func;

    try {
      func = new Function("$$record,$$env", functionBody);
    } catch(e) {
      console.error(e);
      stop(e.name, "in expression [" + exp + "]");
    }

    // protect global object from assigned values
    nullifyUnsetProperties(vars, ctx);

    function getProxyFactory(lyr, arcs) {
      var records = lyr.data ? lyr.data.getRecords() : [];
      var getFeatureById = initFeatureProxy(lyr, arcs);
      function Proxy() {}

      return function(id) {
        var proxy;
        if (id == -1) return null;
        Proxy.prototype = records[id] || {};
        proxy = new Proxy();
        proxy.$ = getFeatureById(id);
        return proxy;
      };
    }

    // idA - id of a record
    // idB - id of a record, or -1
    // rec - optional data record
    return function(idA, idB, rec) {
      var val;
      ctx.A = getA(idA);
      ctx.B = getB(idB);
      if (rec) {
        // initialize new fields to null so assignments work
        nullifyUnsetProperties(vars, rec);
      }
      try {
        val = func.call(ctx, rec || {}, ctx);
      } catch(e) {
        stop(e.name, "in expression [" + exp + "]:", e.message);
      }
      return val;
    };
  }

  function compileFeatureExpression(rawExp, lyr, arcs, opts_) {
    var opts = utils.extend({}, opts_),
        exp = cleanExpression(rawExp || ''),
        mutable = !opts.no_assign, // block assignment expressions
        vars = getAssignedVars(exp),
        func, records;

    if (mutable && vars.length > 0 && !lyr.data) {
      initDataTable(lyr);
    }

    if (!mutable) {
      // protect global object from assigned values
      opts.context = opts.context || {};
      nullifyUnsetProperties(vars, opts.context);
    }

    records = lyr.data ? lyr.data.getRecords() : [];
    func = getExpressionFunction(exp, lyr, arcs, opts);

    // @destRec (optional) substitute for records[recId] (used by -calc)
    return function(recId, destRec) {
      var record;
      if (destRec) {
        record = destRec;
      } else {
        record = records[recId] || (records[recId] = {});
      }

      // initialize new fields to null so assignments work
      if (mutable) {
        nullifyUnsetProperties(vars, record);
      }
      return func(record, recId);
    };
  }

  // Return array of variables on the left side of assignment operations
  // @hasDot (bool) Return property assignments via dot notation
  function getAssignedVars(exp, hasDot) {
    var rxp = /[a-z_$][.a-z0-9_$]*(?= *=[^>=])/ig; // ignore arrow functions and comparisons
    var matches = exp.match(rxp) || [];
    var f = function(s) {
      var i = s.indexOf('.');
      return hasDot ? i > -1 : i == -1;
    };
    var vars = utils.uniq(matches.filter(f));
    return vars;
  }

  // Return array of objects with properties assigned via dot notation
  // e.g.  'd.value = 45' ->  ['d']
  function getAssignmentObjects(exp) {
    var matches = getAssignedVars(exp, true),
        names = [];
    matches.forEach(function(s) {
      var match = /^([^.]+)\.[^.]+$/.exec(s);
      var name = match ? match[1] : null;
      if (name && name != 'this') {
        names.push(name);
      }
    });
    return utils.uniq(names);
  }

  function compileExpressionToFunction(exp, opts) {
    // $$ added to avoid duplication with data field variables (an error condition)
    var functionBody = "with($$env){with($$record){ " + (opts.returns ? 'return ' : '') +
          exp + "}}";
    var func;
    try {
      func = new Function("$$record,$$env",  functionBody);
    } catch(e) {
      // if (opts.quiet) throw e;
      stop(e.name, "in expression [" + exp + "]");
    }
    return func;
  }

  function getExpressionFunction(exp, lyr, arcs, opts) {
    var getFeatureById = initFeatureProxy(lyr, arcs, opts);
    var layerOnlyProxy = addLayerGetters({}, lyr, arcs);
    var ctx = getExpressionContext(lyr, opts.context, opts);
    var func = compileExpressionToFunction(exp, opts);
    return function(rec, i) {
      var val;
      // Assigning feature/layer proxy to '$' -- maybe this should be removed,
      // since it is also exposed as "this".
      // (kludge) i is undefined in calc expressions ... we still
      //   may need layer data (but not single-feature data)
      ctx.$ = i >= 0 ? getFeatureById(i) : layerOnlyProxy;
      ctx._ = ctx; // provide access to functions when masked by variable names
      ctx.d = rec || null; // expose data properties a la d3 (also exposed as this.properties)
      try {
        val = func.call(ctx.$, rec, ctx);
      } catch(e) {
        // if (opts.quiet) throw e;
        stop(e.name, "in expression [" + exp + "]:", e.message);
      }
      return val;
    };
  }

  function nullifyUnsetProperties(vars, obj) {
    for (var i=0; i<vars.length; i++) {
      if (vars[i] in obj === false) {
        obj[vars[i]] = null;
      }
    }
  }

  function getExpressionContext(lyr, mixins, opts) {
    var defs = getStateVar('defs');
    var env = getBaseContext();
    var ctx = {};
    var fields = lyr.data ? lyr.data.getFields() : [];
    opts = opts || {};
    addUtils(env); // mix in round(), sprintf(), etc.
    if (fields.length > 0) {
      // default to null values, so assignments to missing data properties
      // are applied to the data record, not the global object
      nullifyUnsetProperties(fields, env);
    }
    // Add global 'defs' to the expression context
    mixins = utils.defaults(mixins || {}, defs);
    // also add defs as 'global' object
    env.global = defs;
    Object.keys(mixins).forEach(function(key) {
      // Catch name collisions between data fields and user-defined functions
      var d = Object.getOwnPropertyDescriptor(mixins, key);
      if (d.get) {
        // copy accessor function from mixins to context
        Object.defineProperty(ctx, key, {get: d.get}); // copy getter function to context
      } else {
        // copy regular property from mixins to context, but make it non-writable
        Object.defineProperty(ctx, key, {value: mixins[key]});
      }
    });
    // make context properties non-writable, so they can't be replaced by an expression
    return Object.keys(env).reduce(function(memo, key) {
      if (key in memo) {
        // property has already been set (probably by a mixin, above): skip
        // "no_warn" option used in calc= expressions
        if (!opts.no_warn) {
          if (typeof memo[key] == 'function' && fields.indexOf(key) > -1) {
            message('Warning: ' + key + '() function is hiding a data field with the same name');
          } else {
            message('Warning: "' + key + '" has multiple definitions');
          }
        }
      } else {
        Object.defineProperty(memo, key, {value: env[key]}); // writable: false is default
      }
      return memo;
    }, ctx);
  }

  function getBaseContext() {
    // Mask global properties (is this effective/worth doing?)
    var obj = {globalThis: void 0}; // some globals are not iterable
    (function() {
      for (var key in this) {
        obj[key] = void 0;
      }
    }());
    obj.console = console;
    return obj;
  }

  var Expressions = /*#__PURE__*/Object.freeze({
    __proto__: null,
    compileValueExpression: compileValueExpression,
    cleanExpression: cleanExpression,
    compileFeaturePairFilterExpression: compileFeaturePairFilterExpression,
    compileFeaturePairExpression: compileFeaturePairExpression,
    compileFeatureExpression: compileFeatureExpression,
    getAssignedVars: getAssignedVars,
    getAssignmentObjects: getAssignmentObjects,
    compileExpressionToFunction: compileExpressionToFunction,
    getBaseContext: getBaseContext
  });

  function getMode(values) {
    var data = getModeData(values);
    return data.modes[0];
  }

  function getValueCountData(values) {
    var uniqValues = [],
        uniqIndex = {},
        counts = [];
    var i, val;
    for (i=0; i<values.length; i++) {
      val = values[i];
      if (val in uniqIndex === false) {
        uniqIndex[val] = uniqValues.length;
        uniqValues.push(val);
        counts.push(1);
      } else {
        counts[uniqIndex[val]]++;
      }
    }
    return {
      values: uniqValues,
      counts: counts
    };
  }

  function getMaxValue(values) {
    var max = -Infinity;
    var i;
    for (i=0; i<values.length; i++) {
      if (values[i] > max) max = values[i];
    }
    return max;
  }

  function getCountDataSummary(o) {
    var counts = o.counts;
    var values = o.values;
    var maxCount = counts.length > 0 ? getMaxValue(counts) : 0;
    var nextCount = 0;
    var modes = [];
    var i, count;
    for (i=0; i<counts.length; i++) {
      count = counts[i];
      if (count === maxCount) {
        modes.push(values[i]);
      } else if (count > nextCount) {
        nextCount = count;
      }
    }
    return {
      modes: modes,
      margin: modes.length > 1 ? 0 : maxCount - nextCount,
      count: maxCount
    };
  }

  function getModeData(values, verbose) {
    var counts = getValueCountData(values);
    var modes = getCountDataSummary(counts);
    if (verbose) {
      modes.counts = counts.counts;
      modes.values = counts.values;
    }
    return modes;
  }

  var CalcUtils = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getMode: getMode,
    getModeData: getModeData
  });

  var cmd = {}; // command functions get added to this object

  // Get a copy of a layer containing a subset of the layer's features,
  // given a "where" expression in the options object
  function getLayerSelection(lyr, arcs, opts) {
    var lyr2 = utils.extend({}, lyr);
    var filterOpts = {
          expression: opts.where,
          invert: !!opts.invert,
          verbose: false,   // don't print status message
          no_replace: opts.no_replace // copy features if original features will be retained
        };
    return cmd.filterFeatures(lyr2, arcs, filterOpts);
  }

  // Used to run -dissolve with the where= option; could be generalized to support
  // other commands
  function applyCommandToLayerSelection(commandFunc, lyr, arcs, opts) {
    if (!opts || !opts.where) {
      error('Missing required "where" parameter');
    }
    var subsetLyr = getLayerSelection(lyr, arcs, opts);
    var cmdOpts = utils.defaults({where: null}, opts); // prevent infinite recursion
    var outputLyr = commandFunc(subsetLyr, arcs, cmdOpts);
    var filterOpts = utils.defaults({invert: true}, opts);
    var filteredLyr = getLayerSelection(lyr, arcs, filterOpts);
    var merged = cmd.mergeLayers([filteredLyr, outputLyr], {verbose: false, force: true});
    return merged[0];
  }

  // Calculate an expression across a group of features, print and return the result
  // Supported functions include sum(), average(), max(), min(), median(), count()
  // Functions receive an expression to be applied to each feature (like the -each command)
  // Examples: 'sum($.area)' 'min(income)'
  // opts.expression  Expression to evaluate
  // opts.where  Optional filter expression (see -filter command)
  //
  cmd.calc = function(lyr, arcs, opts) {
    var msg = opts.expression,
        result, compiled, defs;
    if (opts.where) {
      // TODO: implement no_replace option for filter() instead of this
      lyr = getLayerSelection(lyr, arcs, opts);
      msg += ' where ' + opts.where;
    }
    // Save any assigned variables to the defs object, so they will be available
    // for later -each expressions to use.
    defs = getStateVar('defs');
    compiled = compileCalcExpression(lyr, arcs, opts.expression);
    result = compiled(null, defs);
    message(msg + ":  " + result);
    return result;
  };

  function evalCalcExpression(lyr, arcs, exp) {
    return compileCalcExpression(lyr, arcs, exp)();
  }

  function compileCalcExpression(lyr, arcs, exp) {
    var rowNo = 0, colNo = 0, cols = [];
    var ctx1 = { // context for first phase (capturing values for each feature)
          count: assign,
          sum: captureNum,
          sums: capture,
          average: captureNum,
          median: captureNum,
          min: captureNum,
          max: captureNum,
          mode: capture,
          collect: capture,
          first: assignOnce,
          every: every,
          some: some,
          last: assign
        },
        ctx2 = { // context for second phase (calculating results)
          count: wrap(function() {return rowNo;}, 0),
          sum: wrap(utils.sum, 0),
          sums: wrap(sums),
          median: wrap(utils.findMedian),
          min: wrap(min),
          max: wrap(max),
          average: wrap(utils.mean),
          mode: wrap(getMode),
          collect: wrap(pass),
          first: wrap(pass),
          every: wrap(pass, false),
          some: wrap(pass, false),
          last: wrap(pass)
        },
        len = getFeatureCount(lyr),
        calc1, calc2, result;

    if (lyr.geometry_type) {
      // add functions related to layer geometry (e.g. for subdivide())
      ctx1.width = ctx1.height = noop;
      ctx2.width = function() {return getLayerBounds(lyr, arcs).width();};
      ctx2.height = function() {return getLayerBounds(lyr, arcs).height();};
    }

    calc1 = compileFeatureExpression(exp, lyr, arcs, {context: ctx1,
        no_assign: true, no_warn: true});
    // changed data-only layer to full layer to expose layer geometry, etc
    // (why not do this originally?)
    // calc2 = compileFeatureExpression(exp, {data: lyr.data}, null,
    //     {returns: true, context: ctx2, no_warn: true});
    calc2 = compileFeatureExpression(exp, lyr, arcs,
        {returns: true, context: ctx2, no_warn: true});

    // @destRec: optional destination record for assignments
    return function(ids, destRec) {
      var result;
      // phase 1: capture data
      if (ids) procRecords(ids);
      else procAll();
      // phase 2: calculate
      result = calc2(undefined, destRec);
      reset();
      return result;
    };

    function pass(o) {return o;}

    function max(arr) {
      return utils.getArrayBounds(arr).max;
    }

    function sums(arr) {
      var n = arr && arr.length ? arr[0].length : 0;
      var output = utils.initializeArray(Array(n), 0);
      arr.forEach(function(arr) {
        if (!arr || !arr.length) return;
        for (var i=0; i<n; i++) {
          output[i] += +arr[i] || 0;
        }
      });
      return output;
    }

    function min(arr) {
      return utils.getArrayBounds(arr).min;
    }

    // process captured data, or return nodata value if no records have been captured
    function wrap(proc, nullVal) {
      var nodata = arguments.length > 1 ? nullVal : null;
      return function() {
        var c = colNo++;
        return rowNo > 0 ? proc(cols[c]) : nodata;
      };
    }

    function procAll() {
      for (var i=0; i<len; i++) {
        procRecord(i);
      }
    }

    function procRecords(ids) {
      ids.forEach(procRecord);
    }

    function procRecord(i) {
      if (i < 0 || i >= len) error("Invalid record index");
      calc1(i);
      rowNo++;
      colNo = 0;
    }

    function noop() {}

    function reset() {
      rowNo = 0;
      colNo = 0;
      cols = [];
    }

    function captureNum(val) {
      if (isNaN(val) && val) { // accepting falsy values (be more strict?)
        stop("Expected a number, received:", val);
      }
      return capture(val);
    }

    function assignOnce(val) {
      if (rowNo === 0) cols[colNo] = val;
      colNo++;
      return val;
    }

    function every(val) {
      val = !!val;
      cols[colNo] = rowNo === 0 ? val : cols[colNo] && val;
      colNo++;
    }

    function some(val) {
      val = !!val;
      cols[colNo] = cols[colNo] || val;
      colNo++;
    }

    function assign(val) {
      cols[colNo++] = val;
      return val;
    }
    /*
    function captureArr(val) {
      capture(val);
      return [];
    }
    */

    function capture(val) {
      var col;
      if (rowNo === 0) {
        cols[colNo] = [];
      }
      col = cols[colNo];
      if (col.length != rowNo) {
        // make sure all functions are called each time
        // (if expression contains a condition, it will throw off the calculation)
        // TODO: allow conditions
        stop("Evaluation failed");
      }
      col.push(val);
      colNo++;
      return val;
    }
  }

  var Calc = /*#__PURE__*/Object.freeze({
    __proto__: null,
    evalCalcExpression: evalCalcExpression,
    compileCalcExpression: compileCalcExpression
  });

  // get function that returns an object containing calculated values
  function getJoinCalc(src, exp) {
    var calc = compileCalcExpression({data: src}, null, exp);
    return function(ids, destRec) {
      if (!ids) ids = [];
      calc(ids, destRec);
    };
  }

  var JoinCalc = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getJoinCalc: getJoinCalc
  });

  // Return a function to convert indexes of original features into indexes of grouped features
  // Uses categorical classification (a different id for each unique combination of values)
  function getCategoryClassifier(fields, data) {
    if (!fields || fields.length === 0) return function() {return 0;};
    fields.forEach(function(f) {
      requireDataField(data, f);
    });
    var index = {},
        count = 0,
        records = data.getRecords(),
        getKey = getMultiFieldKeyFunction(fields);
    return function(i) {
      var key = getKey(records[i]);
      if (key in index === false) {
        index[key] = count++;
      }
      return index[key];
    };
  }

  function getMultiFieldKeyFunction(fields) {
    return fields.reduce(function(partial, field) {
      // TODO: consider using JSON.stringify for fields that contain objects
      var strval = function(rec) {return String(rec[field]);};
      return partial ? function(rec) {return partial(rec) + '~~' + strval(rec);} : strval;
    }, null);
  }

  // Performs many-to-one data record aggregation on an array of data records
  // Returns an array of data records for a set of aggregated features
  //
  // @records input records
  // @getGroupId()  converts input record id to id of aggregated record
  //
  function aggregateDataRecords(records, getGroupId, opts) {
    var groups = groupIds(getGroupId, records.length);
    return aggregateDataRecords2(records, groups, opts);
  }

  // Performs many-to-many data record aggregation on an array of data records
  // (used by the -mosaic command)
  // getSourceIds()  receives the id of an output record and returns
  //    an array of input record ids
  //
  function recombineDataRecords(records, getSourceIds, n, opts) {
    var groups = [];
    for (var i=0; i<n; i++) {
      groups.push(getSourceIds(i));
    }
    return aggregateDataRecords2(records, groups, opts);
  }

  function aggregateDataRecords2(records, groups, opts) {
    var sumFields = opts.sum_fields || [],
        copyFields = opts.copy_fields || [],
        calc;

    if (opts.fields) {
      copyFields = copyFields.concat(opts.fields);
    }

    if (opts.calc) {
      calc = getJoinCalc(new DataTable(records), opts.calc);
    }

    function sum(field, group) {
      var tot = 0, rec;
      for (var i=0; i<group.length; i++) {
        rec = records[group[i]];
        tot += rec && rec[field] || 0;
      }
      return tot;
    }

    return groups.map(function(group) {
      var rec = {},
          j, first;
      group = group || [];
      first = records[group[0]];
      for (j=0; j<sumFields.length; j++) {
        rec[sumFields[j]] = sum(sumFields[j], group);
      }
      for (j=0; j<copyFields.length; j++) {
        rec[copyFields[j]] = first ? first[copyFields[j]] : null;
      }
      if (calc) {
        calc(group, rec);
      }
      return rec;
    });
  }

  // Returns array containing groups of feature indexes
  // @getId() (function) converts feature index into group index
  // @n number of features
  //
  function groupIds(getId, n) {
    var groups = [], id;
    for (var i=0; i<n; i++) {
      id = getId(i);
      if (id in groups) {
        groups[id].push(i);
      } else {
        groups[id] = [i];
      }
    }
    return groups;
  }

  var DataAggregation = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getCategoryClassifier: getCategoryClassifier,
    getMultiFieldKeyFunction: getMultiFieldKeyFunction,
    aggregateDataRecords: aggregateDataRecords,
    recombineDataRecords: recombineDataRecords
  });

  function dissolvePointGeometry(lyr, getGroupId, opts) {
    var useSph = !opts.planar && probablyDecimalDegreeBounds(getLayerBounds(lyr));
    var getWeight = opts.weight ? compileValueExpression(opts.weight, lyr) : null;
    var groups = [];

    // TODO: support multipoints
    if (countMultiPartFeatures(lyr.shapes) !== 0) {
      stop("Dissolving multi-part points is not supported");
    }

    lyr.shapes.forEach(function(shp, i) {
      var groupId = getGroupId(i);
      var weight = getWeight ? getWeight(i) : 1;
      var p = shp && shp[0]; // Using first point (TODO: handle multi-point features)
      var tmp;
      if (!p) return;
      if (useSph) {
        tmp = [];
        geom.lngLatToXYZ(p[0], p[1], tmp);
        p = tmp;
      }
      groups[groupId] = reducePointCentroid(groups[groupId], p, weight);
    });

    return groups.map(function(memo) {
      var p1, p2;
      if (!memo) return null;
      if (useSph) {
        p1 = memo.centroid;
        p2 = [];
        geom.xyzToLngLat(p1[0], p1[1], p1[2], p2);
      } else {
        p2 = memo.centroid;
      }
      return memo ? [p2] : null;
    });
  }

  function reducePointCentroid(memo, p, weight) {
    var x = p[0],
        y = p[1],
        sum, k;

    if (x == x && y == y && weight > 0) {
      if (!memo) {
        memo = {sum: weight, centroid: p.concat()};
      } else {
        sum = memo.sum + weight;
        k = memo.sum / sum;
        memo.centroid[0] = k * memo.centroid[0] + weight * x / sum;
        memo.centroid[1] = k * memo.centroid[1] + weight * y / sum;
        if (p.length == 3) {
          memo.centroid[2] = k * memo.centroid[2] + weight * p[2] / sum;
        }
        memo.sum = sum;
      }
    }
    return memo;
  }

  // Dissolve polyline features
  function dissolvePolylineGeometry(lyr, getGroupId, arcs, opts) {
    var groups = getPolylineDissolveGroups(lyr.shapes, getGroupId);
    var dissolve = getPolylineDissolver(arcs);
    return groups.map(dissolve);
  }

  // Create one array of arc ids for each group
  function getPolylineDissolveGroups(shapes, getGroupId) {
    var groups = [];
    traversePaths(shapes, function(o) {
      var groupId = getGroupId(o.shapeId);
      if (groupId in groups === false) {
        groups[groupId] = [];
      }
      groups[groupId].push(o.arcId);
    });
    return groups;
  }

  function getPolylineDissolver(arcs) {
    var flags = new Uint8Array(arcs.size());
    var testArc = function(id) {return flags[absArcId(id)] > 0;};
    var useArc = function(id) {flags[absArcId(id)] = 0;};
    var nodes = new NodeCollection(arcs);
    return function(ids) {
      ids.forEach(function(id) {flags[absArcId(id)] = 1;});
      var ends = findPolylineEnds(ids, nodes, testArc);
      var straightParts = collectPolylineArcs(ends, nodes, testArc, useArc);
      var ringParts = collectPolylineArcs(ids, nodes, testArc, useArc);
      var allParts = straightParts.concat(ringParts);
      ids.forEach(function(id) {flags[absArcId(id)] = 0;}); // may not be necessary
      return allParts;
    };
  }

  /*



  */

  // TODO: use polygon pathfinder shared code
  function collectPolylineArcs(ids, nodes, testArc, useArc) {
    var parts = [];
    ids.forEach(function(startId) {
      var part = [];
      var nextId = startId;
      var nextIds;
      while (testArc(nextId)) {
        part.push(nextId);
        nextIds = testArc(nextId) ? nodes.getConnectedArcs(nextId, testArc) : [];
        useArc(nextId); // use (unset) arc after connections have been found
        if (nextIds.length > 0) {
          nextId = ~nextIds[0]; // switch arc direction to lead away from node
        } else {
          break;
        }
      }
      if (part.length > 0) parts.push(part);
    });
    return parts;
  }

  // Return array of dead-end arcs for a dissolved group.
  function findPolylineEnds(ids, nodes, filter) {
    var ends = [];
    ids.forEach(function(arcId) {
      if (nodes.getConnectedArcs(arcId, filter).length === 0) {
        ends.push(~arcId); // arc points away from terminus
      }
      if (nodes.getConnectedArcs(~arcId, filter).length === 0) {
        ends.push(arcId);
      }
    });
    return ends;
  }

  function dissolvePolygonGeometry(shapes, getGroupId) {
    var segments = dissolveFirstPass(shapes, getGroupId);
    return dissolveSecondPass(segments, shapes, getGroupId);
  }

  // First pass -- identify pairs of segments that can be dissolved
  function dissolveFirstPass(shapes, getGroupId) {
    var groups = [],
        largeGroups = [],
        segments = [],
        ids = shapes.map(function(shp, i) {
          return getGroupId(i);
        });

    traversePaths(shapes, procArc);
    largeGroups.forEach(splitGroup);
    return segments;

    function procArc(obj) {
      var arcId = obj.arcId,
          idx = arcId < 0 ? ~arcId : arcId,
          segId = segments.length,
          group = groups[idx];
      if (!group) {
        group = [];
        groups[idx] = group;
      }
      group.push(segId);
      obj.group = group;
      segments.push(obj);

      // Three or more segments sharing the same arc is abnormal topology...
      // Need to try to identify pairs of matching segments in each of these
      // groups.
      //
      if (group.length == 3) {
        largeGroups.push(group);
      }
    }

    function findMatchingPair(group, cb) {
      var arc1, arc2;
      for (var i=0; i<group.length - 1; i++) {
        arc1 = segments[group[i]];
        for (var j=i+1; j<group.length; j++) {
          arc2 = segments[group[j]];
          if (cb(arc1, arc2)) {
            return [arc1.segId, arc2.segId];
          }
        }
      }
      return null;
    }

    function checkFwExtension(arc1, arc2) {
      return getNextSegment(arc1, segments, shapes).arcId ===
          ~getNextSegment(arc2, segments, shapes).arcId;
    }

    function checkBwExtension(arc1, arc2) {
      return getPrevSegment(arc1, segments, shapes).arcId ===
          ~getPrevSegment(arc2, segments, shapes).arcId;
    }

    function checkDoubleExtension(arc1, arc2) {
      return checkPairwiseMatch(arc1, arc2) &&
          checkFwExtension(arc1, arc2) &&
          checkBwExtension(arc1, arc2);
    }

    function checkSingleExtension(arc1, arc2) {
      return checkPairwiseMatch(arc1, arc2) &&
          (checkFwExtension(arc1, arc2) ||
          checkBwExtension(arc1, arc2));
    }

    function checkPairwiseMatch(arc1, arc2) {
      return arc1.arcId === ~arc2.arcId && ids[arc1.shapeId] ===
          ids[arc2.shapeId];
    }

    function updateGroupIds(ids) {
      ids.forEach(function(id) {
        segments[id].group = ids;
      });
    }

    // split a group of segments into pairs of matching segments + a residual group
    // @group Array of segment ids
    //
    function splitGroup(group) {
      // find best-match segment pair
      var group2 = findMatchingPair(group, checkDoubleExtension) ||
          findMatchingPair(group, checkSingleExtension) ||
          findMatchingPair(group, checkPairwiseMatch);
      if (group2) {
        group = group.filter(function(i) {
          return !utils.contains(group2, i);
        });
        updateGroupIds(group);
        updateGroupIds(group2);
        // Split again if reduced group is still large
        if (group.length > 2) splitGroup(group);
      }
    }
  }

  // Second pass -- generate dissolved shapes
  //
  function dissolveSecondPass(segments, shapes, getGroupId) {
    var dissolveShapes = [];
    segments.forEach(procSegment);
    return dissolveShapes;

    // @obj is an arc instance
    function procSegment(obj) {
      if (obj.used) return;
      var match = findDissolveArc(obj);
      if (!match) buildRing(obj);
    }

    function addRing(arcs, i) {
      if (i in dissolveShapes === false) {
        dissolveShapes[i] = [];
      }
      dissolveShapes[i].push(arcs);
    }

    // Generate a dissolved ring
    // @firstArc the first arc instance in the ring
    //
    function buildRing(firstArc) {
      var newArcs = [firstArc.arcId],
          nextArc = getNextArc(firstArc);
          firstArc.used = true;

      while (nextArc && nextArc != firstArc) {
        newArcs.push(nextArc.arcId);
        nextArc.used = true;
        nextArc = getNextArc(nextArc);
        if (nextArc && nextArc != firstArc && nextArc.used) error("buildRing() topology error");
      }

      if (!nextArc) error("buildRing() traversal error");
      firstArc.used = true;
      addRing(newArcs, getGroupId(firstArc.shapeId));
    }

    // Get the next arc in a dissolved polygon ring
    // @obj an undissolvable arc instance
    //
    function getNextArc(obj, depth) {
      var next = getNextSegment(obj, segments, shapes),
          match;
      depth = depth || 0;
      if (next != obj) {
        match = findDissolveArc(next);
        if (match) {
          if (depth > 100) {
            error ('deep recursion -- unhandled topology problem');
          }
          // if (match.part.arcs.length == 1) {
          if (shapes[match.shapeId][match.partId].length == 1) {
            // case: @obj has an island inclusion -- keep traversing @obj
            // TODO: test case if @next is first arc in the ring
            next = getNextArc(next, depth + 1);
          } else {
            next = getNextArc(match, depth + 1);
          }
        }
      }
      return next;
    }

    // Look for an arc instance that can be dissolved with segment @obj
    // (must be going the opposite direction and have same dissolve key, etc)
    // Return matching segment or null if no match
    //
    function findDissolveArc(obj) {
      var dissolveId = getGroupId(obj.shapeId), // obj.shape.dissolveKey,
          match, matchId;
      matchId = utils.find(obj.group, function(i) {
        var a = obj,
            b = segments[i];
        if (a == b ||
            b.used ||
            getGroupId(b.shapeId) !== dissolveId ||
            // don't prevent rings from dissolving with themselves (risky?)
            // a.shapeId == b.shapeId && a.partId == b.partId ||
            a.arcId != ~b.arcId) return false;
        return true;
      });
      match = matchId === null ? null : segments[matchId];
      return match;
    }
  }

  function getNextSegment(seg, segments, shapes) {
    return getSegmentByOffs(seg, segments, shapes, 1);
  }

  function getPrevSegment(seg, segments, shapes) {
    return getSegmentByOffs(seg, segments, shapes, -1);
  }

  function getSegmentByOffs(seg, segments, shapes, offs) {
    var arcs = shapes[seg.shapeId][seg.partId],
        partLen = arcs.length,
        nextOffs = (seg.i + offs) % partLen,
        nextSeg;
    if (nextOffs < 0) nextOffs += partLen;
    nextSeg = segments[seg.segId - seg.i + nextOffs];
    if (!nextSeg || nextSeg.shapeId != seg.shapeId) error("index error");
    return nextSeg;
  }

  var PolygonDissolve = /*#__PURE__*/Object.freeze({
    __proto__: null,
    dissolvePolygonGeometry: dissolvePolygonGeometry
  });

  // Generate a dissolved layer
  // @opts.fields (optional) names of data fields (dissolves all if falsy)
  // @opts.sum-fields (Array) (optional)
  // @opts.copy-fields (Array) (optional)
  //
  cmd.dissolve = function(lyr, arcs, opts) {
    var dissolveShapes, getGroupId;
    opts = utils.extend({}, opts);
    if (opts.where) {
      return applyCommandToLayerSelection(cmd.dissolve, lyr, arcs, opts);
    }
    if (opts.field) opts.fields = [opts.field]; // support old "field" parameter
    getGroupId = getCategoryClassifier(opts.fields, lyr.data);
    if (opts.multipart || opts.group_points) {
      dissolveShapes = makeMultipartShapes(lyr, getGroupId);
    } else if (lyr.geometry_type == 'polygon') {
      dissolveShapes = dissolvePolygonGeometry(lyr.shapes, getGroupId);
    } else if (lyr.geometry_type == 'polyline') {
      dissolveShapes = dissolvePolylineGeometry(lyr, getGroupId, arcs, opts);
    } else if (lyr.geometry_type == 'point') {
      dissolveShapes = dissolvePointGeometry(lyr, getGroupId, opts);
    }
    return composeDissolveLayer(lyr, dissolveShapes, getGroupId, opts);
  };

  function makeMultipartShapes(lyr, getGroupId) {
    if (!lyr.shapes || !lyr.geometry_type) {
      stop('Layer is missing geometry');
    }
    var shapes = cloneShapes(lyr.shapes);
    var shapes2 = [];
    lyr.shapes.forEach(function(shp, i) {
      var groupId = getGroupId(i);
      if (!shp) return;
      if (!shapes2[groupId]) {
        shapes2[groupId] = shp;
      } else {
        shapes2[groupId].push.apply(shapes2[groupId], shp);
      }
    });
    return shapes2;
  }

  // @lyr: original undissolved layer
  // @shapes: dissolved shapes
  function composeDissolveLayer(lyr, shapes, getGroupId, opts) {
    var records = null;
    var lyr2;
    if (lyr.data) {
      records = aggregateDataRecords(lyr.data.getRecords(), getGroupId, opts);
      // replace missing shapes with nulls
      for (var i=0, n=records.length; i<n; i++) {
        if (shapes && !shapes[i]) {
          shapes[i] = null;
        }
      }
    }
    lyr2 = {
      name: opts.no_replace ? null : lyr.name,
      shapes: shapes,
      data: records ? new DataTable(records) : null,
      geometry_type: lyr.geometry_type
    };
    if (!opts.silent) {
      printDissolveMessage(lyr, lyr2);
    }
    return lyr2;
  }

  function printDissolveMessage(pre, post) {
    var n1 = getFeatureCount(pre),
        n2 = getFeatureCount(post),
        msg = utils.format('Dissolved %,d feature%s into %,d feature%s',
          n1, utils.pluralSuffix(n1), n2,
          utils.pluralSuffix(n2));
    message(msg);
  }

  // Maps tile ids to shape ids (both are non-negative integers). Supports
  //    one-to-many mapping (a tile may belong to multiple shapes)
  // Also maps shape ids to tile ids. A shape may contain multiple tiles
  // Also supports 'flattening' -- removing one-to-many tile-shape mappings by
  //    removing all but one shape from a tile.
  // Supports one-to-many mapping
  function TileShapeIndex(mosaic, opts) {
    // indexes for mapping tile ids to shape ids
    var singleIndex = new Int32Array(mosaic.length);
    utils.initializeArray(singleIndex, -1);
    var multipleIndex = [];
    // index that maps shape ids to tile ids
    var shapeIndex = [];

    this.getTileIdsByShapeId = function(shapeId) {
      var ids = shapeIndex[shapeId];
      // need to filter out tile ids that have been set to -1 (indicating removal)
      return ids ? ids.filter(function(id) {return id >= 0;}) : [];
    };

    // assumes index has been flattened
    this.getShapeIdByTileId = function(id) {
      var shapeId = singleIndex[id];
      return shapeId >= 0 ? shapeId : -1;
    };

    // return ids of all shapes that include a tile
    this.getShapeIdsByTileId = function(id) {
      var singleId = singleIndex[id];
      if (singleId >= 0) {
        return [singleId];
      }
      if (singleId == -1) {
        return [];
      }
      return multipleIndex[id];
    };

    this.indexTileIdsByShapeId = function(shapeId, tileIds, weightFunction) {
      shapeIndex[shapeId] = [];
      for (var i=0; i<tileIds.length; i++) {
        indexShapeIdByTileId(shapeId, tileIds[i], weightFunction);
      }
    };

    // remove many-to-one tile=>shape mappings
    this.flatten = function() {
      multipleIndex.forEach(function(shapeIds, tileId) {
        flattenStackedTile(tileId);
      });
      multipleIndex = [];
    };

    this.getUnusedTileIds = function() {
      var ids = [];
      for (var i=0, n=singleIndex.length; i<n; i++) {
        if (singleIndex[i] == -1) ids.push(i);
      }
      return ids;
    };

    // used by gap fill; assumes that flatten() has been called
    this.addTileToShape = function(shapeId, tileId) {
      if (shapeId in shapeIndex === false || singleIndex[tileId] != -1) {
        error('Internal error');
      }
      singleIndex[tileId] = shapeId;
      shapeIndex[shapeId].push(tileId);
    };

    // add a shape id to a tile
    function indexShapeIdByTileId(shapeId, tileId, weightFunction) {
      var singleId = singleIndex[tileId];
      if (singleId != -1 && opts.flat) {
        // pick the best shape if we have a weight function
        if (weightFunction && weightFunction(shapeId) > weightFunction(singleId)) {
          // replace existing shape reference
          removeTileFromShape(tileId, singleId); // bottleneck when overlaps are many
          singleIndex[tileId] = singleId;
          singleId = -1;
        } else {
          // keep existing shape reference
          return;
        }
      }
      if (singleId == -1) {
        singleIndex[tileId] = shapeId;
      } else if (singleId == -2) {
        multipleIndex[tileId].push(shapeId);
      } else {
        multipleIndex[tileId] = [singleId, shapeId];
        singleIndex[tileId] = -2;
      }
      shapeIndex[shapeId].push(tileId);
    }


    function flattenStackedTile(tileId) {
      // TODO: select the best shape (using some metric)
      var shapeIds = multipleIndex[tileId];
      // if (!shapeIds || shapeIds.length > 1 === false) error('flattening error');
      var selectedId = shapeIds[0];
      var shapeId;
      singleIndex[tileId] = selectedId; // add shape to single index
      // remove tile from other stacked shapes
      for (var i=0; i<shapeIds.length; i++) {
        shapeId = shapeIds[i];
        if (shapeId != selectedId) {
          removeTileFromShape(tileId, shapeId);
        }
      }
    }

    function removeTileFromShape(tileId, shapeId) {
      var tileIds = shapeIndex[shapeId];
      for (var i=0; i<tileIds.length; i++) {
        if (tileIds[i] === tileId) {
          tileIds[i] = -1;
          break;
        }
      }
    }

    // This function was a bottleneck in datasets with many overlaps
    function removeTileFromShape_old(tileId, shapeId) {
      shapeIndex[shapeId] = shapeIndex[shapeId].filter(function(tileId2) {
        return tileId2 != tileId;
      });
      if (shapeIndex[shapeId].length > 0 === false) {
        // TODO: make sure to test the case where a shape becomes empty
        // error("empty shape")
      }
    }
  }

  // Keep track of whether positive or negative integer ids are 'used' or not.

  function IdTestIndex(n) {
    var index = new Uint8Array(n);
    var setList = [];

    this.setId = function(id) {
      if (!this.hasId(id)) {
        setList.push(id);
      }
      if (id < 0) {
        index[~id] |= 2;
      } else {
        index[id] |= 1;
      }
    };

    this.clear = function() {
      var index = this;
      setList.forEach(function(id) {
        index.clearId(id);
      });
      setList = [];
    };

    this.hasId = function(id) {
      return id < 0 ? (index[~id] & 2) == 2 : (index[id] & 1) == 1;
    };

    // clear a signed id
    this.clearId = function(id) {
      if (id < 0) {
        index[~id] &= 1; // clear reverse arc, preserve fwd arc
      } else {
        index[id] &= 2; // clear fwd arc, preserve rev arc
      }
    };

    this.getIds = function() {
      return setList;
    };

    this.setIds = function(ids) {
      for (var i=0; i<ids.length; i++) {
        this.setId(ids[i]);
      }
    };
  }

  // Clean polygon or polyline shapes (in-place)
  //
  function cleanShapes(shapes, arcs, type) {
    for (var i=0, n=shapes.length; i<n; i++) {
      shapes[i] = cleanShape(shapes[i], arcs, type);
    }
  }

  // Remove defective arcs and zero-area polygon rings
  // Remove simple polygon spikes of form: [..., id, ~id, ...]
  // Don't remove duplicate points
  // Don't check winding order of polygon rings
  function cleanShape(shape, arcs, type) {
    return editShapeParts(shape, function(path) {
      var cleaned = cleanPath(path, arcs);
      if (type == 'polygon' && cleaned) {
        removeSpikesInPath(cleaned); // assumed by addIntersectionCuts()
        if (geom.getPlanarPathArea(cleaned, arcs) === 0) {
          cleaned = null;
        }
      }
      return cleaned;
    });
  }

  function cleanPath(path, arcs) {
    var nulls = 0;
    for (var i=0, n=path.length; i<n; i++) {
      if (arcs.arcIsDegenerate(path[i])) {
        nulls++;
        path[i] = null;
      }
    }
    return nulls > 0 ? path.filter(function(id) {return id !== null;}) : path;
  }


  // Remove pairs of ids where id[n] == ~id[n+1] or id[0] == ~id[n-1];
  // (in place)
  function removeSpikesInPath(ids) {
    var n = ids.length;
    if (n >= 2) {
      if (ids[0] == ~ids[n-1]) {
        ids.pop();
        ids.shift();
      } else {
        for (var i=1; i<n; i++) {
          if (ids[i-1] == ~ids[i]) {
            ids.splice(i-1, 2);
            break;
          }
        }
      }
      if (ids.length < n) {
        removeSpikesInPath(ids);
      }
    }
  }


  // Returns a function for splitting self-intersecting polygon rings
  // The splitter function receives a single polygon ring represented as an array
  // of arc ids, and returns an array of split-apart rings.
  //
  // Self-intersections in the input ring are assumed to occur at vertices, not along segments.
  // This requires that internal.addIntersectionCuts() has already been run.
  //
  // The rings output by this function may overlap each other, but each ring will
  // be non-self-intersecting. For example, a figure-eight shaped ring will be
  // split into two rings that touch each other where the original ring crossed itself.
  //
  function getSelfIntersectionSplitter(nodes) {
    var pathIndex = new IdTestIndex(nodes.arcs.size(), true);
    var filter = function(arcId) {
      return pathIndex.hasId(~arcId);
    };
    return function(path) {
      pathIndex.setIds(path);
      var paths = dividePath(path);
      pathIndex.clear();
      return paths;
    };

    // Returns array of 0 or more divided paths
    function dividePath(path) {
      var subPaths = null;
      for (var i=0, n=path.length; i < n - 1; i++) { // don't need to check last arc
        subPaths = dividePathAtNode(path, path[i]);
        if (subPaths !== null) {
          return subPaths;
        }
      }
      // indivisible path -- clean it by removing any spikes
      removeSpikesInPath(path);
      return path.length > 0 ? [path] : [];
    }

    // If arc @enterId enters a node with more than one open routes leading out:
    //   return array of sub-paths
    // else return null
    function dividePathAtNode(path, enterId) {
      var nodeIds = nodes.getConnectedArcs(enterId, filter),
          exitArcIndexes, exitArcId, idx;
      if (nodeIds.length < 2) return null;
      exitArcIndexes = [];
      for (var i=0; i<nodeIds.length; i++) {
        exitArcId = ~nodeIds[i];
        idx = indexOf(path, exitArcId);
        if (idx > -1) { // repeated scanning may be bottleneck
          // important optimization (TODO: explain this)
          // TODO: test edge case: exitArcId occurs twice in the path
          pathIndex.clearId(exitArcId);
          exitArcIndexes.push(idx);
        } else {
          // TODO: investigate why this happens
        }
      }
      if (exitArcIndexes.length < 2) {
        return null;
      }
      // path forks -- recursively subdivide
      var subPaths = splitPathByIds(path, exitArcIndexes);
      return subPaths.reduce(accumulatePaths, null);
    }

    function accumulatePaths(memo, path) {
      var subPaths = dividePath(path);
      if (memo === null) {
        return subPaths;
      }
      memo.push.apply(memo, subPaths);
      return memo;
    }

    // Added as an optimization -- faster than using Array#indexOf()
    function indexOf(arr, el) {
      for (var i=0, n=arr.length; i<n; i++) {
        if (arr[i] === el) return i;
      }
      return -1;
    }

  }

  // Function returns an array of split-apart rings
  // @path An array of arc ids describing a self-intersecting polygon ring
  // @ids An array of two or more indexes of arcs that originate from a single vertex
  //      where @path intersects itself -- assumes indexes are in ascending sequence
  function splitPathByIds(path, indexes) {
    var subPaths = [];
    utils.genericSort(indexes, true); // sort ascending
    if (indexes[0] > 0) {
      subPaths.push(path.slice(0, indexes[0]));
    }
    for (var i=0, n=indexes.length; i<n; i++) {
      if (i < n-1) {
        subPaths.push(path.slice(indexes[i], indexes[i+1]));
      } else {
        subPaths.push(path.slice(indexes[i]));
      }
    }
    // handle case where first subring is split across endpoint of @path
    if (subPaths.length > indexes.length) {
      utils.merge(subPaths[0], subPaths.pop());
    }
    return subPaths;
  }

  var PathRepair = /*#__PURE__*/Object.freeze({
    __proto__: null,
    cleanShapes: cleanShapes,
    removeSpikesInPath: removeSpikesInPath,
    getSelfIntersectionSplitter: getSelfIntersectionSplitter,
    splitPathByIds: splitPathByIds
  });

  // TODO: also delete positive-space rings nested inside holes
  function deleteHoles(lyr, arcs) {
    editShapes(lyr.shapes, function(path) {
      if (geom.getPathArea(path, arcs) <= 0) {
        return null; // null deletes the path
      }
    });
  }

  // Returns a function that separates rings in a polygon into space-enclosing rings
  // and holes. Also fixes self-intersections.
  //
  function getHoleDivider(nodes, spherical) {
    var split = getSelfIntersectionSplitter(nodes);
    // var split = internal.getSelfIntersectionSplitter_v1(nodes); console.log('split')

    return function(rings, cw, ccw) {
      var pathArea = spherical ? geom.getSphericalPathArea : geom.getPlanarPathArea;
      forEachShapePart(rings, function(ringIds) {
        var splitRings = split(ringIds);
        if (splitRings.length === 0) {
          debug("[getRingDivider()] Defective path:", ringIds);
        }
        splitRings.forEach(function(ringIds, i) {
          var ringArea = pathArea(ringIds, nodes.arcs);
          if (ringArea > 0) {
            cw.push(ringIds);
          } else if (ringArea < 0) {
            ccw.push(ringIds);
          }
        });
      });
    };
  }

  var PolygonHoles = /*#__PURE__*/Object.freeze({
    __proto__: null,
    deleteHoles: deleteHoles,
    getHoleDivider: getHoleDivider
  });

  // Convert an array of intersections into an ArcCollection (for display)
  //

  function getIntersectionPoints(intersections) {
    return intersections.map(function(obj) {
          return [obj.x, obj.y];
        });
  }

  // Identify intersecting segments in an ArcCollection
  //
  // To find all intersections:
  // 1. Assign each segment to one or more horizontal stripes/bins
  // 2. Find intersections inside each stripe
  // 3. Concat and dedup
  //
  // Re-use buffer for temp data -- Chrome's gc starts bogging down
  // if large buffers are repeatedly created.
  var buf;
  function getUint32Array(count) {
    var bytes = count * 4;
    if (!buf || buf.byteLength < bytes) {
      buf = new ArrayBuffer(bytes);
    }
    return new Uint32Array(buf, 0, count);
  }

  function findSegmentIntersections(arcs, optArg) {
    var opts = utils.extend({}, optArg),
        bounds = arcs.getBounds(),
        // TODO: handle spherical bounds
        spherical = !arcs.isPlanar() &&
            geom.containsBounds(getWorldBounds(), bounds.toArray()),
        ymin = bounds.ymin,
        yrange = bounds.ymax - ymin,
        stripeCount = opts.stripes || calcSegmentIntersectionStripeCount(arcs),
        stripeSizes = new Uint32Array(stripeCount),
        stripeId = stripeCount > 1 && yrange > 0 ? multiStripeId : singleStripeId,
        i, j;

    if (opts.tolerance >= 0 === false) {
      // by default, use a small tolerance when detecting segment intersections
      // (intended to overcome the effects of floating point rounding errors in geometrical formulas)
      opts.tolerance = getHighPrecisionSnapInterval(bounds.toArray());
    }

    function multiStripeId(y) {
      return Math.floor((stripeCount-1) * (y - ymin) / yrange);
    }

    function singleStripeId(y) {return 0;}
    // Count segments in each stripe
    arcs.forEachSegment(function(id1, id2, xx, yy) {
      var s1 = stripeId(yy[id1]),
          s2 = stripeId(yy[id2]);
      while (true) {
        stripeSizes[s1] = stripeSizes[s1] + 2;
        if (s1 == s2) break;
        s1 += s2 > s1 ? 1 : -1;
      }
    });

    // Allocate arrays for segments in each stripe
    var stripeData = getUint32Array(utils.sum(stripeSizes)),
        offs = 0;
    var stripes = [];
    utils.forEach(stripeSizes, function(stripeSize) {
      var start = offs;
      offs += stripeSize;
      stripes.push(stripeData.subarray(start, offs));
    });
    // Assign segment ids to each stripe
    utils.initializeArray(stripeSizes, 0);

    arcs.forEachSegment(function(id1, id2, xx, yy) {
      var s1 = stripeId(yy[id1]),
          s2 = stripeId(yy[id2]),
          count, stripe;
      while (true) {
        count = stripeSizes[s1];
        stripeSizes[s1] = count + 2;
        stripe = stripes[s1];
        stripe[count] = id1;
        stripe[count+1] = id2;
        if (s1 == s2) break;
        s1 += s2 > s1 ? 1 : -1;
      }
    });

    // Detect intersections among segments in each stripe.
    var raw = arcs.getVertexData(),
        intersections = [],
        arr;
    for (i=0; i<stripeCount; i++) {
      arr = intersectSegments(stripes[i], raw.xx, raw.yy, opts);
      for (j=0; j<arr.length; j++) {
        intersections.push(arr[j]);
      }
    }
    return dedupIntersections(intersections, opts.unique ? getUniqueIntersectionKey : null);
  }


  function sortIntersections(arr) {
    arr.sort(function(a, b) {
      return a.x - b.x || a.y - b.y;
    });
  }



  function dedupIntersections(arr, keyFunction) {
    var index = {};
    var getKey = keyFunction || getIntersectionKey;
    return arr.filter(function(o) {
      var key = getKey(o);
      if (key in index) {
        return false;
      }
      index[key] = true;
      return true;
    });
  }

  // Get an indexable key from an intersection object
  // Assumes that vertex ids of o.a and o.b are sorted
  function getIntersectionKey(o) {
    return o.a.join(',') + ';' + o.b.join(',');
  }

  function getUniqueIntersectionKey(o) {
    return o.x + ',' + o.y;
  }

  // Fast method
  // TODO: measure performance using a range of input data
  function calcSegmentIntersectionStripeCount2(arcs) {
    var segs = arcs.getFilteredPointCount() - arcs.size();
    var stripes = Math.pow(segs, 0.4) * 2;
    return Math.ceil(stripes) || 1;
  }

  // Alternate fast method
  function calcSegmentIntersectionStripeCount(arcs) {
    var segs = arcs.getFilteredPointCount() - arcs.size();
    var stripes = Math.ceil(Math.pow(segs * 10, 0.6) / 40);
    return stripes > 0 ? stripes : 1;
  }

  // Old method calculates average segment length -- slow
  function calcSegmentIntersectionStripeCount_old(arcs) {
    var yrange = arcs.getBounds().height(),
        segLen = getAvgSegment2(arcs)[1], // slow
        count = 1;
    if (segLen > 0 && yrange > 0) {
      count = Math.ceil(yrange / segLen / 20);
    }
    return count || 1;
  }

  // Find intersections among a group of line segments
  //
  // TODO: handle case where a segment starts and ends at the same point (i.e. duplicate coords);
  //
  // @ids: Array of indexes: [s0p0, s0p1, s1p0, s1p1, ...] where xx[sip0] <= xx[sip1]
  // @xx, @yy: Arrays of x- and y-coordinates
  //
  function intersectSegments(ids, xx, yy, optsArg) {
    var lim = ids.length - 2,
        opts = optsArg || {},
        intersections = [],
        tolerance = opts.tolerance, // may be undefined
        s1p1, s1p2, s2p1, s2p2,
        s1p1x, s1p2x, s2p1x, s2p2x,
        s1p1y, s1p2y, s2p1y, s2p2y,
        hit, seg1, seg2, i, j;

    // Sort segments by xmin, to allow efficient exclusion of segments with
    // non-overlapping x extents.
    sortSegmentIds(xx, ids); // sort by ascending xmin

    i = 0;
    while (i < lim) {
      s1p1 = ids[i];
      s1p2 = ids[i+1];
      s1p1x = xx[s1p1];
      s1p2x = xx[s1p2];
      s1p1y = yy[s1p1];
      s1p2y = yy[s1p2];
      // count++;

      j = i;
      while (j < lim) {
        j += 2;
        s2p1 = ids[j];
        s2p1x = xx[s2p1];

        if (s1p2x < s2p1x) break; // x extent of seg 2 is greater than seg 1: done with seg 1
        //if (s1p2x <= s2p1x) break; // this misses point-segment intersections when s1 or s2 is vertical

        s2p1y = yy[s2p1];
        s2p2 = ids[j+1];
        s2p2x = xx[s2p2];
        s2p2y = yy[s2p2];

        // skip segments with non-overlapping y ranges
        if (s1p1y >= s2p1y) {
          if (s1p1y > s2p2y && s1p2y > s2p1y && s1p2y > s2p2y) continue;
        } else {
          if (s1p1y < s2p2y && s1p2y < s2p1y && s1p2y < s2p2y) continue;
        }

        // skip segments that are adjacent in a path (optimization)
        // TODO: consider if this eliminates some cases that should
        // be detected, e.g. spikes formed by unequal segments
        if (s1p1 == s2p1 || s1p1 == s2p2 || s1p2 == s2p1 || s1p2 == s2p2) {
          continue;
        }

        // test two candidate segments for intersection
        hit = geom.segmentIntersection(s1p1x, s1p1y, s1p2x, s1p2y,
            s2p1x, s2p1y, s2p2x, s2p2y, tolerance);
        if (hit) {
          seg1 = [s1p1, s1p2];
          seg2 = [s2p1, s2p2];
          intersections.push(formatIntersection(hit, seg1, seg2, xx, yy));
          if (hit.length == 4) {
            // two collinear segments may have two endpoint intersections
            intersections.push(formatIntersection(hit.slice(2), seg1, seg2, xx, yy));
          }
        }
      }
      i += 2;
    }
    return intersections;

    // @p is an [x, y] location along a segment defined by ids @id1 and @id2
    // return array [i, j] where i and j are the same endpoint ids with i <= j
    // if @p coincides with an endpoint, return the id of that endpoint twice
    function getEndpointIds(id1, id2, p) {
      var i = id1 < id2 ? id1 : id2,
          j = i === id1 ? id2 : id1;
      if (xx[i] == p[0] && yy[i] == p[1]) {
        j = i;
      } else if (xx[j] == p[0] && yy[j] == p[1]) {
        i = j;
      }
      return [i, j];
    }
  }

  function formatIntersection(xy, s1, s2, xx, yy) {
    var x = xy[0],
        y = xy[1],
        a, b;
    s1 = formatIntersectingSegment(x, y, s1[0], s1[1], xx, yy);
    s2 = formatIntersectingSegment(x, y, s2[0], s2[1], xx, yy);
    a = s1[0] < s2[0] ? s1 : s2;
    b = a == s1 ? s2 : s1;
    return {x: x, y: y, a: a, b: b};
  }

  // Receives:
  //   x, y: coordinates of intersection
  //   i, j: two segment endpoints, as indexes in xx and yy arrays
  // Returns:
  //   if x,y falls within the segment, returns ascending indexes
  //   if x,y coincides with an endpoint, returns the id of that endpoint twice
  function formatIntersectingSegment(x, y, i, j, xx, yy) {
    if (xx[i] == x && yy[i] == y) {
      return [i, i];
    }
    if (xx[j] == x && yy[j] == y) {
      return [j, j];
    }
    return i < j ? [i, j] : [j, i];
  }

  var SegmentIntersection = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getIntersectionPoints: getIntersectionPoints,
    findSegmentIntersections: findSegmentIntersections,
    sortIntersections: sortIntersections,
    dedupIntersections: dedupIntersections,
    calcSegmentIntersectionStripeCount2: calcSegmentIntersectionStripeCount2,
    calcSegmentIntersectionStripeCount: calcSegmentIntersectionStripeCount,
    intersectSegments: intersectSegments,
    formatIntersection: formatIntersection,
    formatIntersectingSegment: formatIntersectingSegment
  });

  // Functions for dividing polygons and polygons at points where arc-segments intersect

  // TODO:
  //    Consider inserting cut points on import, when building initial topology
  //    Improve efficiency (e.g. only update ArcCollection once)
  //    Remove junk arcs (collapsed and duplicate arcs) instead of just removing
  //       references to them

  // Divide a collection of arcs at points where segments intersect
  // and re-index the paths of all the layers that reference the arc collection.
  // (in-place)
  function addIntersectionCuts(dataset, _opts) {
    var opts = _opts || {};
    var arcs = dataset.arcs;
    var arcBounds = arcs && arcs.getBounds();
    var snapDist, nodes;
    if (!arcBounds || !arcBounds.hasBounds()) {
      return new NodeCollection([]);
    }

    if (opts.snap_interval) {
      snapDist = convertIntervalParam(opts.snap_interval, getDatasetCRS(dataset));
    } else if (!opts.no_snap && arcBounds.hasBounds()) {
      snapDist = getHighPrecisionSnapInterval(arcBounds.toArray());
    } else {
      snapDist = 0;
    }
    debug('addIntersectionCuts() snap dist:', snapDist);

    // bake-in any simplification (bug fix; before, -simplify followed by dissolve2
    // used to reset simplification)
    arcs.flatten();

    var changed = snapAndCut(dataset, snapDist);
    // Detect topology again if coordinates have changed
    if (changed || opts.rebuild_topology) {
      buildTopology(dataset);
    }

    // Clean shapes by removing collapsed arc references, etc.
    // TODO: consider alternative -- avoid creating degenerate arcs
    // in insertCutPoints()
    dataset.layers.forEach(function(lyr) {
      if (layerHasPaths(lyr)) {
        cleanShapes(lyr.shapes, arcs, lyr.geometry_type);
      }
    });

    // Further clean-up -- remove duplicate and missing arcs
    nodes = cleanArcReferences(dataset);
    return nodes;
  }

  function snapAndCut(dataset, snapDist) {
    var arcs = dataset.arcs;
    var cutOpts = snapDist > 0 ? {} : {tolerance: 0};
    var coordsHaveChanged = false;
    var snapCount, dupeCount, cutCount;
    snapCount = snapCoordsByInterval(arcs, snapDist);
    dupeCount = arcs.dedupCoords();

    // why was topology built here previously????
    // if (snapCount > 0 || dupeCount > 0) {
    //   // Detect topology again if coordinates have changed
    //   internal.buildTopology(dataset);
    // }

    // cut arcs at points where segments intersect
    cutCount = cutPathsAtIntersections(dataset, cutOpts);
    if (cutCount > 0 || snapCount > 0 || dupeCount > 0) {
      coordsHaveChanged = true;
    }
    // perform a second snap + cut pass if needed
    if (cutCount > 0) {
      cutCount = 0;
      snapCount = snapCoordsByInterval(arcs, snapDist);
      arcs.dedupCoords(); // need to do this here?
      if (snapCount > 0) {
        cutCount = cutPathsAtIntersections(dataset, cutOpts);
      }
      if (cutCount > 0) {
        arcs.dedupCoords(); // need to do this here?
        debug('Second-pass vertices added:', cutCount, 'consider third pass?');
      }
    }
    return coordsHaveChanged;
  }


  // Remap any references to duplicate arcs in paths to use the same arcs
  // Remove any unused arcs from the dataset's ArcCollection.
  // Return a NodeCollection
  function cleanArcReferences(dataset) {
    var nodes = new NodeCollection(dataset.arcs);
    var map = findDuplicateArcs(nodes);
    var dropCount;
    if (map) {
      replaceIndexedArcIds(dataset, map);
    }
    dropCount = deleteUnusedArcs(dataset);
    if (dropCount > 0) {
      // rebuild nodes if arcs have changed
      nodes = new NodeCollection(dataset.arcs);
    }
    return nodes;
  }


  // @map an Object mapping old to new ids
  function replaceIndexedArcIds(dataset, map) {
    var remapPath = function(ids) {
      var arcId, absId, id2;
      for (var i=0; i<ids.length; i++) {
        arcId = ids[i];
        absId = absArcId(arcId);
        id2 = map[absId];
        ids[i] = arcId == absId ? id2 : ~id2;
      }
      return ids;
    };
    dataset.layers.forEach(function(lyr) {
      if (layerHasPaths(lyr)) {
        editShapes(lyr.shapes, remapPath);
      }
    });
  }

  function findDuplicateArcs(nodes) {
    var map = new Int32Array(nodes.arcs.size()),
        count = 0,
        i2;
    for (var i=0, n=nodes.arcs.size(); i<n; i++) {
      i2 = nodes.findDuplicateArc(i);
      map[i] = i2;
      if (i != i2) count++;
    }
    return count > 0 ? map : null;
  }

  function deleteUnusedArcs(dataset) {
    var test = getArcPresenceTest2(dataset.layers, dataset.arcs);
    var count1 = dataset.arcs.size();
    var map = dataset.arcs.deleteArcs(test); // condenses arcs
    var count2 = dataset.arcs.size();
    var deleteCount = count1 - count2;
    if (deleteCount > 0) {
      replaceIndexedArcIds(dataset, map);
    }
    return deleteCount;
  }

  // Return a function for updating a path (array of arc ids)
  // @map array generated by insertCutPoints()
  // @arcCount number of arcs in divided collection (kludge)
  function getDividedArcUpdater(map, arcCount) {
    return function(ids) {
      var ids2 = [];
      for (var j=0; j<ids.length; j++) {
        remapArcId2(ids[j], ids2);
      }
      return ids2;
    };

    function remapArcId2(id, ids) {
      var rev = id < 0,
          absId = rev ? ~id : id,
          min = map[absId],
          max = (absId >= map.length - 1 ? arcCount : map[absId + 1]) - 1,
          id2;
      do {
        if (rev) {
          id2 = ~max;
          max--;
        } else {
          id2 = min;
          min++;
        }
        ids.push(id2);
      } while (max - min >= 0);
    }
  }

  // Divides a collection of arcs at points where arc paths cross each other
  // Returns array for remapping arc ids
  function divideArcs(arcs, opts) {
    var points = findClippingPoints(arcs, opts);
    // TODO: avoid the following if no points need to be added
    var map = insertCutPoints(points, arcs);
    // segment-point intersections currently create duplicate points
    // TODO: consider dedup in a later cleanup pass?
    // arcs.dedupCoords();
    return map;
  }

  function cutPathsAtIntersections(dataset, opts) {
    var n = dataset.arcs.getPointCount();
    var map = divideArcs(dataset.arcs, opts);
    var n2 = dataset.arcs.getPointCount();
    remapDividedArcs(dataset, map);
    return n2 - n;
  }

  function remapDividedArcs(dataset, map) {
    var remapPath = getDividedArcUpdater(map, dataset.arcs.size());
    dataset.layers.forEach(function(lyr) {
      if (layerHasPaths(lyr)) {
        editShapes(lyr.shapes, remapPath);
      }
    });
  }

  // Inserts array of cutting points into an ArcCollection
  // Returns array for remapping arc ids
  function insertCutPoints(unfilteredPoints, arcs) {
    var data = arcs.getVertexData(),
        xx0 = data.xx,
        yy0 = data.yy,
        nn0 = data.nn,
        i0 = 0,
        i1 = 0,
        nn1 = [],
        srcArcTotal = arcs.size(),
        map = new Uint32Array(srcArcTotal),
        points = filterSortedCutPoints(sortCutPoints(unfilteredPoints, xx0, yy0), arcs),
        destPointTotal = arcs.getPointCount() + points.length * 2,
        xx1 = new Float64Array(destPointTotal),
        yy1 = new Float64Array(destPointTotal),
        n0, n1, arcLen, p;

    points.reverse(); // reverse sorted order to use pop()
    p = points.pop();

    for (var srcArcId=0, destArcId=0; srcArcId < srcArcTotal; srcArcId++) {
      // start merging an arc
      arcLen = nn0[srcArcId];
      map[srcArcId] = destArcId;
      n0 = 0;
      n1 = 0;
      while (n0 < arcLen) {
        // copy another point
        xx1[i1] = xx0[i0];
        yy1[i1] = yy0[i0];
        i1++;
        n1++;
        while (p && p.i == i0) {
          // interpolate any clip points that fall within the current segment
          xx1[i1] = p.x;
          yy1[i1] = p.y;
          i1++;
          n1++;
          nn1[destArcId++] = n1; // end current arc at intersection
          n1 = 0; // begin new arc
          xx1[i1] = p.x;
          yy1[i1] = p.y;
          i1++;
          n1++;
          p = points.pop();
        }
        n0++;
        i0++;
      }
      nn1[destArcId++] = n1;
    }

    if (i1 != destPointTotal) error("[insertCutPoints()] Counting error");
    arcs.updateVertexData(nn1, xx1, yy1, null);
    return map;
  }

  function convertIntersectionsToCutPoints(intersections, xx, yy) {
    var points = [], ix, a, b;
    for (var i=0, n=intersections.length; i<n; i++) {
      ix = intersections[i];
      a = getCutPoint(ix.x, ix.y, ix.a[0], ix.a[1], xx, yy);
      b = getCutPoint(ix.x, ix.y, ix.b[0], ix.b[1], xx, yy);
      if (a) points.push(a);
      if (b) points.push(b);
    }
    return points;
  }

  // i, j: indexes of segment endpoints in xx, yy, or of a single endpoint
  //   if point x,y falls on an endpoint
  // Assumes: i <= j
  function getCutPoint(x, y, i, j, xx, yy) {
    var ix = xx[i],
        iy = yy[i],
        jx = xx[j],
        jy = yy[j];
    if (j < i || j > i + 1) {
      error("Out-of-sequence arc ids:", i, j);
    }

    // Removed out-of-range check: small out-of-range intersection points are now allowed.
    // (Such points may occur due to fp rounding, when intersections occur along
    // vertical or horizontal segments)
    // if (geom.outsideRange(x, ix, jx) || geom.outsideRange(y, iy, jy)) {
      // return null;
    // }

    // Removed endpoint check: intersecting arcs need to be cut both at vertices
    // and between vertices, so pathfinding functions will work correctly.
    // if (x == ix && y == iy || x == jx && y == jy) {
      // return null;
    // }
    return {x: x, y: y, i: i};
  }

  // Sort insertion points in order of insertion
  // Insertion order: ascending id of first endpoint of containing segment and
  //   ascending distance from same endpoint.
  function sortCutPoints(points, xx, yy) {
    points.sort(function(a, b) {
      if (a.i != b.i) return a.i - b.i;
      return geom.distanceSq(xx[a.i], yy[a.i], a.x, a.y) - geom.distanceSq(xx[b.i], yy[b.i], b.x, b.y);
      // The old code below is no longer reliable, now that out-of-range intersection
      // points are allowed.
      // return Math.abs(a.x - xx[a.i]) - Math.abs(b.x - xx[b.i]) ||
      // Math.abs(a.y - yy[a.i]) - Math.abs(b.y - yy[b.i]);
    });
    return points;
  }

  // Removes duplicate points and arc endpoints
  function filterSortedCutPoints(points, arcs) {
    var filtered = [],
        pointId = 0;
    arcs.forEach2(function(i, n, xx, yy) {
      var j = i + n - 1,
          x0 = xx[i],
          y0 = yy[i],
          xn = xx[j],
          yn = yy[j],
          p, pp;

      while (pointId < points.length && points[pointId].i <= j) {
        p = points[pointId];
        pp = filtered[filtered.length - 1]; // previous point
        if (p.x == x0 && p.y == y0 || p.x == xn && p.y == yn) {
          // clip point is an arc endpoint -- discard
        } else if (pp && pp.x == p.x && pp.y == p.y && pp.i == p.i) {
          // clip point is a duplicate -- discard
        } else {
          filtered.push(p);
        }
        pointId++;
      }
    });
    return filtered;
  }

  function findClippingPoints(arcs, opts) {
    var intersections = findSegmentIntersections(arcs, opts),
        data = arcs.getVertexData();
    return convertIntersectionsToCutPoints(intersections, data.xx, data.yy);
  }

  var IntersectionCuts = /*#__PURE__*/Object.freeze({
    __proto__: null,
    addIntersectionCuts: addIntersectionCuts,
    divideArcs: divideArcs,
    cutPathsAtIntersections: cutPathsAtIntersections,
    remapDividedArcs: remapDividedArcs,
    insertCutPoints: insertCutPoints,
    getCutPoint: getCutPoint,
    sortCutPoints: sortCutPoints,
    filterSortedCutPoints: filterSortedCutPoints,
    findClippingPoints: findClippingPoints
  });

  // Support for timing using T.start() and T.stop()
  var T$1 = {
    stack: [],
    start: function() {
      T$1.stack.push(Date.now());
    },
    stop: function() {
      return (Date.now() - T$1.stack.pop()) + 'ms';
    }
  };

  function tick(msg) {
    var now = Date.now();
    var elapsed = tickTime ? ' - ' + (now - tickTime) + 'ms' : '';
    tickTime = now;
    console.log((msg || '') + elapsed);
  }

  var tickTime = 0;

  // Create a mosaic layer from a dataset (useful for debugging commands like -clean
  //    that create a mosaic as an intermediate data structure)
  // Create additional layers if the "debug" flag is present
  //
  function mosaic(dataset, opts) {
    var layers2 = [];
    var nodes, output;
    if (!dataset.arcs) stop("Dataset is missing path data");
    nodes = addIntersectionCuts(dataset, opts);
    output = buildPolygonMosaic(nodes);
    layers2.push({
      name: 'mosaic',
      shapes: output.mosaic,
      geometry_type: 'polygon'
    });
    if (opts.debug) {
      layers2.push({
        geometry_type: 'polygon',
        name: 'mosaic-enclosure',
        shapes: output.enclosures
      });

      if (output.lostArcs.length > 0) {
        layers2 = layers2.concat(getLostArcLayers(output.lostArcs, nodes.arcs));
      }
    }
    return layers2;

    function getLostArcLayers(lostArcs, arcs) {
      var arcLyr = {geometry_type: 'polyline', name: 'lost-arcs', shapes: []};
      var pointLyr = {geometry_type: 'point', name: 'lost-arc-endpoints', shapes: []};
      var arcData = [];
      var pointData = [];
      lostArcs.forEach(function(arcId) {
        var first = arcs.getVertex(arcId, 0);
        var last = arcs.getVertex(arcId, -1);
        arcData.push({ARCID: arcId});
        arcLyr.shapes.push([[arcId]]);
        pointData.push({ARCID: arcId}, {ARCID: arcId});
        pointLyr.shapes.push([[first.x, first.y]], [[last.x, last.y]]);
      });
      arcLyr.data = new DataTable(arcData);
      pointLyr.data = new DataTable(pointData);
      return [arcLyr, pointLyr];
    }
  }

  // Process arc-node topology to generate a layer of indivisible mosaic "tiles" {mosaic}
  //   ... also return a layer of outer-boundary polygons {enclosures}
  //   ... also return an array of arcs that were dropped from the mosaic {lostArcs}
  //
  // Assumes that the arc-node topology of @nodes NodeCollection meets several
  //    conditions (expected to be true if addIntersectionCuts() has just been run)
  // 1. Arcs only touch at endpoints.
  // 2. The angle between any two segments that meet at a node is never zero.
  //      (this should follow from 1... but may occur due to FP errors)
  // TODO: a better job of handling FP errors
  //
  function buildPolygonMosaic(nodes) {
    T$1.start();
    // Detach any acyclic paths (spikes) from arc graph (these would interfere with
    //    the ring finding operation). This modifies @nodes -- a side effect.
    nodes.detachAcyclicArcs();
    var data = findMosaicRings(nodes);

    // Process CW rings: these are indivisible space-enclosing boundaries of mosaic tiles
    var mosaic = data.cw.map(function(ring) {return [ring];});
    debug('Find mosaic rings', T$1.stop());
    T$1.start();

    // Process CCW rings: these are either holes or enclosure
    // TODO: optimize -- testing CCW path of every island is costly
    var enclosures = [];
    var index = new PathIndex(mosaic, nodes.arcs); // index CW rings to help identify holes
    data.ccw.forEach(function(ring) {
      var id = index.findSmallestEnclosingPolygon(ring);
      if (id > -1) {
        // Enclosed CCW rings are holes in the enclosing mosaic tile
        mosaic[id].push(ring);
      } else {
        // Non-enclosed CCW rings are outer boundaries -- add to enclosures layer
        reversePath(ring);
        enclosures.push([ring]);
      }
    });
    debug(utils.format("Detect holes (holes: %d, enclosures: %d)", data.ccw.length - enclosures.length, enclosures.length), T$1.stop());

    return {mosaic: mosaic, enclosures: enclosures, lostArcs: data.lostArcs};
  }

  function findMosaicRings(nodes) {
    var arcs = nodes.arcs,
        cw = [],
        ccw = [],
        empty = [],
        lostArcs = [];

    var flags = new Uint8Array(arcs.size());
    var findPath = getPathFinder(nodes, useRoute);

    for (var i=0, n=flags.length; i<n; i++) {
      tryPath(i);
      // TODO: consider skipping detection of island ccw paths here (if possible)
      tryPath(~i);
    }
    return {
      cw: cw,
      ccw: ccw,
      empty: empty,
      lostArcs: lostArcs
    };

    function tryPath(arcId) {
      var ring, area;
      if (!routeIsOpen(arcId)) return;
      ring = findPath(arcId);
      if (!ring) {
        // arc is unused, but can not be extended to a complete ring
        lostArcs.push(arcId);
        debug("Dead-end arc:", arcId);
        return;
      }
      area = geom.getPlanarPathArea(ring, arcs);
      if (area > 0) {
        cw.push(ring);
      } else if (area < 0) {
        ccw.push(ring);
      } else {
        empty.push(ring);
      }
    }

    function useRoute(arcId) {
      return routeIsOpen(arcId, true);
    }

    function routeIsOpen(arcId, closeRoute) {
      var absId = absArcId(arcId);
      var bit = absId == arcId ? 1 : 2;
      var isOpen = (flags[absId] & bit) === 0;
      if (closeRoute && isOpen) flags[absId] |= bit;
      return isOpen;
    }
  }

  var PolygonMosaic = /*#__PURE__*/Object.freeze({
    __proto__: null,
    mosaic: mosaic,
    buildPolygonMosaic: buildPolygonMosaic
  });

  // Map positive or negative integer ids to non-negative integer ids
  function IdLookupIndex(n, clearable) {
    var fwdIndex = new Int32Array(n);
    var revIndex = new Int32Array(n);
    var index = this;
    var setList = [];
    utils.initializeArray(fwdIndex, -1);
    utils.initializeArray(revIndex, -1);

    this.setId = function(id, val) {
      if (clearable && !index.hasId(id)) {
        setList.push(id);
      }
      if (id < 0) {
        revIndex[~id] = val;
      } else {
        fwdIndex[id] = val;
      }
    };

    this.clear = function() {
      if (!clearable) {
        error('Index is not clearable');
      }
      setList.forEach(function(id) {
        index.setId(id, -1);
      });
      setList = [];
    };

    this.clearId = function(id) {
      if (!index.hasId(id)) {
        error('Tried to clear an unset id');
      }
      index.setId(id, -1);
    };

    this.hasId = function(id) {
      var val = index.getId(id);
      return val > -1;
    };

    this.getId = function(id) {
      var idx = id < 0 ? ~id : id;
      if (idx >= n) {
        return -1; // TODO: consider throwing an error?
      }
      return id < 0 ? revIndex[idx] : fwdIndex[idx];
    };
  }

  // Associate mosaic tiles with shapes (i.e. identify the groups of tiles that
  //   belong to each shape)
  //
  function PolygonTiler(mosaic, arcTileIndex, nodes, opts) {
    var arcs = nodes.arcs;
    var visitedTileIndex = new IdTestIndex(mosaic.length, true);
    var divide = getHoleDivider(nodes);
    // temp vars
    var currHoles; // arc ids of all holes in shape
    var currShapeId;
    var currRingBbox;
    var tilesInShape; // accumulator for tile ids of tiles in current shape
    var ringIndex = new IdTestIndex(arcs.size(), true);
    var holeIndex = new IdTestIndex(arcs.size(), true);

    // return ids of tiles in shape
    this.getTilesInShape = function(shp, shapeId) {
      var cw = [], ccw = [], retn;
      tilesInShape = [];
      currHoles = [];
      currShapeId = shapeId;
      if (opts.no_holes) {
        divide(shp, cw, ccw);
        // ccw.forEach(internal.reversePath);
        // cw = cw.concat(ccw);
      } else {
        // divide shape into rings and holes (splits self-intersecting rings)
        // TODO: rewrite divide() -- it is a performance bottleneck and can convert
        //   space-filling areas into ccw holes
        divide(shp, cw, ccw);
        ccw.forEach(procShapeHole);
        holeIndex.setIds(currHoles);
      }
      cw.forEach(procShapeRing);
      retn = tilesInShape;
      // reset tmp vars, etc
      tilesInShape = null;
      holeIndex.clear();
      currHoles = null;
      return retn;
    };

    function procShapeHole(path) {
      currHoles = currHoles ? currHoles.concat(path) : path;
    }

    function procShapeRing(path) {
      currRingBbox = arcs.getSimpleShapeBounds2(path);
      ringIndex.setIds(path);
      procArcIds(path);
      ringIndex.clear();
      // allow overlapping rings to visit the same tiles
      visitedTileIndex.clear();
    }

    // optimized version: traversal without recursion (to avoid call stack oflo, excessive gc, etc)
    function procArcIds(ids) {
      var stack = ids.concat();
      var arcId, tileId;
      while (stack.length > 0) {
        arcId = stack.pop();
        tileId = procRingArc(arcId);
        if (tileId >= 0) {
          accumulateTraversibleArcIds(stack, mosaic[tileId]);
        }
      }
    }

    function accumulateTraversibleArcIds(ids, tile) {
      var arcId, ring;
      for (var j=0, n=tile.length; j<n; j++) {
        ring = tile[j];
        for (var i=0, m=ring.length; i<m; i++) {
          arcId = ring[i];
          if (arcIsTraversible(arcId)) {
            ids.push(~arcId);
          }
        }
      }
    }

    function arcIsTraversible(tileArc) {
      var neighborArc = ~tileArc;
      var traversible = !(ringIndex.hasId(tileArc) || ringIndex.hasId(neighborArc) || holeIndex.hasId(tileArc) || holeIndex.hasId(neighborArc));
      return traversible;
    }

    function procRingArc(arcId) {
      var tileId = arcTileIndex.getShapeIdByArcId(arcId);
      if (tileId == -1 || visitedTileIndex.hasId(tileId)) return -1;
      if (arcs.arcIsContained(absArcId(arcId), currRingBbox) === false) {
        // don't cross boundary of the current ring or of any hole in the current shape
        // TODO: this indicates a geometry bug that should be fixed
        debug('Out-of-bounds ring arc', arcId);
        return -1;
      }
      visitedTileIndex.setId(tileId);
      tilesInShape.push(tileId);
      return tileId;
    }
  }

  var PolygonTiler$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    PolygonTiler: PolygonTiler
  });

  function MosaicIndex(lyr, nodes, optsArg) {
    var opts = optsArg || {};
    var shapes = lyr.shapes;
    var divide = getHoleDivider(nodes);
    var mosaic = buildPolygonMosaic(nodes).mosaic;
    // map arc ids to tile ids
    var arcTileIndex = new ShapeArcIndex(mosaic, nodes.arcs);
    // keep track of which tiles have been assigned to shapes
    var fetchedTileIndex = new IdTestIndex(mosaic.length, true);
    // bidirection index of tile ids <=> shape ids
    var tileShapeIndex = new TileShapeIndex(mosaic, opts);
    // assign tiles to shapes
    var shapeTiler = new PolygonTiler(mosaic, arcTileIndex, nodes, opts);
    var weightFunction = null;
    if (!opts.simple && opts.flat) {
      // opts.simple is an optimization when dissolving everything into one polygon
      // using -dissolve2. In this situation, we don't need a weight function.
      // Otherwise, if polygons are being dissolved into multiple groups,
      // we use a function to assign tiles in overlapping areas to a single shape.
      weightFunction = getOverlapPriorityFunction(lyr.shapes, nodes.arcs, opts.overlap_rule);
    }
    this.mosaic = mosaic;
    this.nodes = nodes; // kludge
    this.getSourceIdsByTileId = tileShapeIndex.getShapeIdsByTileId; // expose for -mosaic command
    this.getTileIdsByShapeId = tileShapeIndex.getTileIdsByShapeId;

    // Assign shape ids to mosaic tile shapes.
    shapes.forEach(function(shp, shapeId) {
      var tileIds = shapeTiler.getTilesInShape(shp, shapeId);
      tileShapeIndex.indexTileIdsByShapeId(shapeId, tileIds, weightFunction);
    });

    // ensure each tile is assigned to only one shape
    if (opts.flat) {
      tileShapeIndex.flatten();
    }

    // fill gaps
    // (assumes that tiles have been allocated to shapes and mosaic has been flattened)
    this.removeGaps = function(filter) {
      if (!opts.flat) {
        error('MosaicIndex#removeGaps() should only be called with a flat mosaic');
      }
      var remainingIds = tileShapeIndex.getUnusedTileIds();
      var filledIds = remainingIds.filter(function(tileId) {
        var tile = mosaic[tileId];
        return filter(tile[0]); // test tile ring, ignoring any holes (does this matter?)
      });
      filledIds.forEach(assignTileToAdjacentShape);
      return {
        removed: filledIds.length,
        remaining: remainingIds.length - filledIds.length
      };
    };

    this.getUnusedTiles = function() {
      return tileShapeIndex.getUnusedTileIds().map(tileIdToTile);
    };

    this.getTilesByShapeIds = function(shapeIds) {
      return getTileIdsByShapeIds(shapeIds).map(tileIdToTile);
    };

    function getOverlapPriorityFunction(shapes, arcs, rule) {
      var f;
      if (!rule || rule == 'max-area') {
        f = getAreaWeightFunction(shapes, arcs, false);
      } else if (rule == 'min-area') {
        f = getAreaWeightFunction(shapes, arcs, true);
      } else if (rule == 'max-id') {
        f = function(shapeId) {
          return shapeId; };
      } else if (rule == 'min-id') {
        f = function(shapeId) { return -shapeId; };
      } else {
        stop('Unknown overlap rule:', rule);
      }
      return f;
    }

    function getAreaWeightFunction(shapes, arcs, invert) {
      var index = [];
      var sign = invert ? -1 : 1;
      return function(shpId) {
        var weight;
        if (shpId in index) {
          weight = index[shpId];
        } else {
          weight = sign * Math.abs(geom.getShapeArea(shapes[shpId], arcs));
          index[shpId] = weight;
        }
        return weight;
      };
    }

    function tileIdToTile(id, i) {
      return mosaic[id];
    }

    function assignTileToAdjacentShape(tileId) {
      var ring = mosaic[tileId][0];
      var arcs = nodes.arcs;
      var arcId, neighborShapeId, neighborTileId, arcLen;
      var shapeId = -1, maxArcLen = 0;
      for (var i=0; i<ring.length; i++) {
        arcId = ring[i];
        neighborTileId = arcTileIndex.getShapeIdByArcId(~arcId);
        if (neighborTileId < 0) continue;
        neighborShapeId = tileShapeIndex.getShapeIdByTileId(neighborTileId);
        if (neighborShapeId < 0) continue;
        arcLen = geom.getPathPerimeter([arcId], arcs);
        if (arcLen > maxArcLen) {
          shapeId = neighborShapeId;
          maxArcLen = arcLen;
        }
      }
      if (shapeId > -1) {
        tileShapeIndex.addTileToShape(shapeId, tileId);
      }
    }

    function getTileIdsByShapeIds(shapeIds) {
      var uniqIds = [];
      var tileId, tileIds, i, j;
      for (i=0; i<shapeIds.length; i++) {
        tileIds = tileShapeIndex.getTileIdsByShapeId(shapeIds[i]);
        for (j=0; j<tileIds.length; j++) {
          tileId = tileIds[j];
          // uniqify tile ids (in case the shape contains overlapping rings)
          if (fetchedTileIndex.hasId(tileId)) continue;
          fetchedTileIndex.setId(tileId);
          uniqIds.push(tileId);
        }
      }
      // clearing this index allows duplicate tile ids between calls to this function
      // (should not happen in a typical dissolve)
      fetchedTileIndex.clear();
      return uniqIds;
    }
  }

  // Map arc ids to shape ids, assuming perfect topology
  // (an arcId maps to at most one shape)
  // Supports looking up a shape id using an arc id.
  function ShapeArcIndex(shapes, arcs) {
    var n = arcs.size();
    var index = new IdLookupIndex(n);
    var shapeId;
    shapes.forEach(onShape);

    function onShape(shp, i) {
      shapeId = i;
      shp.forEach(onPart);
    }
    function onPart(path) {
      var arcId;
      for (var i=0, n=path.length; i<n; i++) {
        arcId = path[i];
        index.setId(arcId, shapeId);
      }
    }

    // returns -1 if shape has not been indexed
    this.getShapeIdByArcId = function(arcId) {
      return index.getId(arcId);
    };
  }

  var MosaicIndex$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    MosaicIndex: MosaicIndex,
    ShapeArcIndex: ShapeArcIndex
  });

  // Assumes that arcs do not intersect except at endpoints
  function dissolvePolygonLayer2(lyr, dataset, opts) {
    opts = utils.extend({}, opts);
    if (opts.field) {
      opts.fields = [opts.field]; // support old "field" parameter
    }
    var getGroupId = getCategoryClassifier(opts.fields, lyr.data);
    var groups = groupPolygons2(lyr, getGroupId);
    var shapes2 = dissolvePolygonGroups2(groups, lyr, dataset, opts);
    return composeDissolveLayer(lyr, shapes2, getGroupId, opts);
  }

  function getArcLayer(arcs, name) {
    var records = [];
    var lyr = {
      geometry_type: 'polyline',
      shapes: [],
      name: name
    };
    for (var i=0, n=arcs.size(); i<n; i++) {
      lyr.shapes.push([[i]]);
      records.push({arc_id: i});
    }
    lyr.data = new DataTable(records);
    return lyr;
  }

  function composeMosaicLayer(lyr, shapes2) {
    var records = shapes2.map(function(shp, i) {
      return {tile_id: i};
    });
    return utils.defaults({
      shapes: shapes2,
      data: new DataTable(records)
    }, lyr);
  }

  function groupPolygons2(lyr, getGroupId) {
    return lyr.shapes.reduce(function(groups, shape, shapeId) {
      var groupId = getGroupId(shapeId);
      if (groupId in groups === false) {
        groups[groupId] = [];
      }
      groups[groupId].push(shapeId);
      return groups;
    }, []);
  }

  function getGapRemovalMessage(removed, retained, areaLabel) {
    var msg;
    if (removed > 0 === false) return '';
    return utils.format('Removed %,d / %,d sliver%s using %s',
        removed, removed + retained, utils.pluralSuffix(removed), areaLabel);
  }

  function dissolvePolygonGroups2(groups, lyr, dataset, opts) {
    var arcFilter = getArcPresenceTest(lyr.shapes, dataset.arcs);
    var nodes = new NodeCollection(dataset.arcs, arcFilter);
    var mosaicOpts = {
      flat: !opts.allow_overlaps,
      simple: groups.length == 1,
      overlap_rule: opts.overlap_rule
    };
    var mosaicIndex = new MosaicIndex(lyr, nodes, mosaicOpts);
    var fillGaps = !opts.allow_overlaps; // gap fill doesn't work yet with overlapping shapes
    var cleanupData, filterData;
    if (fillGaps) {
      var sliverOpts = utils.extend({sliver_control: 1}, opts);
      filterData = getSliverFilter(lyr, dataset, sliverOpts);
      cleanupData = mosaicIndex.removeGaps(filterData.filter);
    }
    var pathfind = getRingIntersector(mosaicIndex.nodes);
    var dissolvedShapes = groups.map(function(shapeIds) {
      var tiles = mosaicIndex.getTilesByShapeIds(shapeIds);
      if (opts.tiles) {
        return tiles.reduce(function(memo, tile) {
          return memo.concat(tile);
        }, []);
      }
      return dissolveTileGroup2(tiles, pathfind);
    });
    // convert self-intersecting rings to outer/inner rings, for OGC
    // Simple Features compliance
    dissolvedShapes = fixTangentHoles(dissolvedShapes, pathfind);

    if (fillGaps && !opts.quiet) {
      var msg = getGapRemovalMessage(cleanupData.removed, cleanupData.remaining, filterData.label);
      if (msg) message(msg);
    }
    return dissolvedShapes;
  }

  function dissolveTileGroup2(tiles, pathfind) {
    var rings = [],
        holes = [],
        dissolved, tile;
    for (var i=0, n=tiles.length; i<n; i++) {
      tile = tiles[i];
      rings.push(tile[0]);
      if (tile.length > 1) {
        holes = holes.concat(tile.slice(1));
      }
    }
    dissolved = pathfind(rings.concat(holes), 'dissolve');
    if (dissolved.length > 1) {
      // Commenting-out nesting order repair -- new method should prevent nesting errors
      // dissolved = internal.fixNestingErrors(dissolved, arcs);
    }
    return dissolved.length > 0 ? dissolved : null;
  }

  function fixTangentHoles(shapes, pathfind) {
    var onRing = function(memo, ring) {
      reversePath(ring);
      var fixed = pathfind([ring], 'flatten');
      if (fixed.length > 1) {
        fixed.forEach(reversePath);
        memo = memo.concat(fixed);
      } else {
        memo.push(reversePath(ring));
      }
      return memo;
    };
    return shapes.map(function(rings) {
      if (!rings) return null;
      return rings.reduce(onRing, []);
    });
  }

  var PolygonDissolve2 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    dissolvePolygonLayer2: dissolvePolygonLayer2,
    composeMosaicLayer: composeMosaicLayer,
    dissolvePolygonGroups2: dissolvePolygonGroups2
  });

  // Assumes intersection cuts have been added and duplicated points removed
  // TODO: consider closing undershoots (see mapshaper-undershoots.js)
  function cleanPolylineLayerGeometry(lyr, dataset, opts) {
    var arcs = dataset.arcs;
    var filter = getArcPresenceTest(lyr.shapes, arcs);
    var nodes = new NodeCollection(arcs, filter);
    var arcIndex = new IdLookupIndex(arcs.size(), true);
    lyr.shapes = lyr.shapes.map(function(shp, i) {
      if (!shp) return null;
      // split parts at nodes (where multiple arcs intersect)
      shp = divideShapeAtNodes(shp, nodes);

      // remove multiple references to the same arc within the same part
      // (this could happen if the path doubles back to form a spike)
      // TODO: remove spikes within a single arc
      arcIndex.clear();
      shp = uniqifyArcs(shp, arcIndex);

      // try to combine parts that form a contiguous line
      // (some datasets may use a separate part for each segment)
      arcIndex.clear();
      shp = combineContiguousParts(shp, nodes, arcIndex);
      return shp;
    });
  }

  function uniqifyArcs(shp, index) {
    var shp2 = shp.reduce(function(memo, ids) {
      addUnusedArcs(memo, ids, index);
      return memo;
    }, []);
    return shp2.length > 0 ? shp2 : null;
  }

  function addUnusedArcs(shp, ids, index) {
    var part = [], arcId;
    for (var i=0; i<ids.length; i++) {
      arcId = ids[i];
      if (!index.hasId(arcId)) {
        part.push(arcId);
      } else if (part.length > 0) {
        shp.push(part);
        part = [];
      }
      index.setId(arcId, i);
      index.setId(~arcId, i);
    }
    if (part.length > 0) shp.push(part);
  }


  function divideShapeAtNodes(shp, nodes) {
    var shp2 = [];
    forEachShapePart(shp, onPart);
    return shp2;

    function onPart(ids) {
      var n = ids.length;
      var id, connected;
      var ids2 = [];
      for (var i=0; i<n; i++) {
        // check each segment of the current part (equivalent to a LineString)
        id = ids[i];
        ids2.push(id);
        if (i < n-1 && nodes.getConnectedArcs(id).length > 1) {
          // divide the current part if the front endpoint of the current segment
          // touches any other segment than the next segment in this part
          // TODO: consider not dividing if the intersection does not involve
          // the current feature (ie. it is not a self-intersection).
          shp2.push(ids2);
          ids2 = [];
        }
      }
      if (ids2.length > 0) shp2.push(ids2);
    }
  }

  function combineContiguousParts(parts, nodes, endpointIndex) {
    if (!parts || parts.length < 2) return parts;

    // Index the terminal arcs of this group of polyline parts
    parts.forEach(function(ids, i) {
      var tailId = ~ids[0]; // index the reversed arc (so it points outwards)
      var headId = ids[ids.length - 1];
      // edge case: an endpoint arc is shared by multiple parts
      // only processing the first of such parts, skipping subsequent parts
      // (this should be an exceptional case... should probably investigate
      // why this happens and handle this better)
      if (endpointIndex.hasId(tailId) || endpointIndex.hasId(headId)) {
        error('Indexing error');
      }
      endpointIndex.setId(tailId, i);
      endpointIndex.setId(headId, i);
      procEndpoint(tailId, i);
      procEndpoint(headId, i);
    });

    return parts.filter(function(ids) { return !!ids; });

    function procEndpoint(endpointId, sourcePartId) {
      var joins = 0;
      var partId2 = -1;
      var endpointId2;
      var indexedPartId = endpointIndex.getId(endpointId);
      nodes.forEachConnectedArc(endpointId, function(arcId) {
        if (endpointIndex.hasId(arcId)) {
          partId2 = endpointIndex.getId(arcId);
          endpointId2 = arcId;
        }
        joins++;
      });
      if (joins == 1 && partId2 > -1 && partId2 < sourcePartId) {
        extendPolylinePart(parts, partId2, endpointId2, indexedPartId, endpointId);
        // update indexed part id of joining endpoint
        endpointIndex.setId(endpointId, partId2);
        // update indexed part id of other endpoint
        var ids = parts[indexedPartId];
        var otherEndpointId = getOtherEndpointId(ids, endpointId);
        endpointIndex.setId(otherEndpointId, partId2);
        if (indexedPartId != partId2) {
          parts[indexedPartId] = null;
        }
      }
    }
  }

  function getOtherEndpointId(ids, endpointId) {
    var headId = ~ids[0];
    var tailId = ids[ids.length-1];
    if (endpointId == headId) return tailId;
    else if (endpointId == tailId) return headId;
    error('Indexing error');
  }

  function extendPolylinePart(parts, partId1, endpoint1, partId2, endpoint2) {
    var ids1 = parts[partId1];
    var ids2 = parts[partId2];
    var joinToTail, joinFromTail;
    if (~endpoint1 == ids1[0]) {
      joinToTail = true;
    } else if (endpoint1 == ids1[ids1.length-1]) {
      joinToTail = false;
    } else {
      error('Index error');
    }
    if (~endpoint2 == ids2[0]) {
      joinFromTail = true;
    } else if (endpoint2 == ids2[ids2.length-1]) {
      joinFromTail = false;
    } else {
      error('Index error 2');
    }
    if (!joinFromTail) {
      ids2 = reversePath(ids2.concat());
    }
    if (joinToTail) {
      prependPath(ids1, ids2);
    } else {
      appendPath(ids1, ids2);
    }
  }

  function prependPath(target, source) {
    source = reversePath(source.concat());
    var args = [0, 0].concat(source);
    target.splice.apply(target, args);
  }

  function appendPath(target, source) {
    target.push.apply(target, source);
  }

  cmd.cleanLayers = cleanLayers;

  function cleanLayers(layers, dataset, optsArg) {
    var opts = optsArg || {};
    var deepClean = !opts.only_arcs;
    var pathClean = utils.some(layers, layerHasPaths);
    var nodes;
    if (opts.debug) {
      addIntersectionCuts(dataset, opts);
      return;
    }
    layers.forEach(function(lyr) {
      if (!layerHasGeometry(lyr)) return;
      if (lyr.geometry_type == 'polygon' && opts.rewind) {
        rewindPolygons(lyr, dataset.arcs);
      }
      if (deepClean) {
        if (!nodes) {
          nodes = addIntersectionCuts(dataset, opts);
        }
        if (lyr.geometry_type == 'polygon') {
          cleanPolygonLayerGeometry(lyr, dataset, opts);
        } else if (lyr.geometry_type == 'polyline') {
          cleanPolylineLayerGeometry(lyr, dataset, opts);
        } else if (lyr.geometry_type == 'point') {
          cleanPointLayerGeometry(lyr, dataset, opts);
        }
      }
      if (!opts.allow_empty) {
        cmd.filterFeatures(lyr, dataset.arcs, {remove_empty: true, verbose: opts.verbose});
      }
    });

    if (!opts.no_arc_dissolve && pathClean && dataset.arcs) {
      // remove leftover endpoints within contiguous lines
      dissolveArcs(dataset);
    }
  }

  function cleanPolygonLayerGeometry(lyr, dataset, opts) {
    // clean polygons by apply the 'dissolve2' function to each feature
    var groups = lyr.shapes.map(function(shp, i) {
      return [i];
    });
    lyr.shapes = dissolvePolygonGroups2(groups, lyr, dataset, opts);
  }

  // Remove duplicate points from multipoint geometries
  // TODO: consider checking for invalid coordinates
  function cleanPointLayerGeometry(lyr, dataset, opts) {
    var index, parts;
    lyr.shapes = lyr.shapes.map(function(shp, i) {
      if (!shp || shp.length > 0 === false) {
        return null;
      }
      if (shp.length == 1) {
        return shp; // single part
      }
      // remove duplicate points from multipoint geometry
      index = {};
      parts = [];
      shp.forEach(onPoint);
      if (parts.length === 0) {
        return null;
      }
      return parts;
    });

    function onPoint(p) {
      var key = p.join('~');
      if (key in index) return;
      index[key] = true;
      parts.push(p);
    }
  }

  // Support the opts.flatten option (for removing polygon overlaps)
  cmd.mergeAndFlattenLayers = function(layers, dataset, opts) {
    if (!opts.flatten) return cmd.mergeLayers(layers, opts);
    layers.forEach(function(lyr) {
      requirePolygonLayer(lyr, 'the flatten option requires polygon layers');
    });
    var output = cmd.mergeLayers(layers, opts);
    replaceLayers(dataset, layers, output);
    cleanLayers(output, dataset, {
      overlap_rule: 'max-id' // later shapes get inlaid in earlier shapes
    });
    replaceLayers(dataset, output, layers);
    return output;
  };

  // Merge layers, checking for incompatible geometries and data fields.
  // Assumes that input layers are members of the same dataset (and therefore
  // share the same ArcCollection, if layers have paths).
  cmd.mergeLayers = function(layersArg, opts) {
    var layers = layersArg.filter(getFeatureCount); // ignore empty layers
    var merged = {};
    opts = opts || {};
    if (!layers.length) return null;
    if (layers.length == 1) {
      message('Use the target= option to specify multiple layers for merging');
      return layers.concat();
    }
    merged.data = mergeDataFromLayers(layers, opts);
    merged.name = mergeLayerNames(layers);
    merged.geometry_type = getMergedLayersGeometryType(layers);
    if (merged.geometry_type) {
      merged.shapes = mergeShapesFromLayers(layers);
    }
    if (merged.shapes && merged.data && merged.shapes.length != merged.data.size()) {
      error("Mismatch between geometry and attribute data");
    }
    return [merged];
  };

  function getMergedLayersGeometryType(layers) {
    var geoTypes = utils.uniq(utils.pluck(layers, 'geometry_type'))
      .filter(function(type) {return !!type;}); // ignore null-type layers
    if (geoTypes.length > 1) {
      stop("Incompatible geometry types:", geoTypes.join(', '));
    }
    return geoTypes[0] || null;
  }

  function mergeShapesFromLayers(layers) {
    return layers.reduce(function(memo, lyr) {
      var shapes = lyr.shapes || [];
      var n = getFeatureCount(lyr);
      var i = -1;
      while (++i < n) memo.push(shapes[i] || null); // add null shapes if layer has no shapes
      return memo;
    }, []);
  }

  function mergeDataFromLayers(layers, opts) {
    var allFields = utils.uniq(layers.reduce(function(memo, lyr) {
      return memo.concat(lyr.data ? lyr.data.getFields() : []);
    }, []));
    if (allFields.length === 0) return null; // no data in any fields
    var mergedRecords = layers.reduce(function(memo, lyr) {
      var records = lyr.data ? lyr.data.getRecords() : new DataTable(getFeatureCount(lyr)).getRecords();
      return memo.concat(records);
    }, []);
    var missingFields = findInconsistentFields(allFields, layers);
    handleMissingFields(missingFields, opts);
    checkInconsistentFieldTypes(allFields, layers);
    if (missingFields.length > 0) {
      fixInconsistentFields(mergedRecords);
    }
    return new DataTable(mergedRecords);
  }

  // handle fields that are missing from one or more layers
  // (warn if force-merging, else error)
  function handleMissingFields(missingFields, opts) {
    var msg;
    if (missingFields.length > 0) {
      msg = '[' + missingFields.join(', ') + ']';
      msg = (missingFields.length == 1 ? 'Field ' + msg + ' is missing' : 'Fields ' + msg + ' are missing') + ' from one or more layers';
      if (!opts.force) {
        stop(msg);
      } else if (opts.verbose !== false) {
        message('Warning: ' + msg);
      }
    }
  }

  function findInconsistentFields(allFields, layers) {
    var missingFields = utils.uniq(layers.reduce(function(memo, lyr) {
      return memo.concat(utils.difference(allFields, lyr.data ? lyr.data.getFields() : []));
    }, []));
    return missingFields;
  }

  // check for fields with incompatible data types (e.g. number, string)
  function checkInconsistentFieldTypes(fields, layers) {
    fields.forEach(function(key) {
      var types = findFieldTypes(key, layers);
      if (types.length > 1) {
        stop("Inconsistent data types in \"" + key + "\" field:", types.join(', '));
      }
    });
  }

  function findFieldTypes(key, layers) {
    // ignores empty-type fields
    return layers.reduce(function(memo, lyr) {
      var type = lyr.data ? getColumnType(key, lyr.data.getRecords()) : null;
      if (type && memo.indexOf(type) == -1) {
        memo.push(type);
      }
      return memo;
    }, []);
  }

  function mergeLayerNames(layers) {
    return layers.reduce(function(memo, lyr) {
      if (memo === null) {
        memo = lyr.name || null;
      } else if (memo && lyr.name) {
        memo = utils.mergeNames(memo, lyr.name);
      }
      return memo;
    }, null) || '';
  }

  var GeoJSON = {};

  GeoJSON.ID_FIELD = "FID"; // default field name of imported *JSON feature ids

  GeoJSON.typeLookup = {
    LineString: 'polyline',
    MultiLineString: 'polyline',
    Polygon: 'polygon',
    MultiPolygon: 'polygon',
    Point: 'point',
    MultiPoint: 'point'
  };

  GeoJSON.translateGeoJSONType = function(type) {
    return GeoJSON.typeLookup[type] || null;
  };

  GeoJSON.pathIsRing = function(coords) {
    var first = coords[0],
        last = coords[coords.length - 1];
    // TODO: consider detecting collapsed rings
    return coords.length >= 4 && first[0] == last[0] && first[1] == last[1];
  };

  GeoJSON.toFeature = function(obj, properties) {
    var type = obj ? obj.type : null;
    var feat;
    if (type == 'Feature') {
      feat = obj;
    } else if (type in GeoJSON.typeLookup) {
      feat = {
        type: 'Feature',
        geometry: obj,
        properties: properties || null
      };
    } else {
      feat = {
        type: 'Feature',
        geometry: null,
        properties: properties || null
      };
    }
    return feat;
  };

  // switch to RFC 7946-compatible output (while retaining the original export function,
  // so numerous tests will continue to work)
  function exportGeoJSON2(dataset, opts) {
    opts = utils.extend({}, opts);
    opts.v2 = !opts.gj2008; // use RFC 7946 as the default
    return exportGeoJSON(dataset, opts);
  }

  function exportGeoJSON(dataset, opts) {
    opts = opts || {};
    var extension = opts.extension || "json";
    var layerGroups, warn;

    // Apply coordinate precision
    // rfc7946 flag is deprecated (default output is now RFC 7946 compatible)
    // the flag is used here to preserve backwards compatibility
    // (the rfc7946 flag applies a default precision threshold, even though rounding
    // coordinates is only a recommendation, not a requirement of RFC 7946)
    if (opts.precision || opts.rfc7946) {
      dataset = copyDatasetForExport(dataset);
      setCoordinatePrecision(dataset, opts.precision || 0.000001);
    }

    if (opts.v2 || opts.rfc7946) {
      warn = getRFC7946Warnings(dataset);
      if (warn) message(warn);
    }

    if (opts.file) {
      // Override default output extension if output filename is given
      extension = getFileExtension(opts.file);
    }
    if (opts.combine_layers) {
      layerGroups = [dataset.layers];
    } else {
      layerGroups = dataset.layers.map(function(lyr) {
        return [lyr];
      });
    }
    return layerGroups.map(function(layers) {
      // Use common part of layer names if multiple layers are being merged
      var name = mergeLayerNames(layers) || 'output';
      var d = utils.defaults({layers: layers}, dataset);
      return {
        content: exportDatasetAsGeoJSON(d, opts, 'buffer'),
        filename: name + '.' + extension
      };
    });
  }

  // Return an array of Features or Geometries as objects or strings
  //
  function exportLayerAsGeoJSON(lyr, dataset, opts, asFeatures, ofmt) {
    var properties = exportProperties(lyr.data, opts),
        shapes = lyr.shapes,
        ids = exportIds(lyr.data, opts),
        items, stringify;

    if (opts.ndjson) {
      stringify = stringifyAsNDJSON;
    } else if (opts.prettify) {
      stringify = getFormattedStringify(['bbox', 'coordinates']);
    } else {
      stringify = JSON.stringify;
    }

    if (properties && shapes && properties.length !== shapes.length) {
      error("Mismatch between number of properties and number of shapes");
    }

    return (shapes || properties || []).reduce(function(memo, o, i) {
      var shape = shapes ? shapes[i] : null,
          exporter = GeoJSON.exporters[lyr.geometry_type],
          geom = shape ? exporter(shape, dataset.arcs, opts) : null,
          obj = null;
      if (asFeatures) {
        obj = GeoJSON.toFeature(geom, properties ? properties[i] : null);
        if (ids) {
          obj.id = ids[i];
        }
      } else if (!geom) {
        return memo; // don't add null objects to GeometryCollection
      } else {
        obj = geom;
      }
      if (ofmt) {
        // stringify features as soon as they are generated, to reduce the
        // number of JS objects in memory (so larger files can be exported)
        obj = stringify(obj);
        if (ofmt == 'buffer') {
          obj = encodeString(obj, 'utf8');
          // obj = stringToBuffer(obj);
          // obj = new Buffer(obj, 'utf8');
        }
      }
      memo.push(obj);
      return memo;
    }, []);
  }


  function getRFC7946Warnings(dataset) {
    var P = getDatasetCRS(dataset);
    var str;
    if (!P || !isLatLngCRS(P)) {
      str = 'RFC 7946 warning: non-WGS84 GeoJSON output.';
      if (P) str += ' Tip: use "-proj wgs84" to convert.';
    }
    return str;
  }

  function getDatasetBbox(dataset, rfc7946) {
    var P = getDatasetCRS(dataset),
        wrapped = rfc7946 && P && isLatLngCRS(P),
        westBounds = new Bounds(),
        eastBounds = new Bounds(),
        mergedBounds, gutter, margins, bbox;

    dataset.layers.forEach(function(lyr) {
      if (layerHasPaths(lyr)) {
        traversePaths(lyr.shapes, null, function(o) {
          var bounds = dataset.arcs.getSimpleShapeBounds(o.arcs);
          (bounds.centerX() < 0 ? westBounds : eastBounds).mergeBounds(bounds);
        });
      } else if (layerHasPoints(lyr)) {
        forEachPoint(lyr.shapes, function(p) {
          (p[0] < 0 ? westBounds : eastBounds).mergePoint(p[0], p[1]);
        });
      }
    });
    mergedBounds = (new Bounds()).mergeBounds(eastBounds).mergeBounds(westBounds);
    if (mergedBounds.hasBounds()) {
      bbox = mergedBounds.toArray();
    }
    if (wrapped && eastBounds.hasBounds() && westBounds.hasBounds()) {
      gutter = eastBounds.xmin - westBounds.xmax;
      margins = 360 + westBounds.xmin - eastBounds.xmax;
      if (gutter > 0 && gutter > margins) {
        bbox[0] = eastBounds.xmin;
        bbox[2] = westBounds.xmax;
      }
    }
    return bbox || null;
  }

  function exportDatasetAsGeoJSON(dataset, opts, ofmt) {
    var geojson = {};
    var layers = dataset.layers;
    var useFeatures = useFeatureCollection(layers, opts);
    var collection, bbox;

    if (useFeatures) {
      geojson.type = 'FeatureCollection';
    } else {
      geojson.type = 'GeometryCollection';
    }

    if (opts.gj2008) {
      preserveOriginalCRS(dataset, geojson);
    }

    if (opts.bbox) {
      bbox = getDatasetBbox(dataset, opts.rfc7946 || opts.v2);
      if (bbox) {
        geojson.bbox = bbox;
      }
    }

    collection = layers.reduce(function(memo, lyr, i) {
      var items = exportLayerAsGeoJSON(lyr, dataset, opts, useFeatures, ofmt);
      return memo.length > 0 ? memo.concat(items) : items;
    }, []);

    if (opts.geojson_type == 'Feature' && collection.length == 1) {
      return collection[0];
    } else if (opts.ndjson) {
      return GeoJSON.formatCollectionAsNDJSON(collection);
    } else if (ofmt) {
      return GeoJSON.formatCollection(geojson, collection);
    } else {
      geojson[collectionName(geojson.type)] = collection;
      return geojson;
    }
  }

  function collectionName(type) {
    if (type == 'FeatureCollection') return 'features';
    if (type == 'GeometryCollection') return 'geometries';
    error('Invalid collection type:', type);
  }

  // collection: an array of Buffers, one per feature
  GeoJSON.formatCollectionAsNDJSON = function(collection) {
    var delim = utils.createBuffer('\n', 'utf8');
    var parts = collection.reduce(function(memo, buf, i) {
      if (i > 0) memo.push(delim);
      memo.push(buf);
      return memo;
    }, []);
    return Buffer.concat(parts);
  };

  // collection: an array of individual GeoJSON Features or geometries as strings or buffers
  GeoJSON.formatCollection = function(container, collection) {
    var head = JSON.stringify(container).replace(/\}$/, ', "' + collectionName(container.type) + '": [\n');
    var tail = '\n]}';
    if (utils.isString(collection[0])) {
      return head + collection.join(',\n') + tail;
    }
    // assume buffers
    return GeoJSON.joinOutputBuffers(head, tail, collection);
  };

  GeoJSON.joinOutputBuffers = function(head, tail, collection) {
    var comma = utils.createBuffer(',\n', 'utf8');
    var parts = collection.reduce(function(memo, buf, i) {
      if (i > 0) memo.push(comma);
      memo.push(buf);
      return memo;
    }, [utils.createBuffer(head, 'utf8')]);
    parts.push(utils.createBuffer(tail, 'utf8'));
    return Buffer.concat(parts);
  };

  // export GeoJSON or TopoJSON point geometry
  GeoJSON.exportPointGeom = function(points, arcs) {
    var geom = null;
    if (points.length == 1) {
      geom = {
        type: "Point",
        coordinates: points[0]
      };
    } else if (points.length > 1) {
      geom = {
        type: "MultiPoint",
        coordinates: points
      };
    }
    return geom;
  };

  GeoJSON.exportLineGeom = function(ids, arcs) {
    var obj = exportPathData(ids, arcs, "polyline");
    if (obj.pointCount === 0) return null;
    var coords = obj.pathData.map(function(path) {
      return path.points;
    });
    return coords.length == 1 ? {
      type: "LineString",
      coordinates: coords[0]
    } : {
      type: "MultiLineString",
      coordinates: coords
    };
  };

  GeoJSON.exportPolygonGeom = function(ids, arcs, opts) {
    var obj = exportPathData(ids, arcs, "polygon");
    if (obj.pointCount === 0) return null;
    var groups = groupPolygonRings(obj.pathData, arcs, opts.invert_y);
    // invert_y is used internally for SVG generation
    // mapshaper's internal winding order is the opposite of RFC 7946
    var reverse = (opts.rfc7946 || opts.v2) && !opts.invert_y;
    var coords = groups.map(function(paths) {
      return paths.map(function(path) {
        if (reverse) path.points.reverse();
        return path.points;
      });
    });
    return coords.length == 1 ? {
      type: "Polygon",
      coordinates: coords[0]
    } : {
      type: "MultiPolygon",
      coordinates: coords
    };
  };

  GeoJSON.exporters = {
    polygon: GeoJSON.exportPolygonGeom,
    polyline: GeoJSON.exportLineGeom,
    point: GeoJSON.exportPointGeom
  };

  // To preserve some backwards compatibility with old-style GeoJSON files,
  // pass through any original CRS object if the crs has not been set by mapshaper
  // jsonObj: a top-level GeoJSON or TopoJSON object
  //
  function preserveOriginalCRS(dataset, jsonObj) {
    var info = dataset.info || {};
    if (!info.crs && 'input_geojson_crs' in info) {
      // use input geojson crs if available and coords have not changed
      jsonObj.crs = info.input_geojson_crs;

    }

    // Removing the following (seems ineffectual at best)
    // else if (info.crs && !isLatLngCRS(info.crs)) {
    //   // Setting output crs to null if coords have been projected
    //   // "If the value of CRS is null, no CRS can be assumed"
    //   // source: http://geojson.org/geojson-spec.html#coordinate-reference-system-objects
    //   jsonObj.crs = null;
    // }
  }

  function useFeatureCollection(layers, opts) {
    var type = opts.geojson_type || '';
    if (type == 'Feature' || type == 'FeatureCollection') {
      return true;
    } else if (type == 'GeometryCollection') {
      return false;
    } else if (type) {
      stop("Unsupported GeoJSON type:", opts.geojson_type);
    }
    // default is true iff layers contain attributes
    return utils.some(layers, function(lyr) {
      var fields = lyr.data ? lyr.data.getFields() : [];
      var haveData = useFeatureProperties(fields, opts);
      var haveId = !!getIdField(fields, opts);
      return haveData || haveId;
    });
  }

  function useFeatureProperties(fields, opts) {
    return !(opts.drop_table || opts.cut_table || fields.length === 0 ||
        fields.length == 1 && fields[0] == GeoJSON.ID_FIELD);
  }

  function exportProperties(table, opts) {
    var fields = table ? table.getFields() : [],
        idField = getIdField(fields, opts),
        properties, records;
    if (!useFeatureProperties(fields, opts)) {
      return null;
    }
    records = table.getRecords();
    if (idField == GeoJSON.ID_FIELD) {// delete default id field, not user-set fields
      properties = records.map(function(rec) {
        rec = utils.extend({}, rec); // copy rec;
        delete rec[idField];
        return rec;
      });
    } else {
      properties = records;
    }
    return properties;
  }

  // @opt value of id-field option (empty, string or array of strings)
  // @fields array
  function getIdField(fields, opts) {
    var ids = [];
    var opt = opts.id_field;
    if (utils.isString(opt)) {
      ids.push(opt);
    } else if (utils.isArray(opt)) {
      ids = opt;
    }
    ids.push(GeoJSON.ID_FIELD); // default id field
    return utils.find(ids, function(name) {
      return utils.contains(fields, name);
    });
  }

  function exportIds(table, opts) {
    var fields = table ? table.getFields() : [],
        idField = getIdField(fields, opts);
    if (!idField) return null;
    return table.getRecords().map(function(rec) {
      return idField in rec ? rec[idField] : null;
    });
  }

  var GeojsonExport = /*#__PURE__*/Object.freeze({
    __proto__: null,
    'default': GeoJSON,
    exportGeoJSON2: exportGeoJSON2,
    exportGeoJSON: exportGeoJSON,
    exportLayerAsGeoJSON: exportLayerAsGeoJSON,
    getRFC7946Warnings: getRFC7946Warnings,
    getDatasetBbox: getDatasetBbox,
    exportDatasetAsGeoJSON: exportDatasetAsGeoJSON,
    preserveOriginalCRS: preserveOriginalCRS,
    useFeatureCollection: useFeatureCollection,
    exportProperties: exportProperties,
    getIdField: getIdField,
    exportIds: exportIds
  });

  var furnitureRenderers = {};

  // @lyr a layer in a dataset
  function layerHasFurniture(lyr) {
    var type = getFurnitureLayerType(lyr);
    return !!type && (type in furnitureRenderers);
  }

  // @mapLayer a map layer object
  function isFurnitureLayer(mapLayer) {
    return !!mapLayer.furniture;
  }

  // @lyr dataset layer
  function getFurnitureLayerType(lyr) {
    var rec = lyr.data && lyr.data.getReadOnlyRecordAt(0);
    return rec && rec.type || null;
  }

  function getFurnitureLayerData(lyr) {
    return lyr.data && lyr.data.getReadOnlyRecordAt(0);
  }

  function importFurniture(d, frame) {
    var renderer = furnitureRenderers[d.type];
    if (!renderer) {
      stop('Missing renderer for', d.type, 'element');
    }
    return renderer(d, frame) || [];
  }

  var Furniture = /*#__PURE__*/Object.freeze({
    __proto__: null,
    furnitureRenderers: furnitureRenderers,
    layerHasFurniture: layerHasFurniture,
    isFurnitureLayer: isFurnitureLayer,
    getFurnitureLayerType: getFurnitureLayerType,
    getFurnitureLayerData: getFurnitureLayerData,
    importFurniture: importFurniture
  });

  // Apply rotation, scale and/or shift to some or all of the features in a dataset
  //
  cmd.affine = function(targetLayers, dataset, opts) {
    // Need to separate the targeted shapes from any other shapes that share
    // the same topology. So we duplicate any arcs that are shared by the targeted
    // shapes and their topological neighbors and remap arc references in the
    // neighbors to point to the copies.
    // TODO: explore alternative: if some arcs are shared between transformed and
    //   non-transformed shapes, first remove topology, then tranform, then rebuild topology
    //
    var rotateArg = opts.rotate || 0;
    var scaleArg = opts.scale || 1;
    var shiftArg = opts.shift ? convertIntervalPair(opts.shift, getDatasetCRS(dataset)) : [0, 0];
    var arcs = dataset.arcs;
    var targetShapes = [];
    var otherShapes = [];
    var targetPoints = [];
    var targetFlags, otherFlags, transform, transformOpts;
    dataset.layers.filter(layerHasGeometry).forEach(function(lyr) {
      var hits = [],
          misses = [],
          test;
      if (targetLayers.indexOf(lyr) == -1) {
        misses = lyr.shapes;
      } else if (opts.where) {
        test = compileValueExpression(opts.where, lyr, dataset.arcs);
        lyr.shapes.forEach(function(shp, i) {
          (test(i) ? hits : misses).push(shp);
        });
      } else {
        hits = lyr.shapes;
      }
      if (lyr.geometry_type == 'point') {
        targetPoints = targetPoints.concat(hits);
      } else {
        targetShapes = targetShapes.concat(hits);
        otherShapes = otherShapes.concat(misses);
      }
    });
    var anchorArg = getAffineAnchor({arcs: dataset.arcs, layers: [{
      geometry_type: 'point', shapes: targetPoints}, {geometry_type: 'polyline',
      shapes: targetShapes}]}, opts);
    transform = getAffineTransform(rotateArg, scaleArg, shiftArg, anchorArg);
    if (targetShapes.length > 0) {
      targetFlags = new Uint8Array(arcs.size());
      otherFlags = new Uint8Array(arcs.size());
      countArcsInShapes(targetShapes, targetFlags);
      if (otherShapes.length > 0) {
        countArcsInShapes(otherShapes, otherFlags);
        applyArrayMask(otherFlags, targetFlags);
        dataset.arcs = duplicateSelectedArcs(otherShapes, arcs, otherFlags);
      }
      dataset.arcs.transformPoints(function(x, y, arcId) {
        if (arcId < targetFlags.length && targetFlags[arcId] > 0) {
          return transform(x, y);
        }
      });
    }
    forEachPoint(targetPoints, function(p) {
      var p2 = transform(p[0], p[1]);
      p[0] = p2[0];
      p[1] = p2[1];
    });
  };

  function getAffineAnchor(dataset, opts) {
    var anchor, bounds;
    if (opts.anchor) {
      anchor = opts.anchor;
    } else {
      // get bounds of selected shapes to calculate center of rotation/scale
      bounds = getDatasetBounds(dataset);
      anchor = [bounds.centerX(), bounds.centerY()];
    }
    return anchor;
  }

  // TODO: handle problems with unprojected datasets
  //   option 1: don't allow affine transformation of unprojected data
  //   option 2: error if transformed data exceeds valid coordinate range
  // source: http://mathworld.wolfram.com/AffineTransformation.html
  function getAffineTransform(rotation, scale, shift, anchor) {
    var angle = rotation * Math.PI / 180;
    var a = scale * Math.cos(angle);
    var b = -scale * Math.sin(angle);
    return function(x, y) {
      var x2 = a * (x - anchor[0]) - b * (y - anchor[1]) + shift[0] + anchor[0];
      var y2 = b * (x - anchor[0]) + a * (y - anchor[1]) + shift[1] + anchor[1];
      return [x2, y2];
    };
  }

  function applyArrayMask(destArr, maskArr) {
    for (var i=0, n=destArr.length; i<n; i++) {
      if (maskArr[i] === 0) destArr[i] = 0;
    }
  }

  function duplicateSelectedArcs(shapes, arcs, flags) {
    var arcCount = 0;
    var vertexCount = 0;
    var data = arcs.getVertexData();
    var xx = [], yy = [], nn = [], map = [], n;
    for (var i=0, len=flags.length; i<len; i++) {
      if (flags[i] > 0) {
        map[i] = arcs.size() + arcCount;
        n = data.nn[i];
        utils.copyElements(data.xx, data.ii[i], xx, vertexCount, n);
        utils.copyElements(data.yy, data.ii[i], yy, vertexCount, n);
        nn.push(n);
        vertexCount += n;
        arcCount++;
      }
    }
    forEachArcId(shapes, function(id) {
      var absId = absArcId(id);
      if (flags[absId] > 0) {
        return id < 0 ? ~map[absId] : map[absId];
      }
    });
    return mergeArcs([arcs, new ArcCollection(nn, xx, yy)]);
  }

  var roundCoord$2 = getRoundingFunction(0.01);

  function stringifyVertex(p) {
    return ' ' + roundCoord$2(p[0]) + ' ' + roundCoord$2(p[1]);
  }

  function stringifyCP(p) {
    return ' ' + roundCoord$2(p[2]) + ' ' + roundCoord$2(p[3]);
  }

  function isCubicCtrl(p) {
    return p.length > 2 && p[2] == 'C';
  }

  function stringifyLineStringCoords(coords) {
    if (coords.length === 0) return '';
    var d = 'M';
    var fromCurve = false;
    var p, i, n;
    for (i=0, n=coords.length; i<n; i++) {
      p = coords[i];
      if (isCubicCtrl(p)) {
        // TODO: add defensive check
        d += ' C' + stringifyVertex(p) + stringifyVertex(coords[++i]) + stringifyVertex(coords[++i]);
        fromCurve = true;
      } else if (fromCurve) {
        d += ' L' + stringifyVertex(p);
        fromCurve = false;
      } else {
        d += stringifyVertex(p);
      }
    }
    return d;
  }

  function stringifyBezierArc(coords) {
    var p1 = coords[0],
        p2 = coords[1];
    return 'M' + stringifyVertex(p1) + ' C' + stringifyCP(p1) +
            stringifyCP(p2) + stringifyVertex(p2);
  }

  var SvgPathUtils = /*#__PURE__*/Object.freeze({
    __proto__: null,
    stringifyLineStringCoords: stringifyLineStringCoords
  });

  /* example patterns
  hatches 1px black 1px red 1px white
  1px black 1px red 1px white // same as above (hatches is default)
  45deg 2px black 2px red     // hatch direction
  dots 2px black 5px white    // 2px black dots with 5px spacing on white
  dots 2px blue 2px red 5px white  // blue and red alternating dots
  */
  function parsePattern(str) {
    if (!str) return null;
    var parts = splitPattern(str);
    var first = parts[0] || '';
    var obj = null;
    // accept variations on type names (dot, dots, square, squares, hatch, hatches, hatched)
    if (first.startsWith('dot')) {
      parts[0] = 'dots';
      obj = parseDots(parts, str);
    } else if (first.startsWith('square')) {
      parts[0] = 'squares';
      obj = parseDots(parts, str);
    } else if (first.startsWith('hatch')) {
      parts[0] = 'hatches';
      obj = parseHatches(parts, str);
    } else if (first.startsWith('dash')) {
      obj = parseDashes(parts, str);
    } else if (!isNaN(parseFloat(first))) {
      parts.unshift('hatches');
      obj = parseHatches(parts, str); // hatches is the default, name can be omitted
    }
    if (!obj) {
      // consider
      message('Invalid pattern, ignoring:', str);
    }
    return obj;
  }

  function parseDashes(parts, str) {
    // format:
    // "dashes" dash-len dash-space width color1 [color2...] space bg-color
    // examples:
    // dashes 4px 3px 1px black 4px white
    var type = parts.shift();
    var colors = [];
    var background = parts.pop();
    var spacing = parseInt(parts.pop());
    var tmp;
    while (parts.length > 0) {
      tmp = parts.pop();
      if (isSize(tmp)) {
        parts.push(tmp);
        break;
      } else {
        colors.push(tmp);
      }
    }
    var width = parseInt(parts.pop());
    var dashes = [parseInt(parts.pop()), parseInt(parts.pop())].reverse();
    var rotation = 45;
    if (parts.length > 0) {
      rotation = parseInt(parts.pop());
    }
    if (parts.length > 0) {
      return null;
    }
    if (width > 0 === false) return null;
    return {
      type: 'dashes',
      tileSize: [colors.length * (width + spacing), utils.sum(dashes)],
      colors: colors,
      width: width,
      dashes: dashes,
      spacing: spacing,
      background: background,
      rotation: rotation
    };
  }

  function parseHatches(parts, str) {
    // format:
    // [hatches] [rotation] width1 color1 [width2 color2 ...]
    // examples:
    // 1px red 1px white 1px black
    // -45deg 3 #eee 3 rgb(0,0,0)
    var type = parts.shift();
    var rot = parts.length % 2 == 1 ? parseInt(parts.shift()) : 45, // default is 45
        colors = [], widths = [], a, b;
    for (var i=0; i<parts.length; i+=2) {
      widths.push(parseInt(parts[i]));
      colors.push(parts[i+1]);
    }
    if (Math.min.apply(null, widths) > 0 === false) return null;
    return {
      tileSize: [utils.sum(widths), 10],
      type: 'hatches',
      colors: colors,
      widths: widths,
      rotation: rot
    };
  }

  function isSize(str) {
    return parseInt(str) > 0;
  }

  function parseDots(parts, str) {
    // format:
    // "dots"|"squares" [rotation] size color1 [color2 ...] spacing bg-color
    // examples:
    // dots 45deg 2px red blue 5px white
    // squares 3px black 1px white
    var colors = [];
    var type = parts.shift();
    var rot = 0;
    if (isSize(parts[1])) { // if rotation is present, there are two numbers
      rot = parseInt(parts.shift());
    }
    var size = parseInt(parts.shift());
    var bg = parts.pop();
    var spacing = parseInt(parts.pop());
    while (parts.length > 0) {
      colors.push(parts.shift());
    }
    if (size > 0 === false || spacing >= 0 === false) return null;
    if (colors.length === 0) return null;
    var side = colors.length * (size + spacing);
    return {
      type: type,
      tileSize: [side, side],
      colors: colors,
      size: size,
      spacing: spacing,
      background: bg,
      rotation: rot
    };
  }

  function splitPattern(str) {
    // split apart space and comma-delimited tokens
    // ... but don't split rgb(...) colors
    var splitRxp = /[, ]+(?![^(]*\))/;
    return String(str).trim().split(splitRxp);
  }

  function getHashId(str) {
    return ('hash_' + str).replace(/[()# ,_]+/g, '_'); // replace some chars that occur in colors
  }

  // properties: properties object of a path data object (prior to conversion to SVG)
  // defs: array of definition objects
  //
  function convertFillPattern(properties, defs) {
    var hatchStr = properties['fill-pattern'];
    var hashId = getHashId(hatchStr);
    var hash = utils.find(defs, function(o) { return o.id == hashId; });
    delete properties['fill-pattern'];
    if (!hash) {
      hash = makeSVGPatternFill(hatchStr, hashId);
      if (!hash) return;
      defs.push(hash);
    }
    properties.fill = hash.href;
  }

  function makeSVGPatternFill(str, id) {
    var o = parsePattern(str);
    var svg;
    if (!o) return null;
    if (o.type == 'hatches') {
      svg = makeHatchPatternSVG(o);
    } else if (o.type == 'dots' || o.type == 'squares') {
      svg = makeDotPatternSVG(o);
    } else if (o.type == 'dashes') {
      svg = makeDashPatternSVG(o);
    }
    return {
      svg: wrapSVGPattern(o, id, svg),
      id: id,
      href: `url(#${ id })`
    };
  }

  function wrapSVGPattern(o, id, str) {
    var w = o.tileSize[0];
    var h = o.tileSize[1];
    var svg = `<pattern id="${id}" patternUnits="userSpaceOnUse" width="${ w }" height="${ h }" patternTransform="rotate(${ o.rotation })">`;
    if (o.background) {
      svg += `<rect x="0" y="0" width="${ w }" height="${ h }" fill="${ o.background }"></rect>`;
    }
    return svg + str + '</pattern>';
  }

  function makeDashPatternSVG(o) {
    var svg = '';
    for (var i=0, x=0; i<o.colors.length; i++) {
      svg += `<rect x="${ x }" y="0" width="${ o.width }" height="${ o.dashes[0] }" fill="${ o.colors[i] }"></rect>`;
      x += o.width + o.spacing;
    }
    return svg;
  }

  function makeHatchPatternSVG(o) {
    var h = o.tileSize[1];
    var svg = '';
    for (var i=0, x=0; i<o.widths.length; i++) {
      svg += `<rect x="${ x }" y="0" width="${ o.widths[i] }" height="${ h }" fill="${ o.colors[i] }"></rect>`;
      x += o.widths[i];
    }
    return svg;
  }

  function makeDotPatternSVG(o) {
    var dotSize = o.size;
    var colorCount = o.colors.length;
    var dotDist = dotSize + o.spacing;
    var dotsPerTile = colorCount * colorCount;
    var makeSymbol = o.type == 'squares' ? makeSquare : makeCircle$1;
    var svg = '';
    for (var i=0, x=0, y=0; i<dotsPerTile; i++) {
      svg += makeSymbol(x, y, dotSize, o.colors[(i + Math.floor(i / colorCount)) % colorCount]);
      x = ((i + 1) % colorCount) * dotDist;
      if (x === 0) y += dotDist;
    }
    return svg;
  }

  function makeCircle$1(x, y, size, fill) {
    const r = size / 2;
    return `<circle cx="${x + r}" cy="${y + r}" r="${r}" fill="${ fill }"></circle>`;
  }

  function makeSquare(x, y, size, fill) {
    return `<rect x="${x}" y="${y}" width="${ size }" height="${ size }" fill="${ fill }"></rect>`;
  }

  var SvgHatch = /*#__PURE__*/Object.freeze({
    __proto__: null,
    parsePattern: parsePattern,
    parseDashes: parseDashes,
    parseHatches: parseHatches,
    parseDots: parseDots,
    convertFillPattern: convertFillPattern
  });

  // parsing hints for -style command cli options
  // null values indicate the lack of a function for parsing/identifying this property
  // (in which case a heuristic is used for distinguishing a string literal from an expression)
  var stylePropertyTypes = {
    class: 'classname',
    dx: 'measure',
    dy: 'measure',
    fill: 'color',
    'fill-pattern': 'pattern',
    'font-family': null,
    'font-size': null,
    'font-style': null,
    'font-weight': null,
    'label-text': null,  // leaving this null
    'letter-spacing': 'measure',
    'line-height': 'measure',
    opacity: 'number',
    r: 'number',
    stroke: 'color',
    'stroke-dasharray': 'dasharray',
    'stroke-width': 'number',
    'stroke-opacity': 'number',
    'fill-opacity': 'number',
    'text-anchor': null
  };

  // The -symbols command accepts some options that are not supported by -style
  // (different symbol types accept different combinations of properties...)
  var symbolPropertyTypes = utils.extend({
    type: null,
    length: 'number', // e.g. arrow length
    rotation: 'number',
    radius: 'number',
    radii: null, // string, parsed by function
    flipped: 'boolean',
    rotated: 'boolean',
    direction: 'number',
    'head-angle': 'number',
    'head-width': 'number',
    'head-length': 'number',
    'stem-width': 'number',
    'stem-curve': 'number', // degrees of arc
    'stem-taper': 'number',
    'stem-length': 'number',
    'min-stem': 'number',
    'arrow-scaling': 'number',
    effect: null // e.g. "fade"
  }, stylePropertyTypes);

  var commonProperties = 'class,opacity,stroke,stroke-width,stroke-dasharray,stroke-opacity,fill-opacity'.split(',');

  var propertiesBySymbolType = {
    polygon: utils.arrayToIndex(commonProperties.concat('fill', 'fill-pattern')),
    polyline: utils.arrayToIndex(commonProperties),
    point: utils.arrayToIndex(commonProperties.concat('fill', 'r')),
    label: utils.arrayToIndex(commonProperties.concat(
      'fill,r,font-family,font-size,text-anchor,font-weight,font-style,letter-spacing,dominant-baseline'.split(',')))
  };

  function isSupportedSvgStyleProperty(name) {
    return name in stylePropertyTypes;
  }

  function isSupportedSvgSymbolProperty(name) {
    return name in symbolPropertyTypes;
  }

  function findPropertiesBySymbolGeom(fields, type) {
    var index = propertiesBySymbolType[type] || {};
    return fields.filter(function(name) {
      return name in index;
    });
  }

  // Returns a function that returns an object containing property values for a single record
  // opts: parsed command line options for the -symbols command
  //
  function getSymbolDataAccessor(lyr, opts) {
    var functions = {};
    var properties = [];
    var fields = lyr.data ? lyr.data.getFields() : [];

    Object.keys(opts).forEach(function(optName) {
      var svgName = optName.replace(/_/g, '-');
      if (!isSupportedSvgSymbolProperty(svgName)) {
        return;
      }
      var val = opts[optName];
      functions[svgName] = getSymbolPropertyAccessor(val, svgName, lyr);
      properties.push(svgName);
    });

    // TODO: consider applying values of existing fields with names of symbol properties

    return function(id) {
      var d = {}, name;
      for (var i=0; i<properties.length; i++) {
        name = properties[i];
        d[name] = functions[name](id);
      }
      return d;
    };
  }

  // need a test that identifies any expression but doesn't get triggered by:
  // * invalid patterns: dots 45deg black 3px red
  // * ???
  //
  function mightBeExpression(str, fields) {
    fields = fields || [];
    if (fields.indexOf(str.trim()) > -1) return true;
    return /[(){}./*?:&|=\[+-]/.test(str);
  }

  function getSymbolPropertyAccessor(val, svgName, lyr) {
    var strVal = String(val).trim();
    var typeHint = symbolPropertyTypes[svgName];
    var fields = lyr.data ? lyr.data.getFields() : [];
    var literalVal = null;
    var accessor;

    if (typeHint && fields.indexOf(strVal) === -1) {
      literalVal = parseSvgLiteralValue(strVal, typeHint);
    }
    if (literalVal === null && mightBeExpression(strVal, fields)) {
      accessor = parseStyleExpression(strVal, lyr); // no longer throws an error
    }
    if (!accessor && literalVal === null && !typeHint) {
      // We don't have a type rule for detecting an invalid value, so we're
      // treating the string as a literal value
      literalVal = strVal;
    }
    // console.log("literalVal:", mightBeExpression(strVal, fields), strVal, fields)
    if (accessor) return accessor;
    if (literalVal !== null) return function(id) {return literalVal;};
    stop('Unexpected value for', svgName + ':', strVal);
  }

  function parseStyleExpression(strVal, lyr) {
    var func;
    try {
      // func = compileValueExpression(strVal, lyr, null, {context: getStateVar('defs'), no_warn: true});
      func = compileValueExpression(strVal, lyr, null, {no_warn: true});
      func(0); // check for runtime errors (e.g. undefined variables)
    } catch(e) {
      func = null;
    }
    return func;
  }

  // returns parsed value or null if @strVal is not recognized as a valid literal value
  function parseSvgLiteralValue(strVal, type) {
    var val = null;
    if (type == 'number') {
      // TODO: handle values with units, like "13px"
      val = isSvgNumber(strVal) ? Number(strVal) : null;
    } else if (type == 'color') {
      val = isSvgColor(strVal) ? strVal : null;
    } else if (type == 'classname') {
      val = isSvgClassName(strVal) ? strVal : null;
    } else if (type == 'measure') { // SVG/CSS length (e.g. 12px, 1em, 4)
      val = isSvgMeasure(strVal) ? parseSvgMeasure(strVal) : null;
    } else if (type == 'dasharray') {
      val = isDashArray(strVal) ? strVal : null;
    } else if (type == 'pattern') {
      val = isPattern(strVal) ? strVal : null;
    } else if (type == 'boolean') {
      val = parseBoolean(strVal);
    }
    //  else {
    //   // unknown type -- assume literal value
    //   val = strVal;
    // }
    return val;
  }

  function isPattern(str) {
    return !!parsePattern(str);
  }

  function isDashArray(str) {
    return /^[0-9]+( [0-9]+)*$/.test(str);
  }

  function isSvgClassName(str) {
    return /^( ?[_a-z][-_a-z0-9]*\b)+$/i.test(str);
  }


  function isSvgNumber(o) {
    return utils.isFiniteNumber(o) || utils.isString(o) && /^-?[.0-9]+$/.test(o);
  }

  function parseBoolean(o) {
    if (o === true || o === 'true') return true;
    if (o === false || o === 'false') return false;
    return null;
  }

  function isSvgMeasure(o) {
    return utils.isFiniteNumber(o) || utils.isString(o) && /^-?[.0-9]+[a-z]*$/.test(o);
  }

  // Can be a number or a string
  function parseSvgMeasure(str) {
    return utils.isString(str) && /[a-z]/.test(str) ? str : Number(str);
  }

  function isSvgColor(str) {
    return /^[a-z]+$/i.test(str) ||
      /^#[0-9a-f]+$/i.test(str) || /^rgba?\([0-9,. ]+\)$/.test(str);
  }

  var SvgProperties = /*#__PURE__*/Object.freeze({
    __proto__: null,
    isSupportedSvgStyleProperty: isSupportedSvgStyleProperty,
    findPropertiesBySymbolGeom: findPropertiesBySymbolGeom,
    getSymbolDataAccessor: getSymbolDataAccessor,
    mightBeExpression: mightBeExpression,
    getSymbolPropertyAccessor: getSymbolPropertyAccessor,
    isSvgClassName: isSvgClassName,
    isSvgNumber: isSvgNumber,
    parseBoolean: parseBoolean,
    isSvgMeasure: isSvgMeasure,
    parseSvgMeasure: parseSvgMeasure,
    isSvgColor: isSvgColor
  });

  var symbolRenderers = {};

  function getTransform(xy, scale) {
    var str = 'translate(' + roundToTenths(xy[0]) + ' ' + roundToTenths(xy[1]) + ')';
    if (scale && scale != 1) {
      str += ' scale(' + scale + ')';
    }
    return str;
  }

  var SvgCommon = /*#__PURE__*/Object.freeze({
    __proto__: null,
    symbolRenderers: symbolRenderers,
    getTransform: getTransform
  });

  function importGeoJSONFeatures(features, opts) {
    opts = opts || {};
    return features.map(function(obj, i) {
      var geom = obj.type == 'Feature' ? obj.geometry : obj; // could be null
      var geomType = geom && geom.type;
      var svgObj = null;
      if (geomType && geom.coordinates) {
        svgObj = geojsonImporters[geomType](geom.coordinates, obj.properties, opts);
      }
      if (!svgObj) {
        return {tag: 'g'}; // empty element
      }
      // TODO: fix error caused by null svgObj (caused by e.g. MultiPolygon with [] coordinates)
      if (obj.properties) {
        applyStyleAttributes(svgObj, geomType, obj.properties);
      }
      if ('id' in obj) {
        if (!svgObj.properties) {
          svgObj.properties = {};
        }
        svgObj.properties.id = (opts.id_prefix || '') + obj.id;
      }
      return svgObj;
    });
  }

  function applyStyleAttributes(svgObj, geomType, rec) {
    var symbolType = GeoJSON.translateGeoJSONType(geomType);
    if (symbolType == 'point' && ('label-text' in rec)) {
      symbolType = 'label';
    }
    var fields = findPropertiesBySymbolGeom(Object.keys(rec), symbolType);
    for (var i=0, n=fields.length; i<n; i++) {
      setAttribute(svgObj, fields[i], rec[fields[i]]);
    }
  }

  function setAttribute(obj, k, v) {
    if (k == 'r') {
      // assigned by importPoint()
    } else {
      if (!obj.properties) obj.properties = {};
      obj.properties[k] = v;
      if (k == 'stroke-dasharray' && v) {
        // kludge for cleaner dashes... make butt the default?
        obj.properties['stroke-linecap'] = 'butt';
      }
    }
  }

  function importMultiPoint(coords, rec, layerOpts) {
    var children = [], p;
    for (var i=0; i<coords.length; i++) {
      p = importPoint(coords[i], rec, layerOpts);
      if (p.tag == 'g' && p.children) {
        children = children.concat(p.children);
      } else {
        children.push(p);
      }
    }
    return children.length > 0 ? {tag: 'g', children: children} : null;
  }

  function importMultiPath(coords, importer) {
    var o;
    for (var i=0; i<coords.length; i++) {
      if (i === 0) {
        o = importer(coords[i]);
      } else {
        o.properties.d += ' ' + importer(coords[i]).properties.d;
      }
    }
    return o;
  }

  function importLineString(coords) {
    var d = stringifyLineStringCoords(coords);
    return {
      tag: 'path',
      properties: {d: d}
    };
  }


  function importMultiLineString(coords) {
    var d = coords.map(stringifyLineStringCoords).join(' ');
    return {
      tag: 'path',
      properties: {d: d}
    };
  }

  // Kludge for applying fill and other styles to a <text> element
  // (for rendering labels in the GUI with the dot in Canvas, not SVG)
  function importStyledLabel(rec, p) {
    var o = importLabel(rec, p);
    applyStyleAttributes(o, 'Point', rec);
    return o;
  }

  function toLabelString(val) {
    if (val || val === 0 || val === false) return String(val);
    return '';
  }

  function importLabel(rec, p) {
    var line = toLabelString(rec['label-text']);
    var morelines, obj;
    // Accepting \n (two chars) as an alternative to the newline character
    // (sometimes, '\n' is not converted to newline, e.g. in a Makefile)
    // Also accepting <br>
    var newline = /\n|\\n|<br>/i;
    var dx = rec.dx || 0;
    var dy = rec.dy || 0;
    var properties = {
      // using x, y instead of dx, dy for shift, because Illustrator doesn't apply
      // dx value when importing text with text-anchor=end
      y: dy,
      x: dx
    };
    if (p) {
      properties.transform = getTransform(p);
    }
    if (newline.test(line)) {
      morelines = line.split(newline);
      line = morelines.shift();
    }
    obj = {
      tag: 'text',
      value: line,
      properties: properties
    };
    if (morelines) {
      // multiline label
      obj.children = [];
      morelines.forEach(function(line) {
        var tspan = {
          tag: 'tspan',
          value: line,
          properties: {
            x: dx,
            dy: rec['line-height'] || '1.1em'
          }
        };
        obj.children.push(tspan);
      });
    }
    return obj;
  }

  function getEmptySymbol() {
    return {tag: 'g', properties: {}, children: []};
  }


  function renderSymbol(d, x, y) {
    var renderer = symbolRenderers[d.type];
     if (!renderer) {
      stop(d.type ? 'Unknown symbol type: ' + d.type : 'Symbol is missing a type property');
    }
    return renderer(d, x || 0, y || 0);
  }

  // d: svg-symbol object from feature data object
  function importSymbol(d, xy) {
    var renderer;
    if (!d) {
      return getEmptySymbol();
    }
    if (utils.isString(d)) {
      d = JSON.parse(d);
    }
    return {
      tag: 'g',
      properties: {
        'class': 'mapshaper-svg-symbol',
        transform: xy ? getTransform(xy) : null
      },
      children: renderSymbol(d)
    };
  }

  function importPoint(coords, rec, layerOpts) {
    rec = rec || {};
    if ('svg-symbol' in rec) {
      return importSymbol(rec['svg-symbol'], coords);
    }
    return importStandardPoint(coords, rec, layerOpts || {});
  }

  function importPolygon(coords) {
    var d, o;
    for (var i=0; i<coords.length; i++) {
      d = o ? o.properties.d + ' ' : '';
      o = importLineString(coords[i]);
      o.properties.d = d + o.properties.d + ' Z';
    }
    if (coords.length > 1) {
      o.properties['fill-rule'] = 'evenodd'; // support polygons with holes
    }
    return o;
  }

  function importStandardPoint(coords, rec, layerOpts) {
    var isLabel = 'label-text' in rec;
    var symbolType = layerOpts.point_symbol || '';
    var children = [];
    var halfSize = rec.r || 0; // radius or half of symbol size
    var p;
    // if not a label, create a symbol even without a size
    // (circle radius can be set via CSS)
    if (halfSize > 0 || !isLabel) {
      if (symbolType == 'square') {
        p = {
          tag: 'rect',
          properties: {
            x: coords[0] - halfSize,
            y: coords[1] - halfSize,
            width: halfSize * 2,
            height: halfSize * 2
          }};
      } else { // default is circle
        p = {
          tag: 'circle',
          properties: {
            cx: coords[0],
            cy: coords[1]
          }};
        if (halfSize > 0) {
          p.properties.r = halfSize;
        }
      }
      children.push(p);
    }
    if (isLabel) {
      children.push(importLabel(rec, coords));
    }
    return children.length > 1 ? {tag: 'g', children: children} : children[0];
  }

  var geojsonImporters = {
    Point: importPoint,
    Polygon: importPolygon,
    LineString: importLineString,
    MultiPoint: function(coords, rec, opts) {
      return importMultiPoint(coords, rec, opts);
    },
    MultiLineString: function(coords) {
      return importMultiPath(coords, importLineString);
    },
    MultiPolygon: function(coords) {
      return importMultiPath(coords, importPolygon);
    }
  };

  var GeojsonToSvg = /*#__PURE__*/Object.freeze({
    __proto__: null,
    importGeoJSONFeatures: importGeoJSONFeatures,
    applyStyleAttributes: applyStyleAttributes,
    importLineString: importLineString,
    importMultiLineString: importMultiLineString,
    importStyledLabel: importStyledLabel,
    importLabel: importLabel,
    renderSymbol: renderSymbol,
    importSymbol: importSymbol,
    importPoint: importPoint,
    importPolygon: importPolygon
  });

  /* require mapshaper-rectangle, mapshaper-furniture */

  cmd.frame = function(catalog, source, opts) {
    var size, bounds, tmp, dataset;
    if (+opts.width > 0 === false && +opts.pixels > 0 === false) {
      stop("Missing a width or area");
    }
    if (opts.width && opts.height) {
      opts = utils.extend({}, opts);
      // Height is a string containing either a number or a
      //   comma-sep. pair of numbers (range); here we convert height to
      //   an aspect-ratio parameter for the rectangle() function
      opts.aspect_ratio = getAspectRatioArg(opts.width, opts.height);
      // TODO: currently returns max,min aspect ratio, should return in min,max order
      // (rectangle() function should handle max,min argument correctly now anyway)
    }
    tmp = cmd.rectangle(source, opts);
    bounds = getDatasetBounds(tmp);
    if (probablyDecimalDegreeBounds(bounds)) {
      stop('Frames require projected, not geographical coordinates');
    } else if (!getDatasetCRS(tmp)) {
      message('Warning: missing projection data. Assuming coordinates are meters and k (scale factor) is 1');
    }
    size = getFrameSize(bounds, opts);
    if (size[0] > 0 === false) {
      stop('Missing a valid frame width');
    }
    if (size[1] > 0 === false) {
      stop('Missing a valid frame height');
    }
    dataset = {info: {}, layers:[{
      name: opts.name || 'frame',
      data: new DataTable([{
        width: size[0],
        height: size[1],
        bbox: bounds.toArray(),
        type: 'frame'
      }])
    }]};
    catalog.addDataset(dataset);
  };

  // Convert width and height args to aspect ratio arg for the rectangle() function
  function getAspectRatioArg(widthArg, heightArg) {
    // heightArg is a string containing either a number or a
    // comma-sep. pair of numbers (range);
    return heightArg.split(',').map(function(opt) {
      var height = Number(opt),
          width = Number(widthArg);
      if (!opt) return '';
      return width / height;
    }).reverse().join(',');
  }

  function getFrameSize(bounds, opts) {
    var aspectRatio = bounds.width() / bounds.height();
    var height, width;
    if (opts.pixels) {
      width = Math.sqrt(+opts.pixels * aspectRatio);
    } else {
      width = +opts.width;
    }
    height = width / aspectRatio;
    return [Math.round(width), Math.round(height)];
  }

  function getDatasetDisplayBounds(dataset) {
    var frameLyr = findFrameLayerInDataset(dataset);
    if (frameLyr) {
      // TODO: check for coordinate issues (non-intersection with other layers, etc)
      return getFrameLayerBounds(frameLyr);
    }
    return getDatasetBounds(dataset);
  }

  // @lyr dataset layer
  function isFrameLayer(lyr) {
    return getFurnitureLayerType(lyr) == 'frame';
  }

  function findFrameLayerInDataset(dataset) {
    return utils.find(dataset.layers, function(lyr) {
      return isFrameLayer(lyr);
    });
  }

  function findFrameDataset(catalog) {
    var target = utils.find(catalog.getLayers(), function(o) {
      return isFrameLayer(o.layer);
    });
    return target ? target.dataset : null;
  }

  function findFrameLayer(catalog) {
    var target = utils.find(catalog.getLayers(), function(o) {
      return isFrameLayer(o.layer);
    });
    return target && target.layer || null;
  }

  function getFrameLayerBounds(lyr) {
    return new Bounds(getFurnitureLayerData(lyr).bbox);
  }


  // @data frame data, including crs property if available
  // Returns a single value: the ratio or
  function getMapFrameMetersPerPixel(data) {
    var bounds = new Bounds(data.bbox);
    var k, toMeters, metersPerPixel;
    if (data.crs) {
      // TODO: handle CRS without inverse projections
      // scale factor is the ratio of coordinate distance to true distance at a point
      k = getScaleFactorAtXY(bounds.centerX(), bounds.centerY(), data.crs);
      toMeters = data.crs.to_meter;
    } else {
      // Assuming coordinates are meters and k is 1 (not safe)
      // A warning should be displayed when relevant furniture element is created
      k = 1;
      toMeters = 1;
    }
    metersPerPixel = bounds.width() / k * toMeters / data.width;
    return metersPerPixel;
  }

  furnitureRenderers.frame = function(d) {
    var lineWidth = 1,
        // inset stroke by half of line width
        off = lineWidth / 2,
        obj = importPolygon([[[off, off], [off, d.height - off],
          [d.width - off, d.height - off],
          [d.width - off, off], [off, off]]]);
    utils.extend(obj.properties, {
        fill: 'none',
        stroke: d.stroke || 'black',
        'stroke-width': d['stroke-width'] || lineWidth
    });
    return [obj];
  };

  var Frame = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getAspectRatioArg: getAspectRatioArg,
    getFrameSize: getFrameSize,
    findFrameLayerInDataset: findFrameLayerInDataset,
    findFrameDataset: findFrameDataset,
    findFrameLayer: findFrameLayer,
    getFrameLayerBounds: getFrameLayerBounds,
    getMapFrameMetersPerPixel: getMapFrameMetersPerPixel
  });

  function transformDatasetToPixels(dataset, opts) {
    var frameLyr = findFrameLayerInDataset(dataset);
    var bounds, bounds2, fwd, frameData;
    if (frameLyr) {
      // TODO: handle options like width, height margin when a frame is present
      // TODO: check that aspect ratios match
      frameData = getFurnitureLayerData(frameLyr);
      bounds = new Bounds(frameData.bbox);
      bounds2 = new Bounds(0, 0, frameData.width, frameData.height);
    } else {
      bounds = getDatasetBounds(dataset);
      bounds2 = calcOutputSizeInPixels(bounds, opts);
    }
    fwd = bounds.getTransform(bounds2, opts.invert_y);
    transformPoints(dataset, function(x, y) {
      return fwd.transform(x, y);
    });
    return [Math.round(bounds2.width()), Math.round(bounds2.height()) || 1];
  }

  function parseMarginOption(opt) {
    var str = utils.isNumber(opt) ? String(opt) : opt || '';
    var margins = str.trim().split(/[, ] */);
    if (margins.length == 1) margins.push(margins[0]);
    if (margins.length == 2) margins.push(margins[0], margins[1]);
    if (margins.length == 3) margins.push(margins[2]);
    return margins.map(function(str) {
      var px = parseFloat(str);
      return isNaN(px) ? 1 : px; // 1 is default
    });
  }

  // bounds: Bounds object containing bounds of content in geographic coordinates
  // returns Bounds object containing bounds of pixel output
  // side effect: bounds param is modified to match the output frame
  function calcOutputSizeInPixels(bounds, opts) {
    var padX = 0,
        padY = 0,
        offX = 0,
        offY = 0,
        width = bounds.width(),
        height = bounds.height(),
        margins = parseMarginOption(opts.margin),
        marginX = margins[0] + margins[2],
        marginY = margins[1] + margins[3],
        // TODO: add option to tweak alignment of content when both width and height are given
        wx = 0.5, // how padding is distributed horizontally (0: left aligned, 0.5: centered, 1: right aligned)
        wy = 0.5, // vertical padding distribution
        widthPx, heightPx, size, kx, ky;

    if (opts.fit_bbox) {
      // scale + shift content to fit within a bbox
      offX = opts.fit_bbox[0];
      offY = opts.fit_bbox[1];
      widthPx = opts.fit_bbox[2] - offX;
      heightPx = opts.fit_bbox[3] - offY;
      if (width / height > widthPx / heightPx) {
        // data is wider than fit box...
        // scale the data to fit widthwise
        heightPx = 0;
      } else {
        widthPx = 0; // fit the data to the height
      }
      marginX = marginY = 0; // TODO: support margins

    } else if (opts.svg_scale > 0) {
      // alternative to using a fixed width (e.g. when generating multiple files
      // at a consistent geographic scale)
      widthPx = width / opts.svg_scale + marginX;
      heightPx = 0;
    } else if (+opts.pixels) {
      size = getFrameSize(bounds, opts);
      widthPx = size[0];
      heightPx = size[1];
    } else {
      heightPx = opts.height || 0;
      widthPx = opts.width || (heightPx > 0 ? 0 : 800); // 800 is default width
    }

    if (heightPx > 0) {
      // vertical meters per pixel to fit height param
      ky = (height || width || 1) / (heightPx - marginY);
    }
    if (widthPx > 0) {
      // horizontal meters per pixel to fit width param
      kx = (width || height || 1) / (widthPx - marginX);
    }

    if (!widthPx) { // heightPx and ky are defined, set width to match
      kx = ky;
      widthPx = width > 0 ? marginX + width / kx : heightPx; // export square graphic if content has 0 width (reconsider this?)
    } else if (!heightPx) { // widthPx and kx are set, set height to match
      ky = kx;
      heightPx = height > 0 ? marginY + height / ky : widthPx;
      // limit height if max_height is defined
      if (opts.max_height > 0 && heightPx > opts.max_height) {
        ky = kx * heightPx / opts.max_height;
        heightPx = opts.max_height;
      }
    }

    if (kx > ky) { // content is wide -- need to pad vertically
      ky = kx;
      padY = ky * (heightPx - marginY) - height;
    } else if (ky > kx) { // content is tall -- need to pad horizontally
      kx = ky;
      padX = kx * (widthPx - marginX) - width;
    }

    bounds.padBounds(
      margins[0] * kx + padX * wx,
      margins[1] * ky + padY * wy,
      margins[2] * kx + padX * (1 - wx),
      margins[3] * ky + padY * (1 - wy));

    if (!(widthPx > 0 && heightPx > 0)) {
      error("Missing valid height and width parameters");
    }
    if (!(kx === ky && kx > 0)) {
      error("Missing valid margin parameters");
    }

    return new Bounds(offX, offY, widthPx + offX, heightPx + offY);
  }

  var PixelTransform = /*#__PURE__*/Object.freeze({
    __proto__: null,
    transformDatasetToPixels: transformDatasetToPixels,
    parseMarginOption: parseMarginOption,
    calcOutputSizeInPixels: calcOutputSizeInPixels
  });

  function stringify(obj) {
    var svg, joinStr;
    if (!obj || !obj.tag) return '';
    svg = '<' + obj.tag;
    // w.s. is significant in text elements
    if (obj.properties) {
      svg += stringifyProperties(obj.properties);
    }
    if (obj.children || obj.value) {
      joinStr = obj.tag == 'text' || obj.tag == 'tspan' ? '' : '\n';
      svg += '>' + joinStr;
      if (obj.value) {
        svg += stringEscape(obj.value);
      }
      if (obj.children) {
        svg += obj.children.map(stringify).join(joinStr);
      }
      svg += joinStr + '</' + obj.tag + '>';
    } else {
      svg += '/>';
    }
    return svg;
  }

  // Replace some chars with XML "predefined entities" to avoid parsing errors
  // https://en.wikipedia.org/wiki/List_of_XML_and_HTML_character_entity_references#Predefined_entities_in_XML
  var rxp = /[&<>"']/g,
      map = {
        '&': '&amp;',
        '<': '&lt;',
        '>': '&gt;',
        '"': '&quot;',
        "'": '&apos;'
      };
  function stringEscape(s) {
    return String(s).replace(rxp, function(match, i) {
      var entity = map[match];
      // don't replace &amp; with &amp;amp;
      if (match == '&' && s.substr(i, entity.length) == entity) {
        return '&';
      }
      return entity;
    });
  }

  function stringifyProperties(o) {
    return Object.keys(o).reduce(function(memo, key) {
      var val = o[key],
          strval;
      if (!val && val !== 0) return memo; // omit undefined / empty / null values
      strval = utils.isString(val) ? val : JSON.stringify(val);
      if (key == 'href') {
        key = 'xlink:href';
      }
      return memo + ' ' + key + '="' + stringEscape(strval) + '"';
    }, '');
  }

  var SvgStringify = /*#__PURE__*/Object.freeze({
    __proto__: null,
    stringify: stringify,
    stringEscape: stringEscape,
    stringifyProperties: stringifyProperties
  });

  // public domain implementation
  // source: https://github.com/jbt/js-crypto
  function sha1(str1){
    for (
      var blockstart = 0,
        i = 0,
        W = [],
        A, B, C, D, F, G,
        H = [A=0x67452301, B=0xEFCDAB89, ~A, ~B, 0xC3D2E1F0],
        word_array = [],
        temp2,
        s = unescape(encodeURI(str1)),
        str_len = s.length;

      i <= str_len;
    ){
      word_array[i >> 2] |= (s.charCodeAt(i)||128) << (8 * (3 - i++ % 4));
    }
    word_array[temp2 = ((str_len + 8) >> 2) | 15] = str_len << 3;

    for (; blockstart <= temp2; blockstart += 16) {
      A = H; i = 0;

      for (; i < 80;
        A = [[
          (G = ((s = A[0]) << 5 | s >>> 27) + A[4] + (W[i] = (i<16) ? ~~word_array[blockstart + i] : G << 1 | G >>> 31) + 1518500249) + ((B = A[1]) & (C = A[2]) | ~B & (D = A[3])),
          F = G + (B ^ C ^ D) + 341275144,
          G + (B & C | B & D | C & D) + 882459459,
          F + 1535694389
        ][0|((i++) / 20)] | 0, s, B << 30 | B >>> 2, C, D]
      ) {
        G = W[i - 3] ^ W[i - 8] ^ W[i - 14] ^ W[i - 16];
      }

      for(i = 5; i; ) H[--i] = H[i] + A[i] | 0;
    }

    for(str1 = ''; i < 40; )str1 += (H[i >> 3] >> (7 - i++ % 8) * 4 & 15).toString(16);
    return str1;
  }

  var cache = {};
  function fetchFileSync(url) {
    if (url in cache) return cache[url];
    var res  = require('sync-request')('GET', url, {timeout: 2000});
    var content = res.getBody().toString();
    cache[url] = content;
    return content;
  }

  // convert object properties to definitions for images and hatch fills
  function convertPropertiesToDefinitions(obj, defs) {
    procNode(obj);

    function procNode(obj) {
      if (obj.tag == 'path' && obj.properties['fill-pattern']) {
        convertFillPattern(obj.properties, defs);
      }
      if (obj.tag == 'image') {
        if (/\.svg/.test(obj.properties.href || '')) {
          convertSvgImage(obj, defs);
        }
      } else if (obj.children) {
        obj.children.forEach(procNode);
      }
    }
  }

  function convertSvgImage(obj, defs) {
    // Same-origin policy prevents embedding images in the web UI
    var href = obj.properties.href;
    // look for a previously added definition to use
    // (assumes that images that share the same href can also use the same defn)
    var item = utils.find(defs, function(item) {return item.href == href;});
    if (!item) {
      item = {
        href: href,
        id: urlToId(href) // generating id from href, to try to support multiple inline svgs on page
      };
      item.svg = serializeSvgImage(href, item.id);
      defs.push(item);
    }
    if (item.svg) {
      obj.tag = 'use';
      obj.properties.href = '#' + item.id;
    } else {
      // no svg property means the image was not able to be converted to a defn
      // -- it will be serialized as a regular inline image
    }
  }

  // Returns the content of an SVG file from a local path or URL
  // Returns '' if unable to get the content (e.g. due to cross-domain security rules)
  function serializeSvgImage(href, id) {
    var svg = '';
    try {
      // try to download the SVG content and use that
      svg = convertSvgToDefn(getSvgContent(href), id) + '\n';
      svg = '<!-- ' + href + '-->\n' + svg; // add href as a comment, to aid in debugging
    } catch(e) {
      // tried creating a symbol as a fallback... encounted problems with icon
      // size and placement, giving up on this for now
      // svg = `<symbol><image xlink:href="${obj.properties.href}" id="${id}"></image></symbol>`;
    }
    return svg;
  }

  // TODO: download SVG files asynchronously
  // (currently, files are downloaded synchronously, which is obviously undesirable)
  //
  function getSvgContent(href) {
    var content;
    if (href.indexOf('http') === 0) {
      content = fetchFileSync(href);
    } else if (require('fs').existsSync(href)) { // assume href is a relative path
      content = require('fs').readFileSync(href, 'utf8');
    } else {
      stop("Invalid SVG location:", href);
    }
    return content;
  }

  function convertSvgToDefn(svg, id) {
    // Remove stuff before <svg> tag
    svg = svg.replace(/[^]*<svg/, '<svg');
    return svg.replace(/^<svg[^>]*>/, function(a) {
      // set id property of <svg>
      a = a.replace(/ id="[^"]*"/, '');
      a = a.replace(/<svg/, '<svg id="' + id + '"');
      return a;
    });
  }

  function urlToId(url) {
    return sha1(url).substr(0, 12);
  }

  /*
  function convertSvgToSymbol(svg, id) {
    svg = svg.replace(/[^]*<svg/, '<svg');
    // Remove inkscape tags (there were errors caused when namespaces were
    // stripped when converting <svg> to <symbol> ... this may be futile, may
    // have to go back to embedding entire SVG document instead of using symbols)
    svg = svg.replace(/<metadata[^]*?metadata>/, '');
    svg = svg.replace(/<sodipodi[^>]*>/, '');
    // convert <svg> to <symbol>
    svg = svg.replace(/^<svg[^>]*>/, function(a) {
      var viewBox = a.match(/viewBox=".*?"/)[0];
      return '<symbol id="' + id + '" ' + viewBox + '>';
    });
    svg = svg.replace('svg>', 'symbol>');
    return svg;
  }
  */

  //
  //
  function exportSVG(dataset, opts) {
    var namespace = 'xmlns="http://www.w3.org/2000/svg"';
    var defs = [];
    var size, svg;
    var style = '';

    // kludge for map keys
    if (opts.crisp_paths) {
      style = `
<style>
  path {shape-rendering: crispEdges;}
</style>`;
    }

    // TODO: consider moving this logic to mapshaper-export.js
    if (opts.final) {
      if (dataset.arcs) dataset.arcs.flatten();
    } else {
      dataset = copyDataset(dataset); // Modify a copy of the dataset
    }
    // invert_y setting for screen coordinates and geojson polygon generation
    utils.extend(opts, {invert_y: true});
    size = transformCoordsForSVG(dataset, opts);

    // error if one or more svg_data fields are not present in any layers
    if (opts.svg_data) validateSvgDataFields(dataset.layers, opts.svg_data);

    svg = dataset.layers.map(function(lyr) {
      var obj = exportLayerForSVG(lyr, dataset, opts);
      convertPropertiesToDefinitions(obj, defs);
      return stringify(obj);
    }).join('\n');
    if (defs.length > 0) {
      svg = '<defs>\n' + utils.pluck(defs, 'svg').join('') + '</defs>\n' + svg;
    }
    if (svg.includes('xlink:')) {
      namespace += ' xmlns:xlink="http://www.w3.org/1999/xlink"';
    }
    var capStyle = opts.default_linecap || 'round';
    var template = `<?xml version="1.0"?>
<svg ${namespace} version="1.2" baseProfile="tiny" width="%d" height="%d" viewBox="%s %s %s %s" stroke-linecap="${capStyle}" stroke-linejoin="round">${style}
${svg}
</svg>`;
    svg = utils.format(template,size[0], size[1], 0, 0, size[0], size[1]);
    return [{
      content: svg,
      filename: opts.file || getOutputFileBase(dataset) + '.svg'
    }];
  }

  function transformCoordsForSVG(dataset, opts) {
    var size = transformDatasetToPixels(dataset, opts);
    var precision = opts.precision || 0.0001;
    setCoordinatePrecision(dataset, precision);
    return size;
  }

  function exportLayerForSVG(lyr, dataset, opts) {
    var layerObj = getEmptyLayerForSVG(lyr, opts);
    if (layerHasFurniture(lyr)) {
      layerObj.children = exportFurnitureForSVG(lyr, dataset, opts);
    } else {
      layerObj.children = exportSymbolsForSVG(lyr, dataset, opts);
    }
    return layerObj;
  }

  function exportFurnitureForSVG(lyr, dataset, opts) {
    var frameLyr = findFrameLayerInDataset(dataset);
    var frameData;
    if (!frameLyr) return [];
    frameData = getFurnitureLayerData(frameLyr);
    frameData.crs = getDatasetCRS(dataset); // required by e.g. scalebar
    return importFurniture(getFurnitureLayerData(lyr), frameData);
  }

  function exportSymbolsForSVG(lyr, dataset, opts) {
    // TODO: convert geojson features one at a time
    var d = utils.defaults({layers: [lyr]}, dataset);
    var geojson = exportDatasetAsGeoJSON(d, opts);
    var features = geojson.features || geojson.geometries || (geojson.type ? [geojson] : []);
    var children = importGeoJSONFeatures(features, opts);
    var data;
    if (opts.svg_data && lyr.data) {
      addDataAttributesToSVG(children, lyr.data, opts.svg_data);
    }
    return children;
  }

  function validateSvgDataFields(layers, fieldsArg) {
    var missingFields = fieldsArg.reduce(function(memo, field) {
      if (!fieldExists(layers, field)) {
        memo.push(field);
      }
      return memo;
    }, []);

    if (missingFields.length && missingFields.indexOf('*') == -1) {
      stop("Missing data field(s):", missingFields.join(', '));
    }

    function fieldExists(layers, field) {
      return utils.some(layers, function(lyr) {
        return lyr.data && lyr.data.fieldExists(field) || false;
      });
    }
  }

  function addDataAttributesToSVG(children, table, fieldsArg) {
    var allFields = table.getFields();
    var dataFields = fieldsArg.indexOf('*') > -1 ? allFields.concat() : fieldsArg;
    var missingFields = utils.difference(dataFields, allFields);
    if (missingFields.length > 0) {
      dataFields = utils.difference(dataFields, missingFields);
      // stop("Missing data field(s):", missingFields.join(', '));
    }
    var records = table.getRecords();
    var data = exportDataAttributesForSVG(records, dataFields);
    if (children.length != data.length) {
      error("Mismatch between number of SVG symbols and data attributes");
    }
    children.forEach(function(child, i) {
      utils.extend(child.properties || {}, data[i]);
    });
  }

  function exportDataAttributesForSVG(records, fields) {
    var validRxp = /^[a-z_][a-z0-9_-]*$/i;
    var invalidRxp = /^xml/;
    var validFields = fields.filter(function(name) {
      return validRxp.test(name) && !invalidRxp.test(name);
    });
    var invalidFields = utils.difference(fields, validFields);
    if (invalidFields.length > 0) {
      message("Unable to add data-* attributes for field(s):", invalidFields.join(', '));
      message("data-* names should match pattern [a-z_][a-z0-9_-]*");
    }
    return records.map(function(rec) {
      var obj = {};
      for (var i=0; i<validFields.length; i++) {
        obj['data-' + validFields[i].toLowerCase()] =
          validDataAttributeValue(rec[validFields[i]]);
      }
      return obj;
    });
  }

  function validDataAttributeValue(val) {
    // TODO: consider converting some falsy values to empty strings
    // (e.g. null, undefined, NaN)
    return String(val);
  }

  // internal.validDataAttributeNames = function(names) {
  //   return utils.uniqifyNames(names.map(internal.validDataAttributeName));
  // };

  // There are restrictions on data-* attribute names
  // This function modifies names so they can be used
  // See: https://developer.mozilla.org/en-US/docs/Web/SVG/Attribute/data-*
  // Mapshaper's rules are a bit more restrictive than the spec -- e.g.
  //   the first character after "data-" is restricted to "_" | [a-z]
  //
  // internal.validDataAttributeName = function(name) {
  //   name = name.toLowerCase();
  //   name = name.replace(/[^a-z0-9_-]/g, ''); // accept only these letters
  //   if (/^([0-9-]|xml)/.test(name) || name === '') {
  //     name = '_' + name; // prepend underscore if needed
  //   }
  //   return name;
  // };

  function getEmptyLayerForSVG(lyr, opts) {
    var id = (opts.id_prefix || '') + (lyr.name || utils.getUniqueName('layer'));
    var layerObj = {
      tag: 'g',
      properties: {id: id},
      children: []
    };

    // override default black fill for layers that might have open paths
    // TODO: set fill="none" in SVG symbols, not on the container
    //   (setting fill=none on the container overrides the default black fill
    //   on paths, which may alter the appearance of SVG icons loaded from external URLs).
    if (lyr.geometry_type == 'polyline' || layerHasSvgSymbols(lyr)) {
      layerObj.properties.fill = 'none';
    }

    // add default display properties to line layers
    // (these are overridden by feature-level styles set via -style)
    if (lyr.geometry_type == 'polyline') {
      layerObj.properties.stroke = 'black';
      layerObj.properties['stroke-width'] = 1;
    }


    // add default text properties to layers with labels
    if (layerHasLabels(lyr) || layerHasSvgSymbols(lyr) || layerHasFurniture(lyr)) {
      layerObj.properties['font-family'] = 'sans-serif';
      layerObj.properties['font-size'] = '12';
      layerObj.properties['text-anchor'] = 'middle';
    }

    return layerObj;
  }

  function layerHasSvgSymbols(lyr) {
    return lyr.geometry_type == 'point' && lyr.data && lyr.data.fieldExists('svg-symbol');
  }

  function layerHasLabels(lyr) {
    var hasLabels = lyr.geometry_type == 'point' && lyr.data && lyr.data.fieldExists('label-text');
    //if (hasLabels && internal.findMaxPartCount(lyr.shapes) > 1) {
    //  console.error('Multi-point labels are not fully supported');
    //}
    return hasLabels;
  }

  var Svg = /*#__PURE__*/Object.freeze({
    __proto__: null,
    exportSVG: exportSVG,
    exportLayerForSVG: exportLayerForSVG,
    validateSvgDataFields: validateSvgDataFields,
    exportDataAttributesForSVG: exportDataAttributesForSVG,
    getEmptyLayerForSVG: getEmptyLayerForSVG,
    layerHasSvgSymbols: layerHasSvgSymbols,
    layerHasLabels: layerHasLabels
  });

  function buffersAreIdentical(a, b) {
    var alen = BinArray.bufferSize(a);
    var blen = BinArray.bufferSize(b);
    if (alen != blen) {
      return false;
    }
    for (var i=0; i<alen; i++) {
      if (a[i] !== b[i]) {
        return false;
      }
    }
    return true;
  }

  // Wrapper for DataView class for more convenient reading and writing of
  //   binary data; Remembers endianness and read/write position.
  // Has convenience methods for copying from buffers, etc.
  //
  function BinArray(buf, le) {
    if (utils.isNumber(buf)) {
      buf = new ArrayBuffer(buf);
    } else if (typeof Buffer == 'function' && buf instanceof Buffer) {
      // Since node 0.10, DataView constructor doesn't accept Buffers,
      //   so need to copy Buffer to ArrayBuffer
      buf = BinArray.toArrayBuffer(buf);
    }
    if (buf instanceof ArrayBuffer == false) {
      error("BinArray constructor takes an integer, ArrayBuffer or Buffer argument");
    }
    this._buffer = buf;
    this._bytes = new Uint8Array(buf);
    this._view = new DataView(buf);
    this._idx = 0;
    this._le = le !== false;
  }

  BinArray.bufferToUintArray = function(buf, wordLen) {
    if (wordLen == 4) return new Uint32Array(buf);
    if (wordLen == 2) return new Uint16Array(buf);
    if (wordLen == 1) return new Uint8Array(buf);
    error("BinArray.bufferToUintArray() invalid word length:", wordLen);
  };

  BinArray.uintSize = function(i) {
    return i & 1 || i & 2 || 4;
  };

  BinArray.bufferCopy = function(dest, destId, src, srcId, bytes) {
    srcId = srcId || 0;
    bytes = bytes || src.byteLength - srcId;
    if (dest.byteLength - destId < bytes)
      error("Buffer overflow; tried to write:", bytes);

    // When possible, copy buffer data in multi-byte chunks... Added this for faster copying of
    // shapefile data, which is aligned to 32 bits.
    var wordSize = Math.min(BinArray.uintSize(bytes), BinArray.uintSize(srcId),
        BinArray.uintSize(dest.byteLength), BinArray.uintSize(destId),
        BinArray.uintSize(src.byteLength));

    var srcArr = BinArray.bufferToUintArray(src, wordSize),
        destArr = BinArray.bufferToUintArray(dest, wordSize),
        count = bytes / wordSize,
        i = srcId / wordSize,
        j = destId / wordSize;

    while (count--) {
      destArr[j++] = srcArr[i++];
    }
    return bytes;
  };

  BinArray.toArrayBuffer = function(src) {
    var n = src.length,
        dest = new ArrayBuffer(n),
        view = new Uint8Array(dest);
    for (var i=0; i<n; i++) {
        view[i] = src[i];
    }
    return dest;
  };

  // Return length in bytes of an ArrayBuffer or Buffer
  //
  BinArray.bufferSize = function(buf) {
    return (buf instanceof ArrayBuffer ?  buf.byteLength : buf.length | 0);
  };

  BinArray.prototype = {
    size: function() {
      return this._buffer.byteLength;
    },

    littleEndian: function() {
      this._le = true;
      return this;
    },

    bigEndian: function() {
      this._le = false;
      return this;
    },

    buffer: function() {
      return this._buffer;
    },

    bytesLeft: function() {
      return this._buffer.byteLength - this._idx;
    },

    skipBytes: function(bytes) {
      this._idx += (bytes + 0);
      return this;
    },

    readUint8: function() {
      return this._bytes[this._idx++];
    },

    writeUint8: function(val) {
      this._bytes[this._idx++] = val;
      return this;
    },

    readInt8: function() {
      return this._view.getInt8(this._idx++);
    },

    writeInt8: function(val) {
      this._view.setInt8(this._idx++, val);
      return this;
    },

    readUint16: function() {
      var val = this._view.getUint16(this._idx, this._le);
      this._idx += 2;
      return val;
    },

    writeUint16: function(val) {
      this._view.setUint16(this._idx, val, this._le);
      this._idx += 2;
      return this;
    },

    readUint32: function() {
      var val = this._view.getUint32(this._idx, this._le);
      this._idx += 4;
      return val;
    },

    writeUint32: function(val) {
      this._view.setUint32(this._idx, val, this._le);
      this._idx += 4;
      return this;
    },

    readInt32: function() {
      var val = this._view.getInt32(this._idx, this._le);
      this._idx += 4;
      return val;
    },

    writeInt32: function(val) {
      this._view.setInt32(this._idx, val, this._le);
      this._idx += 4;
      return this;
    },

    readFloat64: function() {
      var val = this._view.getFloat64(this._idx, this._le);
      this._idx += 8;
      return val;
    },

    writeFloat64: function(val) {
      this._view.setFloat64(this._idx, val, this._le);
      this._idx += 8;
      return this;
    },

    // Returns a Float64Array containing @len doubles
    //
    readFloat64Array: function(len) {
      var bytes = len * 8,
          i = this._idx,
          buf = this._buffer,
          arr;
      // Inconsistent: first is a view, second a copy...
      if (i % 8 === 0) {
        arr = new Float64Array(buf, i, len);
      } else if (buf.slice) {
        arr = new Float64Array(buf.slice(i, i + bytes));
      } else { // ie10, etc
        var dest = new ArrayBuffer(bytes);
        BinArray.bufferCopy(dest, 0, buf, i, bytes);
        arr = new Float64Array(dest);
      }
      this._idx += bytes;
      return arr;
    },

    readUint32Array: function(len) {
      var arr = [];
      for (var i=0; i<len; i++) {
        arr.push(this.readUint32());
      }
      return arr;
    },

    peek: function(i) {
      return this._view.getUint8(i >= 0 ? i : this._idx);
    },

    position: function(i) {
      if (i != null) {
        this._idx = i;
        return this;
      }
      return this._idx;
    },

    readCString: function(fixedLen, asciiOnly) {
      var str = "",
          count = fixedLen >= 0 ? fixedLen : this.bytesLeft();
      while (count > 0) {
        var byteVal = this.readUint8();
        count--;
        if (byteVal == 0) {
          break;
        } else if (byteVal > 127 && asciiOnly) {
          str = null;
          break;
        }
        str += String.fromCharCode(byteVal);
      }

      if (fixedLen > 0 && count > 0) {
        this.skipBytes(count);
      }
      return str;
    },

    writeString: function(str, maxLen) {
      var bytesWritten = 0,
          charsToWrite = str.length,
          cval;
      if (maxLen) {
        charsToWrite = Math.min(charsToWrite, maxLen);
      }
      for (var i=0; i<charsToWrite; i++) {
        cval = str.charCodeAt(i);
        if (cval > 127) {
          // Unicode value beyond ascii range
          cval = '?'.charCodeAt(0);
        }
        this.writeUint8(cval);
        bytesWritten++;
      }
      return bytesWritten;
    },

    writeCString: function(str, fixedLen) {
      var maxChars = fixedLen ? fixedLen - 1 : null,
          bytesWritten = this.writeString(str, maxChars);

      this.writeUint8(0); // terminator
      bytesWritten++;

      if (fixedLen) {
        while (bytesWritten < fixedLen) {
          this.writeUint8(0);
          bytesWritten++;
        }
      }
      return this;
    },

    writeBuffer: function(buf, bytes, startIdx) {
      this._idx += BinArray.bufferCopy(this._buffer, this._idx, buf, startIdx, bytes);
      return this;
    }
  };

  var BinArray$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    buffersAreIdentical: buffersAreIdentical,
    BinArray: BinArray
  });

  var Dbf = {};
  var MAX_STRING_LEN = 254;

  Dbf.MAX_STRING_LEN = MAX_STRING_LEN;
  Dbf.convertValueToString = convertValueToString;
  Dbf.convertFieldNames = convertFieldNames;
  Dbf.discoverFieldType = discoverFieldType;
  Dbf.getDecimalFormatter = getDecimalFormatter;
  Dbf.getNumericFieldInfo = getNumericFieldInfo;
  Dbf.truncateEncodedString = truncateEncodedString;
  Dbf.getFieldInfo = getFieldInfo;
  Dbf.exportRecords = exportRecords;

  function BufferPool() {
    var n = 5000,
        pool, i;
    newPool();

    function newPool() {
      pool = new Uint8Array(n);
      i = 0;
    }

    return {
      reserve: function(bytes) {
        if (i + bytes > n) newPool();
        i += bytes;
        return pool.subarray(i - bytes, i);
      },
      putBack: function(bytes) {
        i -= bytes;
      }
    };
  }

  var bufferPool = new BufferPool();

  function exportRecords(records, encoding, fieldOrder) {
    var rows = records.length;
    var fields = findFieldNames(records, fieldOrder);
    var dataEncoding = encoding || 'utf8';
    var headerEncoding = stringIsAscii(fields.join('')) ? 'ascii' : dataEncoding;
    var fieldNames = convertFieldNames(fields, headerEncoding);
    var fieldBuffers = encodeFieldNames(fieldNames, headerEncoding); // array of 11-byte buffers
    var fieldData = fields.map(function(name, i) {
      var info = getFieldInfo(records, name, dataEncoding);
      if (info.warning) {
        message('[' + name + '] ' + info.warning);
      }
      return info;
    });

    var headerBytes = getHeaderSize(fieldData.length),
        recordBytes = getRecordSize(utils.pluck(fieldData, 'size')),
        fileBytes = headerBytes + rows * recordBytes + 1;

    var buffer = new ArrayBuffer(fileBytes);
    var bin = new BinArray(buffer).littleEndian();
    var now = new Date();

    // write header
    bin.writeUint8(3);
    bin.writeUint8(now.getFullYear() - 1900);
    bin.writeUint8(now.getMonth() + 1);
    bin.writeUint8(now.getDate());
    bin.writeUint32(rows);
    bin.writeUint16(headerBytes);
    bin.writeUint16(recordBytes);
    bin.skipBytes(17);
    bin.writeUint8(0); // language flag; TODO: improve this
    bin.skipBytes(2);


    // field subrecords
    fieldData.reduce(function(recordOffset, obj, i) {
      // bin.writeCString(obj.name, 11);
      bin.writeBuffer(fieldBuffers[i], 11, 0);
      bin.writeUint8(obj.type.charCodeAt(0));
      bin.writeUint32(recordOffset);
      bin.writeUint8(obj.size);
      bin.writeUint8(obj.decimals);
      bin.skipBytes(14);
      return recordOffset + obj.size;
    }, 1);

    bin.writeUint8(0x0d); // "field descriptor terminator"
    if (bin.position() != headerBytes) {
      error("Dbf#exportRecords() header size mismatch; expected:", headerBytes, "written:", bin.position());
    }

    records.forEach(function(rec, i) {
      var start = bin.position();
      bin.writeUint8(0x20); // delete flag; 0x20 valid 0x2a deleted
      for (var j=0, n=fieldData.length; j<n; j++) {
        fieldData[j].write(i, bin);
      }
      if (bin.position() - start != recordBytes) {
        error("#exportRecords() Error exporting record:", rec);
      }
    });

    bin.writeUint8(0x1a); // end-of-file

    if (bin.position() != fileBytes) {
      error("Dbf#exportRecords() file size mismatch; expected:", fileBytes, "written:", bin.position());
    }
    return buffer;
  }

  function getHeaderSize(numFields) {
    return 33 + numFields * 32;
  }

  function getRecordSize(fieldSizes) {
    return utils.sum(fieldSizes) + 1; // delete byte plus data bytes
  }

  function initNumericField(info, arr, name) {
    var MAX_FIELD_SIZE = 18,
        data, size;

    data = getNumericFieldInfo(arr, name);
    info.decimals = data.decimals;
    size = Math.max(data.max.toFixed(info.decimals).length,
        data.min.toFixed(info.decimals).length);
    if (size > MAX_FIELD_SIZE) {
      size = MAX_FIELD_SIZE;
      info.decimals -= size - MAX_FIELD_SIZE;
      if (info.decimals < 0) {
        error ("Dbf#getFieldInfo() Out-of-range error.");
      }
    }
    info.size = size;

    var formatter = getDecimalFormatter(size, info.decimals);
    info.write = function(i, bin) {
      var rec = arr[i],
          str = formatter(rec[name]);
      if (str.length < size) {
        str = utils.lpad(str, size, ' ');
      }
      bin.writeString(str, size);
    };
  }

  function initBooleanField(info, arr, name) {
    info.size = 1;
    info.write = function(i, bin) {
      var val = arr[i][name],
          c;
      if (val === true) c = 'T';
      else if (val === false) c = 'F';
      else c = '?';
      bin.writeString(c);
    };
  }

  function initDateField(info, arr, name) {
    info.size = 8;
    info.write = function(i, bin) {
      var d = arr[i][name],
          str;
      if (d instanceof Date === false) {
        str = '00000000';
      } else {
        str = utils.lpad(d.getUTCFullYear(), 4, '0') +
              utils.lpad(d.getUTCMonth() + 1, 2, '0') +
              utils.lpad(d.getUTCDate(), 2, '0');
      }
      bin.writeString(str);
    };
  }

  function convertValueToString(s) {
    return s === undefined || s === null ? '' : String(s);
  }

  function initStringField(info, arr, name, encoding) {
    var formatter = encoding == 'ascii' ? encodeValueAsAscii : getStringWriterEncoded(encoding);
    var size = 0;
    var truncated = 0;
    var buffers = arr.map(function(rec) {
      var strval = convertValueToString(rec[name]);
      var buf = formatter(strval);
      if (buf.length > MAX_STRING_LEN) {
        if (encoding == 'ascii') {
          buf = buf.subarray(0, MAX_STRING_LEN);
        } else {
          buf = truncateEncodedString(buf, encoding, MAX_STRING_LEN);
        }
        truncated++;
      }
      size = Math.max(size, buf.length);
      return buf;
    });
    info.size = size;
    info.write = function(i, bin) {
      var buf = buffers[i],
          n = Math.min(size, buf.length),
          dest = bin._bytes,
          pos = bin.position(),
          j;
      for (j=0; j<n; j++) {
        dest[j + pos] = buf[j];
      }
      bin.position(pos + size);
    };
    if (truncated > 0) {
      info.warning = 'Truncated ' + truncated + ' string' + (truncated == 1 ? '' : 's') + ' to fit the 254-byte limit';
    }
  }

  // Convert string names to 11-byte buffers terminated by 0
  function encodeFieldNames(names, encoding) {
    return names.map(function(name) {
      var encoded = encodeString(name, encoding);
      var encLen = encoded.length;
      var buf = utils.createBuffer(11);
      for (var i=0; i < 11; i++) {
        buf[i] = i < 10 && encLen >= i - 1 ? encoded[i] : 0;
      }
      return buf;
    });
  }

  // Truncate and dedup field names
  //
  function convertFieldNames(names, encoding) {
    var names2 = getUniqFieldNames(names.map(cleanFieldName), 10, encoding);
    names2.forEach(function(name2, i) {
      if (names[i] != name2) {
        message('Changed field name from "' + names[i] + '" to "' + name2 + '"');
      }
    });
    return names2;
  }

  // Replace non-alphanumeric characters with _ and merge adjacent _
  // See: https://desktop.arcgis.com/en/arcmap/latest/manage-data/tables/fundamentals-of-adding-and-deleting-fields.htm#GUID-8E190093-8F8F-4132-AF4F-B0C9220F76B3
  // TODO: decide whether or not to avoid initial numerals
  function cleanFieldName_v1(name) {
    return name.replace(/[^A-Za-z0-9]+/g, '_');
  }

  // Support non-ascii field names
  function cleanFieldName(name) {
    return name.replace(/[-\s]+/g, '_');
  }

  function getFieldInfo(arr, name, encoding) {
    var type = discoverFieldType(arr, name),
        info = {
          type: type,
          decimals: 0
        };
    if (type == 'N') {
      initNumericField(info, arr, name);
    } else if (type == 'C') {
      initStringField(info, arr, name, encoding);
    } else if (type == 'L') {
      initBooleanField(info, arr, name);
    } else if (type == 'D') {
      initDateField(info, arr, name);
    } else {
      // Treat null fields as empty numeric fields; this way, they will be imported
      // again as nulls.
      info.size = 0;
      info.type = 'N';
      if (type) {
        info.warning = 'Unable to export ' + type + '-type data, writing null values';
      }
      info.write = function() {};
    }
    return info;
  }

  function discoverFieldType(arr, name) {
    var val;
    for (var i=0, n=arr.length; i<n; i++) {
      val = arr[i][name];
      if (utils.isString(val)) return "C";
      if (utils.isNumber(val)) return "N";
      if (utils.isBoolean(val)) return "L";
      if (val instanceof Date) return "D";
      if (val) return (typeof val);
    }
    return null;
  }

  function getDecimalFormatter(size, decimals) {
    // TODO: find better way to handle nulls
    var nullValue = ' '; // ArcGIS may use 0
    return function(val) {
      // TODO: handle invalid values better
      var valid = utils.isFiniteNumber(val),
          strval = valid ? val.toFixed(decimals) : String(nullValue);
      return utils.lpad(strval, size, ' ');
    };
  }

  function getNumericFieldInfo(arr, name) {
    var min = 0,
        max = 0,
        k = 1,
        power = 1,
        decimals = 0,
        eps = 1e-15,
        val;
    for (var i=0, n=arr.length; i<n; i++) {
      val = arr[i][name];
      if (!utils.isFiniteNumber(val)) {
        continue;
      }
      if (val < min || val > max) {
        if (val < min) min = val;
        if (val > max) max = val;
        while (Math.abs(val) >= power) {
          power *= 10;
          eps *= 10;
        }
      }
      while (Math.abs(Math.round(val * k) - val * k) > eps) {
        if (decimals == 15) { // dbf limit
          // TODO: round overflowing values ?
          break;
        }
        decimals++;
        eps *= 10;
        k *= 10;
      }
    }
    return {
      decimals: decimals,
      min: min,
      max: max
    };
  }

  // return an array buffer or null if value contains non-ascii chars
  function encodeValueAsAscii(val, strict) {
    var str = String(val),
        n = str.length,
        view = bufferPool.reserve(n),
        i, c;
    for (i=0; i<n; i++) {
      c = str.charCodeAt(i);
      if (c > 127) {
        if (strict) {
          view = null;
          i = 0; // return all bytes to pool
          break;
        }
        c = '?'.charCodeAt(0);
      }
      view[i] = c;
    }
    bufferPool.putBack(n-i);
    return view ? view.subarray(0, i) : null;
  }

  function getStringWriterEncoded(encoding) {
    return function(val) {
      // optimization -- large majority of strings in real-world datasets are
      // ascii. Try (faster) ascii encoding first, fall back to text encoder.
      var buf = encodeValueAsAscii(val, true);
      if (buf === null) {
        buf = encodeString(String(val), encoding);
      }
      return buf;
    };
  }

  // try to remove partial multi-byte characters from the end of an encoded string.
  function truncateEncodedString(buf, encoding, maxLen) {
    var truncated = buf.slice(0, maxLen);
    var len = maxLen;
    var tmp, str;
    while (len > 0 && len >= maxLen - 3) {
      tmp = len == maxLen ? truncated : buf.slice(0, len);
      str = decodeString(tmp, encoding);
      if (str.charAt(str.length-1) != '\ufffd') {
        truncated = tmp;
        break;
      }
      len--;
    }
    return truncated;
  }

  function exportDbf(dataset, opts) {
    return dataset.layers.reduce(function(files, lyr) {
      if (lyr.data) {
        files = files.concat(exportDbfFile(lyr, dataset, opts));
      }
      return files;
    }, []);
  }

  function exportDbfFile(lyr, dataset, opts) {
    var data = lyr.data,
        buf;
    // create empty data table if missing a table or table is being cut out
    if (!data || opts.cut_table || opts.drop_table) {
      data = new DataTable(lyr.shapes ? lyr.shapes.length : 0);
    }
    // dbfs should have at least one column; add id field if none
    if (data.isEmpty()) {
      data.addIdField();
    }
    if (data.exportAsDbf) {
      buf = data.exportAsDbf(opts);
    } else {
      buf = Dbf.exportRecords(data.getRecords(), opts.encoding, opts.field_order);
    }
    if (utils.isInteger(opts.ldid)) {
      new Uint8Array(buf)[29] = opts.ldid; // set language driver id
    }
    // TODO: also export .cpg page
    return [{
      content: buf,
      filename: lyr.name + '.dbf'
    }];
  }

  function exportRecordsAsFixedWidthString(fields, records, opts) {
    var rows = [], col;
    for (var i=0; i<fields.length; i++) {
      col = formatFixedWidthColumn(fields[i], records, opts);
      if (i === 0) {
        rows = col;
      } else for (var j=0; j<rows.length; j++) {
        rows[j] += ' ' + col[j];
      }
    }
    return rows.join('\n');
  }

  function formatFixedWidthColumn(field, records, opts) {
    var arr = [],
        maxLen = field.length,
        n = records.length,
        i, val;
    arr.push(field);
    for (i=0; i<n; i++) {
      val = formatFixedWidthValue(records[i][field], opts);
      maxLen = Math.max(maxLen, val.length);
      arr.push(val);
    }
    for (i=0; i<arr.length; i++) {
      arr[i] = arr[i].padEnd(maxLen, ' ');
    }
    return arr;
  }

  function formatFixedWidthValue(val, opts) {
    // TODO: remove duplication with mapshaper-delim-export.js
    var s;
    if (val == null) {
      s = '';
    } else if (utils.isString(val)) {
      s = val; // TODO: handle wide characters, newlines etc.
    } else if (utils.isNumber(val)) {
      s = opts.decimal_comma ? utils.formatIntlNumber(val) : utils.formatNumber(val);
    } else if (utils.isObject(val)) {
      s = JSON.stringify(val);
    } else {
      s = val + '';
    }
    return s;
  }


  function readFixedWidthRecords(reader, opts) {
    var str = reader.toString(opts.encoding || 'ascii');
    return readFixedWidthRecordsFromString(str, opts);
  }

  function readFixedWidthRecordsFromString(str, ops) {
    var fields = parseFixedWidthInfo(str.substring(0, 2000));
    if (!fields) return [];
    var lines = utils.splitLines(str);
    if (lines[lines.length - 1] === '') lines.pop(); // handle newline at end of string
    var records = [];
    for (var i=1; i<lines.length; i++) {
      records.push(parseFixedWidthLine(lines[i], fields));
    }
    return records;
  }

  function parseFixedWidthInfo(sample) {
    var lines = utils.splitLines(sample);
    if (lines.length > 2) lines.pop(); // remove possible partial line
    var n = getMaxLineLength(lines);
    var headerLine = lines[0];
    var colInfo = [];
    var colStart = 0;
    var inContent = false;
    var inHeader = false;
    var isContentChar, isHeaderChar, isColStart, colEnd;
    for (var i=0; i<=n; i++) {
      isHeaderChar = testContentChar(headerLine, i);
      isContentChar = !testEmptyCol(lines, i);
      isColStart = isHeaderChar && !inHeader;
      if (isColStart && inContent) {
        // all lines should have a space char in the position right before a header starts
        return null;
      }
      if (i == n || i > 0 && isColStart) {
        colEnd = i == n ? undefined : i-1;
        colInfo.push({
          name: readValue$1(headerLine, colStart, colEnd),
          end: colEnd,
          start: colStart
        });
        colStart = i;
      }
      inContent = isContentChar;
      inHeader = isHeaderChar;
    }
    return colInfo.length > 0 ? colInfo : null;
  }

  function getMaxLineLength(lines) {
    var max = 0;
    for (var i=0; i<lines.length; i++) {
      max = Math.max(max, lines[i].length);
    }
    return max;
  }

  function readValue$1(line, start, end) {
    return line.substring(start, end).trim();
  }

  function parseFixedWidthLine(str, fields) {
    var obj = {}, field;
    for (var i=0; i<fields.length; i++) {
      field = fields[i];
      obj[field.name] = readValue$1(str, field.start, field.end);
    }
    return obj;
  }

  function testContentChar(str, i) {
    return i < str.length && str[i] !== ' ';
  }

  // return true iff all samples are blank at index i
  function testEmptyCol(samples, i) {
    var line;
    for (var j=0; j<samples.length; j++) {
      line = samples[j];
      if (testContentChar(line, i)) return false;
    }
    return true;
  }

  // Generate output content from a dataset object
  function exportDelim(dataset, opts) {
    var delim = getExportDelimiter(dataset.info, opts),
        ext = getDelimFileExtension(delim, opts);
    return dataset.layers.reduce(function(arr, lyr) {
      if (lyr.data){
        arr.push({
          // TODO: consider supporting encoding= option
          content: exportLayerAsDSV(lyr, delim, opts),
          filename: (lyr.name || 'output') + '.' + ext
        });
      }
      return arr;
    }, []);
  }

  function exportLayerAsDSV(lyr, delim, optsArg) {
    var opts = optsArg || {};
    var encoding = opts.encoding || 'utf8';
    var records = lyr.data.getRecords();
    var fields = findFieldNames(records, opts.field_order);
    if (delim == ' ') {
      return exportRecordsAsFixedWidthString(fields, records, opts);
    }
    var formatRow = getDelimRowFormatter(fields, delim, opts);
    // exporting utf8 and ascii text as string by default (for now)
    var exportAsString = encodingIsUtf8(encoding) && !opts.to_buffer &&
        (records.length < 10000 || opts.to_string);
    if (exportAsString) {
      return exportRecordsAsString(fields, records, formatRow);
    } else {
      return exportRecordsAsBuffer(fields, records, formatRow, encoding);
    }
  }

  function exportRecordsAsString(fields, records, formatRow) {
    var header = formatHeader(fields, formatRow);
    if (!records.length) return header;
    return header + '\n' + records.map(formatRow).join('\n');
  }

  function exportRecordsAsBuffer(fields, records, formatRow, encoding) {
    var str = formatHeader(fields, formatRow);
    var buffers = [encodeString(str, encoding)];
    var tmp = [];
    var n = records.length;
    var i = 0;
    while (i < n) {
      tmp.push(formatRow(records[i]));
      i++;
      if (i % 1000 === 0 || i == n) {
        str = '\n' + tmp.join('\n');
        tmp = [];
        buffers.push(encodeString(str, encoding));
      }
    }
    return Buffer.concat(buffers);
  }

  function formatHeader(fields, formatRow) {
    var rec = fields.reduce(function(memo, f) {
      memo[f] = f;
      return memo;
    }, {});
    return formatRow(rec);
  }

  function formatDelimHeader(fields, delim) {
    var formatValue = getDelimValueFormatter(delim);
    return fields.map(formatValue).join(delim);
  }

  function getDelimRowFormatter(fields, delim, opts) {
    var formatValue = getDelimValueFormatter(delim, opts);
    return function(rec) {
      return fields.map(function(f) {
        return formatValue(rec[f]);
      }).join(delim);
    };
  }

  function getDelimValueFormatter(delim, opts) {
    var dquoteRxp = new RegExp('["\n\r' + delim + ']');
    var decimalComma = opts && opts.decimal_comma || false;
    function formatString(s) {
      if (dquoteRxp.test(s)) {
        s = '"' + s.replace(/"/g, '""') + '"';
      }
      return s;
    }
    return function(val) {
      var s;
      if (val == null) {
        s = '';
      } else if (utils.isString(val)) {
        s = formatString(val);
      } else if (utils.isNumber(val)) {
        s = decimalComma ? utils.formatIntlNumber(val) : utils.formatNumber(val);
      } else if (utils.isObject(val)) {
        s = formatString(JSON.stringify(val));
      } else {
        s = val + '';
      }
      return s;
    };
  }

  function getExportDelimiter(info, opts) {
    var delim = ','; // default
    var outputExt = opts.file ? getFileExtension(opts.file) : '';
    if (opts.delimiter) {
      delim = opts.delimiter;
    } else if (outputExt == 'tsv') {
      delim = '\t';
    } else if (outputExt == 'csv') {
      delim = ',';
    } else if (info.input_delimiter) {
      delim = info.input_delimiter;
    }
    return delim;
  }

  // If output filename is not specified, use the delimiter char to pick
  // an extension.
  function getDelimFileExtension(delim, opts) {
    var ext = 'txt'; // default
    if (opts.file) {
      ext = getFileExtension(opts.file);
    } else if (delim == '\t') {
      ext = 'tsv';
    } else if (delim == ',') {
      ext = 'csv';
    }
    return ext;
  }

  var DelimExport = /*#__PURE__*/Object.freeze({
    __proto__: null,
    exportDelim: exportDelim,
    exportLayerAsDSV: exportLayerAsDSV,
    getDelimValueFormatter: getDelimValueFormatter
  });

  var ShpType = {
    NULL: 0,
    POINT: 1,
    POLYLINE: 3,
    POLYGON: 5,
    MULTIPOINT: 8,
    POINTZ: 11,
    POLYLINEZ: 13,
    POLYGONZ: 15,
    MULTIPOINTZ: 18,
    POINTM: 21,
    POLYLINEM: 23,
    POLYGONM: 25,
    MULIPOINTM: 28,
    MULTIPATCH: 31 // not supported
  };

  ShpType.isPolygonType = function(t) {
    return t == 5 || t == 15 || t == 25;
  };

  ShpType.isPolylineType = function(t) {
    return t == 3 || t == 13 || t == 23;
  };

  ShpType.isMultiPartType = function(t) {
    return ShpType.isPolygonType(t) || ShpType.isPolylineType(t);
  };

  ShpType.isMultiPointType = function(t) {
    return t == 8 || t == 18 || t == 28;
  };

  ShpType.isZType = function(t) {
    return [11,13,15,18].includes(t);
  };

  ShpType.isMType = function(t) {
    return ShpType.isZType(t) || [21,23,25,28].includes(t);
  };

  ShpType.hasBounds = function(t) {
    return ShpType.isMultiPartType(t) || ShpType.isMultiPointType(t);
  };

  // Convert a dataset to Shapefile files
  function exportShapefile(dataset, opts) {
    return dataset.layers.reduce(function(files, lyr) {
      var prj = exportPrjFile(lyr, dataset);
      files = files.concat(exportShpAndShxFiles(lyr, dataset, opts));
      files = files.concat(exportDbfFile(lyr, dataset, opts));
      if (prj) files.push(prj);
      return files;
    }, []);
  }

  function exportPrjFile(lyr, dataset) {
    var info = dataset.info || {};
    var prj = info.prj;
    if (!prj) {
      try {
        prj = crsToPrj(getDatasetCRS(dataset));
      } catch(e) {}
    }
    if (!prj) {
      message("Unable to generate .prj file for", lyr.name + '.shp');
    }
    return prj ? {
      content: prj,
      filename: lyr.name + '.prj'
    } : null;
  }

  function getShapefileExportType(lyr) {
    var type = lyr.geometry_type;
    var shpType;
    if (type == 'point') {
      shpType = findMaxPartCount(lyr.shapes || []) <= 1 ? ShpType.POINT : ShpType.MULTIPOINT;
    } else if (type == 'polygon') {
      shpType = ShpType.POLYGON;
    } else if (type == 'polyline') {
      shpType = ShpType.POLYLINE;
    } else {
      shpType = ShpType.NULL;
    }
    return shpType;
  }

  function exportShpAndShxFiles(layer, dataset, opts) {
    var shapes = layer.shapes || utils.initializeArray(new Array(getFeatureCount(layer)), null);
    var bounds = new Bounds();
    var shpType = getShapefileExportType(layer);
    var fileBytes = 100;
    var shxBytes = 100 + shapes.length * 8;
    var shxBin = new BinArray(shxBytes).bigEndian().position(100); // jump to record section
    var shpBin;

    // TODO: consider writing records to an expanding buffer instead of generating
    // individual buffers for each record (for large point datasets,
    // creating millions of buffers impacts performance significantly)
    var shapeBuffers = shapes.map(function(shape, i) {
      var pathData = exportPathData(shape, dataset.arcs, layer.geometry_type);
      var rec = exportShpRecord(pathData, i+1, shpType);
      var recBytes = rec.buffer.byteLength;

      // add shx record
      shxBin.writeInt32(fileBytes / 2); // record offset in 16-bit words
      // alternative to below: shxBin.writeBuffer(rec.buffer, 4, 4)
      shxBin.writeInt32(recBytes / 2 - 4); // record content length in 16-bit words

      fileBytes += recBytes;
      if (rec.bounds) bounds.mergeBounds(rec.bounds);
      return rec.buffer;
    });

    // write .shp header section
    shpBin = new BinArray(fileBytes, false)
      .writeInt32(9994)
      .skipBytes(5 * 4)
      .writeInt32(fileBytes / 2)
      .littleEndian()
      .writeInt32(1000)
      .writeInt32(shpType);

    if (bounds.hasBounds()) {
      shpBin.writeFloat64(bounds.xmin || 0) // using 0s as empty value
        .writeFloat64(bounds.ymin || 0)
        .writeFloat64(bounds.xmax || 0)
        .writeFloat64(bounds.ymax || 0);
    } else {
      // no bounds -- assume no shapes or all null shapes -- using 0s as bbox
      shpBin.skipBytes(4 * 8);
    }
    shpBin.skipBytes(4 * 8); // skip Z & M type bounding boxes;

    // write records section of .shp
    shapeBuffers.forEach(function(buf) {
      shpBin.writeBuffer(buf);
    });

    // write .shx header
    shxBin.position(0)
      .writeBuffer(shpBin.buffer(), 100) // copy .shp header to .shx
      .position(24) // substitute shx file size for shp file size
      .writeInt32(shxBytes / 2);

    return [{
        content: shpBin.buffer(),
        filename: layer.name + ".shp"
      }, {
        content: shxBin.buffer(),
        filename: layer.name + ".shx"
      }];
  }

  // Returns an ArrayBuffer containing a Shapefile record for one shape
  //   and the bounding box of the shape.
  // TODO: remove collapsed rings, convert to null shape if necessary
  //
  function exportShpRecord(data, id, shpType) {
    var multiPartType = ShpType.isMultiPartType(shpType),
        singlePointType = !multiPartType && !ShpType.isMultiPointType(shpType),
        isNull = data.pointCount > 0 === false,
        bounds = isNull ? null : data.bounds,
        bin = null;

    if (isNull) {
      bin = new BinArray(12, false)
        .writeInt32(id)
        .writeInt32(2)
        .littleEndian()
        .writeInt32(0);

    } else if (singlePointType) {
      bin = new BinArray(28, false)
        .writeInt32(id)
        .writeInt32(10)
        .littleEndian()
        .writeInt32(shpType)
        .writeFloat64(data.pathData[0].points[0][0])
        .writeFloat64(data.pathData[0].points[0][1]);

    } else {
      var partIndexIdx = 52,
          pointsIdx = multiPartType ? partIndexIdx + 4 * data.pathCount : 48,
          recordBytes = pointsIdx + 16 * data.pointCount,
          pointCount = 0;

      bin = new BinArray(recordBytes, false)
        .writeInt32(id)
        .writeInt32((recordBytes - 8) / 2)
        .littleEndian()
        .writeInt32(shpType)
        .writeFloat64(bounds.xmin)
        .writeFloat64(bounds.ymin)
        .writeFloat64(bounds.xmax)
        .writeFloat64(bounds.ymax);

      if (multiPartType) {
        bin.writeInt32(data.pathCount);
      }

      bin.writeInt32(data.pointCount);
      data.pathData.forEach(function(path, i) {
        if (multiPartType) {
          bin.position(partIndexIdx + i * 4).writeInt32(pointCount);
        }
        bin.position(pointsIdx + pointCount * 16);
        for (var j=0, len=path.points.length; j<len; j++) {
          bin.writeFloat64(path.points[j][0]);
          bin.writeFloat64(path.points[j][1]);
        }
        pointCount += j;
      });
      if (data.pointCount != pointCount) {
        error("Shp record point count mismatch; pointCount:",
            pointCount, "data.pointCount:", data.pointCount);
      }
    }

    return {bounds: bounds, buffer: bin.buffer()};
  }

  var ShpExport = /*#__PURE__*/Object.freeze({
    __proto__: null,
    exportShapefile: exportShapefile
  });

  var TopoJSON = {};

  // Iterate over all arrays of arc is in a geometry object
  // @cb callback: function(ids)
  // callback returns undefined or an array of replacement ids
  //
  TopoJSON.forEachShapePart = function forEachShapePart(obj, cb) {
    var iterators = {
          GeometryCollection: function(o) {o.geometries.forEach(eachGeom);},
          LineString: function(o) {
            var retn = cb(o.arcs);
            if (retn) o.arcs = retn;
          },
          MultiLineString: function(o) {eachMultiPath(o.arcs);},
          Polygon: function(o) {eachMultiPath(o.arcs);},
          MultiPolygon: function(o) {o.arcs.forEach(eachMultiPath);}
        };

    eachGeom(obj);

    function eachGeom(o) {
      if (o.type in iterators) {
        iterators[o.type](o);
      }
    }

    function eachMultiPath(arr) {
      var retn;
      for (var i=0; i<arr.length; i++) {
        retn = cb(arr[i]);
        if (retn) arr[i] = retn;
      }
    }
  };

  TopoJSON.forEachArc = function forEachArc(obj, cb) {
    TopoJSON.forEachShapePart(obj, function(ids) {
      var retn;
      for (var i=0; i<ids.length; i++) {
        retn = cb(ids[i]);
        if (utils.isInteger(retn)) {
          ids[i] = retn;
        }
      }
    });
  };

  function getPresimplifyFunction(width) {
    var quanta = 10000,  // enough resolution for pixel-level detail at 1000px width and 10x zoom
        k = quanta / width;
    return function(z) {
      // could substitute a rounding function with decimal precision
      return z === Infinity ? 0 : Math.ceil(z * k);
    };
  }

  function importMetadata(dataset, obj) {
    if (obj.proj4) {
      dataset.info.crs = getCRS(obj.proj4);
    }
  }

  function exportMetadata(dataset) {
    var crs = getDatasetCRS(dataset);
    var proj4 = null;
    if (crs) {
      proj4 = crsToProj4(crs);
    }
    return {
      proj4: proj4
    };
  }

  cmd.explodeFeatures = function(lyr, arcs, opts) {
    var properties = lyr.data ? lyr.data.getRecords() : null,
        explodedProperties = properties ? [] : null,
        explodedShapes = [],
        explodedLyr = utils.extend({}, lyr);

    lyr.shapes.forEach(function(shp, shpId) {
      var exploded;
      if (!shp) {
        explodedShapes.push(null);
      } else {
        if (lyr.geometry_type == 'polygon' && shp.length > 1) {
          if (opts && opts.naive) {
            exploded = explodePolygonNaive(shp, arcs);
          } else {
            exploded = explodePolygon(shp, arcs);
          }
        } else {
          exploded = explodeShape(shp);
        }
        utils.merge(explodedShapes, exploded);
      }
      if (explodedProperties !== null) {
        for (var i=0, n=exploded ? exploded.length : 1; i<n; i++) {
          explodedProperties.push(cloneProperties(properties[shpId]));
        }
      }
    });

    explodedLyr.shapes = explodedShapes;
    if (explodedProperties !== null) {
      explodedLyr.data = new DataTable(explodedProperties);
    }

    printMessage(lyr, explodedLyr);

    return explodedLyr;
  };

  function printMessage(pre, post) {
  var n1 = getFeatureCount(pre),
      n2 = getFeatureCount(post),
      msg = utils.format('Exploded %,d feature%s into %,d feature%s',
        n1, utils.pluralSuffix(n1), n2,
        utils.pluralSuffix(n2));
    message(msg);
  }

  function explodeShape(shp) {
    return shp.map(function(part) {
      return [part.concat()];
    });
  }

  function explodePolygon(shape, arcs, reverseWinding) {
    var paths = getPathMetadata(shape, arcs, "polygon");
    var groups = groupPolygonRings(paths, arcs, reverseWinding);
    return groups.map(function(group) {
      return group.map(function(ring) {
        return ring.ids;
      });
    });
  }

  function explodePolygonNaive(shape, arcs) {
    var paths = getPathMetadata(shape, arcs, "polygon");
    return paths.map(function(path) {
      if (path.area < 0) {
        reversePath(path.ids);
      }
      return [path.ids];
    });
  }

  function cloneProperties(obj) {
    return Object.assign({}, obj);
  }

  var Explode = /*#__PURE__*/Object.freeze({
    __proto__: null,
    explodePolygon: explodePolygon
  });

  TopoJSON.getPresimplifyFunction = getPresimplifyFunction;

  function exportTopoJSON(dataset, opts) {
    var extension = '.' + (opts.extension || 'json'),
        needCopy = !opts.final || datasetHasPaths(dataset) && dataset.arcs.getRetainedInterval() > 0,
        stringify = JSON.stringify;

    if (needCopy) {
      dataset = copyDatasetForExport(dataset);
    }

    if (opts.prettify) {
      stringify = getFormattedStringify('coordinates,arcs,bbox,translate,scale'.split(','));
    }

    if (opts.width > 0 || opts.height > 0) {
      opts = utils.defaults({invert_y: true}, opts);
      transformDatasetToPixels(dataset, opts);
    } else if (opts.fit_bbox) {
      transformDatasetToPixels(dataset, {fit_bbox: opts.fit_bbox});
    }

    if (opts.precision) {
      setCoordinatePrecision(dataset, opts.precision);
    }

    if (opts.singles) {
      return splitDataset(dataset).map(function(dataset) {
        return {
          content: stringify(TopoJSON.exportTopology(dataset, opts)),
          filename: (dataset.layers[0].name || 'output') + extension
        };
      });
    } else {
      return [{
        filename: opts.file || getOutputFileBase(dataset) + extension,
        content: stringify(TopoJSON.exportTopology(dataset, opts))
      }];
    }
  }

  // Convert a dataset object to a TopoJSON topology object
  // Careful -- arcs must be a copy if further processing will occur.
  TopoJSON.exportTopology = function(dataset, opts) {
    var topology = {type: "Topology", arcs: []},
        hasPaths = datasetHasPaths(dataset),
        bounds = getDatasetBounds(dataset);

    if (opts.bbox && bounds.hasBounds()) {
      topology.bbox = bounds.toArray();
    }

    if (hasPaths && opts.presimplify && !dataset.arcs.getVertexData().zz) {
      // Calculate simplification thresholds if needed
      cmd.simplify(dataset, opts);
    }
    // auto-detect quantization if arcs are present
    if (!opts.no_quantization && (opts.quantization || hasPaths)) {
      topology.transform = TopoJSON.transformDataset(dataset, bounds, opts);
    }
    if (hasPaths) {
      dissolveArcs(dataset); // dissolve/prune arcs for more compact output
      topology.arcs = TopoJSON.exportArcs(dataset.arcs, bounds, opts);
      if (topology.transform) {
        TopoJSON.deltaEncodeArcs(topology.arcs);
      }
    }

    // export layers as TopoJSON named objects
    topology.objects = dataset.layers.reduce(function(objects, lyr, i) {
      var name = lyr.name || "layer" + (i + 1);
      objects[name] = TopoJSON.exportLayer(lyr, dataset.arcs, opts);
      return objects;
    }, {});

    if (opts.metadata) {
      topology.metadata = exportMetadata(dataset);
    }
    return topology;
  };

  TopoJSON.transformDataset = function(dataset, bounds, opts) {
    var bounds2 = TopoJSON.calcExportBounds(bounds, dataset.arcs, opts),
        fw = bounds.getTransform(bounds2),
        inv = fw.invert();

    function transform(x, y) {
      var p = fw.transform(x, y);
      return [Math.round(p[0]), Math.round(p[1])];
    }

    if (dataset.arcs) {
      dataset.arcs.transformPoints(transform);
    }
    // support non-standard format with quantized arcs and non-quantized points
    if (!opts.no_point_quantization) {
      dataset.layers.filter(layerHasPoints).forEach(function(lyr) {
        transformPointsInLayer(lyr, transform);
      });
    }

    // TODO: think about handling geometrical errors introduced by quantization,
    // e.g. segment intersections and collapsed polygon rings.
    return {
      scale: [inv.mx, inv.my],
      translate: [inv.bx, inv.by]
    };
  };

  // Export arcs as arrays of [x, y] and possibly [z] coordinates
  TopoJSON.exportArcs = function(arcs, bounds, opts) {
    var fromZ = null,
        output = [];
    if (opts.presimplify) {
      fromZ = getPresimplifyFunction(bounds.width());
    }
    arcs.forEach2(function(i, n, xx, yy, zz) {
      var arc = [], p;
      for (var j=i + n; i<j; i++) {
        p = [xx[i], yy[i]];
        if (fromZ) {
          p.push(fromZ(zz[i]));
        }
        arc.push(p);
      }
      output.push(arc.length > 1 ? arc : null);
    });
    return output;
  };

  // Apply delta encoding in-place to an array of topojson arcs
  TopoJSON.deltaEncodeArcs = function(arcs) {
    arcs.forEach(function(arr) {
      var ax, ay, bx, by, p;
      for (var i=0, n=arr.length; i<n; i++) {
        p = arr[i];
        bx = p[0];
        by = p[1];
        if (i > 0) {
          p[0] = bx - ax;
          p[1] = by - ay;
        }
        ax = bx;
        ay = by;
      }
    });
  };

  // Calculate the x, y extents that map to an integer unit in topojson output
  // as a fraction of the x- and y- extents of the average segment.
  TopoJSON.calcExportResolution = function(arcs, k) {
    // TODO: think about the effect of long lines, e.g. from polar cuts.
    var xy = getAvgSegment2(arcs);
    return [xy[0] * k, xy[1] * k];
  };

  // Calculate the bounding box of quantized topojson coordinates using one
  // of several methods.
  TopoJSON.calcExportBounds = function(bounds, arcs, opts) {
    var unitXY, xmax, ymax;
    if (opts.topojson_precision > 0) {
      unitXY = TopoJSON.calcExportResolution(arcs, opts.topojson_precision);
    } else if (opts.quantization > 0) {
      unitXY = [bounds.width() / (opts.quantization-1), bounds.height() / (opts.quantization-1)];
    } else if (opts.precision > 0) {
      unitXY = [opts.precision, opts.precision];
    } else {
      // default -- auto quantization at 0.02 of avg. segment len
      unitXY = TopoJSON.calcExportResolution(arcs, 0.02);
    }
    xmax = Math.ceil(bounds.width() / unitXY[0]) || 0;
    ymax = Math.ceil(bounds.height() / unitXY[1]) || 0;
    return new Bounds(0, 0, xmax, ymax);
  };

  TopoJSON.exportProperties = function(geometries, table, opts) {
    var properties = exportProperties(table, opts),
        ids = exportIds(table, opts);
    geometries.forEach(function(geom, i) {
      if (properties) {
        geom.properties = properties[i];
      }
      if (ids) {
        geom.id = ids[i];
      }
    });
  };

  // Export a mapshaper layer as a TopoJSON GeometryCollection
  TopoJSON.exportLayer = function(lyr, arcs, opts) {
    var n = getFeatureCount(lyr),
        geometries = [],
        exporter = TopoJSON.exporters[lyr.geometry_type] || null,
        shp;
    for (var i=0; i<n; i++) {
      shp = exporter && lyr.shapes[i];
      if (shp) {
        geometries[i] = exporter(shp, arcs, opts);
      } else {
        geometries[i] = {type: null};
      }
    }
    if (lyr.data) {
      TopoJSON.exportProperties(geometries, lyr.data, opts);
    }
    return {
      type: "GeometryCollection",
      geometries: geometries
    };
  };

  TopoJSON.exportPolygonGeom = function(shape, coords, opts) {
    var geom = {};
    shape = filterEmptyArcs(shape, coords);
    if (!shape || shape.length === 0) {
      geom.type = null;
    } else if (shape.length > 1) {
      geom.arcs = explodePolygon(shape, coords, opts.invert_y);
      if (geom.arcs.length == 1) {
        geom.arcs = geom.arcs[0];
        geom.type = "Polygon";
      } else {
        geom.type = "MultiPolygon";
      }
    } else {
      geom.arcs = shape;
      geom.type = "Polygon";
    }
    return geom;
  };

  TopoJSON.exportLineGeom = function(shape, coords) {
    var geom = {};
    shape = filterEmptyArcs(shape, coords);
    if (!shape || shape.length === 0) {
      geom.type = null;
    } else if (shape.length == 1) {
      geom.type = "LineString";
      geom.arcs = shape[0];
    } else {
      geom.type = "MultiLineString";
      geom.arcs = shape;
    }
    return geom;
  };

  TopoJSON.exporters = {
    polygon: TopoJSON.exportPolygonGeom,
    polyline: TopoJSON.exportLineGeom,
    point: GeoJSON.exportPointGeom
  };

  var TopojsonExport = /*#__PURE__*/Object.freeze({
    __proto__: null,
    exportTopoJSON: exportTopoJSON
  });

  function importJSONTable(arr) {
    fixInconsistentFields(arr);
    return {
      layers: [{
        data: new DataTable(arr)
      }],
      info: {}
    };
  }

  function exportJSON(dataset, opts) {
    return dataset.layers.reduce(function(arr, lyr) {
      if (lyr.data){
        arr.push({
          content: exportJSONTable(lyr, opts),
          filename: (lyr.name || 'output') + '.json'
        });
      }
      return arr;
    }, []);
  }

  function exportJSONTable(lyr, opts) {
    opts = opts || {};
    var records = lyr.data.getRecords();
    if (opts.ndjson) {
      return records.map(stringifyAsNDJSON).join('\n');
    }
    if (opts.prettify) {
      return getFormattedStringify([])(records);
    }
    return JSON.stringify(records);
  }

  var JsonTable = /*#__PURE__*/Object.freeze({
    __proto__: null,
    importJSONTable: importJSONTable,
    exportJSON: exportJSON,
    exportJSONTable: exportJSONTable
  });

  // Guess the type of a data file from file extension, or return null if not sure
  function guessInputFileType(file) {
    var ext = getFileExtension(file || '').toLowerCase(),
        type = null;
    if (ext == 'dbf' || ext == 'shp' || ext == 'prj' || ext == 'shx') {
      type = ext;
    } else if (/json$/.test(ext)) {
      type = 'json';
    } else if (ext == 'csv' || ext == 'tsv' || ext == 'txt' || ext == 'tab') {
      type = 'text';
    }
    return type;
  }

  function guessInputContentType(content) {
    var type = null;
    if (utils.isString(content)) {
      type = stringLooksLikeJSON(content) ? 'json' : 'text';
    } else if (utils.isObject(content) && content.type || utils.isArray(content)) {
      type = 'json';
    }
    return type;
  }

  function guessInputType(file, content) {
    return guessInputFileType(file) || guessInputContentType(content);
  }

  //
  function stringLooksLikeJSON(str) {
    return /^\s*[{[]/.test(String(str));
  }

  function couldBeDsvFile(name) {
    var ext = getFileExtension(name).toLowerCase();
    return /csv|tsv|txt$/.test(ext);
  }

  function isZipFile(file) {
    return /\.zip$/i.test(file);
  }

  function isSupportedOutputFormat(fmt) {
    var types = ['geojson', 'topojson', 'json', 'dsv', 'dbf', 'shapefile', 'svg'];
    return types.indexOf(fmt) > -1;
  }

  function getFormatName(fmt) {
    return {
      geojson: 'GeoJSON',
      topojson: 'TopoJSON',
      json: 'JSON records',
      dsv: 'CSV',
      dbf: 'DBF',
      shapefile: 'Shapefile',
      svg: 'SVG'
    }[fmt] || '';
  }

  // Assumes file at @path is one of Mapshaper's supported file types
  function isSupportedBinaryInputType(path) {
    var ext = getFileExtension(path).toLowerCase();
    return ext == 'shp' || ext == 'shx' || ext == 'dbf'; // GUI also supports zip files
  }

  // Detect extensions of some unsupported file types, for cmd line validation
  function filenameIsUnsupportedOutputType(file) {
    var rxp = /\.(shx|prj|xls|xlsx|gdb|sbn|sbx|xml|kml)$/i;
    return rxp.test(file);
  }

  var FileTypes = /*#__PURE__*/Object.freeze({
    __proto__: null,
    guessInputFileType: guessInputFileType,
    guessInputContentType: guessInputContentType,
    guessInputType: guessInputType,
    stringLooksLikeJSON: stringLooksLikeJSON,
    couldBeDsvFile: couldBeDsvFile,
    isZipFile: isZipFile,
    isSupportedOutputFormat: isSupportedOutputFormat,
    getFormatName: getFormatName,
    isSupportedBinaryInputType: isSupportedBinaryInputType,
    filenameIsUnsupportedOutputType: filenameIsUnsupportedOutputType
  });

  function getOutputFormat(dataset, opts) {
    var outFile = opts.file || null,
        inFmt = dataset.info && dataset.info.input_formats && dataset.info.input_formats[0],
        outFmt = null;

    // if user has specified a format, use that
    if (opts.format) {
      return opts.format;
    }

    // if an output filename is given, try to infer format from filename etc.
    if (outFile) {
      outFmt = inferOutputFormat(outFile, inFmt);
    } else if (inFmt) {
      outFmt = inFmt;
    }

    if (outFmt == 'json' && datasetHasGeometry(dataset)) {
      // special case: inferred output format is a json table (either because
      // the output file has a .json extension or because the input file was a
      // json table), but the output dataset contains shapes
      outFmt = 'geojson';
    }

    return outFmt || null;
  }

  // Infer output format by considering file name and (optional) input format
  function inferOutputFormat(file, inputFormat) {
    var ext = getFileExtension(file).toLowerCase(),
        format = null;
    if (ext == 'shp') {
      format = 'shapefile';
    } else if (ext == 'dbf') {
      format = 'dbf';
    } else if (ext == 'svg') {
      format = 'svg';
    } else if (/json$/.test(ext)) {
      format = 'geojson';
      if (ext == 'topojson' || inputFormat == 'topojson' && ext != 'geojson') {
        format = 'topojson';
      } else if (ext == 'json' && inputFormat == 'json') {
        // .json -> json table is not always the best inference...
        // additional logic should be applied downstream
        format = 'json'; // JSON table
      }
    } else if (couldBeDsvFile(file)) {
      format = 'dsv';
    } else if (inputFormat) {
      format = inputFormat;
    }
    return format;
  }

  var OutputFormat = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getOutputFormat: getOutputFormat,
    inferOutputFormat: inferOutputFormat
  });

  // @targets - non-empty output from Catalog#findCommandTargets()
  //
  function exportTargetLayers(targets, opts) {
    // convert target fmt to dataset fmt
    var datasets = targets.map(function(target) {
      return utils.defaults({layers: target.layers}, target.dataset);
    });
    return exportDatasets(datasets, opts);
  }

  //
  //
  function exportDatasets(datasets, opts) {
    var format = getOutputFormat(datasets[0], opts);
    var files;
    if (format == 'svg' || format == 'topojson' || format == 'geojson' && opts.combine_layers) {
      // multi-layer formats: combine multiple datasets into one
      if (datasets.length > 1) {
        datasets = [mergeDatasetsForExport(datasets)];
        if (format == 'topojson') {
          // Build topology, in case user has loaded several
          // files derived from the same source, with matching coordinates
          // (Downsides: useless work if geometry is unrelated;
          // could create many small arcs if layers are partially related)
          buildTopology(datasets[0]);
        }
        // KLUDGE let exporter know that copying is not needed
        // (because shape data was deep-copied during merge)
        opts = utils.defaults({final: true}, opts);
      }
    } else {
      datasets = datasets.map(copyDatasetForRenaming);
      assignUniqueLayerNames2(datasets);
    }
    files = datasets.reduce(function(memo, dataset) {
      if (runningInBrowser()) {
        utils.sortOn(dataset.layers, 'stack_id', true);
      } else {
        // kludge to export layers in order that target= option or previous
        // -target command matched them (useful mainly for SVG output)
        // target_id was assigned to each layer by findCommandTargets()
        utils.sortOn(dataset.layers, 'target_id', true);
      }
      return memo.concat(exportFileContent(dataset, opts));
    }, []);
    // need unique names for multiple output files
    assignUniqueFileNames(files);
    return files;
  }

  // Return an array of objects with "filename" and "content" members.
  //
  function exportFileContent(dataset, opts) {
    var outFmt = opts.format = getOutputFormat(dataset, opts),
        exporter = exporters[outFmt],
        files = [];

    if (!outFmt) {
      error("Missing output format");
    } else if (!exporter) {
      error("Unknown output format:", outFmt);
    }

    // shallow-copy dataset and layers, so layers can be renamed for export
    dataset = utils.defaults({
      layers: dataset.layers.map(function(lyr) {return utils.extend({}, lyr);})
    }, dataset);

    // Adjust layer names, so they can be used as output file names
    // (except for multi-layer formats TopoJSON and SVG)
    if (opts.file && outFmt != 'topojson' && outFmt != 'svg') {
      dataset.layers.forEach(function(lyr) {
        lyr.name = getFileBase(opts.file);
      });
    }
    assignUniqueLayerNames(dataset.layers);

    // apply coordinate precision, except:
    //   svg precision is applied by the SVG exporter, after rescaling
    //   GeoJSON precision is applied by the exporter, to handle default precision
    //   TopoJSON precision is applied to avoid redundant copying
    if (opts.precision && outFmt != 'svg' && outFmt != 'geojson' && outFmt != 'topojson') {
      dataset = copyDatasetForExport(dataset);
      setCoordinatePrecision(dataset, opts.precision);
    }

    if (opts.cut_table) {
      files = exportDataTables(dataset.layers, opts).concat(files);
    }

    if (opts.extension) {
      opts.extension = fixFileExtension(opts.extension, outFmt);
    }

    validateLayerData(dataset.layers);

    files = exporter(dataset, opts).concat(files);
    // If rounding or quantization are applied during export, bounds may
    // change somewhat... consider adding a bounds property to each layer during
    // export when appropriate.
    if (opts.bbox_index) {
      files.push(createIndexFile(dataset));
    }

    validateFileNames(files);
    return files;
  }

  var exporters = {
    geojson: exportGeoJSON2,
    topojson: exportTopoJSON,
    shapefile: exportShapefile,
    dsv: exportDelim,
    dbf: exportDbf,
    json: exportJSON,
    svg: exportSVG
  };


  // Generate json file with bounding boxes and names of each export layer
  // TODO: consider making this a command, or at least make format settable
  //
  function createIndexFile(dataset) {
    var index = dataset.layers.map(function(lyr) {
      var bounds = getLayerBounds(lyr, dataset.arcs);
      return {
        bbox: bounds.toArray(),
        name: lyr.name
      };
    });

    return {
      content: JSON.stringify(index),
      filename: "bbox-index.json"
    };
  }

  // Throw errors for various error conditions
  function validateLayerData(layers) {
    layers.forEach(function(lyr) {
      if (!lyr.geometry_type) {
        // allowing data-only layers
        if (lyr.shapes && utils.some(lyr.shapes, function(o) {
          return !!o;
        })) {
          error("A layer contains shape records and a null geometry type");
        }
      } else {
        if (!utils.contains(['polygon', 'polyline', 'point'], lyr.geometry_type)) {
          error ("A layer has an invalid geometry type:", lyr.geometry_type);
        }
        if (!lyr.shapes) {
          error ("A layer is missing shape data");
        }
      }
    });
  }

  function validateFileNames(files) {
    var index = {};
    files.forEach(function(file, i) {
      var filename = file.filename;
      if (!filename) error("Missing a filename for file" + i);
      if (filename in index) error("Duplicate filename", filename);
      index[filename] = true;
    });
  }

  function assignUniqueLayerNames(layers) {
    var names = layers.map(function(lyr) {
      return lyr.name || "layer";
    });
    var uniqueNames = utils.uniqifyNames(names);
    layers.forEach(function(lyr, i) {
      lyr.name = uniqueNames[i];
    });
  }

  // Assign unique layer names across multiple datasets
  function assignUniqueLayerNames2(datasets) {
    var layers = datasets.reduce(function(memo, dataset) {
      return memo.concat(dataset.layers);
    }, []);
    assignUniqueLayerNames(layers);
  }

  function assignUniqueFileNames(output) {
    var names = output.map(function(o) {return o.filename;});
    var uniqnames = utils.uniqifyNames(names, formatVersionedFileName);
    output.forEach(function(o, i) {o.filename = uniqnames[i];});
  }

  // TODO: remove this -- format=json creates the same output
  //   (but need to make sure there's a way to prevent names of json data files
  //    from colliding with names of GeoJSON or TopoJSON files)
  function exportDataTables(layers, opts) {
    var tables = [];
    layers.forEach(function(lyr) {
      if (lyr.data) {
        tables.push({
          content: JSON.stringify(lyr.data),
          filename: (lyr.name ? lyr.name + '-' : '') + 'table.json'
        });
      }
    });
    return tables;
  }

  function formatVersionedFileName(filename, i) {
    var parts = filename.split('.');
    var ext, base;
    if (parts.length < 2) {
      return utils.formatVersionedName(filename, i);
    }
    ext = parts.pop();
    base = parts.join('.');
    return utils.formatVersionedName(base, i) + '.' + ext;
  }

  function fixFileExtension(ext, fmt) {
    // TODO: use fmt to validate
    return ext.replace(/^\.+/, '');
  }

  var Export = /*#__PURE__*/Object.freeze({
    __proto__: null,
    exportTargetLayers: exportTargetLayers,
    exportFileContent: exportFileContent,
    assignUniqueLayerNames: assignUniqueLayerNames,
    assignUniqueFileNames: assignUniqueFileNames,
    formatVersionedFileName: formatVersionedFileName
  });

  // convert targets from [{layers: [...], dataset: <>}, ...] format to
  // [{layer: <>, dataset: <>}, ...] format
  function expandCommandTargets(targets) {
    return targets.reduce(function(memo, target) {
      target.layers.forEach(function(lyr) {
        memo.push({layer: lyr, dataset: target.dataset});
      });
      return memo;
    }, []);
  }

  function findCommandTargets(layers, pattern, type) {
    var targets = [];
    var matches = findMatchingLayers(layers, pattern, true);
    if (type) {
      matches = matches.filter(function(o) {return o.layer.geometry_type == type;});
    }
    // assign target_id to matched layers
    // (kludge so layers can be sorted in the order that they match; used by -o command)
    layers.forEach(function(o) {o.layer.target_id = -1;});
    matches.forEach(function(o, i) {o.layer.target_id = i;});
    return groupLayersByDataset(matches);
  }

  // arr: array of {layer: <>, dataset: <>} objects
  function groupLayersByDataset(arr) {
    var datasets = [];
    var targets = [];
    arr.forEach(function(o) {
      var i = datasets.indexOf(o.dataset);
      if (i == -1) {
        datasets.push(o.dataset);
        targets.push({layers: [o.layer], dataset: o.dataset});
      } else {
        targets[i].layers.push(o.layer);
      }
    });
    return targets;
  }

  // layers: array of {layer: <>, dataset: <>} objects
  // pattern: is a layer identifier or a comma-sep. list of identifiers.
  // An identifier is a literal name, a pattern containing "*" wildcard or
  // a 1-based index (1..n)
  function findMatchingLayers(layers, pattern, throws) {
    var matchedLayers = [];
    var unmatchedIds = [];
    var index = {};
    pattern.split(',').forEach(function(subpattern, i) {
      var test = getLayerMatch(subpattern);
      var matched = false;
      layers.forEach(function(o, layerId) {
        // if (matchedLayers.indexOf(lyr) > -1) return; // performance bottleneck with 1000s of layers
        if (layerId in index) {
          matched = true;
        } else if (test(o.layer, layerId + 1)) {  // layers are 1-indexed
          matchedLayers.push(o);
          index[layerId] = true;
          matched = true;
        }
      });
      if (matched == false) {
        unmatchedIds.push(subpattern);
      }
    });
    if (throws && unmatchedIds.length) {
      stop(utils.format('Missing layer%s: %s', unmatchedIds.length == 1 ? '' : 's', unmatchedIds.join(',')));
    }
    return matchedLayers;
  }

  function getLayerMatch(pattern) {
    var isIndex = utils.isInteger(Number(pattern));
    var nameRxp = isIndex ? null : utils.wildcardToRegExp(pattern);
    return function(lyr, i) {
      return isIndex ? String(i) == pattern : nameRxp.test(lyr.name || '');
    };
  }

  function countTargetLayers(targets) {
    return targets.reduce(function(memo, target) {
      return memo + target.layers.length;
    }, 0);
  }

  // get an identifier for a layer that can be used in a target= option
  // (returns name if layer has a unique name, or a numerical id)
  function getLayerTargetId(catalog, lyr) {
    var nameCount = 0,
        name = lyr.name,
        id;
    catalog.getLayers().forEach(function(o, i) {
      if (lyr.name && o.layer.name == lyr.name) nameCount++;
      if (lyr == o.layer) id = String(i + 1);
    });
    if (!id) error('Layer not found');
    return nameCount == 1 ? lyr.name : id;
  }

  var TargetUtils = /*#__PURE__*/Object.freeze({
    __proto__: null,
    expandCommandTargets: expandCommandTargets,
    findCommandTargets: findCommandTargets,
    groupLayersByDataset: groupLayersByDataset,
    findMatchingLayers: findMatchingLayers,
    getLayerMatch: getLayerMatch,
    countTargetLayers: countTargetLayers,
    getLayerTargetId: getLayerTargetId
  });

  function readFirstChars(reader, n) {
    return bufferToString(reader.readSync(0, Math.min(n || 1000, reader.size())));
  }

  // Wraps a BufferReader or FileReader with an API that keeps track of position in the file
  function Reader2(reader) {
    var offs = 0; // read-head position in bytes

    this.position = function() {return offs;};

    this.remaining = function() {
      return Math.max(reader.size() - offs, 0);
    };

    this.advance = function(i) {
      offs += i;
    };

    this.readSync = function() {
      return reader.readSync(offs);
    };

    this.expandBuffer = function() {
      reader.expandBuffer();
    };
  }

  // Same interface as FileReader, for reading from a Buffer or ArrayBuffer instead of a file.
  function BufferReader(src) {
    var bufSize = src.byteLength || src.length,
        binArr, buf;

    this.readToBinArray = function(start, length) {
      if (bufSize < start + length) error("Out-of-range error");
      if (!binArr) binArr = new BinArray(src);
      binArr.position(start);
      return binArr;
    };

    this.toString = function(enc) {
      return bufferToString(buffer(), enc);
    };

    this.readSync = function(start, length) {
      // TODO: consider using a default length like FileReader
      return buffer().slice(start, length ? start + length : bufSize);
    };

    function buffer() {
      if (!buf) {
        buf = (src instanceof ArrayBuffer) ? utils.createBuffer(src) : src;
      }
      return buf;
    }

    this.findString = FileReader.prototype.findString;
    this.expandBuffer = function() {return this;};
    this.size = function() {return bufSize;};
    this.close = function() {};
  }

  function FileReader(path, opts) {
    var fs = require('fs'),
        fileLen = fs.statSync(path).size,
        DEFAULT_CACHE_LEN = opts && opts.cacheSize || 0x1000000, // 16MB
        DEFAULT_BUFFER_LEN = opts && opts.bufferSize || 0x40000, // 256K
        fd, cacheOffs, cache, binArr;

    getStateVar('input_files').push(path); // bit of a kludge

    // Double the default size of the Buffer returned by readSync()
    this.expandBuffer = function() {
      DEFAULT_BUFFER_LEN *= 2;
      if (DEFAULT_BUFFER_LEN * 2 > DEFAULT_CACHE_LEN) {
        // Keep the file cache larger than the default buffer size.
        // This fixes a performance bug caused when the size of the buffer returned by
        // readSync() grows as large as the file cache, causing each subsequent
        // call to readSync() to trigger a call to fs.readFileSync()
        DEFAULT_CACHE_LEN = DEFAULT_BUFFER_LEN * 2;
      }
      return this;
    };

    // Read to BinArray (for compatibility with ShpReader)
    this.readToBinArray = function(start, length) {
      if (updateCache(start, length)) {
        binArr = new BinArray(cache);
      }
      binArr.position(start - cacheOffs);
      return binArr;
    };

    // Returns a Buffer containing a string of bytes read from the file
    // start: file offset of the first byte
    // length: (optional) length of the returned Buffer
    this.readSync = function(start, length) {
      if (length > 0 === false) {
        // use default size if length is not specified
        length = DEFAULT_BUFFER_LEN;
      }

      if (start + length > fileLen) {
        length = fileLen - start; // truncate at eof
      }
      if (length === 0) {
        return utils.createBuffer(0); // kludge to allow reading up to eof
      }
      updateCache(start, length);
      return cache.slice(start - cacheOffs, start - cacheOffs + length);
    };

    this.size = function() {
      return fileLen;
    };

    this.toString = function(enc) {
      // TODO: use fd
      return cli.readFile(path, enc || 'utf8');
    };

    this.close = function() {
      if (fd) {
        fs.closeSync(fd);
        fd = null;
        cache = null;
      }
    };

    // Update the file cache (if necessary) so that a given range of bytes is available.
    // Receive: offset and length of byte string that must be read
    // Returns: true if cache was updated, or false
    function updateCache(fileOffs, bytesNeeded) {
      var headroom = fileLen - fileOffs,
          bytesRead, bytesToRead;
      if (headroom < bytesNeeded || headroom < 0) {
        error("Tried to read past end-of-file");
      }
      if (cache && fileOffs >= cacheOffs && cacheOffs + cache.length >= fileOffs + bytesNeeded) {
        // cache contains enough data to satisfy the request (no need to read from disk)
        return false;
      }
      bytesToRead = Math.max(DEFAULT_CACHE_LEN, bytesNeeded);
      if (headroom < bytesToRead) {
        bytesToRead = headroom;
      }
      if (!cache || bytesToRead != cache.length) {
        cache = utils.createBuffer(bytesToRead);
      }
      if (!fd) {
        fd = fs.openSync(path, 'r');
      }
      bytesRead = fs.readSync(fd, cache, 0, bytesToRead, fileOffs);
      cacheOffs = fileOffs;
      if (bytesRead != bytesToRead) error("Error reading file");
      return true;
    }
  }

  FileReader.prototype.findString = function (str, maxLen) {
    var len = Math.min(this.size(), maxLen || this.size());
    var buf = this.readSync(0, len);
    var strLen = str.length;
    var n = buf.length - strLen;
    var firstByte = str.charCodeAt(0);
    var i;
    for (i=0; i < n; i++) {
      if (buf[i] == firstByte && buf.toString('utf8', i, i + strLen) == str) {
        return {
          offset: i + strLen,
          text: buf.toString('utf8', 0, i)
        };
      }
    }
    return null;
  };

  var FileReader$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    readFirstChars: readFirstChars,
    Reader2: Reader2,
    BufferReader: BufferReader,
    FileReader: FileReader
  });

  // Read and parse a DSV file
  // This version performs field filtering before fields are extracted (faster)
  // (tested with a 40GB CSV)
  //
  // TODO: confirm compatibility with all supported encodings
  function readDelimRecords(reader, delim, optsArg) {
    var opts = optsArg || {};
    if (delim == ' ') return readFixedWidthRecords(reader, opts);
    var reader2 = new Reader2(reader),
        headerStr = readLinesAsString(reader2, getDelimHeaderLines(opts), opts.encoding),
        header = parseDelimHeaderSection(headerStr, delim, opts),
        convertRowArr = getRowConverter(header.import_fields),
        batchSize = opts.batch_size || 1000,
        records = [],
        str, batch;
    if (header.import_fields.length === 0) return []; // e.g. empty file
    // read in batches (faster than line-by-line)
    while ((str = readLinesAsString(reader2, batchSize, opts.encoding))) {
      batch = parseDelimText(str, delim, convertRowArr, header.column_filter || false, header.row_filter || false);
      records.push.apply(records, batch);
      if (opts.csv_lines && records.length >= opts.csv_lines) {
        return records.slice(0, opts.csv_lines);
      }
    }
    return records;
  }

  // Fallback for readDelimRecords(), for encodings that do not use ascii values
  // for delimiter characters and newlines. Input size is limited by the maximum
  // string size.
  function readDelimRecordsFromString(str, delim, opts) {
    if (delim == ' ') return readFixedWidthRecordsFromString(str, opts);
    var header = parseDelimHeaderSection(str, delim, opts);
    if (header.import_fields.length === 0 || !header.remainder) return [];
    var convert = getRowConverter(header.import_fields);
    var records = parseDelimText(header.remainder, delim, convert, header.column_filter, header.row_filter);
    if (opts.csv_lines > 0) {
      // TODO: don't parse unneeded rows
      records = records.slice(0, opts.csv_lines);
    }
    return records;
  }

  // Get index in string of the nth line
  // line numbers are 1-based (first line is 1)
  function indexOfLine(str, nth) {
    var rxp = /\r\n|[\r\n]|.$/g; // dot prevents matching end of string twice
    var i = 1;
    if (nth === 1) return 0;
    if (nth > 1 === false) return -1;
    while (rxp.exec(str)) {
      i++;
      if (i < nth === false) return rxp.lastIndex;
    }
    return -1;
  }

  function getDelimHeaderLines(opts) {
    var skip = opts.csv_skip_lines || 0;
    if (!opts.csv_field_names) skip++;
    return skip;
  }

  // Adapted from https://github.com/d3/d3-dsv
  function getRowConverter(fields) {
    return new Function('arr', 'return {' + fields.map(function(name, i) {
      return JSON.stringify(name) + ': arr[' + i + '] || ""';
    }).join(',') + '}');
  }

  function parseDelimHeaderSection(str, delim, opts) {
    var nodata = {headers: [], import_fields: []},
        retn = {},
        i;
    str = str || '';
    if (opts.csv_skip_lines > 0) {
      i = indexOfLine(str, opts.csv_skip_lines + 1);
      if (i === -1) return nodata;
      str = str.substr(i);
    }
    if (opts.csv_field_names) {
      retn.headers = opts.csv_field_names;
    } else {
      i = indexOfLine(str, 2);
      if (i === -1) return nodata;
      retn.headers = parseDelimText(str.slice(0, i), delim)[0];
      str = str.substr(i);
    }
    if (opts.csv_dedup_fields) {
      retn.headers = utils.uniqifyNames(retn.headers);
    }
    if (opts.csv_filter) {
      retn.row_filter = getDelimRecordFilterFunction(opts.csv_filter);
    }
    if (opts.csv_fields) {
      retn.column_filter = getDelimFieldFilter(retn.headers, opts.csv_fields);
      retn.import_fields = retn.headers.filter(function(name, i) {return retn.column_filter(i);});
    } else {
      retn.import_fields = retn.headers;
    }
    retn.remainder = str;
    return retn;
  }

  // Returns a function for filtering records
  // TODO: look into using more code from standard expressions.
  function getDelimRecordFilterFunction(expression) {
    var rowFilter = compileExpressionToFunction(expression, {returns: true});
    var ctx = getBaseContext();
    return function(rec) {
      var val;
      try {
        val = rowFilter.call(null, rec, ctx);
      } catch(e) {
        stop(e.name, "in expression [" + expression + "]:", e.message);
      }
      if (val !== true && val !== false) {
        stop("Filter expression must return true or false");
      }
      return val;
    };
  }

  // Returns a function for filtering fields by column index
  // The function returns true for retained fields and false for excluded fields
  function getDelimFieldFilter(header, fieldsToKeep) {
    var index = utils.arrayToIndex(fieldsToKeep);
    var map = header.map(function(name) {
      return name in index;
    });
    var missing = utils.difference(fieldsToKeep, header);
    if (missing.length > 0) {
      var foundStr = [''].concat(header).join('\n  ');
      var missingStr = [''].concat(missing).join('\n  ');
      stop('csv-fields option has', missing.length == 1 ? 'a name' : missing.length + ' names',  'not found in the file\nFields:', foundStr, '\nMissing:', missingStr);
    }
    return function(colIdx) {
      return map[colIdx];
    };
  }

  // May be useful in the future to implement reading a range of CSV records
  function skipDelimLines(reader, lines) {
    // TODO: divide lines into batches, to prevent exceeding maximum buffer size
    var buf = reader.readSync();
    var retn = readLinesFromBuffer(buf, lines);
    if (retn.bytesRead == buf.length && retn.bytesRead < reader.remaining()) {
      reader.expandBuffer(); // buffer oflo, grow the buffer and try again
      return skipDelimLines(reader, lines);
    }
    reader.advance(retn.bytesRead);
  }

  function readLinesAsString(reader, lines, encoding) {
    var buf = reader.readSync();
    var retn = readLinesFromBuffer(buf, lines);
    var str;
    if (retn.bytesRead == buf.length && retn.bytesRead < reader.remaining()) {
      // buffer overflow -- enlarge buffer and read lines again
      reader.expandBuffer();
      return readLinesAsString(reader, lines, encoding);
    }
    // str = retn.bytesRead > 0 ? retn.buffer.toString('ascii', 0, retn.bytesRead) : '';
    str = retn.bytesRead > 0 ? decodeString(retn.buffer, encoding) : '';
    if (reader.position() === 0) {
     str = trimBOM(str);
    }
    reader.advance(retn.bytesRead);
    return str;
  }

  function readLinesFromBuffer(buf, linesToRead) {
    var CR = 13, LF = 10, DQUOTE = 34,
        inQuotedText = false,
        lineCount = 0,
        bufLen = buf.length,
        i, c;

    lineCount++;
    for (i=0; i < bufLen && lineCount <= linesToRead; i++) {
      c = buf[i];
      if (c == DQUOTE) {
        inQuotedText = !inQuotedText;
      } else if ((c == CR || c == LF) && !inQuotedText) {
        if (c == CR && i + 1 < bufLen && buf[i + 1] == LF) {
          // first half of CRLF pair: advance one byte
          i++;
        }
        lineCount++;
      }
    }
    return {
      bytesRead: i,
      buffer: buf.slice(0, i)
    };
  }

  // Convert a string of CSV data into an array of data records
  // convert: optional function for converting an array record to an object record (values indexed by field names)
  // colFilter: optional function for filtering columns by numerical column id (0-based); accepts an array record and an id
  // rowFilter: optional function for filtering rows; accepts a record in object format
  function parseDelimText(text, delim, convert, colFilter, rowFilter) {
    var CR = 13, LF = 10, DQUOTE = 34,
        DELIM = delim.charCodeAt(0),
        inQuotedText = false,
        capturing = false,
        srcCol = -1,
        records = [],
        fieldStart, i, c, len, record;

    if (!convert) convert = function(d) {return d;};

    function endLine() {
      var rec = convert ? convert(record) : record;
      if (!rowFilter || rowFilter(rec)) records.push(rec);
      srcCol = -1;
    }

    function startFieldAt(j) {
      fieldStart = j;
      srcCol++;
      if (srcCol === 0) record = [];
      if (!colFilter || colFilter(srcCol)) {
        capturing = true;
      }
    }

    function captureField(start, end) {
      var s;
      if (!capturing) return;
      capturing = false;
      if (start === end) {
        s = '';
      } else if (text.charCodeAt(start) == DQUOTE) {
        s = text.slice(start+1, end-1).replace(/""/g, '"');
      } else {
        s = text.slice(start, end);
      }
      record.push(s);
    }

    startFieldAt(0);
    for (i=0, len=text.length; i < len; i++) {
      c = text.charCodeAt(i);
      if (c == DQUOTE) {
        inQuotedText = !inQuotedText;
      } else if (inQuotedText) {
        //
      } else if (c == DELIM) {
        captureField(fieldStart, i);
        startFieldAt(i + 1);
      } else if (c == CR || c == LF) {
        captureField(fieldStart, i);
        endLine();
        if (c == CR && text.charCodeAt(i+1) == LF) {
          i++; // first half of CRLF pair; skip a char
        }
        if (i + 1 < len) startFieldAt(i+1);
      }
    }

    if (srcCol > -1) { // finish last line (if file ends without newline)
      if (capturing) captureField(fieldStart, i);
      endLine();
    }

    return records;
  }

  var DelimReader = /*#__PURE__*/Object.freeze({
    __proto__: null,
    readDelimRecords: readDelimRecords,
    readDelimRecordsFromString: readDelimRecordsFromString,
    indexOfLine: indexOfLine,
    getRowConverter: getRowConverter,
    parseDelimHeaderSection: parseDelimHeaderSection,
    getDelimFieldFilter: getDelimFieldFilter,
    readLinesAsString: readLinesAsString,
    parseDelimText: parseDelimText
  });

  function detectEncodingFromBOM(bytes) {
    // utf8 EF BB BF
    // utf16be FE FF
    // utf16le FF FE
    var n = bytes.length;
    if (n >= 2 && bytes[0] == 0xFE && bytes[1] == 0xFF) return 'utf16be';
    if (n >= 2 && bytes[0] == 0xFF && bytes[1] == 0xFE) return 'utf16le';
    if (n >= 3 && bytes[0] == 0xEF && bytes[1] == 0xBB && bytes[2] == 0xBF) return 'utf8';
    return '';
  }

  // Try to detect the encoding of some sample text.
  // Returns an encoding name or null.
  // @samples Array of buffers containing sample text fields
  // TODO: Improve reliability and number of detectable encodings.
  function detectEncoding(samples) {
    var encoding = null;
    if (looksLikeUtf8(samples)) {
      encoding = 'utf8';
    } else if (looksLikeWin1252(samples)) {
      // Win1252 is the same as Latin1, except it replaces a block of control
      // characters with n-dash, Euro and other glyphs. Encountered in-the-wild
      // in Natural Earth (airports.dbf uses n-dash).
      encoding = 'win1252';
    }
    return encoding;
  }

  // Convert an array of text samples to a single string using a given encoding
  function decodeSamples(enc, samples) {
    return samples.map(function(buf) {
      return decodeString(buf, enc).trim();
    }).join('\n');
  }


  // Quick-and-dirty win1251 detection: decoded string contains mostly common ascii
  // chars and almost no chars other than word chars + punctuation.
  // This excludes encodings like Greek, Cyrillic or Thai, but
  // is susceptible to false positives with encodings like codepage 1250 ("Eastern
  // European").
  function looksLikeWin1252(samples) {
    var ascii = 'abcdefghijklmnopqrstuvwxyz0123456789.\'"?+-\n,:;/|_$% ', //common l.c. ascii chars
        extended = '', // common extended
        str = decodeSamples('win1252', samples),
        asciiScore = getCharScore(str, ascii),
        totalScore = getCharScore(str, extended + ascii);
    return totalScore > 0.97 && asciiScore >= 0.6; // mostly unaccented ascii chars
  }

  // Reject string if it contains the "replacement character" after decoding to UTF-8
  function looksLikeUtf8(samples) {
    // Remove the byte sequence for the utf-8-encoded replacement char before decoding,
    // in case the file is in utf-8, but contains some previously corrupted text.
    // samples = samples.map(internal.replaceUtf8ReplacementChar);
    var str = decodeSamples('utf8', samples);
    return str.indexOf('\ufffd') == -1;
  }

  // function replaceUtf8ReplacementChar(buf) {
  //   var isCopy = false;
  //   for (var i=0, n=buf.length; i<n; i++) {
  //     // Check for UTF-8 encoded replacement char (0xEF 0xBF 0xBD)
  //     if (buf[i] == 0xef && i + 2 < n && buf[i+1] == 0xbf && buf[i+2] == 0xbd) {
  //       if (!isCopy) {
  //         buf = utils.createBuffer(buf);
  //         isCopy = true;
  //       }
  //       buf[i] = buf[i+1] = buf[i+2] = 63; // ascii question mark
  //     }
  //   }
  //   return buf;
  // }

  // Calc percentage of chars in a string that are present in a second string
  // @chars String of chars to look for in @str
  function getCharScore(str, chars) {
    var index = {},
        count = 0,
        score;
    str = str.toLowerCase();
    for (var i=0, n=chars.length; i<n; i++) {
      index[chars[i]] = 1;
    }
    for (i=0, n=str.length; i<n; i++) {
      count += index[str[i]] || 0;
    }
    return count / str.length;
  }

  // Convert a string containing delimited text data into a dataset object
  function importDelim(str, opts) {
    return importDelim2({content: str}, opts);
  }

  // Convert a string, buffer or file containing delimited text into a dataset obj.
  function importDelim2(data, opts) {
    // TODO: remove duplication with importJSON()
    var readFromFile = !data.content && data.content !== '',
        content = data.content,
        filter, reader, records, delimiter, table, encoding;
    opts = opts || {};

    // // read content of all but very large files into a buffer
    // if (readFromFile && cli.fileSize(data.filename) < 2e9) {
    //   content = cli.readFile(data.filename);
    //   readFromFile = false;
    // }

    if (readFromFile) {
      reader = new FileReader(data.filename);
    } else if (content instanceof ArrayBuffer || content instanceof Buffer) {
      // Web API may import as ArrayBuffer, to support larger files
      reader = new BufferReader(content);
      content = null;
    } else if (utils.isString(content)) {
      // import as string
    } else {
      error("Unexpected object type");
    }

    if (reader) {
      encoding = detectEncodingFromBOM(reader.readSync(0, Math.min(reader.size(), 3)));
      // Files in some encodings have to be converted to strings before parsing
      // Other encodings are similar enough to ascii that CSV can be parsed
      // byte-by-byte.
      if (encoding == 'utf16be' || encoding == 'utf16le') {
        content = trimBOM(reader.toString(encoding));
        reader = null;
      } else if (opts.encoding && !encodingIsAsciiCompat(opts.encoding)) {
        content = reader.toString(opts.encoding);
        reader = null;
      }
    }

    if (reader) {
      delimiter = guessDelimiter(readFirstChars(reader, 2000));
      records = readDelimRecords(reader, delimiter, opts);
    } else {
      delimiter = guessDelimiter(content);
      records = readDelimRecordsFromString(content, delimiter, opts);
    }
    if (records.length === 0) {
      message("Unable to read any data records");
    }
    adjustRecordTypes(records, opts);
    table = new DataTable(records);
    deleteFields(table, isInvalidFieldName);
    return {
      layers: [{data: table}],
      info: {input_delimiter: delimiter}
    };
  }

  var supportedDelimiters = ['|', '\t', ',', ';', ' '];

  function isSupportedDelimiter(d) {
    return utils.contains(supportedDelimiters, d);
  }

  function guessDelimiter(content) {
    return utils.find(supportedDelimiters, function(delim) {
      var rxp = getDelimiterRxp(delim);
      return rxp.test(content);
    }) || ',';
  }

  // Get RegExp to test for a delimiter before first line break of a string
  // Assumes that the first line does not contain alternate delim chars (this will
  // be true if the first line has field headers composed of word characters).
  function getDelimiterRxp(delim) {
    var rxp = "^[^\\n\\r]+" + utils.regexEscape(delim);
    return new RegExp(rxp);
  }

  function getFieldTypeHints(opts) {
    var hints = {};
    opts = opts || {};
    if (opts.string_fields) {
      opts.string_fields.forEach(function(f) {
        hints[f] = 'string';
      });
    }
    if (opts.field_types) {
      opts.field_types.forEach(function(raw) {
        var parts, name, type;
        if (raw.indexOf(':') != -1) {
          parts = raw.split(':');
          name = parts[0];
          type = validateFieldType(parts[1]);
        } else if (raw[0] === '+') { // d3-style type hint: unary plus
          name = raw.substr(1);
          type = 'number';
        }
        if (type) {
          hints[name] = type;
        } else {
          message("Invalid type hint (expected :str or :num) [" + raw + "]");
        }
      });
    }
    return hints;
  }


  // Detect and convert data types of data from csv files.
  // TODO: decide how to handle records with inconstent properties. Mapshaper
  //    currently assumes tabular data
  function adjustRecordTypes(records, optsArg) {
    var opts = optsArg || {},
        typeIndex = getFieldTypeHints(opts),
        singleType = typeIndex['*'], // support for setting all fields to a single type
        fields = Object.keys(records[0] || []),
        detectedNumFields = [],
        parseNumber = opts.decimal_comma ? utils.parseIntlNumber : utils.parseNumber,
        replacements = {};
    fields.forEach(function(key) {
      var typeHint = typeIndex[key];
      var values = null;
      if (typeHint == 'number' || singleType == 'number') {
        values = convertDataField(key, records, parseNumber);
      } else if (typeHint == 'string' || singleType == 'string') {
        // We should be able to assume that imported CSV fields are strings,
        //   so parsing + replacement is not required
        // values = internal.convertDataField(key, records, utils.parseString);
        values = null;
      } else {
        values = tryNumericField(key, records, parseNumber);
        if (values) detectedNumFields.push(key);
      }
      if (values) replacements[key] = values;
    });
    if (Object.keys(replacements).length > 0) {
      updateFieldsInRecords(fields, records, replacements);
    }
    if (detectedNumFields.length > 0) {
      message(utils.format("Auto-detected number field%s: %s",
          detectedNumFields.length == 1 ? '' : 's', detectedNumFields.join(', ')));
    }
  }

  // Copy original data properties and replacements to a new set of records
  // (Better performance in v8 than making in-place replacements)
  function updateFieldsInRecords(fields, records, replacements) {
    // Use object-literal syntax (faster than alternative)
    var convertBody = 'return {' + fields.map(function(name) {
        var key = JSON.stringify(name);
        return key + ': ' + (replacements[name] ? 'replacements[' + key + '][i]' : 'rec[' + key + ']');
      }).join(', ') + '}';
    var convert = new Function('rec', 'replacements', 'i', convertBody);
    records.forEach(function(rec, i) {
      records[i] = convert(rec, replacements, i);
    });
  }

  function tryNumericField(key, records, parseNumber) {
    var arr = [],
        count = 0,
        raw, str, num;
    for (var i=0, n=records.length; i<n; i++) {
      raw = records[i][key];
      num = parseNumber(raw);
      if (num === null) {
        str = raw ? raw.trim() : '';
        if (str.length > 0 && str != 'NA' && str != 'NaN') { // ignore NA values ("NA" seen in R output)
          return null; // unparseable value -- fail
        }
      } else {
        count++;
      }
      arr.push(num);
    }
    return count > 0 ? arr : null;
  }

  function convertDataField(name, records, f) {
    var values = [];
    for (var i=0, n=records.length; i<n; i++) {
      values.push(f(records[i][name]));
    }
    return values;
  }

  // Accept a type hint from a header like "FIPS:str"
  // Return standard type name (number|string) or null if hint is not recognized
  function validateFieldType(hint) {
    var str = hint.toLowerCase(),
        type = null;
    if (str[0] == 'n') {
      type = 'number';
    } else if (str[0] == 's') {
      type = 'string';
    }
    return type;
  }

  var DelimImport = /*#__PURE__*/Object.freeze({
    __proto__: null,
    importDelim: importDelim,
    importDelim2: importDelim2,
    isSupportedDelimiter: isSupportedDelimiter,
    guessDelimiter: guessDelimiter,
    getFieldTypeHints: getFieldTypeHints,
    adjustRecordTypes: adjustRecordTypes
  });

  function validateInputOpts(cmd) {
    var o = cmd.options,
        _ = cmd._;

    if (_.length > 0 && !o.files) {
      o.files = _;
    }
    if (o.files) {
      o.files = cli.expandInputFiles(o.files);
      if (o.files[0] == '-' || o.files[0] == '/dev/stdin') {
        delete o.files;
        o.stdin = true;
      }
    }

    if ("precision" in o && o.precision > 0 === false) {
      error("precision= option should be a positive number");
    }

    if (o.encoding) {
      o.encoding = validateEncoding(o.encoding);
    }
  }

  function validateSimplifyOpts(cmd) {
    var o = cmd.options,
        arg = cmd._[0];

    if (arg) {
      if (/^[0-9.]+%?$/.test(arg)) {
        o.percentage = utils.parsePercent(arg);
      } else {
        error("Unparsable option:", arg);
      }
    }

    // var intervalStr = o.interval;
    // if (intervalStr) {
    //   o.interval = Number(intervalStr);
    //   if (o.interval >= 0 === false) {
    //     error(utils.format("Out-of-range interval value: %s", intervalStr));
    //   }
    // }

    if (!o.interval && !o.percentage && !o.resolution) {
      error("Command requires an interval, percentage or resolution parameter");
    }
  }

  function validateProjOpts(cmd) {
    var _ = cmd._,
        proj4 = [];

    if (_.length > 0 && !cmd.options.crs) {
      cmd.options.crs = _.join(' ');
      _ = [];
    }

    // separate proj4 options
    // _ = _.filter(function(arg) {
    //   if (/^\+[a-z]/i.test(arg)) {
    //     proj4.push(arg);
    //     return false;
    //   }
    //   return true;
    // });

    // if (proj4.length > 0) {
    //   cmd.options.crs = proj4.join(' ');
    // } else if (_.length > 0) {
    //   cmd.options.crs = _.shift();
    // }

    if (_.length > 0) {
      error("Received one or more unexpected parameters: " + _.join(', '));
    }

    if (!(cmd.options.crs || cmd.options.match || cmd.options.init)) {
      stop("Missing projection data");
    }
  }

  function validateGridOpts(cmd) {
    var o = cmd.options;
    if (cmd._.length == 1) {
      var tmp = cmd._[0].split(',');
      o.cols = parseInt(tmp[0], 10);
      o.rows = parseInt(tmp[1], 10) || o.cols;
    }
  }

  function validateExpressionOpt(cmd) {
    if (!cmd.options.expression) {
      error("Command requires a JavaScript expression");
    }
  }

  function validateOutputOpts(cmd) {
    var _ = cmd._,
        o = cmd.options,
        arg = _[0] || "",
        pathInfo = parseLocalPath(arg);

    if (_.length > 1) {
      error("Command takes one file or directory argument");
    }

    if (arg == '-' || arg == '/dev/stdout') {
      o.stdout = true;
    } else if (arg && !pathInfo.extension) {
      if (!cli.isDirectory(arg)) {
        error("Unknown output option:", arg);
      }
      o.directory = arg;
    } else if (arg) {
      if (pathInfo.directory) {
        o.directory = pathInfo.directory;
        // no longer checking for missing directory
        // (cli.writeFile() now creates directories that don't exist)
        // cli.validateOutputDir(o.directory);
      }
      o.file = pathInfo.filename;
      if (filenameIsUnsupportedOutputType(o.file)) {
        error("Output file looks like an unsupported file type:", o.file);
      }
    }

    if (o.format) {
      o.format = o.format.toLowerCase();
      if (o.format == 'csv') {
        o.format = 'dsv';
        o.delimiter = o.delimiter || ',';
      } else if (o.format == 'tsv') {
        o.format = 'dsv';
        o.delimiter = o.delimiter || '\t';
      }
      if (!isSupportedOutputFormat(o.format)) {
        error("Unsupported output format:", o.format);
      }
    }

    if (o.delimiter) {
      // convert "\t" '\t' \t to tab
      o.delimiter = o.delimiter.replace(/^["']?\\t["']?$/, '\t');
      if (!isSupportedDelimiter(o.delimiter)) {
        error("Unsupported delimiter:", o.delimiter);
      }
    }

    if (o.encoding) {
      o.encoding = validateEncoding(o.encoding);
    }

    if (o.field_order && o.field_order != 'ascending') {
      error('Unsupported field order:', o.field_order);
    }

    // topojson-specific
    if ("quantization" in o && o.quantization > 0 === false) {
      error("quantization= option should be a nonnegative integer");
    }

    if ("topojson_precision" in o && o.topojson_precision > 0 === false) {
      error("topojson-precision= option should be a positive number");
    }
  }

  var assignmentRxp = /^([a-z0-9_+-]+)=(?!\=)(.*)$/i; // exclude ==

  function splitShellTokens(str) {
    var BAREWORD = '([^\'"\\s])+';
    var DOUBLE_QUOTE = '"((\\\\"|[^"])*?)"';
    var SINGLE_QUOTE = '\'((\\\\\'|[^\'])*?)\'';
    var rxp = new RegExp('(' + BAREWORD + '|' + SINGLE_QUOTE + '|' + DOUBLE_QUOTE + ')*', 'g');
    var matches = str.match(rxp) || [];
    var chunks = matches.filter(function(chunk) {
      // single backslashes may be present in multiline commands pasted from a makefile, e.g.
      return !!chunk && chunk != '\\';
    }).map(utils.trimQuotes);
    return chunks;
  }

  function parseNumberList(token) {
    return token.split(',').map(parseFloat);
  }

  // Split comma-delimited list, trim quotes from entire list and
  // individual members
  function parseStringList(token) {
    var delim = ',';
    var list = splitOptionList(token, delim);
    if (list.length == 1) {
      list = splitOptionList(list[0], delim);
    }
    return list;
  }

  // Accept spaces and/or commas as delimiters
  function parseColorList(token) {
    var delim = ', ';
    // accept rgb(0 0 0) rgb(0,0,0) rgb(0, 0, 0)
    var token2 = token.replace(/[ ,] *(?=[^(]*\))/g, '~~~'); // kludge: protect rgba() functions from being split apart
    var list = splitOptionList(token2, delim);
    if (list.length == 1) {
      list = splitOptionList(list[0], delim);
    }
    list = list.map(function(str) {
      return str.replace(/~~~/g, ',');
    });
    return list;
  }

  function cleanArgv(argv) {
    // Note: original trim caused some quoted spaces to be removed
    // (e.g. bash shell seems to convert [delimiter=" "] to [delimiter= ],
    //  which then got trimmed to [delimiter=] below)
    //// argv = argv.map(function(s) {return s.trim();}); // trim whitespace

    // Updated: don't trim space from tokens like [delimeter= ]
    argv = argv.map(function(s) {
      if (!/= $/.test(s)) {
        s = utils.rtrim(s);
      }
      s = utils.ltrim(s);
      return s;
    });
    argv = argv.filter(function(s) {return s !== '';}); // remove empty tokens
    // Note: removing trimQuotes() call... now, strings like 'name="Meg"' will no longer
    // be parsed the same way as name=Meg and name="Meg"
    //// argv = argv.map(utils.trimQuotes); // remove one level of single or dbl quotes
    return argv;
  }

  function splitOptionList(str, delimChars) {
    var BAREWORD = '([^' + delimChars + '\'"][^' + delimChars + ']*)'; // TODO: make safer
    var DOUBLE_QUOTE = '"((\\\\"|[^"])*?)"';
    var SINGLE_QUOTE = '\'((\\\\\'|[^\'])*?)\'';
    var rxp = new RegExp('^(' + BAREWORD + '|' + SINGLE_QUOTE + '|' + DOUBLE_QUOTE + ')([' + delimChars + ']+|$)');
    var chunks = [];
    var match;
    while ((match = rxp.exec(str)) !== null) {
      chunks.push(match[1]);
      str = str.substr(match[0].length);
    }
    return chunks.filter(function(chunk) {
      return !!chunk && chunk != '\\';
    }).map(utils.trimQuotes);
  }

  // Prepare a value to be used as an option value.
  // Places quotes around strings containing spaces.
  // e.g. converts   Layer 1 -> "Layer 1"
  //   for use in contexts like: name="Layer 1"
  function formatOptionValue(val) {
    val = String(val);
    if (val.indexOf(' ') > -1) {
      val = JSON.stringify(val); // quote ids with spaces
    }
    return val;
  }

  function isAssignment(token) {
    return assignmentRxp.test(token);
  }

  function splitAssignment(token) {
    var match = assignmentRxp.exec(token),
        name = match[1],
        val = utils.trimQuotes(match[2]);
    return [name, val];
  }

  var OptionParsingUtils = /*#__PURE__*/Object.freeze({
    __proto__: null,
    splitShellTokens: splitShellTokens,
    parseNumberList: parseNumberList,
    parseStringList: parseStringList,
    parseColorList: parseColorList,
    cleanArgv: cleanArgv,
    formatOptionValue: formatOptionValue,
    isAssignment: isAssignment,
    splitAssignment: splitAssignment
  });

  function CommandParser() {
    var commandRxp = /^--?([a-z][\w-]*)$/i,
        invalidCommandRxp = /^--?[a-z][\w-]*[=]/i, // e.g. -target=A // could be more general
        _usage = "",
        _examples = [],
        _commands = [],
        _default = null,
        _note;

    if (this instanceof CommandParser === false) return new CommandParser();

    this.usage = function(str) {
      _usage = str;
      return this;
    };

    this.note = function(str) {
      _note = str;
      return this;
    };

    // set a default command; applies to command line args preceding the first
    // explicit command
    this.default = function(str) {
      _default = str;
    };

    this.example = function(str) {
      _examples.push(str);
    };

    this.command = function(name) {
      var opts = new CommandOptions(name);
      // support 'verbose' and 'debug' flags for each command, without help entries
      opts.option('verbose', {type: 'flag'});
      opts.option('debug', {type: 'flag'});
      _commands.push(opts);
      return opts;
    };

    this.section = function(name) {
      return this.command("").title(name);
    };

    this.isCommandName = tokenIsCommandName;

    this.parseArgv = function(raw) {
      var commandDefs = getCommands(),
          commands = [], cmd,
          argv = cleanArgv(raw),
          cmdName, cmdDef, opt;

      if (argv.length == 1 && tokenIsCommandName(argv[0])) {
        // show help if only a command name is given
        argv.unshift('-help'); // kludge (assumes -help <command> syntax)
      } else if (argv.length > 0 && !tokenLooksLikeCommand(argv[0]) && _default) {
        // if there are arguments before the first explicit command, use the default command
        argv.unshift('-' + _default);
      }

      while (argv.length > 0) {
        cmdName = readCommandName(argv);
        if (!cmdName) {
          stop("Invalid command:", argv[0]);
        }
        cmdDef = findCommandDefn(cmdName, commandDefs);
        if (!cmdDef) {
          // In order to support adding commands at runtime, unknown commands
          // are parsed without options (tokens get stored for later parsing)
          // stop("Unknown command:", cmdName);
          cmdDef = {name: cmdName, options: [], multi_arg: true};
        }
        cmd = {
          name: cmdDef.name,
          options: {},
          _: []
        };

        while (argv.length > 0 && !tokenLooksLikeCommand(argv[0])) {
          readOption(cmd, argv, cmdDef);
        }

        try {
          if (cmd._.length > 0 && cmdDef.no_arg) {
            error("Received one or more unexpected parameters:", cmd._.join(' '));
          }
          if (cmd._.length > 1 && !cmdDef.multi_arg) {
            error("Command expects a single value. Received:", cmd._.join(' '));
          }
          if (cmdDef.default && cmd._.length == 1) {
            // TODO: support multiple-token values, like -i filenames
            readDefaultOptionValue(cmd, cmdDef);
          }
          if (cmdDef.validate) {
            cmdDef.validate(cmd);
          }
        } catch(e) {
          stop("[" + cmdName + "] " + e.message);
        }
        commands.push(cmd);
      }
      return commands;

      function tokenLooksLikeCommand(s) {
        if (invalidCommandRxp.test(s)) {
          stop('Invalid command syntax:', s);
        }
        return commandRxp.test(s);
      }

      // Try to read an option for command @cmdDef from @argv
      function readOption(cmd, argv, cmdDef) {
        var token = argv.shift(),
            optName, optDef, parts;

        if (isAssignment(token)) {
          // token looks like name=value style option
          parts = splitAssignment(token);
          optDef = findOptionDefn(parts[0], cmdDef);
          if (!optDef) {
            // left-hand identifier is not a recognized option...
            // assignment to an unrecognized identifier could be an expression
            // (e.g. -each 'id=$.id') -- handle this case below
          } else if (optDef.type == 'flag' || optDef.assign_to) {
            stop("-" + cmdDef.name + " " + parts[0] + " option doesn't take a value");
          } else {
            argv.unshift(parts[1]);
          }
        } else {
          // try to parse as a flag option,
          // or as a space-delimited assignment option (for backwards compatibility)
          optDef = findOptionDefn(token, cmdDef);
        }

        if (!optDef) {
          // token is not a defined option; add it to _ array for later processing
          // Stripping surrounding quotes here, although this may not be necessary since
          // (some, most, all?) shells seem to remove quotes.
          cmd._.push(utils.trimQuotes(token));
          return;
        }

        if (optDef.alias_to) {
          optDef = findOptionDefn(optDef.alias_to, cmdDef);
        }

        optName = optDef.name;
        optName = optName.replace(/-/g, '_');

        if (optDef.assign_to) {
          cmd.options[optDef.assign_to] = optDef.name;
        } else if (optDef.type == 'flag') {
          cmd.options[optName] = true;
        } else {
          cmd.options[optName] = readOptionValue(argv, optDef);
        }
      }

      // Read an option value for @optDef from @argv
      function readOptionValue(argv, optDef) {
        if (argv.length === 0 || tokenLooksLikeCommand(argv[0])) {
          stop("Missing value for " + optDef.name + " option");
        }
        return parseOptionValue(argv.shift(), optDef); // remove token from argv
      }

      function readDefaultOptionValue(cmd, cmdDef) {
        var optDef = findOptionDefn(cmdDef.default, cmdDef);
        cmd.options[cmdDef.default] = readOptionValue(cmd._, optDef);
      }

      function parseOptionValue(token, optDef) {
        var type = optDef.type;
        var val, err;
        if (type == 'number') {
          val = Number(token);
        } else if (type == 'integer') {
          val = Math.round(Number(token));
        } else if (type == 'colors') {
          val = parseColorList(token);
        } else if (type == 'strings') {
          val = parseStringList(token);
        } else if (type == 'bbox' || type == 'numbers') {
          val = parseNumberList(token);
        } else if (type == 'percent') {
          // val = utils.parsePercent(token);
          val = token; // string value is parsed by command function
        } else if (type == 'distance' || type == 'area') {
          val = token; // string value is parsed by command function
        } else {
          val = token; // assume string type
        }

        if (val !== val) {
          err = "Invalid numeric value";
        }

        if (err) {
          stop(err + " for " + optDef.name + " option");
        }
        return val;
      }

      // Check first element of an array of tokens; remove and return if it looks
      // like a command name, else return null;
      function readCommandName(args) {
        var match = commandRxp.exec(args[0]);
        if (match) {
          args.shift();
          return match[1];
        }
        return null;
      }

    };

    this.getHelpMessage = function(cmdName) {
      var helpCommands, singleCommand, lines;

      if (cmdName) {
        singleCommand = findCommandDefn(cmdName, getCommands());
        if (!singleCommand) {
          stop(cmdName, "is not a known command");
        }
        lines = getSingleCommandLines(singleCommand);
      } else {
        helpCommands = getCommands().filter(function(cmd) {return cmd.name && cmd.describe || cmd.title;});
        lines = getMultiCommandLines(helpCommands);
      }

      return formatLines(lines);

      function formatLines(lines) {
        var colWidth = calcColWidth(lines);
        var gutter = '  ';
        var indent = runningInBrowser() ? '' : '  ';
        var helpStr = lines.map(function(line) {
          if (Array.isArray(line)) {
            line = indent + utils.rpad(line[0], colWidth, ' ') + gutter + line[1];
          }
          return line;
        }).join('\n');
        return helpStr;
      }

      function getSingleCommandLines(cmd) {
        var lines = [];
        // command name
        lines.push('COMMAND', getCommandLine(cmd));

        // options
        if (cmd.options.length > 0) {
          lines.push('', 'OPTIONS');
          cmd.options.forEach(function(opt) {
            lines = lines.concat(getOptionLines(opt, cmd));
          });
        }

        // examples
        if (cmd.examples) {
          lines.push('', 'EXAMPLE' + (cmd.examples.length > 1 ? 'S' : ''));
          cmd.examples.forEach(function(ex, i) {
            if (i > 0) lines.push('');
            ex.split('\n').forEach(function(line, i) {
              lines.push('  ' + line);
            });
          });
        }
        return lines;
      }

      function getOptionLines(opt, cmd) {
        var lines = [];
        var description = opt.describe;
        var label;
        if (!description) {
          // empty
        } else if (opt.label) {
          lines.push([opt.label, description]);
        } else if (opt.name == cmd.default) {
          label = opt.name + '=';
          lines.push(['<' + opt.name + '>', 'shortcut for ' + label]);
          lines.push([label, description]);
        } else {
          label = opt.name;
          if (opt.alias) label += ', ' + opt.alias;
          if (opt.type != 'flag' && !opt.assign_to) label += '=';
          lines.push([label, description]);
        }
        return lines;
      }

      function getCommandLine(cmd) {
        var name = cmd.name ? "-" + cmd.name : '';
        if (cmd.alias) name += ', -' + cmd.alias;
        return [name, cmd.describe || '(undocumented command)'];
      }

      function getMultiCommandLines(commands) {
        var lines = [];
        // usage
        if (_usage) lines.push(_usage);

        // list of commands
        commands.forEach(function(cmd) {
          if (cmd.title) {
            lines.push('', cmd.title);
          } else {
            lines.push(getCommandLine(cmd));
          }
        });

        // examples
        if (_examples.length > 0) {
          lines.push('', 'Examples');
          _examples.forEach(function(str) {
            lines.push('', str);
          });
        }

        // note
        if (_note) {
          lines.push('', _note);
        }
        return lines;
      }


      function calcColWidth(lines) {
        var w = 0;
        lines.forEach(function(line) {
          if (Array.isArray(line)) {
            w = Math.max(w, line[0].length);
          }
        });
        return w;
      }
    };

    this.printHelp = function(command) {
      print(this.getHelpMessage(command));
    };

    function getCommands() {
      return _commands.map(function(cmd) {
        return cmd.done();
      });
    }

    function tokenIsCommandName(s) {
      var cmd = findCommandDefn(s, getCommands());
      return !!cmd;
    }

    function findCommandDefn(name, arr) {
      return utils.find(arr, function(cmd) {
        return cmd.name === name || cmd.alias === name || cmd.old_alias === name;
      });
    }

    function findOptionDefn(name, cmdDef) {
      return utils.find(cmdDef.options, function(o) {
        return o.name === name || o.alias === name || o.old_alias === name;
      });
    }
  }

  function CommandOptions(name) {
    var _command = {
      name: name,
      options: []
    };

    this.validate = function(f) {
      _command.validate = f;
      return this;
    };

    this.describe = function(str) {
      _command.describe = str;
      return this;
    };

    this.example = function(str) {
      if (!_command.examples) {
        _command.examples = [];
      }
      _command.examples.push(str);
      return this;
    };

    this.alias = function(name) {
      _command.alias = name;
      return this;
    };

    // define an alias command name that doesn't appear in command line help
    // (to support old versions of renamed commands)
    this.oldAlias = function(name) {
      _command.old_alias = name;
      return this;
    };

    this.title = function(str) {
      _command.title = str;
      return this;
    };

    this.flag = function(name) {
      _command[name] = true;
      return this;
    };

    this.option = function(name, opts) {
      opts = utils.extend({}, opts); // accept just a name -- some options don't need properties
      if (!utils.isString(name) || !name) error("Missing option name");
      if (!utils.isObject(opts)) error("Invalid option definition:", opts);
      // default option -- assign unnamed argument to this option
      if (opts.DEFAULT) _command.default = name;
      opts.name = name;
      _command.options.push(opts);
      return this;
    };

    this.done = function() {
      return _command;
    };
  }

  function getOptionParser() {
    // definitions of options shared by more than one command
    var targetOpt = {
          describe: 'layer(s) to target (comma-sep. list)'
        },
        nameOpt = {
          describe: 'rename the edited layer(s)'
        },
        noReplaceOpt = {
          alias: '+',
          type: 'flag',
          label: '+, no-replace', // show alias as primary option
          // describe: 'retain the original layer(s) instead of replacing'
          describe: 'retain both input and output layer(s)'
        },
        noSnapOpt = {
          // describe: 'don't snap points before applying command'
          type: 'flag'
        },
        encodingOpt = {
          describe: 'text encoding (applies to .dbf and delimited text files)'
        },
        snapIntervalOpt = {
          describe: 'snapping distance in source units (default is tiny)',
          type: 'distance'
        },
        minGapAreaOpt = {
          old_alias: 'min-gap-area',
          describe: 'threshold for filling gaps, e.g. 1.5km2 (default is small)',
          type: 'area'
        },
        sliverControlOpt = {
          describe: 'boost gap-fill-area of slivers (0-1, default is 1)',
          type: 'number'
        },
        calcOpt = {
          describe: 'use a JS expression to aggregate data values'
        },
        sumFieldsOpt = {
          describe: 'fields to sum when dissolving  (comma-sep. list)',
          type: 'strings'
        },
        copyFieldsOpt = {
          describe: 'fields to copy when dissolving (comma-sep. list)',
          type: 'strings'
        },
        dissolveFieldsOpt = {
          DEFAULT: true,
          type: 'strings',
          describe: '(optional) field(s) to dissolve on (comma-sep. list)'
        },
        fieldTypesOpt = {
          describe: 'type hints for csv source files, e.g. FIPS:str,ZIPCODE:str',
          type: 'strings'
        },
        stringFieldsOpt = {
          describe: 'csv field(s) to import as strings, e.g. FIPS,ZIPCODE',
          type: 'strings'
        },
        bboxOpt = {
          type: 'bbox',
          describe: 'comma-sep. bounding box: xmin,ymin,xmax,ymax'
        },
        invertOpt = {
          type: 'flag',
          describe: 'retain only features that would have been deleted'
        },
        whereOpt = {
          describe: 'use a JS expression to select a subset of features'
        },
        whereOpt2 = {
          describe: 'filter polygon boundaries using a JS expression (with A and B)'
        },
        eachOpt2 = {
          describe: 'apply a JS expression to each polygon boundary (with A and B)'
        },
        aspectRatioOpt = {
          describe: 'aspect ratio as a number or range (e.g. 2 0.8,1.6 ,2)'
        },
        offsetOpt = {
          describe: 'padding as distance or pct of h/w (single value or list)',
          type: 'distance'
        };

    var parser = new CommandParser();
    parser.usage('Usage:  mapshaper -<command> [options] ...');

    /*
    parser.example('Fix minor topology errors, simplify to 10%, convert to GeoJSON\n' +
        '$ mapshaper states.shp snap -simplify 10% -o format=geojson');

    parser.example('Aggregate census tracts to counties\n' +
        '$ mapshaper tracts.shp -each \'CTY_FIPS=FIPS.substr(0, 5)\' -dissolve CTY_FIPS');
    */

    parser.note('Enter mapshaper -help <command> to view options for a single command');

    parser.section('I/O commands');

    parser.default('i');

    parser.command('i')
      .describe('input one or more files')
      .validate(validateInputOpts)
      .flag('multi_arg')
      .option('files', {
        DEFAULT: true,
        type: 'strings',
        describe: 'one or more files to import, or - to use stdin'
      })
      .option('combine-files', {
        describe: 'import files to separate layers with shared topology',
        type: 'flag'
      })
      .option('merge-files', {
        // describe: 'merge features from compatible files into the same layer',
        type: 'flag'
      })
      .option('no-topology', {
        describe: 'treat each shape as topologically independent',
        type: 'flag'
      })
      .option('precision', {
        describe: 'coordinate precision in source units, e.g. 0.001',
        type: 'number'
      })
      .option('snap', {
        type: 'flag',
        describe: 'snap nearly identical points to fix minor topology errors'
      })
      .option('auto-snap', {alias_to: 'snap'})
      .option('snap-interval', snapIntervalOpt)
      .option('encoding', encodingOpt)
      /*
      .option('fields', {
        describe: 'attribute fields to import (comma-sep.) (default is all fields)',
        type: 'strings'
      }) */
      .option('id-field', {
        describe: 'import Topo/GeoJSON id property to this field'
      })
      .option('string-fields', stringFieldsOpt)
      .option('field-types', fieldTypesOpt)
      .option('name', {
        describe: 'Rename the imported layer(s)'
      })
      .option('geometry-type', {
        // undocumented; GeoJSON import rejects all but one kind of geometry
        // describe: '[GeoJSON] Import one kind of geometry (point|polygon|polyline)'
      })
      .option('json-path', {
        // describe: path to an array of data values
      })
      .option('csv-skip-lines', {
        type: 'integer',
        describe: '[CSV] number of lines to skip at the beginning of the file'
      })
      .option('csv-lines', {
        type: 'integer',
        describe: '[CSV] number of data records to read'
      })
      .option('csv-field-names', {
        type: 'strings',
        describe: '[CSV] comma-sep. list of field names to assign each column'
      })
      .option('csv-dedup-fields', {
        type: 'flag',
        describe: '[CSV] rename fields with duplicate names'
      })
      .option('csv-filter', {
        describe: '[CSV] JS expression for filtering records'
      })
      .option('csv-fields', {
        type: 'strings',
        describe: '[CSV] comma-sep. list of fields to import'
      })
      // .option('csv-comment', {
      //   describe: '[CSV] comment line character(s)'
      // })
      .option('decimal-comma', {
        type: 'flag',
        describe: '[CSV] import numbers formatted like 1.000,01 or 1 000,01'
      })
      .option('json-path', {
        old_alias: 'json-subtree',
        describe: '[JSON] path to JSON input data; separator is /'
      });

    parser.command('o')
      .describe('output edited content')
      .validate(validateOutputOpts)
      .option('_', {
        label: '<file|directory>',
        describe: '(optional) name of output file or directory, - for stdout'
      })
      .option('format', {
        describe: 'options: shapefile,geojson,topojson,json,dbf,csv,tsv,svg'
      })
      .option('target', targetOpt)
      .option('force', {
        describe: 'allow overwriting input files',
        type: 'flag'
      })
      .option('dry-run', {
        // describe: 'do not output any files'
        type: 'flag'
      })
      .option('ldid', {
        // describe: 'language driver id of dbf file',
        type: 'number'
      })
      .option('precision', {
        describe: 'coordinate precision in source units, e.g. 0.001',
        type: 'number'
      })
      .option('bbox-index', {
        describe: 'export a .json file with bbox of each layer',
        type: 'flag'
      })
      .option('cut-table', {
        describe: 'detach data attributes from shapes and save as a JSON file',
        type: 'flag'
      })
      .option('drop-table', {
        describe: 'remove data attributes from output',
        type: 'flag'
      })
      .option('encoding', {
        describe: '[Shapefile/CSV] text encoding (default is utf8)'
      })
      .option('field-order', {
        describe: '[Shapefile/CSV] field-order=ascending sorts columns A-Z'
      })
      .option('id-field', {
        describe: '[Topo/GeoJSON/SVG] field to use for id property',
        type: 'strings'
      })
      .option('bbox', {
        type: 'flag',
        describe: '[Topo/GeoJSON] add bbox property'
      })
      .option('extension', {
        describe: '[Topo/GeoJSON] set file extension (default is ".json")'
      })
      .option('prettify', {
        type: 'flag',
        describe: '[Topo/GeoJSON/JSON] format output for readability'
      })
      .option('singles', {
        describe: '[TopoJSON] save each target layer as a separate file',
        type: 'flag'
      })
      .option('quantization', {
        describe: '[TopoJSON] specify quantization (auto-set by default)',
        type: 'integer'
      })
      .option('no-quantization', {
        describe: '[TopoJSON] export coordinates without quantization',
        type: 'flag'
      })
      .option('no-point-quantization', {
        // describe: '[TopoJSON] export point coordinates without quantization',
        type: 'flag'
      })
      .option('presimplify', {
        describe: '[TopoJSON] add per-vertex data for dynamic simplification',
        type: 'flag'
      })
      .option('topojson-precision', {
        // describe: 'pct of avg segment length for rounding (0.02 is default)',
        type: 'number'
      })
      .option('rfc7946', {
        // obsolete -- rfc 7946 compatible outptu is now the default.
        // This option also rounds coordinates to 7 decimals. I'm retaining the
        // option for backwards compatibility.
        // describe: '[GeoJSON] follow RFC 7946 (CCW outer ring order, etc.)',
        type: 'flag'
      })
      // .option('winding', {
      //   describe: '[GeoJSON] set polygon winding order (use CW with d3-geo)'
      // })
      .option('gj2008', {
        describe: '[GeoJSON] use original GeoJSON spec (not RFC 7946)',
        type: 'flag'
      })
      .option('combine-layers', {
        describe: '[GeoJSON] output layers as a single file',
        type: 'flag'
      })
      .option('geojson-type', {
        describe: '[GeoJSON] FeatureCollection, GeometryCollection or Feature'
      })
      .option('ndjson', {
        describe: '[GeoJSON/JSON] output newline-delimited features or records',
        type: 'flag'
      })
      .option('width', {
        describe: '[SVG/TopoJSON] pixel width of output (SVG default is 800)',
        type: 'number'
      })
      .option('height', {
        describe: '[SVG/TopoJSON] pixel height of output (optional)',
        type: 'number'
      })
      .option('max-height', {
        describe: '[SVG/TopoJSON] max pixel height of output (optional)',
        type: 'number'
      })
      .option('margin', {
        describe: '[SVG/TopoJSON] space betw. data and viewport (default is 1)'
      })
      .option('pixels', {
        describe: '[SVG/TopoJSON] output area in pix. (alternative to width=)',
        type: 'number'
      })
      .option('fit-bbox', {
        type: 'bbox',
        describe: '[TopoJSON] scale and shift coordinates to fit a bbox'
      })
      .option('svg-scale', {
        describe: '[SVG] source units per pixel (alternative to width= option)',
        type: 'number'
      })
      .option('point-symbol', {
        describe: '[SVG] circle or square (default is circle)'
      })
      .option('svg-data', {
        type: 'strings',
        describe: '[SVG] fields to export as data-* attributes'
      })
      .option('id-prefix', {
        describe: '[SVG] prefix for namespacing layer and feature ids'
      })
      .option('delimiter', {
        describe: '[CSV] field delimiter'
      })
      .option('decimal-comma', {
        type: 'flag',
        describe: '[CSV] export numbers with decimal commas not points'
      })
      .option('final', {
        type: 'flag' // for testing
      })
      .option('metadata', {
        // describe: '[TopoJSON] add a metadata object',
        type: 'flag'
      });

    parser.section('Editing commands');

    parser.command('affine')
      .describe('transform coordinates by shifting, scaling and rotating')
      .flag('no_args')
      .option('shift', {
        type: 'strings',
        describe: 'x,y offsets in source units (e.g. 5000,-5000)'
      })
      .option('scale', {
        type: 'number',
        describe: 'scale (default is 1)'
      })
      .option('rotate', {
        type: 'number',
        describe: 'angle of rotation in degrees (default is 0)'
      })
      .option('anchor', {
        type: 'numbers',
        describe: 'center of rotation/scaling (default is center of selected shapes)'
      })
      .option('where', whereOpt)
      .option('target', targetOpt);

    parser.command('buffer')
      // .describe('')
      .option('radius', {
        describe: 'radius of buffer, as an expression or a constant',
        DEFAULT: true
      })
      .option('tolerance', {
        // describe: 'acceptable deviation for approximating curves'
      })
      .option('vertices', {
        // describe: 'number of vertices to use when buffering points',
        type: 'integer'
      })
      .option('backtrack', {
        type: 'integer'
      })
      .option('type', {
        // left, right, outer, inner (default is full buffer)
      })
      .option('planar', {
        type: 'flag'
      })
      .option('v2', { // use v2 method
        type: 'flag'
      })
      .option('debug-division', {
        type: 'flag'
      })
      .option('debug-mosaic', {
        type: 'flag'
      })
      .option('no-cleanup', {
        type: 'flag'
      })
      .option('units', {
        describe: 'distance units (meters|miles|km|feet) (default is meters)'
      })
      .option('name', nameOpt)
      .option('target', targetOpt)
      .option('no-replace', noReplaceOpt);

    parser.command('classify')
      // .describe('apply sequential or categorical classification')
      .describe('assign colors or values using one of several methods')
      .option('field', {
        describe: 'name of field to classify',
        DEFAULT: true
      })
      .option('save-as', {
          describe: 'name of output field (default is fill|stroke|class)'
      })
      .option('colors', {
        describe: 'list of CSS colors or color scheme name (see -colors)',
        type: 'colors'
      })
      .option('values', {
        describe: 'values to assign to classes (alternative to colors=)',
        type: 'strings'
      })
      .option('color-scheme', {
        // deprecated in favor of colors=
        // describe: 'name of a predefined color scheme (see -colors command)'
      })
      .option('non-adjacent', {
        describe: 'assign non-adjacent colors to a polygon layer',
        assign_to: 'method'
      })
      .option('stops', {
        describe: 'a pair of values (0-100) for limiting a color ramp',
        type: 'numbers'
      })
      .option('null-value', {
        describe: 'value (or color) to use for invalid or missing data'
      })
      .option('method', {
        describe: 'one of: quantile, nice, equal-interval, hybrid'
      })
      .option('quantile', {
        //describe: 'shortcut for method=quantile (the default)',
        assign_to: 'method'
      })
      .option('equal-interval', {
        //describe: 'short for method=equal-interval',
        assign_to: 'method'
      })
      .option('hybrid', {
        // describe: 'short for method=hybrid (equal-interval inner breaks + quantile outliers)',
        assign_to: 'method'
      })
      .option('nice', {
        //describe: 'short for method=nice (rounded, equal inner breaks)',
        assign_to: 'method'
      })
      .option('breaks', {
        describe: 'user-defined sequential class breaks',
        type: 'numbers'
      })
      .option('classes', {
        describe: 'number of classes (can be inferred from other options)',
        type: 'integer'
      })
      .option('invert', {
        describe: 'reverse the order of colors/values',
        type: 'flag'
      })
      .option('continuous', {
        describe: 'output continuous interpolated values (experimental)',
        type: 'flag'
      })
      .option('index-field', {
        describe: 'apply pre-calculated classes (0 ... n-1, -1)'
      })
      .option('precision', {
        describe: 'round data values before classification (e.g. 0.1)',
        type: 'number'
      })
      .option('categories', {
        describe: 'list of data values for categorical color scheme',
        type: 'strings'
      })
      .option('other', {
        describe: 'default value for categorical scheme'
      })
      .option('key', {type: 'flag'})
      .option('key-style', {
        describe: 'one of: simple, gradient, dataviz'
      })
      .option('key-name', {
        describe: 'name of output SVG file'
      })
      .option('key-width', {
        describe: 'width of key in pixels',
        type: 'number'
      })
      .option('key-font-size', {
        describe: 'label size in pixels',
        type: 'number'
      })
      .option('key-tile-height', {
        describe: 'height of color tiles in pixels',
        type: 'number'
      })
      .option('key-tic-length', {
        describe: 'length of tic mark in pixels'
      })
      .option('key-label-suffix', {
        describe: 'string to append to each label'
      })
      .option('key-last-suffix', {
        describe: 'string to append to last label'
      })
      .option('target', targetOpt);

    parser.command('clean')
      .describe('fixes geometry issues, such as polygon overlaps and gaps')
      .option('gap-fill-area', minGapAreaOpt)
      .option('sliver-control', sliverControlOpt)
      .option('snap-interval', snapIntervalOpt)
      .option('no-snap', noSnapOpt)
      .option('allow-overlaps', {
        describe: 'allow polygons to overlap (disables gap fill)',
        type: 'flag'
      })
      .option('overlap-rule', {
        describe: 'how to resolve overlaps: min-id|max-id|min-area|[max-area]'
      })
      .option('allow-empty', {
        describe: 'keep null geometries (removed by default)',
        type: 'flag'
      })
      .option('rewind', {
        describe: 'fix errors in the CW/CCW winding order of polygon rings',
        type: 'flag'
      })
      // TODO: consider making this the standard way of removing null geometry
      // (currently there's -filter remove-empty)
      // .option('empty', {
      //   describe: 'remove features with null geometry',
      //   type: 'flag'
      // })
      .option('arcs', { // old name for arcs-only
        alias_to: 'only-arcs'
      })
      .option('only-arcs', {
        describe: 'delete unused arcs but don\'t remove gaps and overlaps',
        type: 'flag'
      })
      .option('no-arc-dissolve', {
        type: 'flag' // no description
      })
      .option('target', targetOpt);

    parser.command('clip')
      .describe('use a polygon layer to clip another layer')
      .example('$ mapshaper states.shp -clip land_area.shp -o clipped.shp')
      .option('source', {
        DEFAULT: true,
        describe: 'file or layer containing clip polygons'
      })
      .option('remove-slivers', {
        describe: 'remove sliver polygons created by clipping',
        type: 'flag'
      })
      .option('bbox', bboxOpt)
      .option('bbox2', {
          type: 'bbox',
          describe: 'experimental fast bbox clipping'
        })
      .option('name', nameOpt)
      .option('no-snap', noSnapOpt)
      .option('target', targetOpt)
      .option('no-replace', noReplaceOpt);

    parser.command('colorizer')
      .describe('define a function to convert data values to color classes')
      .flag('no_arg')
      .option('colors', {
        describe: 'comma-separated list of CSS colors',
        type: 'colors'
      })
      .option('breaks', {
        describe: 'ascending-order list of breaks for sequential color scheme',
        type: 'numbers'
      })
      .option('categories', {
        describe: 'comma-sep. list of keys for categorical color scheme',
        type: 'strings'
      })
      .option('random', {
        describe: 'randomly assign colors',
        type: 'flag'
      })
      .option('other', {
        describe: 'default color for categorical scheme (defaults to no-data color)'
      })
      .option('nodata', {
        describe: 'color to use for invalid or missing data (default is white)'
      })
      .option('name', {
        describe: 'function name to use in -each and -svg-style commands'
      })
      .option('precision', {
        describe: 'rounding precision to apply before classification (e.g. 0.1)',
        type: 'number'
      })
      .example('Define a sequential color scheme and use it to create a new field\n' +
          '$ mapshaper data.json -colorizer name=getColor nodata=#eee breaks=20,40 \\\n' +
          '  colors=#e0f3db,#a8ddb5,#43a2ca -each \'fill = getColor(RATING)\' -o output.json');

    parser.command('dashlines')
      .describe('split lines into sections, with or without a gap')
      .oldAlias('split-lines')
      .option('dash-length', {
        type: 'distance',
        describe: 'length of split-apart lines (e.g. 200km)'
      })
      .option('gap-length', {
        type: 'distance',
        describe: 'length of gaps between dashes (default is 0)'
      })
      .option('scaled', {
        type: 'flag',
        describe: 'scale dashes and gaps to prevent partial dashes'
      })
      .option('planar', {
        type: 'flag',
        describe: 'use planar geometry'
      })
      .option('where', whereOpt)
      .option('target', targetOpt);

    parser.command('define')
      // .describe('define expression variables')
      .option('expression', {
        DEFAULT: true,
        describe: 'one or more assignment expressions (comma-sep.)'
      });

    parser.command('dissolve')
      .describe('merge features within a layer')
      .example('Dissolve all polygons in a feature layer into a single polygon\n' +
        '$ mapshaper states.shp -dissolve -o country.shp')
      .example('Generate state-level polygons by dissolving a layer of counties\n' +
        '(STATE_FIPS, POPULATION and STATE_NAME are attribute field names)\n' +
        '$ mapshaper counties.shp -dissolve STATE_FIPS copy-fields=STATE_NAME sum-fields=POPULATION -o states.shp')
      .option('field', {}) // old arg handled by dissolve function
      .option('fields', dissolveFieldsOpt)
      .option('calc', calcOpt)
      .option('sum-fields', sumFieldsOpt)
      .option('copy-fields', copyFieldsOpt)
      .option('multipart', {
        type: 'flag',
        describe: 'make multipart features instead of dissolving'
      })
      .option('where', whereOpt)
      .option('group-points', {
        type: 'flag',
        describe: '[points] group points instead of converting to centroids'
      })
      .option('weight', {
        describe: '[points] field or expression to use for weighting centroid'
      })
      .option('planar', {
        type: 'flag',
        describe: '[points] use 2D math to find centroids of latlong points'
      })
      .option('name', nameOpt)
      .option('target', targetOpt)
      .option('no-replace', noReplaceOpt);


    parser.command('dissolve2')
      .describe('merge adjacent polygons (repairs overlaps and gaps)')
      .option('field', {}) // old arg handled by dissolve function
      .option('fields', dissolveFieldsOpt)
      // UPDATE: Use -mosaic command for debugging
      //.option('mosaic', {type: 'flag'}) // debugging option
      //.option('arcs', {type: 'flag'}) // debugging option
      //.option('tiles', {type: 'flag'}) // debugging option
      .option('calc', calcOpt)
      .option('sum-fields', sumFieldsOpt)
      .option('copy-fields', copyFieldsOpt)
      .option('gap-fill-area', minGapAreaOpt)
      .option('sliver-control', sliverControlOpt)
      .option('allow-overlaps', {
        describe: 'allow dissolved polygons to overlap (disables gap fill)',
        type: 'flag'
      })
      .option('name', nameOpt)
      .option('no-snap', noSnapOpt)
      .option('target', targetOpt)
      .option('no-replace', noReplaceOpt);

    parser.command('divide')
      .describe('divide lines by polygons, copy polygon data to lines')
      .option('fields', {
        describe: 'fields to copy (comma-sep.) (default is all but key field)',
        type: 'strings'
      })
      .option('calc', {
        describe: 'use a JS expression to assign values (for many-to-one joins)'
      })
      .option('force', {
        describe: 'replace values from same-named fields',
        type: 'flag'
      })
      .option('source', {
        DEFAULT: true,
        describe: 'file or layer containing polygons'
      })
      .option('target', targetOpt);
      // .option('no-replace', noReplaceOpt);

    parser.command('dots')
      .describe('fill polygons with dots of one or more colors')
      .option('fields', {
        DEFAULT: true,
        describe: 'one or more fields containing numbers of dots',
        type: 'strings'
      })
      .option('colors', {
        describe: 'one or more colors',
        type: 'strings'
      })
      .option('values', {
        describe: 'values to assign to dot classes (alternative to colors=)',
        type: 'strings'
      })
      .option('save-as', {
        describe: 'name of color/value output field (default is fill)'
      })
      .option('progressive', {
        // describe: 'fill in points progressively',
        type: 'flag'
      })
      .option('r', {
        describe: 'radius of each dot in pixels',
        type: 'number'
      })
      .option('evenness', {
        describe: '(0-1) dot spacing, from random to even (default is 1)',
        type: 'number'
      })
      .option('per-dot', {
        describe: 'number for scaling data values (e.g. 10 per dot)',
        type: 'number'
      })
      .option('copy-fields', {
        describe: 'list of fields to copy from polygons to dots',
        type: 'strings'
      })
      .option('multipart', {
        describe: 'combine groups of same-color dots into multi-part features',
        type: 'flag'
      })
      .option('target', targetOpt)
      .option('name', nameOpt)
      .option('no-replace', noReplaceOpt);

    parser.command('drop')
      .describe('delete layer(s) or elements within the target layer(s)')
      .flag('no_arg') // prevent trying to pass a list of layer names as default option
      .option('geometry', {
        describe: 'delete all geometry from the target layer(s)',
        type: 'flag'
      })
      .option('holes', {
        describe: 'delete holes from polygons',
        type: 'flag'
      })
      .option('fields', {
        type: 'strings',
        describe: 'delete a list of attribute data fields, e.g. \'id,name\' \'*\''
      })
      .option('target', targetOpt);

    parser.command('each')
      .describe('create/update/delete data fields using a JS expression')
      .example('Add two calculated data fields to a layer of U.S. counties\n' +
          '$ mapshaper counties.shp -each \'STATE_FIPS=CNTY_FIPS.substr(0, 2), AREA=$.area\'')
      .option('expression', {
        DEFAULT: true,
        describe: 'JS expression to apply to each target feature'
      })
      .option('where', whereOpt)
      .option('target', targetOpt);

    parser.command('erase')
      .describe('use a polygon layer to erase another layer')
      .example('$ mapshaper land_areas.shp -erase water_bodies.shp -o erased.shp')
      .option('source', {
        DEFAULT: true,
        describe: 'file or layer containing erase polygons'
      })
      .option('remove-slivers', {
        describe: 'remove sliver polygons created by erasing',
        type: 'flag'
      })
      .option('bbox', bboxOpt)
      .option('name', nameOpt)
      .option('no-snap', noSnapOpt)
      .option('target', targetOpt)
      .option('no-replace', noReplaceOpt);

    parser.command('explode')
      .describe('divide multi-part features into single-part features')
      .option('naive', {type: 'flag'}) // testing
      .option('target', targetOpt);

    parser.command('filter')
      .describe('delete features using a JS expression')
      .option('expression', {
        DEFAULT: true,
        describe: 'delete features that evaluate to false'
      })
      .option('bbox', {
        describe: 'delete features outside bbox (xmin,ymin,xmax,ymax)',
        type: 'bbox'
      })
      .option('invert', invertOpt)
      .option('remove-empty', {
        type: 'flag',
        describe: 'delete features with null geometry'
      })
      .option('keep-shapes', {
        type: 'flag'
      })
      .option('ids', {
        // describe: 'filter on a list of feature ids',
        type: 'numbers'
      })
      .option('cleanup', {type: 'flag'}) // TODO: document
      .option('name', nameOpt)
      .option('target', targetOpt)
      .option('no-replace', noReplaceOpt);

    parser.command('filter-fields')
      .describe('retain a subset of data fields')
      .option('fields', {
        DEFAULT: true,
        type: 'strings',
        describe: 'fields to retain (comma-sep.), e.g. \'fips,name\''
      })
      .option('target', targetOpt);

    parser.command('filter-geom')
      .describe('')
      .option('bbox', {
        type: 'bbox',
        describe: 'remove non-intersecting geometry (xmin,ymin,xmax,ymax)'
      })
      .option('target', targetOpt);

    parser.command('filter-islands2')
      // .describe('remove small detached polygon rings (islands)')
      .option('min-area', {
        type: 'area',
        describe: 'remove small-area islands (e.g. 10km2)'
      })
      .option('min-vertices', {
        type: 'integer',
        describe: 'remove low-vertex-count islands'
      })
      .option('keep-shapes', {
        type: 'flag',
        describe: 'only filter smaller parts of multipart polygons',
      })
      .option('remove-empty', {
        type: 'flag',
        describe: 'delete features with null geometry'
      })
      .option('target', targetOpt);

    parser.command('filter-islands')
      .describe('remove small detached polygon rings (islands)')
      .option('min-area', {
        type: 'area',
        describe: 'remove small-area islands (e.g. 10km2)'
      })
      .option('min-vertices', {
        type: 'integer',
        describe: 'remove low-vertex-count islands'
      })
      .option('remove-empty', {
        type: 'flag',
        describe: 'delete features with null geometry'
      })
      .option('target', targetOpt);

    parser.command('filter-slivers')
      .describe('remove small polygon rings')
      .option('min-area', {
        type: 'area',
        describe: 'area threshold (e.g. 2sqkm)'
      })
      .option('sliver-control', {
        describe: 'boost area threshold of slivers (0-1, default is 1)',
        type: 'number'
      })
      .option('weighted', {
        // describe: 'multiply min-area by Polsby-Popper compactness (0-1)'
        type: 'flag',
      })
      /*
      .option('remove-empty', {
        type: 'flag',
        describe: 'delete features with null geometry'
      })
      */
      .option('target', targetOpt);

    parser.command('graticule')
      .describe('create a graticule layer')
      .option('interval', {
        describe: 'size of grid cells in degrees (options: 5 10 15 30 45, default is 10)',
        type: 'number'
      })
      .option('polygon', {
        describe: 'create a polygon to match the outline of the graticule',
        type: 'flag'
      });

    parser.command('grid')
      .describe('create a grid of square or hexagonal polygons')
      .option('type', {
        describe: 'square, hex or hex2 (default is square)'
      })
      .option('interval', {
        describe: 'side length (e.g. 500m, 12km)',
        type: 'distance'
      })
      // .option('cols', {
      //   type: 'integer'
      // })
      // .option('rows', {
      //   type: 'integer'
      // })
      // .option('bbox', {
      //   type: 'bbox',
      //   describe: 'xmin,ymin,xmax,ymax (default is bbox of data)'
      // })
      .option('name', nameOpt)
      .option('target', targetOpt)
      .option('no-replace', noReplaceOpt);

    parser.command('ignore')
      // .describe('stop processing if a condition is met')
      .option('empty', {
        describe: 'ignore empty files',
        type: 'flag'
      })
      .option('target', targetOpt);

    parser.command('include')
      .describe('import JS data and functions for use in JS expressions')
      .option('file', {
        DEFAULT: true,
        describe: 'file containing a JS object with key:value pairs to import'
      });

    parser.command('inlay')
      .describe('inscribe a polygon layer inside another polygon layer')
      .option('source', {
        DEFAULT: true,
        describe: 'file or layer containing polygons to inlay'
      })
      .option('target', targetOpt);

    parser.command('innerlines')
      .describe('convert polygons to polylines along shared edges')
      .flag('no_arg')
      .option('where', whereOpt2)
      // .option('each', eachOpt2)
      .option('name', nameOpt)
      .option('target', targetOpt)
      .option('no-replace', noReplaceOpt);

    parser.command('join')
      .describe('join data records from a file or layer to a layer')
      .example('Join a csv table to a Shapefile (don\'t auto-convert FIPS column to numbers)\n' +
        '$ mapshaper states.shp -join data.csv keys=STATE_FIPS,FIPS string-fields=FIPS -o joined.shp')
      .validate(function(cmd) {
        if (!cmd.options.source) {
          error('Command requires the name of a layer or file to join');
        }
      })
      .option('source', {
        DEFAULT: true,
        describe: 'file or layer containing data records'
      })
      .option('keys', {
        describe: 'join by matching target,source key fields, e.g. keys=FID,id',
        type: 'strings'
      })
      .option('calc', {
        describe: 'use a JS expression to assign values (for many-to-one joins)'
      })
      .option('where', {
        describe: 'use a JS expression to filter source records'
      })
      .option('fields', {
        describe: 'fields to copy (comma-sep.) (default is all but key field)',
        type: 'strings'
      })
      .option('prefix', {
        describe: 'prefix for renaming fields joined from the source table'
      })
      .option('interpolate', {
        describe: '(polygon-polygon join) list of area-interpolated fields',
        type: 'strings'
      })
      .option('point-method', {
        describe: '(polygon-polygon join) join polygons via inner points',
        type: 'flag'
      })
      .option('largest-overlap', {
        describe: '(polygon-polygon join) use max overlap to join one polygon',
        type: 'flag'
      })
      // .option('nearest-point', {
      //   describe: '(point-point join)',
      //   type: 'flag'
      // })
      .option('max-distance', {
        describe: '(point-point join) join source points within this radius',
        type: 'distance'
      })
      .option('planar', {
        // describe: 'use planar geometry when interpolating by area' // useful for testing
        type: 'flag'
      })
      .option('duplication', {
        describe: 'duplicate target features on many-to-one joins',
        type: 'flag'
      })
      .option('string-fields', stringFieldsOpt)
      .option('field-types', fieldTypesOpt)
      .option('sum-fields', {
        describe: 'fields to sum in a many-to-one join (or use calc= for this)',
        type: 'strings'
      })
      .option('force', {
        describe: 'replace values from same-named fields',
        type: 'flag'
      })
      .option('unjoined', {
        describe: 'copy unjoined records from source table to "unjoined" layer',
        type: 'flag'
      })
      .option('unmatched', {
        describe: 'copy unmatched records in target table to "unmatched" layer',
        type: 'flag'
      })
      .option('encoding', encodingOpt)
      .option('target', targetOpt);

    parser.command('lines')
      .describe('convert a polygon or point layer to a polyline layer')
      .option('fields', {
        DEFAULT: true,
        describe: 'field(s) to create a hierarchy of boundary lines',
        type: 'strings'
      })
      .option('where', whereOpt2)
      .option('each', eachOpt2)
      .option('segments', {
        describe: 'convert paths to segments, for debugging',
        type: 'flag'
      })
      .option('callouts', {
        // describe: 'convert points to lines for editing in the GUI',
        type: 'flag'
      })
      .option('arcs', {
        describe: 'convert paths to arcs, for debugging',
        type: 'flag'
      })
      .option('groupby', {
        describe: 'field for grouping point input into multiple lines'
      })
      .option('name', nameOpt)
      .option('target', targetOpt)
      .option('no-replace', noReplaceOpt);

    parser.command('merge-layers')
      .describe('merge multiple layers into as few layers as possible')
      .flag('no_arg')
      .option('force', {
        type: 'flag',
        describe: 'merge layers with inconsistent data fields'
      })
      .option('flatten', {
        describe: 'remove polygon overlaps; higher-id polygons take priority',
        type: 'flag'
      })
      .option('name', nameOpt)
      .option('target', targetOpt);

    parser.command('mosaic')
      .describe('convert a polygon layer with overlaps into a flat mosaic')
      .option('calc', calcOpt)
      .option('name', nameOpt)
      .option('target', targetOpt)
      .option('no-replace', noReplaceOpt);

    parser.command('point-grid')
      .describe('create a rectangular grid of points')
      .validate(validateGridOpts)
      .option('-', {
        label: '<cols,rows>',
        describe: 'size of the grid, e.g. -point-grid 100,100'
      })
      .option('interval', {
        describe: 'distance between adjacent points, in source units',
        type: 'distance'
      })
      .option('cols', {
        type: 'integer'
      })
      .option('rows', {
        type: 'integer'
      })
      .option('bbox', {
        type: 'bbox',
        describe: 'xmin,ymin,xmax,ymax (default is bbox of data)'
      })
      .option('name', nameOpt)
      .option('target', targetOpt)
      .option('no-replace', noReplaceOpt);

    parser.command('points')
      .describe('create a point layer from a different layer type')
      .flag('no_arg')
      .option('x', {
        describe: 'field containing x coordinate'
      })
      .option('y', {
        describe: 'field containing y coordinate'
      })
      .option('inner', {
        describe: 'create an interior point for each polygon\'s largest ring',
        type: 'flag'
      })
      .option('centroid', {
        describe: 'create a centroid point for each polygon\'s largest ring',
        type: 'flag'
      })
      .option('vertices', {
        describe: 'capture unique vertices of polygons and polylines',
        type: 'flag'
      })
      .option('vertices2', {
        describe: 'like vertices, but without removal of duplicate coordinates',
        type: 'flag'
      })
      .option('endpoints', {
        describe: 'capture unique endpoints of polygons and polylines',
        type: 'flag'
      })
      .option('midpoints', {
        describe: 'find the (planar) midpoint of each polyline',
        type: 'flag'
      })
      // WORK IN PROGRESS todo: create a point layer containing segment intersections
      .option('intersections', {
       // describe: 'capture line segment intersections of polygons and polylines',
       type: 'flag'
      })
      .option('interpolated', {
        describe: 'interpolate points along polylines; requires interval=',
        type: 'flag'
      })
      .option('interval', {
        describe: 'distance between interpolated points (meters or projected units)',
        type: 'distance'
      })
      .option('name', nameOpt)
      .option('target', targetOpt)
      .option('no-replace', noReplaceOpt);

    parser.command('polygons')
      .describe('convert polylines to polygons')
      .option('gap-tolerance', {
        describe: 'specify gap tolerance in source units',
        type: 'distance'
      })
      .option('from-rings', {
        describe: 'do simple conversion from a layer of closed paths',
        type: 'flag'
      })
      .option('target', targetOpt);

    parser.command('proj')
      .describe('project your data (using Proj.4)')
      .flag('multi_arg')
      .option('crs', {
        DEFAULT: true,
        describe: 'set destination CRS using a Proj.4 definition or alias'
      })
      .option('projection', {
        alias_to: 'crs'
      })
      .option('match', {
        describe: 'set destination CRS using a .prj file or layer id'
      })
      .option('source', {
        // describe: '(deprecated) alias for match',
        alias_to: 'match'
      })
      .option('from', {
        alias_to: 'init',
        describe: '(deprecated) alias for init='
      })
      .option('init', {
        describe: 'set source CRS (if unset) using a string, .prj or layer id'
      })
      .option('densify', {
        type: 'flag',
        describe: 'add points along straight segments to approximate curves'
      })
      .option('clip-angle', {
        describe: 'use a custom clipping radius (for azimuthal projections)',
        type: 'number'
      })
      .option('clip-bbox', {
        describe: 'clip to a lat-long bounding box before projecting',
        type: 'bbox'
      })
      .option('target', targetOpt)
      .validate(validateProjOpts);

    parser.command('rectangle')
      .describe('create a rectangle from a bbox or target layer extent')
      .option('bbox', {
        describe: 'rectangle coordinates (xmin,ymin,xmax,ymax)',
        type: 'bbox'
      })
      .option('offset', offsetOpt)
      .option('aspect-ratio', aspectRatioOpt)
      .option('source', {
        describe: 'name of layer to enclose'
      })
      .option('name', nameOpt)
      .option('target', targetOpt)
      .option('no-replace', noReplaceOpt);

    parser.command('rectangles')
      .describe('create a rectangle around each feature in a layer')
      .option('offset', offsetOpt)
      .option('aspect-ratio', aspectRatioOpt)
      .option('name', nameOpt)
      .option('target', targetOpt)
      .option('no-replace', noReplaceOpt);

    parser.command('rename-fields')
      .describe('rename data fields')
      .option('fields', {
        DEFAULT: true,
        type: 'strings',
        describe: 'list of replacements (comma-sep.), e.g. \'fips=STATE_FIPS,st=state\''
      })
      .option('target', targetOpt);

    parser.command('rename-layers')
      .describe('assign new names to layers')
      .option('names', {
        DEFAULT: true,
        type: 'strings',
        describe: 'list of replacements (comma-sep.)'
      })
      .option('target', targetOpt);


    parser.command('simplify')
      .validate(validateSimplifyOpts)
      .example('Retain 10% of removable vertices\n$ mapshaper input.shp -simplify 10%')
      .describe('simplify the geometry of polygon and polyline features')
      .option('percentage', {
        DEFAULT: true,
        alias: 'p',
        type: 'percent',
        describe: 'percentage of removable points to retain, e.g. 10%'
      })
      .option('dp', {
        alias: 'rdp',
        describe: 'use Ramer-Douglas-Peucker simplification',
        assign_to: 'method'
      })
      .option('visvalingam', {
        describe: 'use Visvalingam simplification with "effective area" metric',
        assign_to: 'method'
      })
      .option('weighted', {
        describe: 'use weighted Visvalingam simplification (default)',
        assign_to: 'method'
      })
      .option('method', {
        // hidden option
      })
      .option('weighting', {
        type: 'number',
        describe: 'weighted Visvalingam coefficient (default is 0.7)'
      })
      .option('resolution', {
        describe: 'output resolution as a grid (e.g. 1000x500)'
      })
      .option('interval', {
        // alias: 'i',
        describe: 'output resolution as a distance (e.g. 100)',
        type: 'distance'
      })
      /*
      .option('value', {
        // for testing
        // describe: 'raw value of simplification threshold',
        type: 'number'
      })
      */
      .option('variable', {
        // describe: 'expect an expression with interval=, percentage= or resolution=',
        describe: 'JS expr. assigning to one of: interval= percentage= resolution=',
        type: 'flag'
      })
      .option('planar', {
        describe: 'simplify decimal degree coords in 2D space (default is 3D)',
        type: 'flag'
      })
      .option('cartesian', {
        // describe: '(deprecated) alias for planar',
        alias_to: 'planar'
      })
      .option('keep-shapes', {
        describe: 'prevent small polygon features from disappearing',
        type: 'flag'
      })
      .option('lock-box', {
        // describe: 'don't remove vertices along bbox edges'
        type: 'flag'
      })
      .option('no-repair', {
        describe: 'don\'t remove intersections introduced by simplification',
        type: 'flag'
      })
      .option('stats', {
        describe: 'display simplification statistics',
        type: 'flag'
      })
      .option('target', targetOpt);

    parser.command('slice')
      // .describe('slice a layer using polygons in another layer')
      .option('source', {
        DEFAULT: true,
        describe: 'file or layer containing clip polygons'
      })
      /*
      .option('remove-slivers', {
        describe: 'remove sliver polygons created by clipping',
        type: 'flag'
      }) */
      .option('id-field', {
        describe: 'slice id field (from source layer)'
      })
      .option('name', nameOpt)
      .option('no-snap', noSnapOpt)
      .option('target', targetOpt)
      .option('no-replace', noReplaceOpt);

    parser.command('snap')
      .describe('snap together nearby vertices')
      .option('interval', {
        describe: 'snap together vertices within a tolerance (default is small)',
        DEFAULT: true,
        type: 'distance'
      })
      .option('precision', {
        describe: 'round all coordinates to a given decimal precision (e.g. 0.000001)',
        type: 'number'
      })
      .option('target', targetOpt);

    parser.command('sort')
      .describe('sort features using a JS expression')
      .option('expression', {
        DEFAULT: true,
        describe: 'JS expression to generate a sort key for each feature'
      })
      .option('ascending', {
        describe: 'sort in ascending order (default)',
        type: 'flag'
      })
      .option('descending', {
        describe: 'sort in descending order',
        type: 'flag'
      })
      .option('target', targetOpt);

    parser.command('split')
      .describe('split a layer into single-feature or multi-feature layers')
      .option('field', {
        // former name
        alias_to: 'expression'
      })
      .option('expression', {
        DEFAULT: true,
        describe: 'expression or field for grouping features and naming split layers'
      })
      .option('ids', {
        // used by gui history to split on selected features
        // describe: 'split on a list of feature ids',
        type: 'numbers'
      })
      .option('apart', {
        describe: 'save output layers to independent datasets',
        type: 'flag'
      })
      .option('target', targetOpt)
      .option('no-replace', noReplaceOpt);

    parser.command('split-on-grid')
      .describe('split features into separate layers using a grid')
      .validate(validateGridOpts)
      .option('-', {
        label: '<cols,rows>',
        describe: 'size of the grid, e.g. -split-on-grid 12,10'
      })
      .option('cols', {
        type: 'integer'
      })
      .option('rows', {
        type: 'integer'
      })
      .option('id-field', {
        describe: 'assign each feature a cell id instead of splitting layer'
      })
      // .option('no-replace', noReplaceOpt)
      .option('target', targetOpt);

    parser.command('style')
      .oldAlias('svg-style')
      .describe('set SVG style properties using JS or literal values')
      .option('where', whereOpt)
      .option('class', {
        describe: 'name of CSS class or classes (space-separated)'
      })
      // .option('css', {
      //   describe: 'inline css style'
      // })
      .option('fill', {
        describe: 'fill color; examples: #eee pink rgba(0, 0, 0, 0.2)'
      })
      .option('fill-pattern', {
        describe: 'pattern fill, ex: "hatches 2px grey 2px blue"'
      })
      .option('fill-opacity', {
        describe: 'fill opacity'
      })
      .option('fill-hatch', {
        alias_to: 'fill-pattern'
      })
      .option('stroke', {
        describe: 'stroke color'
      })
      .option('stroke-width', {
        describe: 'stroke width'
      })
      .option('stroke-dasharray', {
        describe: 'stroke dashes. Examples: "4" "2 4"'
      })
      .option('stroke-opacity', {
        describe: 'stroke opacity'
      })
      .option('opacity', {
        describe: 'opacity; example: 0.5'
      })
      .option('r', {
        describe: 'symbol radius (set this to export points as circles)',
      })
      .option('label-text', {
        describe: 'label text (set this to export points as labels)'
      })
      .option('text-anchor', {
        describe: 'label alignment; one of: start, end, middle (default)'
      })
      .option('dx', {
        describe: 'x offset of labels (default is 0)'
      })
      .option('dy', {
        describe: 'y offset of labels (default is 0/baseline-aligned)'
      })
      .option('font-size', {
        describe: 'size of label text (default is 12)'
      })
      .option('font-family', {
        describe: 'CSS font family of labels (default is sans-serif)'
      })
      .option('font-weight', {
        describe: 'CSS font weight property of labels (e.g. bold, 700)'
      })
      .option('font-style', {
        describe: 'CSS font style property of labels (e.g. italic)'
      })
       .option('letter-spacing', {
        describe: 'CSS letter-spacing property of labels'
      })
       .option('line-height', {
        describe: 'line spacing of multi-line labels (default is 1.1em)'
      })
     .option('target', targetOpt);

    parser.command('symbols')
      // .describe('symbolize points as polygons, circles, stars or arrows')
      .option('type', {
        describe: 'symbol type (e.g. star, polygon, circle, arrow)'
      })
      .option('scale', {
        describe: 'scale symbols by a factor',
        type: 'number'
      })
      .option('pixel-scale', {
        describe: 'symbol scale in meters-per-pixel (see polygons option)',
        type: 'number',
      })
      .option('polygons', {
        describe: 'generate symbols as polygons instead of SVG objects',
        type: 'flag'
      })
      .option('radius', {
        describe: 'distance from center to farthest point on the symbol',
        type: 'distance'
      })
      .option('sides', {
        describe: 'sides of a polygon or star symbol',
        type: 'number'
      })
      .option('orientation', {
        // describe: 'use orientation=b for a rotated or flipped orientation'
      })
      .option('flipped', {
        type: 'flag',
        describe: 'symbol is vertically flipped'
      })
      .option('rotated', {
        type: 'flag',
        describe: 'symbol is rotated to a different orientation'
      })
      .option('rotation', {
        describe: 'rotation of symbol in degrees'
      })
      .option('length', {
        // alias for arrow-length
      })
      .option('point-ratio', {
        old_alias: 'star-ratio',
        describe: '(star) ratio of minor to major radius of star',
        type: 'number'
      })
      .option('radii', {
        describe: '(ring) comma-sep. list of concentric radii, ascending order'
      })
      .option('length', {
        old_alias: 'arrow-length',
        describe: '(arrow) length of arrow in pixels'
      })
      .option('direction', {
        old_alias: 'arrow-direction',
        describe: '(arrow) angle off vertical (-90 = left-pointing)'
      })
      .option('head-angle', {
        old_alias: 'arrow-head-angle',
        describe: '(arrow) angle of tip of arrow (default is 40 degrees)'
      })
      .option('head-width', {
        old_alias: 'arrow-head-width',
        describe: '(arrow) width of arrow head from side to side'
      })
      .option('head-length', {
        old_alias: 'arrow-head-width',
        describe: '(arrow) length of head (alternative to head-angle)'
      })
      .option('head-shape', {
        // describe: 'options: a b c'
      })
      .option('stem-width', {
        old_alias: 'arrow-stem-width',
        describe: '(arrow) width of stem at its widest point'
      })
      .option('stem-length', {
        old_alias: 'arrow-stem-length',
        describe: '(arrow) alternative to length'
      })
      .option('stem-taper', {
        old_alias: 'arrow-stem-taper',
        describe: '(arrow) factor for tapering the width of the stem (0-1)'
      })
      .option('stem-curve', {
        old_alias: 'arrow-stem-curve',
        describe: '(arrow) curvature in degrees (default is 0)'
      })
      .option('min-stem-ratio', {
        old_alias: 'arrow-min-stem',
        describe: '(arrow) min ratio of stem to total length',
        type: 'number'
      })
      .option('stroke', {})
      .option('stroke-width', {})
      .option('fill', {
        describe: 'symbol fill color'
      })
      .option('effect', {})
      // .option('where', whereOpt)
      .option('name', nameOpt)
      .option('target', targetOpt)
      .option('no-replace', noReplaceOpt);
      // .option('name', nameOpt);


    parser.command('target')
      .describe('set active layer (or layers)')
      .option('target', {
        DEFAULT: true,
        describe: 'name or index of layer to target'
      })
      .option('type', {
        describe: 'type of layer to target (polygon|polyline|point)'
      })
      .option('name', {
        describe: 'rename the target layer'
      });

    parser.command('union')
      .describe('create a flat mosaic from two or more polygon layers')
      // .option('add-fid', {
      //   describe: 'add FID_A, FID_B, ... fields to output layer',
      //   type: 'flag'
      // })
      .option('fields', {
        type: 'strings',
        describe: 'fields to retain (comma-sep.) (default is all fields)',
      })
      .option('name', nameOpt)
      .option('target', {
        describe: 'specify layers to target (comma-sep. list)'
      })
      .option('no-replace', noReplaceOpt);

    parser.command('uniq')
      .describe('delete features with the same id as a previous feature')
      .option('expression', {
        DEFAULT: true,
        describe: 'JS expression to obtain the id of a feature'
      })
      .option('max-count', {
        type: 'number',
        describe: 'max features with the same id (default is 1)'
      })
      .option('index', {
        // describe: 'add an index instead of filtering'
        type: 'flag'
      })
      .option('invert', invertOpt)
      .option('verbose', {
        describe: 'print each removed feature',
        type: 'flag'
      })
      .option('target', targetOpt);

    // Experimental commands
    parser.section('Experimental commands (may give unexpected results)');

    parser.command('alpha-shapes')
      // .describe('convert points to alpha shapes (aka concave hulls)')
      .option('interval', {
        describe: 'alpha parameter',
        type: 'number'
      })
      .option('keep-points', {
        // describe: 'replace single points with tiny triangles',
        type: 'flag'
      })
      .option('name', nameOpt)
      .option('target', targetOpt)
      .option('no-replace', noReplaceOpt);

    parser.command('cluster')
      .describe('group polygons into compact clusters')
      .option('id-field', {
        describe: 'field name of cluster id (default is "cluster")'
      })
      .option('pct', {
        alias: 'p',
        type: 'percent',
        describe: 'percentage of shapes to retain, e.g. 50%'
      })
      .option('max-width', {
        describe: 'max width of cluster bounding box',
        type: 'number'
      })
      .option('max-height', {
        describe: 'max height of cluster bounding box',
        type: 'number'
      })
      .option('max-area', {
        describe: 'max area of a cluster',
        type: 'number'
      })
      .option('group-by', {
        describe: 'field name; only same-value shapes will be grouped'
      })
      .option('target', targetOpt);

    parser.command('data-fill')
      .describe('fill in missing values in a polygon layer')
      .option('field', {
        describe: 'name of field to fill in'
      })
      .option('postprocess', {alias_to: 'contiguous'})
      .option('contiguous', {
        describe: 'remove non-contiguous data islands',
        type: 'flag'
      })
      // .option('min-weight-pct', {
      //   describe: 'retain data islands weighted more than this pct'
      // })
      .option('weight-field', {
        describe: 'use field values to calculate data island weights'
      });

    parser.command('external')
      .option('module', {
        DEFAULT: true,
        describe: 'name of Node module containing the command'
      });

    parser.command('filter-points')
      // .describe('remove points that are not part of a group')
      // .option('min-group-size', {
      //   // describe: 'drop points with fewer points in the vicinity',
      //   type: 'number'
      // })
      .option('group-interval', {
        // describe: max interval separating a point from other points
        type: 'number'
      });

    parser.command('frame')
      // .describe('create a map frame at a given size')
      .option('bbox', {
        describe: 'frame coordinates (xmin,ymin,xmax,ymax)',
        type: 'bbox'
      })
      .option('offset', offsetOpt)
      .option('width', {
        describe: 'pixel width of output (default is 800)'
      })
      .option('height', {
        describe: 'pixel height of output (may be a range)'
      })
      .option('pixels', {
        describe: 'area of output in pixels (alternative to width and height)',
        type: 'number'
      })
      .option('source', {
        describe: 'name of layer to enclose'
      })
      .option('name', nameOpt);

    parser.command('fuzzy-join')
      .describe('join points to polygons, with data fill and fuzzy match')
      .option('source', {
        DEFAULT: true,
        describe: 'file or layer containing data records'
      })
      .option('field', {
        describe: 'field to join'
      })
      .option('dedup-points', {
        describe: 'uniqify points with the same location and field value',
        type: 'flag'
      })
      .option('no-dropouts', {
        describe: 'try to retain all values from the point layer',
        type: 'flag'
      })
      .option('postprocess', {alias_to: 'contiguous'})
      .option('contiguous', {
        describe: 'remove non-contiguous data islands',
        type: 'flag'
      })
      .option('target', targetOpt);

    parser.command('point-to-grid')
      .option('interval', {
        // describe: size of grid in projected units
        type: 'number'
      })
      .option('radius', {
        // describe: radius to assign each point
        type: 'number'
      })
      .option('circles', {
        // describe: create a grid of circles instead of squares
        type: 'flag'
      })
      .option('cell-margin', {
        // describe: (0-1) inset grid shapes by a percentage
        type: 'number'
      })
      .option('calc', calcOpt)
      .option('name', nameOpt)
      .option('target', targetOpt)
      .option('no-replace', noReplaceOpt);

    parser.command('require')
      .describe('require a Node module for use in -each expressions')
      .option('module', {
        DEFAULT: true,
        describe: 'name of Node module or path to module file'
      })
      .option('alias', {
        describe: 'Set the module name to an alias'
      })
      .option('init', {
        describe: 'JS expression to run after the module loads'
      });

    parser.command('rotate')
      // .describe('apply d3-style 3-axis rotation to a lat-long dataset')
      .option('rotation', {
        // describe: 'two or three angles of rotation',
        DEFAULT: true,
        type: 'numbers'
      })
      .option('invert', {
        type: 'flag'
      });

    parser.command('run')
      .describe('create commands on-the-fly and run them')
      .option('include', {
        // TODO: remove this option
      })
      .option('commands', {
        DEFAULT: true,
        describe: 'command string or JS expresson to generate command(s)'
      })
      .option('target', targetOpt);

    parser.command('scalebar')
      // .describe()
      .option('top', {})
      .option('right', {})
      .option('bottom', {})
      .option('left', {})
      .option('font-size', {})
      // .option('font-family', {})
      .option('label-position', {}) // top or bottom
      .option('label-text', {});

    parser.command('shape')
      .describe('create a polyline or polygon from coordinates')
      .option('coordinates', {
        describe: 'list of vertices as x,y,x,y...',
        type: 'numbers'
      })
      .option('offsets', {
        describe: 'list of vertices as offsets from coordinates list',
        type: 'numbers'
      })
      .option('closed', {
        describe: 'close an open path to create a polygon',
        type: 'flag'
      })
      .option('type', {
        // describe: 'circle or ???'
        DEFAULT: true,
      })
      .option('center', {
        //describe: 'center of the circle (default is 0,0)',
        type: 'numbers'
      })
      .option('radius', {
        //describe: 'radius of the circle in meters',
        type: 'number'
      })
      .option('radius-angle', {
        //describe: 'radius of the circle in degrees',
        type: 'number'
      })
      .option('bbox', {
        // describe: 'rectangle bounding box',
        type: 'numbers'
      })
      .option('geometry', {
        //describe: 'polygon or polyline'
      })
      .option('rotation', {
        // describe: 'two or three angles of rotation',
        type: 'numbers'
      })
      .option('name', nameOpt);

    parser.command('subdivide')
      .describe('recursively split a layer using a JS expression')
      .validate(validateExpressionOpt)
      .option('expression', {
        DEFAULT: true,
        describe: 'boolean JS expression'
      })
      .option('target', targetOpt);

    parser.section('Informational commands');

    parser.command('calc')
      .describe('calculate statistics about the features in a layer')
      .example('Calculate the total area of a polygon layer\n' +
        '$ mapshaper polygons.shp -calc \'sum($.area)\'')
      .example('Count census blocks in NY with zero population\n' +
        '$ mapshaper ny-census-blocks.shp -calc \'count()\' where=\'POPULATION == 0\'')
      .validate(validateExpressionOpt)
      .option('expression', {
        DEFAULT: true,
        describe: 'functions: sum() average() median() max() min() count()'
      })
      .option('where', whereOpt)
      .option('target', targetOpt);

    parser.command('colors')
      .describe('print list of color scheme names');

    parser.command('encodings')
      .describe('print list of supported text encodings (for .dbf import)');

    parser.command('help')
      .alias('h')
      .describe('print help; takes optional command name')
      .option('command', {
        DEFAULT: true,
        describe: 'view detailed information about a command'
      });

    parser.command('info')
      .describe('print information about data layers')
      .option('target', targetOpt);

    parser.command('inspect')
      .describe('print information about a feature')
      .option('expression', {
        DEFAULT: true,
        describe: 'boolean JS expression for selecting a feature'
      })
      .option('target', targetOpt)
      .validate(validateExpressionOpt);

    parser.command('projections')
      .describe('print list of supported projections');

    parser.command('quiet')
      .describe('inhibit console messages');

    parser.command('verbose')
      .describe('print verbose processing messages');

    parser.command('version')
      .alias('v')
      .describe('print mapshaper version');

    parser.command('debug');

    return parser;
  }

  // DBF format references:
  // http://www.dbf2002.com/dbf-file-format.html
  // http://www.digitalpreservation.gov/formats/fdd/fdd000325.shtml
  // http://www.clicketyclick.dk/databases/xbase/format/index.html
  // http://www.clicketyclick.dk/databases/xbase/format/data_types.html

  // source: http://webhelp.esri.com/arcpad/8.0/referenceguide/index.htm#locales/task_code.htm
  var languageIds = [0x01,'437',0x02,'850',0x03,'1252',0x08,'865',0x09,'437',0x0A,'850',0x0B,'437',0x0D,'437',0x0E,'850',0x0F,'437',0x10,'850',0x11,'437',0x12,'850',0x13,'932',0x14,'850',0x15,'437',0x16,'850',0x17,'865',0x18,'437',0x19,'437',0x1A,'850',0x1B,'437',0x1C,'863',0x1D,'850',0x1F,'852',0x22,'852',0x23,'852',0x24,'860',0x25,'850',0x26,'866',0x37,'850',0x40,'852',0x4D,'936',0x4E,'949',0x4F,'950',0x50,'874',0x57,'1252',0x58,'1252',0x59,'1252',0x64,'852',0x65,'866',0x66,'865',0x67,'861',0x6A,'737',0x6B,'857',0x6C,'863',0x78,'950',0x79,'949',0x7A,'936',0x7B,'932',0x7C,'874',0x86,'737',0x87,'852',0x88,'857',0xC8,'1250',0xC9,'1251',0xCA,'1254',0xCB,'1253',0xCC,'1257'];

  // Language & Language family names for some code pages
  var encodingNames = {
    '932': "Japanese",
    '936': "Simplified Chinese",
    '950': "Traditional Chinese",
    '1252': "Western European",
    '949': "Korean",
    '874': "Thai",
    '1250': "Eastern European",
    '1251': "Russian",
    '1254': "Turkish",
    '1253': "Greek",
    '1257': "Baltic"
  };

  var ENCODING_PROMPT =
    "To avoid corrupted text, re-import using the \"encoding=\" option.\n" +
    "To see a list of supported encodings, run the \"encodings\" command.";

  function lookupCodePage(lid) {
    var i = languageIds.indexOf(lid);
    return i == -1 ? null : languageIds[i+1];
  }

  // function readAsciiString(bin, size) {
  //   var require7bit = true;
  //   var str = bin.readCString(size, require7bit);
  //   if (str === null) {
  //     stop("DBF file contains non-ascii text.\n" + ENCODING_PROMPT);
  //   }
  //   return utils.trim(str);
  // }

  function readStringBytes(bin, size, buf) {
    var start = bin.position();
    var count = 0, c;
    for (var i=0; i<size; i++) {
      c = bin.readUint8();
      // treating 0 as C-style string terminator (observed in-the-wild)
      // TODO: in some encodings (e.g. utf-16) the 0-byte occurs in other
      //   characters than the NULL character (ascii 0). The following code
      //   should be changed to support non-ascii-compatible encodings
      if (c === 0) break;
      if (count > 0 || c != 32) { // ignore leading spaces (e.g. DBF numbers)
        buf[count++] = c;
      }
    }
    // ignore trailing spaces (DBF string fields are typically r-padded w/ spaces)
    while (count > 0 && buf[count-1] == 32) {
      count--;
    }
    bin.position(start + size);
    return count;
  }


  function getStringReader(arg) {
    var encoding = arg || 'ascii';
    var slug = standardizeEncodingName(encoding);
    var buf = utils.createBuffer(256);
    var inNode = typeof module == 'object';

    // optimization -- use (fast) native Node conversion if available
    if (inNode && (slug == 'utf8' || slug == 'ascii')) {
      return function(bin, size) {
        var n = readStringBytes(bin, size, buf);
        return buf.toString(slug, 0, n);
      };
    }

    return function readEncodedString(bin, size) {
      var n = readStringBytes(bin, size, buf),
          str = '', i, c;
      // optimization: fall back to text decoder only if string contains non-ascii bytes
      // (data files of any encoding typically contain mostly ascii fields)
      // TODO: verify this assumption - some supported encodings may not be ascii-compatible
      for (i=0; i<n; i++) {
        c = buf[i];
        if (c > 127) {
          return bufferToString(buf, encoding, 0, n);
        }
        str += String.fromCharCode(c);
      }
      return str;
    };
  }

  function bufferContainsHighBit(buf, n) {
    for (var i=0; i<n; i++) {
      if (buf[i] >= 128) return true;
    }
    return false;
  }

  function getNumberReader() {
    var read = getStringReader('ascii');
    return function readNumber(bin, size) {
      var str = read(bin, size);
      var val;
      if (str.indexOf(',') >= 0) {
        str = str.replace(',', '.'); // handle comma decimal separator
      }
      val = parseFloat(str);
      return isNaN(val) ? null : val;
    };
  }

  function readInt(bin, size) {
    return bin.readInt32();
  }

  function readBool(bin, size) {
    var c = bin.readCString(size),
        val = null;
    if (/[ty]/i.test(c)) val = true;
    else if (/[fn]/i.test(c)) val = false;
    return val;
  }

  function readDate(bin, size) {
    var str = bin.readCString(size),
        yr = str.substr(0, 4),
        mo = str.substr(4, 2),
        day = str.substr(6, 2);
    return new Date(Date.UTC(+yr, +mo - 1, +day));
  }

  // cf. http://code.google.com/p/stringencoding/
  //
  // @src is a Buffer or ArrayBuffer or filename
  //
  function DbfReader(src, encodingArg) {
    if (utils.isString(src)) {
      error("[DbfReader] Expected a buffer, not a string");
    }
    var bin = new BinArray(src);
    var header = readHeader(bin);

    // encoding and fields are set on first access
    var fields;
    var encoding;

    this.size = function() {return header.recordCount;};

    this.readRow = function(i) {
      // create record reader on-the-fly
      // (delays encoding detection until we need to read data)
      return getRecordReader()(i);
    };

    this.getFields = getFieldNames;

    this.getBuffer = function() {return bin.buffer();};

    this.deleteField = function(f) {
      prepareToRead();
      fields = fields.filter(function(field) {
        return field.name != f;
      });
    };

    this.readRows = function() {
      var reader = getRecordReader();
      var data = [];
      for (var r=0, n=this.size(); r<n; r++) {
        data.push(reader(r));
      }
      return data;
    };

    // Prepare to read from table:
    // * determine encoding
    // * convert encoded field names to strings
    //   (DBF standard is ascii names, but ArcGIS etc. support encoded names)
    //
    function prepareToRead() {
      if (fields) return; // already initialized
      var headerEncoding = 'ascii';
      initEncoding();
      if (getNonAsciiHeaders().length > 0) {
        headerEncoding = getEncoding();
      }
      fields = header.fields.map(function(f) {
        var copy = utils.extend({}, f);
        copy.name = decodeString(f.namebuf, headerEncoding);
        return copy;
      });
      // Uniqify header names
      getUniqFieldNames(utils.pluck(fields, 'name')).forEach(function(name2, i) {
        fields[i].name = name2;
      });
    }

    function readHeader(bin) {
      bin.position(0).littleEndian();
      var header = {
        version: bin.readInt8(),
        updateYear: bin.readUint8(),
        updateMonth: bin.readUint8(),
        updateDay: bin.readUint8(),
        recordCount: bin.readUint32(),
        dataOffset: bin.readUint16(),
        recordSize: bin.readUint16(),
        incompleteTransaction: bin.skipBytes(2).readUint8(),
        encrypted: bin.readUint8(),
        mdx: bin.skipBytes(12).readUint8(),
        ldid: bin.readUint8()
      };
      var colOffs = 1; // first column starts on second byte of record
      var field;
      bin.skipBytes(2);
      header.fields = [];

      // Detect header terminator (LF is standard, CR has been seen in the wild)
      while (bin.peek() != 0x0D && bin.peek() != 0x0A && bin.position() < header.dataOffset - 1) {
        field = readFieldHeader(bin);
        field.columnOffset = colOffs;
        header.fields.push(field);
        colOffs += field.size;
      }
      if (colOffs != header.recordSize) {
        error("Record length mismatch; header:", header.recordSize, "detected:", colOffs);
      }
      if (bin.peek() != 0x0D) {
        message('Found a non-standard DBF header terminator (' + bin.peek() + '). DBF file may be corrupted.');
      }

      return header;
    }

    function readFieldHeader(bin) {
      var buf = utils.createBuffer(11);
      var chars = readStringBytes(bin, 11, buf);
      return {
        // name: bin.readCString(11),
        namebuf: utils.createBuffer(buf.slice(0, chars)),
        type: String.fromCharCode(bin.readUint8()),
        address: bin.readUint32(),
        size: bin.readUint8(),
        decimals: bin.readUint8(),
        id: bin.skipBytes(2).readUint8(),
        position: bin.skipBytes(2).readUint8(),
        indexFlag: bin.skipBytes(7).readUint8()
      };
    }

    function getFieldNames() {
      prepareToRead();
      return utils.pluck(fields, 'name');
    }

    function getRowOffset(r) {
      return header.dataOffset + header.recordSize * r;
    }

    function initEncoding() {
      encoding = encodingArg || findStringEncoding();
      if (!encoding) {
        // fall back to utf8 if detection fails (so GUI can continue without further errors)
        encoding = 'utf8';
        stop("Unable to auto-detect the text encoding of the DBF file.\n" + ENCODING_PROMPT);
      }
    }

    function getEncoding() {
      if (!encoding) initEncoding();
      return encoding;
    }

    // Create new record objects using object literal syntax
    // (Much faster in v8 and other engines than assigning a series of properties
    //  to an object)
    function getRecordConstructor() {
      var args = getFieldNames().map(function(name, i) {
            return JSON.stringify(name) + ': arguments[' + i + ']';
          });
      return new Function('return {' + args.join(',') + '};');
    }

    function findEofPos(bin) {
      var pos = bin.size() - 1;
      if (bin.peek(pos) != 0x1A) { // last byte may or may not be EOF
        pos++;
      }
      return pos;
    }

    function getRecordReader() {
      prepareToRead();
      var readers = fields.map(getFieldReader),
          eofOffs = findEofPos(bin),
          create = getRecordConstructor(),
          values = [];

      return function readRow(r) {
        var offs = getRowOffset(r),
            fieldOffs, field;
        for (var c=0, cols=fields.length; c<cols; c++) {
          field = fields[c];
          fieldOffs = offs + field.columnOffset;
          if (fieldOffs + field.size > eofOffs) {
            stop('Invalid DBF file: encountered end-of-file while reading data');
          }
          bin.position(fieldOffs);
          values[c] = readers[c](bin, field.size);
        }
        return create.apply(null, values);
      };
    }

    // @f Field metadata from dbf header
    function getFieldReader(f) {
      var type = f.type,
          r = null;
      if (type == 'I') {
        r = readInt;
      } else if (type == 'F' || type == 'N') {
        r = getNumberReader();
      } else if (type == 'L') {
        r = readBool;
      } else if (type == 'D') {
        r = readDate;
      } else if (type == 'C') {
        r = getStringReader(getEncoding());
      } else {
        message("Field \"" + f.name + "\" has an unsupported type (" + f.type + ") -- converting to null values");
        r = function() {return null;};
      }
      return r;
    }

    function findStringEncoding() {
      var ldid = header.ldid,
          codepage = lookupCodePage(ldid),
          samples = getNonAsciiSamples(),
          only7bit = samples.length === 0,
          encoding, msg;

      // First, check the ldid (language driver id) (an obsolete way to specify which
      // codepage to use for text encoding.)
      // ArcGIS up to v.10.1 sets ldid and encoding based on the 'locale' of the
      // user's Windows system :P
      //
      if (codepage && ldid != 87) {
        // if 8-bit data is found and codepage is detected, use the codepage,
        // except ldid 87, which some GIS software uses regardless of encoding.
        encoding = codepage;
      } else if (only7bit) {
        // Text with no 8-bit chars should be compatible with 7-bit ascii
        // (Most encodings are supersets of ascii)
        encoding = 'ascii';
      }

      // As a last resort, try to guess the encoding:
      if (!encoding) {
        encoding = detectEncoding(samples);
      }

      // Show a sample of decoded text if non-ascii-range text has been found
      if (encoding && samples.length > 0) {
        msg = decodeSamples(encoding, samples);
        msg = formatStringsAsGrid(msg.split('\n'));
        msg = "\nSample text containing non-ascii characters:" + (msg.length > 60 ? '\n' : '') + msg;
        msg = "Detected DBF text encoding: " + encoding + (encoding in encodingNames ? " (" + encodingNames[encoding] + ")" : "") + msg;
        message(msg);
      }
      return encoding;
    }

    function getNonAsciiHeaders() {
      var arr = [];
      header.fields.forEach(function(f) {
        if (bufferContainsHighBit(f.namebuf, f.namebuf.length)) {
          arr.push(f.namebuf);
        }
      });
      return arr;
    }

    // Return an array of buffers containing text samples
    // with at least one byte outside the 7-bit ascii range.
    function getNonAsciiSamples() {
      var samples = [];
      var stringFields = header.fields.filter(function(f) {
        return f.type == 'C';
      });
      var cols = stringFields.length;
      // don't scan all the rows in large files (slow)
      var rows = Math.min(header.recordCount, 10000);
      var maxSamples = 50;
      var buf = utils.createBuffer(256);
      var index = {};
      var f, chars, sample, hash;
      // include non-ascii field names, if any
      samples = getNonAsciiHeaders();
      for (var r=0; r<rows; r++) {
        for (var c=0; c<cols; c++) {
          if (samples.length >= maxSamples) break;
          f = stringFields[c];
          bin.position(getRowOffset(r) + f.columnOffset);
          chars = readStringBytes(bin, f.size, buf);
          if (chars > 0 && bufferContainsHighBit(buf, chars)) {
            sample = utils.createBuffer(buf.slice(0, chars)); //
            hash = sample.toString('hex');
            if (hash in index === false) { // avoid duplicate samples
              index[hash] = true;
              samples.push(sample);
            }
          }
        }
      }
      return samples;
    }
  }

  function importDbfTable(buf, o) {
    var opts = o || {};
    return new ShapefileTable(buf, opts.encoding);
  }

  // Implements the DataTable api for DBF file data.
  // We avoid touching the raw DBF field data if possible. This way, we don't need
  // to parse the DBF at all in common cases, like importing a Shapefile, editing
  // just the shapes and exporting in Shapefile format.
  // TODO: consider accepting just the filename, so buffer doesn't consume memory needlessly.
  //
  function ShapefileTable(buf, encoding) {
    var reader = new DbfReader(buf, encoding),
        altered = false,
        table;

    function getTable() {
      if (!table) {
        // export DBF records on first table access
        table = new DataTable(reader.readRows());
        reader = null;
        buf = null; // null out references to DBF data for g.c.
      }
      return table;
    }

    this.exportAsDbf = function(opts) {
      // export original dbf bytes if possible, for performance
      var useOriginal = !!reader && !altered && !opts.field_order && !opts.encoding;
      if (useOriginal) return reader.getBuffer();
      return Dbf.exportRecords(getTable().getRecords(), opts.encoding, opts.field_order);
    };

    this.getReadOnlyRecordAt = function(i) {
      return reader ? reader.readRow(i) : table.getReadOnlyRecordAt(i);
    };

    this.deleteField = function(f) {
      if (table) {
        table.deleteField(f);
      } else {
        altered = true;
        reader.deleteField(f);
      }
    };

    this.getRecords = function() {
      return getTable().getRecords();
    };

    this.getFields = function() {
      return reader ? reader.getFields() : table.getFields();
    };

    this.isEmpty = function() {
      return reader ? this.size() === 0 : table.isEmpty();
    };

    this.size = function() {
      return reader ? reader.size() : table.size();
    };
  }

  Object.assign(ShapefileTable.prototype, DataTable.prototype);

  var DbfImport = /*#__PURE__*/Object.freeze({
    __proto__: null,
    importDbfTable: importDbfTable,
    ShapefileTable: ShapefileTable
  });

  function translateShapefileType(shpType) {
    if ([ShpType.POLYGON, ShpType.POLYGONM, ShpType.POLYGONZ].includes(shpType)) {
      return 'polygon';
    } else if ([ShpType.POLYLINE, ShpType.POLYLINEM, ShpType.POLYLINEZ].includes(shpType)) {
      return 'polyline';
    } else if ([ShpType.POINT, ShpType.POINTM, ShpType.POINTZ,
        ShpType.MULTIPOINT, ShpType.MULTIPOINTM, ShpType.MULTIPOINTZ].includes(shpType)) {
      return 'point';
    }
    return null;
  }

  function isSupportedShapefileType(t) {
    return [0,1,3,5,8,11,13,15,18,21,23,25,28].includes(t);
  }

  var ShpCommon = /*#__PURE__*/Object.freeze({
    __proto__: null,
    translateShapefileType: translateShapefileType,
    isSupportedShapefileType: isSupportedShapefileType
  });

  function getNullRecord(id) {
    return {
      id: id,
      isNull: true,
      pointCount: 0,
      partCount: 0,
      byteLength: 12
    };
  }

  // Returns a constructor function for a shape record class with
  //   properties and methods for reading coordinate data.
  //
  // Record properties
  //   type, isNull, byteLength, pointCount, partCount (all types)
  //
  // Record methods
  //   read(), readPoints() (all types)
  //   readBounds(), readCoords()  (all but single point types)
  //   readPartSizes() (polygon and polyline types)
  //   readZBounds(), readZ() (Z types except POINTZ)
  //   readMBounds(), readM(), hasM() (M and Z types, except POINT[MZ])
  //
  function ShpRecordClass(type) {
    var hasBounds = ShpType.hasBounds(type),
        hasParts = ShpType.isMultiPartType(type),
        hasZ = ShpType.isZType(type),
        hasM = ShpType.isMType(type),
        singlePoint = !hasBounds,
        mzRangeBytes = singlePoint ? 0 : 16,
        constructor, proto;

    // @bin is a BinArray set to the first data byte of a shape record
    constructor = function ShapeRecord(bin, bytes) {
      var pos = bin.position();
      this.id = bin.bigEndian().readUint32();
      this.type = bin.littleEndian().skipBytes(4).readUint32();
      if (this.type === 0 || type === 0) {
        return getNullRecord(this.id);
      }
      if (bytes > 0 !== true || (this.type != type && this.type !== 0)) {
        error("Unable to read a shape -- .shp file may be corrupted");
      }
      this.byteLength = bytes; // bin.readUint32() * 2 + 8; // bytes in content section + 8 header bytes
      if (singlePoint) {
        this.pointCount = 1;
        this.partCount = 1;
      } else {
        bin.skipBytes(32); // skip bbox
        this.partCount = hasParts ? bin.readUint32() : 1;
        this.pointCount = bin.readUint32();
      }
      this._data = function() {
        return bin.position(pos);
      };
    };

    // base prototype has methods shared by all Shapefile types except NULL type
    // (Type-specific methods are mixed in below)
    var baseProto = {
      // return offset of [x, y] point data in the record
      _xypos: function() {
        var offs = 12; // skip header & record type
        if (!singlePoint) offs += 4; // skip point count
        if (hasBounds) offs += 32;
        if (hasParts) offs += 4 * this.partCount + 4; // skip part count & index
        return offs;
      },

      readCoords: function() {
        if (this.pointCount === 0) return null;
        var partSizes = this.readPartSizes(),
            xy = this._data().skipBytes(this._xypos());

        return partSizes.map(function(pointCount) {
          return xy.readFloat64Array(pointCount * 2);
        });
      },

      readXY: function() {
        if (this.pointCount === 0) return new Float64Array(0);
        return this._data().skipBytes(this._xypos()).readFloat64Array(this.pointCount * 2);
      },

      readPoints: function() {
        var xy = this.readXY(),
            zz = hasZ ? this.readZ() : null,
            mm = hasM && this.hasM() ? this.readM() : null,
            points = [], p;

        for (var i=0, n=xy.length / 2; i<n; i++) {
          p = [xy[i*2], xy[i*2+1]];
          if (zz) p.push(zz[i]);
          if (mm) p.push(mm[i]);
          points.push(p);
        }
        return points;
      },

      // Return an array of point counts in each part
      // Parts containing zero points are skipped (Shapefiles with zero-point
      // parts are out-of-spec but exist in the wild).
      readPartSizes: function() {
        var sizes = [];
        var partLen, startId, bin;
        if (this.pointCount === 0) {
          // no parts
        } else if (this.partCount == 1) {
          // single-part type or multi-part type with one part
          sizes.push(this.pointCount);
        } else {
          // more than one part
          startId = 0;
          bin = this._data().skipBytes(56); // skip to second entry in part index
          for (var i=0, n=this.partCount; i<n; i++) {
            partLen = (i < n - 1 ? bin.readUint32() : this.pointCount) - startId;
            if (partLen > 0) {
              sizes.push(partLen);
              startId += partLen;
            }
          }
        }
        return sizes;
      }
    };

    var singlePointProto = {
      read: function() {
        var n = 2;
        if (hasZ) n++;
        if (this.hasM()) n++;
        return this._data().skipBytes(12).readFloat64Array(n);
      },

      stream: function(sink) {
        var src = this._data().skipBytes(12);
        sink.addPoint(src.readFloat64(), src.readFloat64());
        sink.endPath();
      }
    };

    var multiCoordProto = {
      readBounds: function() {
        return this._data().skipBytes(12).readFloat64Array(4);
      },

      stream: function(sink) {
        var sizes = this.readPartSizes(),
            xy = this.readXY(),
            i = 0, j = 0, n;
        while (i < sizes.length) {
          n = sizes[i];
          while (n-- > 0) {
            sink.addPoint(xy[j++], xy[j++]);
          }
          sink.endPath();
          i++;
        }
        if (xy.length != j) error('Counting error');
      },

      // TODO: consider switching to this simpler functino
      stream2: function(sink) {
        var sizes = this.readPartSizes(),
            bin = this._data().skipBytes(this._xypos()),
            i = 0, n;
        while (i < sizes.length) {
          n = sizes[i];
          while (n-- > 0) {
            sink.addPoint(bin.readFloat64(), bin.readFloat64());
          }
          sink.endPath();
          i++;
        }
      },

      read: function() {
        var parts = [],
            sizes = this.readPartSizes(),
            points = this.readPoints();
        for (var i=0, n = sizes.length - 1; i<n; i++) {
          parts.push(points.splice(0, sizes[i]));
        }
        parts.push(points);
        return parts;
      }
    };

    var mProto = {
      _mpos: function() {
        var pos = this._xypos() + this.pointCount * 16;
        if (hasZ) {
          pos += this.pointCount * 8 + mzRangeBytes;
        }
        return pos;
      },

      readMBounds: function() {
        return this.hasM() ? this._data().skipBytes(this._mpos()).readFloat64Array(2) : null;
      },

      // TODO: group into parts, like readCoords()
      readM: function() {
        return this.hasM() ? this._data().skipBytes(this._mpos() + mzRangeBytes).readFloat64Array(this.pointCount) : null;
      },

      // Test if this record contains M data
      // (according to the Shapefile spec, M data is optional in a record)
      //
      hasM: function() {
        var bytesWithoutM = this._mpos(),
            bytesWithM = bytesWithoutM + this.pointCount * 8 + mzRangeBytes;
        if (this.byteLength == bytesWithoutM) {
          return false;
        } else if (this.byteLength == bytesWithM) {
          return true;
        } else {
          error("#hasM() Counting error");
        }
      }
    };

    var zProto = {
      _zpos: function() {
        return this._xypos() + this.pointCount * 16;
      },

      readZBounds: function() {
        return this._data().skipBytes(this._zpos()).readFloat64Array(2);
      },

      // TODO: group into parts, like readCoords()
      readZ: function() {
        return this._data().skipBytes(this._zpos() + mzRangeBytes).readFloat64Array(this.pointCount);
      }
    };

    if (type === 0) {
      proto = {};
    } else if (singlePoint) {
      proto = Object.assign(baseProto, singlePointProto);
    } else {
      proto = Object.assign(baseProto, multiCoordProto);
    }
    if (hasZ) Object.assign(proto, zProto);
    if (hasM) Object.assign(proto, mProto);

    constructor.prototype = proto;
    proto.constructor = constructor;
    return constructor;
  }

  // Read data from a .shp file
  // @src is an ArrayBuffer, Node.js Buffer or filename
  //
  //    // Example: iterating using #nextShape()
  //    var reader = new ShpReader(buf), s;
  //    while (s = reader.nextShape()) {
  //      // process the raw coordinate data yourself...
  //      var coords = s.readCoords(); // [[x,y,x,y,...], ...] Array of parts
  //      var zdata = s.readZ();  // [z,z,...]
  //      var mdata = s.readM();  // [m,m,...] or null
  //      // .. or read the shape into nested arrays
  //      var data = s.read();
  //    }
  //
  //    // Example: reading records using a callback
  //    var reader = new ShpReader(buf);
  //    reader.forEachShape(function(s) {
  //      var data = s.read();
  //    });
  //
  function ShpReader(shpSrc, shxSrc) {
    if (this instanceof ShpReader === false) {
      return new ShpReader(shpSrc, shxSrc);
    }
    var shpFile = utils.isString(shpSrc) ? new FileReader(shpSrc) : new BufferReader(shpSrc);
    var header = parseHeader(shpFile.readToBinArray(0, 100));
    var shpType = header.type;
    var shpOffset = 100; // used when reading .shp without .shx
    var recordCount = 0;
    var badRecordNumberCount = 0;
    var RecordClass = new ShpRecordClass(shpType);
    var shxBin, shxFile;

    if (shxSrc) {
      shxFile = utils.isString(shxSrc) ? new FileReader(shxSrc) : new BufferReader(shxSrc);
      shxBin = shxFile.readToBinArray(0, shxFile.size()).bigEndian();
    }

    this.header = function() {
      return header;
    };

    // Callback interface: for each record in a .shp file, pass a
    //   record object to a callback function
    //
    this.forEachShape = function(callback) {
      var shape = this.nextShape();
      while (shape) {
        callback(shape);
        shape = this.nextShape();
      }
    };

    // Iterator interface for reading shape records
    this.nextShape = function() {
      var shape;
      if (!shpFile) {
        error('Tried to read from a used ShpReader');
        // return null; // this reader was already used
      }
      shape = readNextShape(recordCount);
      if (!shape) {
        done();
        return null;
      }
      recordCount++;
      return shape;
    };

    // Returns a shape record or null if no more shapes can be read
    // i: Expected 0-based index of the next record
    //
    function readNextShape(i) {
      return shxBin ?
        readIndexedShape(shpFile, shxBin, i) :
        readNonIndexedShape(shpFile, shpOffset, i);
    }

    function done() {
      shpFile.close();
      shpFile = shxFile = shxBin = null;
      if (badRecordNumberCount > 0) {
        message(`Warning: ${badRecordNumberCount}/${recordCount} features have non-standard record numbers in the .shp file.`);
      }
    }

    function parseHeader(bin) {
      var header = {
        signature: bin.bigEndian().readUint32(),
        byteLength: bin.skipBytes(20).readUint32() * 2,
        version: bin.littleEndian().readUint32(),
        type: bin.readUint32(),
        bounds: bin.readFloat64Array(4), // xmin, ymin, xmax, ymax
        zbounds: bin.readFloat64Array(2),
        mbounds: bin.readFloat64Array(2)
      };

      if (header.signature != 9994) {
        error("Not a valid .shp file");
      }

      if (!isSupportedShapefileType(header.type)) {
        error("Unsupported .shp type:", header.type);
      }

      if (header.byteLength != shpFile.size()) {
        error("File size of .shp doesn't match size in header");
      }

      return header;
    }


    function readShapeAtOffset(shpFile, offset) {
      var fileSize = shpFile.size();
      if (offset + 12 > fileSize) return null; // reached end-of-file
      var bin = shpFile.readToBinArray(offset, 12);
      var recordId = bin.bigEndian().readUint32();
      // record size is bytes in content section + 8 header bytes
      var recordSize = bin.readUint32() * 2 + 8;
      var recordType = bin.littleEndian().readUint32();
      var goodSize = offset + recordSize <= fileSize && recordSize >= 12;
      var goodType = recordType === 0 || recordType == shpType;
      if (!goodSize || !goodType) {
        return null;
      }
      bin = shpFile.readToBinArray(offset, recordSize);
      return new RecordClass(bin, recordSize);
    }

    function readIndexedShape(shpFile, shxBin, i) {
      if (shxBin.size() <= 100 + i * 8) return null; // done
      shxBin.position(100 + i * 8);
      var expectedId = i + 1;
      var offset = shxBin.readUint32() * 2;
      var recLen = shxBin.readUint32() * 2; // TODO: match this to recLen in .shp
      var shape = readShapeAtOffset(shpFile, offset);
      if (!shape) {
        stop('Index of Shapefile record', expectedId, 'in the .shx file is invalid.');
      }
      if (shape.id != expectedId) {
        badRecordNumberCount++;
        verbose(`Warning: A feature has a different record number in .shx (${expectedId}) and .shp (${shape.id}).`);
      }
      // TODO: consider printing verbose message if a .shp file contains garbage bytes
      // example files:
      // ne_10m_admin_0_boundary_lines_land.shp
      // ne_110m_admin_0_scale_rank.shp
      return shape;
    }

    // The Shapefile specification does not require records to be densely packed or
    // in consecutive sequence in the .shp file. This is a problem when the .shx
    // index file is not present.
    //
    // Here, we try to scan past any invalid content to find the next record.
    // Records are required to be in sequential order.
    //
    function readNonIndexedShape(shpFile, start, i) {
      var expectedId = i + 1, // Shapefile ids are 1-based
          offset = start,
          fileSize = shpFile.size(),
          shape = null,
          bin, recordId, recordType, isValidType;
      while (offset + 12 <= fileSize) {
        bin = shpFile.readToBinArray(offset, 12);
        recordId = bin.bigEndian().readUint32();
        recordType = bin.littleEndian().skipBytes(4).readUint32();
        isValidType = recordType == shpType || recordType === 0;
        if (!isValidType || recordId != expectedId && recordType === 0) {
          offset += 4; // keep scanning -- try next integer position
          continue;
        }
        shape = readShapeAtOffset(shpFile, offset);
        if (!shape) break; // probably ran into end of file
        shpOffset = offset + shape.byteLength; // update
        if (recordId == expectedId) break; // found an apparently valid shape
        if (recordId < expectedId) {
          message("Found a Shapefile record with the same id as a previous record (" + shape.id + ") -- skipping.");
          offset += shape.byteLength;
        } else {
          stop("Shapefile contains an out-of-sequence record. Possible data corruption -- bailing.");
        }
      }
      if (shape && offset > start) {
        verbose("Skipped over " + (offset - start) + " non-data bytes in the .shp file.");
      }
      return shape;
    }
  }

  ShpReader.prototype.type = function() {
    return this.header().type;
  };

  // Apply snapping, remove duplicate coords and clean up defective paths in a dataset
  // Assumes that any CRS info has been added to the dataset
  // @opts: import options
  function cleanPathsAfterImport(dataset, opts) {
    var arcs = dataset.arcs;
    var snapDist;
    if (opts.snap || opts.auto_snap || opts.snap_interval) { // auto_snap is older name
      if (opts.snap_interval) {
        snapDist = convertIntervalParam(opts.snap_interval, getDatasetCRS(dataset));
      }
      if (arcs) {
        snapCoords(arcs, snapDist);
      }
    }
    dataset.layers.forEach(function(lyr) {
      if (layerHasPaths(lyr)) {
        cleanShapes(lyr.shapes, arcs, lyr.geometry_type);
      }
    });
  }

  function pointHasValidCoords(p) {
    // The Shapefile spec states that "measures" less then -1e38 indicate null values
    // This should not apply to coordinate data, but in-the-wild Shapefiles have been
    // seen with large negative values indicating null coordinates.
    // This test catches these and also NaNs, but does not detect other kinds of
    // invalid coords
    return p[0] > -1e38 && p[1] > -1e38;
  }

  // Accumulates points in buffers until #endPath() is called
  // @drain callback: function(xarr, yarr, size) {}
  //
  function PathImportStream(drain) {
    var buflen = 10000,
        xx = new Float64Array(buflen),
        yy = new Float64Array(buflen),
        i = 0;

    this.endPath = function() {
      drain(xx, yy, i);
      i = 0;
    };

    this.addPoint = function(x, y) {
      if (i >= buflen) {
        buflen = Math.ceil(buflen * 1.3);
        xx = utils.extendBuffer(xx, buflen);
        yy = utils.extendBuffer(yy, buflen);
      }
      xx[i] = x;
      yy[i] = y;
      i++;
    };
  }

  // Import path data from a non-topological source (Shapefile, GeoJSON, etc)
  // in preparation for identifying topology.
  // @opts.reserved_points -- estimate of points in dataset, for pre-allocating buffers
  //
  function PathImporter(opts) {
    var bufSize = opts.reserved_points > 0 ? opts.reserved_points : 20000,
        xx = new Float64Array(bufSize),
        yy = new Float64Array(bufSize),
        shapes = [],
        properties = [],
        nn = [],
        types = [],
        collectionType = opts.type || null, // possible values: polygon, polyline, point
        round = null,
        pathId = -1,
        shapeId = -1,
        pointId = 0,
        dupeCount = 0,
        openRingCount = 0;

    if (opts.precision) {
      round = getRoundingFunction(opts.precision);
    }

    // mix in #addPoint() and #endPath() methods
    utils.extend(this, new PathImportStream(importPathCoords));

    this.startShape = function(d) {
      shapes[++shapeId] = null;
      if (d) properties[shapeId] = d;
    };

    this.importLine = function(points) {
      if (points.length < 2) {
        verbose("Skipping a defective line");
        return;
      }
      setShapeType('polyline');
      this.importPath(points);
    };

    this.importPoints = function(points) {
      setShapeType('point');
      points = points.filter(pointHasValidCoords);
      if (round) {
        points.forEach(function(p) {
          p[0] = round(p[0]);
          p[1] = round(p[1]);
        });
      }
      points.forEach(appendToShape);
    };

    this.importRing = function(points, isHole) {
      var area = geom.getPlanarPathArea2(points);
      if (!area || points.length < 4) {
        verbose("Skipping a defective ring");
        return;
      }
      setShapeType('polygon');
      if (isHole === true && area > 0 || isHole === false && area < 0) {
        // GeoJSON rings may be either direction -- no point in logging reversal
        // verbose("Reversing", isHole ? "a CW hole" : "a CCW ring");
        points.reverse();
      }
      this.importPath(points);
    };

    // Import an array of [x, y] Points
    this.importPath = function importPath(points) {
      var p;
      for (var i=0, n=points.length; i<n; i++) {
        p = points[i];
        this.addPoint(p[0], p[1]);
      }
      this.endPath();
    };

    // Return imported dataset
    // Apply any requested snapping and rounding
    // Remove duplicate points, check for ring inversions
    //
    this.done = function() {
      var arcs;
      var layers;
      var lyr = {name: ''};
      var snapDist;

      if (dupeCount > 0) {
        verbose(utils.format("Removed %,d duplicate point%s", dupeCount, utils.pluralSuffix(dupeCount)));
      }
      if (openRingCount > 0) {
        message(utils.format("Closed %,d open polygon ring%s", openRingCount, utils.pluralSuffix(openRingCount)));
      }
      if (pointId > 0) {
         if (pointId < xx.length) {
          xx = xx.subarray(0, pointId);
          yy = yy.subarray(0, pointId);
        }
        arcs = new ArcCollection(nn, xx, yy);

        //if (opts.snap || opts.auto_snap || opts.snap_interval) { // auto_snap is older name
        //  internal.snapCoords(arcs, opts.snap_interval);
        //}
      }

      if (collectionType == 'mixed') {
        layers = divideFeaturesByType(shapes, properties, types);

      } else {
        lyr = {geometry_type: collectionType};
        if (collectionType) {
          lyr.shapes = shapes;
        }
        if (properties.length > 0) {
          lyr.data = new DataTable(properties);
        }
        layers = [lyr];
      }

      layers.forEach(function(lyr) {
        //if (internal.layerHasPaths(lyr)) {
          //internal.cleanShapes(lyr.shapes, arcs, lyr.geometry_type);
        //}
        if (lyr.data) {
          fixInconsistentFields(lyr.data.getRecords());
        }
      });

      return {
        arcs: arcs || null,
        info: {},
        layers: layers
      };
    };

    function setShapeType(t) {
      var currType = shapeId < types.length ? types[shapeId] : null;
      if (!currType) {
        types[shapeId] = t;
        if (!collectionType) {
          collectionType = t;
        } else if (t != collectionType) {
          collectionType = 'mixed';
        }
      } else if (currType != t) {
        stop("Unable to import mixed-geometry features");
      }
    }

    function checkBuffers(needed) {
      if (needed > xx.length) {
        var newLen = Math.max(needed, Math.ceil(xx.length * 1.5));
        xx = utils.extendBuffer(xx, newLen, pointId);
        yy = utils.extendBuffer(yy, newLen, pointId);
      }
    }

    function appendToShape(part) {
      var currShape = shapes[shapeId] || (shapes[shapeId] = []);
      currShape.push(part);
    }

    function appendPath(n) {
      pathId++;
      nn[pathId] = n;
      appendToShape([pathId]);
    }

    function importPathCoords(xsrc, ysrc, n) {
      var count = 0;
      var x, y, prevX, prevY;
      checkBuffers(pointId + n);
      for (var i=0; i<n; i++) {
        x = xsrc[i];
        y = ysrc[i];
        if (round) {
          x = round(x);
          y = round(y);
        }
        if (i > 0 && x == prevX && y == prevY) {
          dupeCount++;
        } else {
          xx[pointId] = x;
          yy[pointId] = y;
          pointId++;
          count++;
        }
        prevY = y;
        prevX = x;
      }

      // check for open rings
      if (collectionType == 'polygon' && count > 0) {
        if (xsrc[0] != xsrc[n-1] || ysrc[0] != ysrc[n-1]) {
          checkBuffers(pointId + 1);
          xx[pointId] = xsrc[0];
          yy[pointId] = ysrc[0];
          openRingCount++;
          pointId++;
          count++;
        }
      }

      appendPath(count);
    }
  }

  var PathImport = /*#__PURE__*/Object.freeze({
    __proto__: null,
    cleanPathsAfterImport: cleanPathsAfterImport,
    pointHasValidCoords: pointHasValidCoords,
    PathImporter: PathImporter
  });

  // Read Shapefile data from a file, ArrayBuffer or Buffer
  // @shp, @shx: filename or buffer
  function importShp(shp, shx, opts) {
    var reader = new ShpReader(shp, shx),
        shpType = reader.type(),
        type = translateShapefileType(shpType),
        importOpts = utils.defaults({
          type: type,
          reserved_points: Math.round(reader.header().byteLength / 16)
        }, opts),
        importer = new PathImporter(importOpts);

    if (!isSupportedShapefileType(shpType)) {
      stop("Unsupported Shapefile type:", shpType);
    }
    if (ShpType.isZType(shpType)) {
      message("Warning: Shapefile Z data will be lost.");
    } else if (ShpType.isMType(shpType)) {
      message("Warning: Shapefile M data will be lost.");
    }

    // TODO: test cases: null shape; non-null shape with no valid parts
    reader.forEachShape(function(shp) {
      importer.startShape();
      if (shp.isNull) {
        // skip
      } else if (type == 'point') {
        importer.importPoints(shp.readPoints());
      } else {
        shp.stream(importer);
        // shp.stream2(importer);
      }
    });

    return importer.done();
  }

  var ShpImport = /*#__PURE__*/Object.freeze({
    __proto__: null,
    importShp: importShp
  });

  function importGeoJSON(src, optsArg) {
    var opts = optsArg || {};
    var supportedGeometries = Object.keys(GeoJSON.pathImporters),
        srcObj = utils.isString(src) ? JSON.parse(src) : src,
        importer = new GeoJSONParser(opts),
        srcCollection, dataset;

    // Convert single feature or geometry into a collection with one member
    if (srcObj.type == 'Feature') {
      srcCollection = {
        type: 'FeatureCollection',
        features: [srcObj]
      };
    } else if (supportedGeometries.includes(srcObj.type)) {
      srcCollection = {
        type: 'GeometryCollection',
        geometries: [srcObj]
      };
    } else {
      srcCollection = srcObj;
    }
    (srcCollection.features || srcCollection.geometries || []).forEach(importer.parseObject);
    dataset = importer.done();
    importCRS(dataset, srcObj); // TODO: remove this
    return dataset;
  }

  function GeoJSONParser(opts) {
    var idField = opts.id_field || GeoJSON.ID_FIELD,
        importer = new PathImporter(opts),
        dataset;

    this.parseObject = function(o) {
      var geom, rec;
      if (!o || !o.type) {
        // not standard GeoJSON -- importing as null record
        // (useful when parsing GeoJSON generated internally)
        geom = null;
      } else if (o.type == 'Feature') {
        geom = o.geometry;
        rec = o.properties || {};
        if ('id' in o) {
          rec[idField] = o.id;
        }
      } else {
        geom = o;
      }
      // TODO: improve so geometry_type option skips features instead of creating null geometries
      if (geom && geom.type == 'GeometryCollection') {
        GeoJSON.importComplexFeature(importer, geom, rec, opts);
      } else {
        GeoJSON.importSimpleFeature(importer, geom, rec, opts);
      }
    };

    this.done = function() {
      return importer.done();
    };
  }

  GeoJSON.importComplexFeature = function(importer, geom, rec, opts) {
    var types = divideGeometriesByType(geom.geometries || []);
    if (types.length === 0) {
      importer.startShape(rec); // import a feature with null geometry
      return;
    }
    types.forEach(function(geometries, i) {
      importer.startShape(copyRecord(rec));
      geometries.forEach(function(geom) {
        GeoJSON.importSimpleGeometry(importer, geom, opts);
      });
    });
  };

  function divideGeometriesByType(geometries, index) {
    index = index || {};
    geometries.forEach(function(geom) {
      if (!geom) return;
      var mtype = GeoJSON.translateGeoJSONType(geom.type);
      if (mtype) {
        if (mtype in index === false) {
          index[mtype] = [];
        }
        index[mtype].push(geom);
      } else if (geom.type == 'GeometryCollection') {
        divideGeometriesByType(geom.geometries || [], index);
      }
    });
    return Object.values(index);
  }

  GeoJSON.importSimpleFeature = function(importer, geom, rec, opts) {
    importer.startShape(rec);
    GeoJSON.importSimpleGeometry(importer, geom, opts);
  };

  GeoJSON.importSimpleGeometry = function(importer, geom, opts) {
    var type = geom ? geom.type : null;
    if (type === null) {
      // no geometry to import
    } else if (type in GeoJSON.pathImporters) {
      if (opts.geometry_type && opts.geometry_type != GeoJSON.translateGeoJSONType(type)) {
        // kludge to filter out all but one type of geometry
        return;
      }
      GeoJSON.pathImporters[type](geom.coordinates, importer);
    } else {
      verbose("Unsupported geometry type:", geom.type);
    }
  };


  // Functions for importing geometry coordinates using a PathImporter
  //
  GeoJSON.pathImporters = {
    LineString: function(coords, importer) {
      importer.importLine(coords);
    },
    MultiLineString: function(coords, importer) {
      for (var i=0; i<coords.length; i++) {
        GeoJSON.pathImporters.LineString(coords[i], importer);
      }
    },
    Polygon: function(coords, importer) {
      for (var i=0; i<coords.length; i++) {
        importer.importRing(coords[i], i > 0);
      }
    },
    MultiPolygon: function(coords, importer) {
      for (var i=0; i<coords.length; i++) {
        GeoJSON.pathImporters.Polygon(coords[i], importer);
      }
    },
    Point: function(coord, importer) {
      importer.importPoints([coord]);
    },
    MultiPoint: function(coords, importer) {
      importer.importPoints(coords);
    }
  };


  function importCRS(dataset, jsonObj) {
    if ('crs' in jsonObj) {
      dataset.info.input_geojson_crs = jsonObj.crs;
    }
  }

  var GeojsonImport = /*#__PURE__*/Object.freeze({
    __proto__: null,
    importGeoJSON: importGeoJSON,
    GeoJSONParser: GeoJSONParser,
    importCRS: importCRS
  });

  // Convert a TopoJSON topology into mapshaper's internal format
  // Side-effect: data in topology is modified
  //
  function importTopoJSON(topology, opts) {
    var dataset, arcs, layers;

    if (utils.isString(topology)) {
      topology = JSON.parse(topology);
    }

    if (topology.arcs && topology.arcs.length > 0) {
      // TODO: apply transform to ArcCollection, not input arcs
      if (topology.transform) {
        TopoJSON.decodeArcs(topology.arcs, topology.transform);
      }

      if (opts && opts.precision) {
        TopoJSON.roundCoords(topology.arcs, opts.precision);
      }

      arcs = new ArcCollection(topology.arcs);
    }

    layers = Object.keys(topology.objects).reduce(function(memo, name) {
      var layers = TopoJSON.importObject(topology.objects[name], arcs, opts),
          lyr;
      for (var i=0, n=layers.length; i<n; i++) {
        lyr = layers[i];
        lyr.name = name; // TODO: consider type-suffixes if different-typed layers
        memo.push(lyr);
      }
      return memo;
    }, []);

    layers.forEach(function(lyr) {
      if (layerHasPaths(lyr)) {
        // Cleaning here may be unnecessary
        // (cleanPathsAfterImport() is called in mapshaper-import.js)
        cleanShapes(lyr.shapes, arcs, lyr.geometry_type);
      }
      if (lyr.geometry_type == 'point' && topology.transform) {
        TopoJSON.decodePoints(lyr.shapes, topology.transform);
      }
      if (lyr.data) {
        fixInconsistentFields(lyr.data.getRecords());
      }
    });

    dataset = {
      layers: layers,
      arcs: arcs,
      info: {}
    };
    importCRS(dataset, topology);
    if (topology.metadata) {
      importMetadata(dataset, topology.metadata);
    }
    return dataset;
  }

  TopoJSON.decodePoints = function(shapes, transform) {
    forEachPoint(shapes, function(p) {
      p[0] = p[0] * transform.scale[0] + transform.translate[0];
      p[1] = p[1] * transform.scale[1] + transform.translate[1];
    });
  };

  TopoJSON.decodeArcs = function(arcs, transform) {
    var mx = transform.scale[0],
        my = transform.scale[1],
        bx = transform.translate[0],
        by = transform.translate[1];

    arcs.forEach(function(arc) {
      var prevX = 0,
          prevY = 0,
          xy, x, y;
      for (var i=0, len=arc.length; i<len; i++) {
        xy = arc[i];
        x = xy[0] + prevX;
        y = xy[1] + prevY;
        xy[0] = x * mx + bx;
        xy[1] = y * my + by;
        prevX = x;
        prevY = y;
      }
    });
  };

  // TODO: consider removing dupes...
  TopoJSON.roundCoords = function(arcs, precision) {
    var round = getRoundingFunction(precision),
        p;
    arcs.forEach(function(arc) {
      for (var i=0, len=arc.length; i<len; i++) {
        p = arc[i];
        p[0] = round(p[0]);
        p[1] = round(p[1]);
      }
    });
  };

  TopoJSON.importObject = function(obj, arcs, opts) {
    var importer = new TopoJSON.GeometryImporter(arcs, opts);
    var geometries = obj.type == 'GeometryCollection' ? obj.geometries : [obj];
    geometries.forEach(importer.addGeometryObject, importer);
    return importer.done();
  };

  //
  //
  TopoJSON.GeometryImporter = function(arcs, opts) {
    var idField = opts && opts.id_field || GeoJSON.ID_FIELD,
        properties = [],
        shapes = [], // topological ids
        types = [],
        dataNulls = 0,
        shapeNulls = 0,
        collectionType = null,
        shapeId;

    this.addGeometryObject = function(geom) {
      var rec = geom.properties || null;
      shapeId = shapes.length;
      shapes[shapeId] = null;
      if ('id' in geom) {
        rec = rec || {};
        rec[idField] = geom.id;
      }
      properties[shapeId] = rec;
      if (!rec) dataNulls++;
      if (geom.type) {
        this.addShape(geom);
      }
      if (shapes[shapeId] === null) {
        shapeNulls++;
      }
    };

    this.addShape = function(geom) {
      var curr = shapes[shapeId];
      var type = GeoJSON.translateGeoJSONType(geom.type);
      var shape, importer;
      if (geom.type == "GeometryCollection") {
        geom.geometries.forEach(this.addShape, this);
      } else if (type) {
        this.setGeometryType(type);
        shape = TopoJSON.shapeImporters[geom.type](geom, arcs);
        // TODO: better shape validation
        if (!shape || !shape.length) {
          // do nothing
        } else if (!Array.isArray(shape[0])) {
          stop("Invalid TopoJSON", geom.type, "geometry");
        } else {
          shapes[shapeId] = curr ? curr.concat(shape) : shape;
        }
      } else if (geom.type) {
        stop("Invalid TopoJSON geometry type:", geom.type);
      }
    };

    this.setGeometryType = function(type) {
      var currType = shapeId < types.length ? types[shapeId] : null;
      if (!currType) {
        types[shapeId] = type;
        this.updateCollectionType(type);
      } else if (currType != type) {
        stop("Unable to import mixed-type TopoJSON geometries");
      }
    };

    this.updateCollectionType = function(type) {
      if (!collectionType) {
        collectionType = type;
      } else if (type && collectionType != type) {
        collectionType = 'mixed';
      }
    };

    this.done = function() {
      var layers;
      if (collectionType == 'mixed') {
        layers = divideFeaturesByType(shapes, properties, types);
      } else {
        layers = [{
          geometry_type: collectionType,
          shapes : collectionType ? shapes : null,
          data: dataNulls < shapes.length ? new DataTable(properties) : null
        }];
      }
      return layers;
    };
  };

  // TODO: check that interior ring bboxes are contained in external ring
  // TODO: check that rings are closed
  TopoJSON.importPolygonArcs = function(rings, arcs) {
    var ring = rings[0],
        imported = null, area;
    if (!arcs) stop("Invalid TopoJSON file: missing arc data.");
    area = ring ? geom.getPlanarPathArea(ring, arcs) : null;
    if (!area) {
      return null;
    }
    if (area < 0) reversePath(ring);
    imported = [ring];
    for (var i=1; i<rings.length; i++) {
      ring = rings[i];
      area = geom.getPlanarPathArea(ring, arcs);
      if (!area) continue;
      if (area > 0) reversePath(ring);
      imported.push(ring);
    }
    return imported;
  };

  TopoJSON.shapeImporters = {
    Point: function(geom) {
      return [geom.coordinates];
    },
    MultiPoint: function(geom) {
      return geom.coordinates;
    },
    LineString: function(geom) {
      return [geom.arcs];
    },
    MultiLineString: function(geom) {
      return geom.arcs;
    },
    Polygon: function(geom, arcColl) {
      return TopoJSON.importPolygonArcs(geom.arcs, arcColl);
    },
    MultiPolygon: function(geom, arcColl) {
      return geom.arcs.reduce(function(memo, arr) {
        var rings = TopoJSON.importPolygonArcs(arr, arcColl);
        if (rings) {
          memo = memo ? memo.concat(rings) : rings;
        }
        return memo;
      }, null);
    }
  };

  var TopojsonImport = /*#__PURE__*/Object.freeze({
    __proto__: null,
    importTopoJSON: importTopoJSON
  });

  // This is a JSON parser optimized for GeoJSON files.
  //
  // The native JSON parser, JSON.parse(), is limited by the maximum string
  // size, about ~536.8M chars in Node.
  // (See https://github.com/v8/v8/blob/ea56bf5513d0cbd2a35a9035c5c2996272b8b728/src/objects/string.h#L365).
  // This parser can parse much larger files -- it is limited by available memory.
  //
  // Performance:
  // In Node, this parser is about twice as fast as JSON.parse() when parsing
  // GeoJSON files containing mostly coordinate data and when coordinate precision
  // is less than the float64 maximum. Similar files with full-precision
  // coordinates see a smaller improvement. Files that contain mostly attribute
  // data (e.g. a typical Point feature file) may be parsed a bit slower than
  // JSON.parse().
  //
  // JSON parsing reference: https://www.json.org/json-en.html
  //
  var
    LBRACE = 123,
    RBRACE = 125,
    LBRACK = 91,
    RBRACK = 93,
    DQUOTE = 34,
    COMMA = 44;

  var EOF; // undefined is used as an EOF marker

  var RESERVE = 0X1000; // RESERVE is the number of bytes to keep in read buffer
  var BUFLEN = 1e7; // buffer chunk size
  var MAX_STRLEN = 5e6; // max byte len of a value string (object keys are shorter)

  // Parse from a Buffer -- similar to JSON.parse(), used for testing
  function parse(buf) {
    var reader = new BufferReader(buf);
    var src = ByteReader(reader, 0);
    skipWS(src);
    var val = readValue(src);
    skipWS(src);
    if (src.peek() != EOF) {
      unexpectedCharAt(src.peek(), src.index());
    }
    return val;
  }

  // Read and parse JSON objects from a FileReader
  function parseObjects(reader, offset, cb) {
    var src = ByteReader(reader, offset);
    seekObjectStart(src);
    while (src.peek() == LBRACE) {
      cb(readObject(src));
      readToken(src, COMMA);
    }
  }

  function parseError(msg, i) {
    if (i >= 0) {
      msg += ' at position ' + i;
    }
    stop(msg);
  }

  function unexpectedCharAt(tok, i) {
    var msg;
    if (tok == EOF) {
      return parseError('Unexpected end of JSON input');
    }
    if (tok == DQUOTE) {
      msg = 'Unexpected string in JSON';
    } else if (tok < 33 || tok > 126) { // not ascii glyph
      msg = 'Unexpected token in JSON';
    } else {
      msg = 'Unexpected token ' + String.fromCharCode(tok) + ' in JSON';
    }
    parseError(msg, i);
  }

  function stringOverflow(i, c) {
    if (c == EOF) {
      parseError('Unterminated string in JSON', i);
    }
    parseError('Too-long string in JSON', i);
  }

  function seekObjectStart(src) {
    var c = src.getChar();
    var i = 0;
    while (c != EOF && i < RESERVE) {
      i++;
      if (c == LBRACE) {
        src.back();
        return true;
      }
      c = src.getChar();
    }
    return false;
  }

  function isWS(c) {
    return c == 32 || c == 10 || c == 13 || c == 9;
  }

  function skipWS(src) {
    while (isWS(src.peek())) src.advance();
  }

  function readArray(src) {
    var arr = [], c;
    eatChar(src, LBRACK);
    c = readToken(src, RBRACK);
    while (c != RBRACK) {
      src.refresh();
      arr.push(readArrayElement(src));
      c = readAorB(src, COMMA, RBRACK);
    }
    return arr;
  }

  // Using this function instead of readValue() to read array elements
  // gives up to a 25% reduction in overall processing time when parsing
  // coordinate-heavy GeoJSON files.
  function readArrayElement(src) {
    var i = src.index();
    var x, y, a, b;
    if (src.getChar() == LBRACK && isFirstNumChar(src.peek())) {
      x = readNumber(src);
      a = src.getChar();
      skipWS(src);
      if (a == COMMA && isFirstNumChar(src.peek())) {
        y = readNumber(src);
        b = src.getChar();
        if (b == RBRACK) {
          return [x, y];
        } else if (b == COMMA) {
          return extendArray(src, [x, y]);
        }
      }
    }
    // Fall back to general-purpose value reader
    src.index(i);
    return readValue(src);
  }

  function extendArray(src, arr) {
    skipWS(src);
    do {
      src.refresh(); // make make sure long arrays of numbers don't overflow
      arr.push(readValue(src));
    } while(readAorB(src, COMMA, RBRACK) == COMMA);
    return arr;
  }

  function eatChars(src, str) {
    for (var i = 0; i < str.length; i++) {
      eatChar(src, str.charCodeAt(i));
    }
    return true;
  }

  function eatChar(src, char) {
    var c = src.getChar();
    if (c != char) {
      unexpectedCharAt(c, src.index() - 1);
    }
  }

  // Reads and returns tok if tok is the next non-whitespace byte,
  // else returns null.
  // Scans past WS chars, both before and after tok
  function readToken(src, tok) {
    skipWS(src);
    var c = src.peek();
    if (c === tok) {
      src.advance();
      skipWS(src);
      return tok;
    }
    return null;
  }

  // assumes no leading WS
  function readValue(src) {
    var c = src.peek();
    var val;
    if (isFirstNumChar(c)) val = readNumber(src);
    else if (c == LBRACK) val = readArray(src);
    else if (c == DQUOTE) val = readString(src);
    else if (c == LBRACE) val = readObject(src);
    else if (c == 110) val = eatChars(src, "null") && null;
    else if (c == 116) val = eatChars(src, "true") && true;
    else if (c == 102) val = eatChars(src, "false") && false;
    else unexpectedCharAt(c, src.index());
    return val;
  }

  function readAorB(src, a, b) {
    skipWS(src);
    var c = src.getChar();
    if (c != a && c != b) unexpectedCharAt(c, src.index() - 1);
    skipWS(src);
    return c;
  }

  function readObject(src) {
    var o = {};
    var key, c;
    eatChar(src, LBRACE);
    c = readToken(src, RBRACE);
    while (c != RBRACE) {
      src.refresh();
      key = readKey(src); // use caching for faster key parsing
      skipWS(src);
      eatChar(src, 58);
      skipWS(src);
      // use caching with GeoJSON "type" params
      o[key] = key == 'type' && src.peek() == DQUOTE ?
        readKey(src) : readValue(src);
      c = readAorB(src, COMMA, RBRACE);
    }
    return o;
  }

  function growReserve() {
    RESERVE *= 2;
    return RESERVE <= MAX_STRLEN;
  }

  // Uses caching to speed up parsing of repeated strings.
  // The caching scheme used here can give a 20% overall speed improvement
  // when parsing files consisting mostly of attribute data (e.g. typical Point features)
  function readKey(src) {
    var MAXLEN = 2000; // must be less than RESERVE
    var i = src.index();
    var cache = src.cache;
    var escapeNext = false;
    var n = 0;
    eatChar(src, DQUOTE);
    var c = src.getChar();
    while (c != DQUOTE || escapeNext === true) {
      n++;
      if (n > MAXLEN) {
        stringOverflow(i, c);
      }
      if (escapeNext) {
        escapeNext = false;
      } else if (c == 92) {
        escapeNext = true;
      }
      if (!cache[c]) {
        cache[c] = [];
      }
      cache = cache[c];
      c = src.getChar();
    }
    if (cache[0]) {
      return cache[0];
    }
    src.index(i);
    cache[0] = readString(src);
    return cache[0];
  }

  // Fast path for reading strings.
  // A slower fallback is used to read strings that are longer, non-ascii or
  // contain escaped chars
  function readString(src) {
    var i = src.index();
    eatChar(src, DQUOTE);
    var LIMIT = 256;
    var n = 0;
    var str = '';
    var c = src.getChar();
    while (c != DQUOTE) {
      n++;
      if (n > LIMIT || c == 92 || c < 32 || c > 126) {
        src.index(i);
        return readString_slow(src);
      }
      // String concatenation is faster than Buffer#toString()
      // (as tested with typical strings found in GeoJSON)
      str += String.fromCharCode(c);
      c = src.getChar();
    }
    return str;
  }

  // Fallback for reading long strings, escaped strings, non-ascii strings, etc.
  function readString_slow(src) {
    src.refresh();
    var LIMIT = RESERVE - 2;
    var i = src.index();
    var n = 0;
    var escapeNext = false;
    eatChar(src, DQUOTE);
    var c = src.getChar();
    var str;
    while (c != DQUOTE || escapeNext === true) {
      n++;
      if (n > LIMIT) {
        // we've exceeded the number of reserved bytes
        // expand the limit and try reading this string again
        if (c == EOF || !growReserve()) {
          stringOverflow(i, c);
        }
        src.index(i);
        return readString_slow(src);
      }
      if (escapeNext) {
        escapeNext = false;
      } else if (c == 92) {
        escapeNext = true;
      }
      c = src.getChar();
    }
    // skipping JSON.parse() is faster, but doesn't work when strings contain
    // escapes or a handful of ascii control characters.
    // str = src.toString(i + 1, n);
    str = JSON.parse(src.toString(i, n + 2));
    src.refresh();
    return str;
  }

  function isDigit(c) {
    return c >= 48 && c <= 57;
  }

  function isFirstNumChar(c) {
    return c >= 48 && c <= 57 || c == 45;
  }

  function isNumChar(c) {
    return c >= 48 && c <= 57 || c == 45 || c == 46 || c == 43 || c == 69 || c == 101;
  }


  // Correctly parses any valid JSON number
  // This function gives the correctly rounded result for numbers that are
  // incorrectly rounded using the fast method (a subset of numbers with >15 digits).
  function readNumber_slow(src) {
    var i = src.index();
    var n = 0;
    while (isNumChar(src.getChar())) {
      n++;
    }
    src.back();
    var str = src.toString(i, n);
    var num = Number(str);
    if (isNaN(num)) parseError('Invalid number in JSON', i);
    return num;
  }

  // Parses numbers quickly, falls back to a slower method when
  // correct fp rounding is not assured.
  function readNumber(src) {
    var i = src.index();
    var num = 0;
    var den = 1;
    var sign = 1;
    var oflo = false;
    var invalid = false;
    var c = src.getChar();
    var d0, d;
    if (c === 45) {
      sign = -1;
      c = src.getChar();
    }
    d0 = c;
    while (isDigit(c)) {
      d = c - 48;
      num = num * 10 + d;
      c = src.getChar();
    }
    if (num > 0 && d0 === 48) {
      // catch "01" "-01" etc.
      invalid = true;
    }
    if (c == 46) { // "."
      while (isDigit(c = src.getChar())) {
        d = c - 48;
        den *= 10;
        num = num * 10 + d;
      }
      if (den == 1 || d0 == 46) {
        // catch "1." "1.e" "-.1"
        invalid = true;
      }
    }
    if (num === 0 && d0 != 48) {
      invalid = true; // catch "-";
    }
    if (invalid) parseError('Invalid number in JSON', i);
    if (den > 1e22) oflo = true; // denominator gets rounded above this limit
    if (num >= 0x20000000000000) { // 2^53
      // Some numerators get rounded with > 52 bits of mantissa
      // (When numerator or denominator are rounded, dividing them may
      // not have the same result as JSON.parse() and the IEEE standard)
      // See: https://www.exploringbinary.com/fast-path-decimal-to-floating-point-conversion/
      if (num >= 0x40000000000000 || (d & 1) === 1) {
        // We don't need to fall back to the slow routine
        // for even integers with 53 bits
        // This optimization can reduce overall processing time by 15% for
        // GeoJSON files with full-precision coordinates.
        oflo = true;
      }
    }
    if (oflo || c == 69 || c == 101) { // e|E
      // Exponents are uncommon in GeoJSON... simpler to use slow function
      // than to parse manually and check for overflow and rounding errors
      src.index(i);
      return readNumber_slow(src);
    }
    src.back();
    return sign * num / den;
  }

  // Wrap a FileReader to support reading files one byte at a time.
  function ByteReader(reader, start) {
    var fileLen = reader.size();
    var bufOffs = start;
    var buf = reader.readSync(bufOffs, BUFLEN);
    var i = 0;
    var obj = { peek, getChar, advance, back, toString, index, refresh };
    obj.cache = []; // kludgy place to put the key cache
    refresh();
    return obj;

    // This function should be called to make sure that the buffer has enough
    // bytes remaining to read any reasonable JSON content.
    function refresh() {
      // if RESERVE bytes are still available in the buffer, no update is required
      if (buf.length - i >= RESERVE) return;

      // CHANGE: now using undefined as an EOF marker, so a bounds check is unneeded
      // // if we're close to the end of the file, start checking for overflow
      // // (we don't do this all the time because the bounds check on every read
      // // causes a significant slowdown, as much as 20%)
      // if (fileLen - (bufOffs + i) < RESERVE) {
      //   obj.peek = safePeek;
      //   obj.getChar = safeGetChar;
      // }

      // if buffer reaches the end of the file, no update is required
      if (bufOffs + buf.length >= fileLen) return;

      // fewer than RESERVE bytes are unread in buffer -- update the buffer
      bufOffs += i;
      i = 0;
      buf = reader.readSync(bufOffs, BUFLEN);
    }
    function peek() {
      return buf[i];
    }
    function getChar() {
      return buf[i++];
    }
    function advance() {
      i++;
    }
    function back() {
      i--;
    }
    function index(idx) {
      if (idx >= 0 === false) return i + bufOffs;
      i = idx - bufOffs;
    }
    function toString(idx, n) {
      var i = idx - bufOffs;
      return buf.toString("utf8", i, i + n);
    }
  }

  // Read GeoJSON Features or geometry objects from a file
  // @reader: a FileReader
  function GeoJSONReader(reader) {

    // Read objects synchronously, with callback
    this.readObjects = function(onObject) {
      // Search first x bytes of file for features|geometries key
      // 300 bytes not enough... GeoJSON files can have additional non-standard properties, e.g. 'metadata'
      // var bytesToSearch = 300;
      var bytesToSearch = 5000;
      var start = reader.findString('"features"', bytesToSearch) ||
          reader.findString('"geometries"', bytesToSearch);
      // Assume single Feature or geometry if collection not found
      // (this works for ndjson files too)
      var offset = start ? start.offset : 0;
      T$1.start();
      parseObjects(reader, offset, onObject);
      // parseObjects_native(reader, offset, onObject);
      debug('Parse GeoJSON', T$1.stop());
    };
  }

  // Parse the entire file with JSON.parse() (for a performance comparison)
  function parseObjects_native(reader, offset, cb) {
    var obj = JSON.parse(reader.toString());
    var arr = obj.features || obj.geometries || [obj];
    arr.forEach(o => cb(o));
  }

  // Identify JSON type from the initial subset of a JSON string
  function identifyJSONString(str, opts) {
    var maxChars = 1000;
    var fmt = null;
    if (str.length > maxChars) str = str.substr(0, maxChars);
    str = str.replace(/\s/g, '');
    if (opts && opts.json_path) {
      fmt = 'json'; // TODO: make json_path compatible with other types
    } else if (/^\[[{\]]/.test(str)) {
      // empty array or array of objects
      fmt = 'json';
    } else if (/"arcs":\[|"objects":\{|"transform":\{/.test(str)) {
      fmt =  'topojson';
    } else if (/^\{"/.test(str)) {
      fmt = 'geojson';
    }
    return fmt;
  }

  function identifyJSONObject(o) {
    var fmt = null;
    if (!o) {
      //
    } else if (o.type == 'Topology') {
      fmt = 'topojson';
    } else if (o.type) {
      fmt = 'geojson';
    } else if (utils.isArray(o)) {
      fmt = 'json';
    }
    return fmt;
  }

  function importGeoJSONFile(fileReader, opts) {
    var importer = new GeoJSONParser(opts);
    new GeoJSONReader(fileReader).readObjects(importer.parseObject);
    return importer.done();
  }

  // Parse GeoJSON directly from a binary data source (supports parsing larger files
  // than the maximum JS string length) or return a string with the entire
  // contents of the file.
  // reader: a binary file reader
  //
  function readJSONFile(reader, opts) {
    var str = readFirstChars(reader, 1000);
    var type = identifyJSONString(str, opts);
    var dataset, retn;
    if (type == 'geojson') { // consider only for larger files
      dataset = importGeoJSONFile(reader, opts);
      retn = {
        dataset: dataset,
        format: 'geojson'
      };
    } else {
      retn = {
        // content: cli.readFile(path, 'utf8')}
        content: reader.toString('utf8')
      };
    }
    reader.close();
    return retn;
  }

  function importJSON(data, opts) {
    var content = data.content,
        filename = data.filename,
        retn = {filename: filename},
        reader, fmt;

    if (!content) {
      reader = new FileReader(filename);
    } else if (content instanceof ArrayBuffer) {
      // Web API imports JSON as ArrayBuffer, to support larger files
      if (content.byteLength < 1e7) {
        // content = utils.createBuffer(content).toString();
        content = bufferToString(utils.createBuffer(content));
      } else {
        reader = new BufferReader(content);
        content = null;
      }
    }

    if (reader) {
      data = readJSONFile(reader, opts);
      if (data.dataset) {
        retn.dataset = data.dataset;
        retn.format = data.format;
      } else {
        content = data.content;
      }
    }

    if (content) {
      if (utils.isString(content)) {
        try {
          content = JSON.parse(content); // ~3sec for 100MB string
        } catch(e) {
          // stop("Unable to parse JSON");
          stop('JSON parsing error --', e.message);
        }
      }
      if (opts.json_path) {
        content = selectFromObject(content, opts.json_path);
        fmt = identifyJSONObject(content, opts);
        if (!fmt) {
          stop('Unexpected object type at JSON path:', opts.json_path);
        }
      } else {
        fmt = identifyJSONObject(content, opts);
      }
      if (fmt == 'topojson') {
        retn.dataset = importTopoJSON(content, opts);
      } else if (fmt == 'geojson') {
        retn.dataset = importGeoJSON(content, opts);
      } else if (fmt == 'json') {
        retn.dataset = importJSONTable(content, opts);
      } else {
        stop("Unknown JSON format");
      }
      retn.format = fmt;
    }

    return retn;
  }

  // path: path from top-level to the target object
  function selectFromObject(o, path) {
    var arrayRxp = /(.*)\[([0-9]+)\]$/; // array bracket notation w/ index
    var separator = path.indexOf('/') > 0 ? '/' : '.';
    var parts = path.split(separator);
    var subpath, array, match;
    while (parts.length > 0) {
      subpath = parts.shift();
      match = arrayRxp.exec(subpath);
      if (match) {
        array = o[match[1]];
        o = array && array[+match[2]] || null;
      } else {
        o = o[subpath];
      }
      if (!o) return null;
    }
    return o;
  }

  var JsonImport = /*#__PURE__*/Object.freeze({
    __proto__: null,
    identifyJSONString: identifyJSONString,
    identifyJSONObject: identifyJSONObject,
    importGeoJSONFile: importGeoJSONFile,
    importJSON: importJSON
  });

  // Parse content of one or more input files and return a dataset
  // @obj: file data, indexed by file type
  // File data objects have two properties:
  //    content: Buffer, ArrayBuffer, String or Object
  //    filename: String or null
  //
  function importContent(obj, opts) {
    var dataset, content, fileFmt, data;
    opts = opts || {};
    if (obj.json) {
      data = importJSON(obj.json, opts);
      fileFmt = data.format;
      dataset = data.dataset;
      cleanPathsAfterImport(dataset, opts);

    } else if (obj.text) {
      fileFmt = 'dsv';
      data = obj.text;
      dataset = importDelim2(data, opts);

    } else if (obj.shp) {
      fileFmt = 'shapefile';
      data = obj.shp;
      dataset = importShapefile(obj, opts);
      cleanPathsAfterImport(dataset, opts);

    } else if (obj.dbf) {
      fileFmt = 'dbf';
      data = obj.dbf;
      dataset = importDbf(obj, opts);

    } else if (obj.prj) {
      // added for -proj command source
      fileFmt = 'prj';
      data = obj.prj;
      dataset = {layers: [], info: {prj: data.content}};
    }

    if (!dataset) {
      stop("Missing an expected input type");
    }

    // Convert to topological format, if needed
    if (dataset.arcs && !opts.no_topology && fileFmt != 'topojson') {
      buildTopology(dataset);
    }

    // Use file basename for layer name, except TopoJSON, which uses object names
    if (fileFmt != 'topojson') {
      dataset.layers.forEach(function(lyr) {
        if (!lyr.name) {
          lyr.name = filenameToLayerName(data.filename || '');
        }
      });
    }

    // Add input filename and format to the dataset's 'info' object
    // (this is useful when exporting if format or name has not been specified.)
    if (data.filename) {
      dataset.info.input_files = [data.filename];
    }
    dataset.info.input_formats = [fileFmt];
    return dataset;
  }

  // Deprecated (included for compatibility with older tests)
  function importFileContent(content, filename, opts) {
    var type = guessInputType(filename, content),
        input = {};
    input[type] = {filename: filename, content: content};
    return importContent(input, opts);
  }


  function importShapefile(obj, opts) {
    var shpSrc = obj.shp.content || obj.shp.filename, // read from a file if (binary) content is missing
        shxSrc = obj.shx ? obj.shx.content || obj.shx.filename : null,
        dataset = importShp(shpSrc, shxSrc, opts),
        lyr = dataset.layers[0],
        dbf;
    if (obj.dbf) {
      dbf = importDbf(obj, opts);
      utils.extend(dataset.info, dbf.info);
      lyr.data = dbf.layers[0].data;
      if (lyr.shapes && lyr.data.size() != lyr.shapes.length) {
        message("Mismatched .dbf and .shp record count -- possible data loss.");
      }
    }
    if (obj.prj) {
      dataset.info.prj = obj.prj.content;
    }
    return dataset;
  }

  function importDbf(input, opts) {
    var table;
    opts = utils.extend({}, opts);
    if (input.cpg && !opts.encoding) {
      opts.encoding = input.cpg.content;
    }
    table = importDbfTable(input.dbf.content, opts);
    return {
      info: {},
      layers: [{data: table}]
    };
  }

  function filenameToLayerName(path) {
    var name = 'layer1';
    var obj = parseLocalPath(path);
    if (obj.basename && obj.extension) { // exclude paths like '/dev/stdin'
      name = obj.basename;
    }
    return name;
  }

  var Import = /*#__PURE__*/Object.freeze({
    __proto__: null,
    importContent: importContent,
    importFileContent: importFileContent
  });

  // Import multiple files to a single dataset
  function importFiles(files, opts) {
    var unbuiltTopology = false;
    var datasets = files.map(function(fname) {
      // import without topology or snapping
      var importOpts = utils.defaults({no_topology: true, snap: false, snap_interval: null, files: [fname]}, opts);
      var dataset = importFile(fname, importOpts);
      // check if dataset contains non-topological paths
      // TODO: may also need to rebuild topology if multiple topojson files are merged
      if (dataset.arcs && dataset.arcs.size() > 0 && dataset.info.input_formats[0] != 'topojson') {
        unbuiltTopology = true;
      }
      return dataset;
    });
    var combined = mergeDatasets(datasets);
    // Build topology, if needed
    // TODO: consider updating topology of TopoJSON files instead of concatenating arcs
    // (but problem of mismatched coordinates due to quantization in input files.)
    if (unbuiltTopology && !opts.no_topology) {
      cleanPathsAfterImport(combined, opts);
      buildTopology(combined);
    }
    return combined;
  }

  var MergeFiles = /*#__PURE__*/Object.freeze({
    __proto__: null,
    importFiles: importFiles
  });

  cmd.importFiles = function(opts) {
    var files = opts.files || [],
        dataset;

    if (opts.stdin) {
      return importFile('/dev/stdin', opts);
    }

    if (files.length > 0 === false) {
      stop('Missing input file(s)');
    }

    verbose("Importing: " + files.join(' '));

    if (files.length == 1) {
      dataset = importFile(files[0], opts);
    } else if (opts.merge_files) {
      // TODO: deprecate and remove this option (use -merge-layers cmd instead)
      dataset = importFiles(files, opts);
      dataset.layers = cmd.mergeLayers(dataset.layers);
    } else if (opts.combine_files) {
      dataset = importFiles(files, opts);
    } else {
      stop('Invalid inputs');
    }
    return dataset;
  };

  // Let the web UI replace importFile() with a browser-friendly version
  function replaceImportFile(func) {
    _importFile = func;
  }

  function importFile(path, opts) {
    return _importFile(path, opts);
  }

  var _importFile = function(path, opts) {
    var fileType = guessInputFileType(path),
        input = {},
        encoding = opts && opts.encoding || null,
        cache = opts && opts.input || null,
        cached = cache && (path in cache),
        content;

    cli.checkFileExists(path, cache);
    if (fileType == 'shp' && !cached) {
      // let ShpReader read the file (supports larger files)
      content = null;

    } else if (fileType == 'json' && !cached) {
      // postpone reading of JSON files, to support incremental parsing
      content = null;

    } else if (fileType == 'text' && !cached) {
      // content = cli.readFile(path); // read from buffer
      content = null; // read from file, to support largest files (see mapshaper-delim-import.js)

    } else if (fileType && isSupportedBinaryInputType(path)) {
      content = cli.readFile(path, null, cache);
      if (utils.isString(content)) {
        // Fix for issue #264 (applyCommands() input is file path instead of binary content)
        stop('Expected binary content, received a string');
      }

    } else if (fileType) { // string type
      content = cli.readFile(path, encoding || 'utf-8', cache);

    } else { // type can't be inferred from filename -- try reading as text
      content = cli.readFile(path, encoding || 'utf-8', cache);
      fileType = guessInputContentType(content);
      if (fileType == 'text' && content.indexOf('\ufffd') > -1) {
        // invalidate string data that contains the 'replacement character'
        fileType = null;
      }
    }

    if (!fileType) {
      stop(getUnsupportedFileMessage(path));
    }
    input[fileType] = {filename: path, content: content};
    content = null; // for g.c.
    if (fileType == 'shp' || fileType == 'dbf') {
      readShapefileAuxFiles(path, input, cache);
    }
    if (fileType == 'shp' && !input.dbf) {
      message(utils.format("[%s] .dbf file is missing - shapes imported without attribute data.", path));
    }
    return importContent(input, opts);
  };

  function getUnsupportedFileMessage(path) {
    var ext = getFileExtension(path);
    var msg = 'Unable to import ' + path;
    if (ext.toLowerCase() == 'zip') {
      msg += ' (ZIP files must be unpacked before running mapshaper)';
    } else {
      msg += ' (unknown file type)';
    }
    return msg;
  }

  function readShapefileAuxFiles(path, obj, cache) {
    var dbfPath = replaceFileExtension(path, 'dbf');
    var shxPath = replaceFileExtension(path, 'shx');
    var cpgPath = replaceFileExtension(path, 'cpg');
    var prjPath = replaceFileExtension(path, 'prj');
    if (cli.isFile(prjPath, cache)) {
      obj.prj = {filename: prjPath, content: cli.readFile(prjPath, 'utf-8', cache)};
    }
    if (cli.isFile(shxPath, cache)) {
      obj.shx = {filename: shxPath, content: cli.readFile(shxPath, null, cache)};
    }
    if (!obj.dbf && cli.isFile(dbfPath, cache)) {
      obj.dbf = {filename: dbfPath, content: cli.readFile(dbfPath, null, cache)};
    }
    if (obj.dbf && cli.isFile(cpgPath, cache)) {
      obj.cpg = {filename: cpgPath, content: cli.readFile(cpgPath, 'utf-8', cache).trim()};
    }
  }

  var FileImport = /*#__PURE__*/Object.freeze({
    __proto__: null,
    replaceImportFile: replaceImportFile,
    importFile: importFile
  });

  function convertSourceName(name, targets) {
    if (!nameIsInterpolated(name)) return name;
    if (targets.length > 1 || targets[0].layers.length != 1) {
      stop("Interpolated names are not compatible with multiple targets.");
    }
    return convertInterpolatedName(name, targets[0].layers[0]);
  }

  function convertInterpolatedName(name, lyr) {
    var ctx = {target: lyr.name || ''};
    var body = 'with($$ctx) { return `' + name + '`; }';
    var func;
    try {
      func = new Function("$$ctx", body);
      name = func(ctx);
    } catch(e) {
      stop("Unable to interpolate [" + name + "]");
    }
    return name;
  }

  function nameIsInterpolated(name) {
    return /[$][{]/.test(name);
  }

  function findCommandSource(sourceName, catalog, opts) {
    var source = catalog.findSingleLayer(sourceName);
    var sourceDataset;
    if (!source) {
      // assuming opts.source is a filename
      // don't need to build topology, because:
      //    join -- don't need topology
      //    clip/erase -- topology is built later, when datasets are combined
      sourceDataset = importFile(sourceName, utils.defaults({no_topology: true}, opts));
      if (!sourceDataset) {
        stop(utils.format('Unable to find source [%s]', sourceName));
      } else if (sourceDataset.layers.length > 1) {
        stop('Multiple-layer sources are not supported');
      }
      // mark as disposable to indicate that data can be mutated
      source = {dataset: sourceDataset, layer: sourceDataset.layers[0], disposable: true};
    }
    return source;
  }

  var SourceUtils = /*#__PURE__*/Object.freeze({
    __proto__: null,
    convertSourceName: convertSourceName,
    convertInterpolatedName: convertInterpolatedName,
    findCommandSource: findCommandSource
  });

  // Catalog contains zero or more multi-layer datasets
  // One layer is always "active", corresponding to the currently selected
  //   layer in the GUI or the current target in the CLI
  function Catalog() {
    var datasets = [],
        defaultTargets = [];// saved default command targets [{layers:[], dataset}, ...]

    this.forEachLayer = function(cb) {
      var i = 0;
      datasets.forEach(function(dataset) {
        dataset.layers.forEach(function(lyr) {
          cb(lyr, dataset, i++);
        });
      });
    };

    // remove a layer from a dataset
    this.deleteLayer = function(lyr, dataset) {
      // if deleting first target layer (selected in gui) -- switch to some other layer
      if (this.getActiveLayer().layer == lyr) {
        defaultTargets = [];
      }

      // remove layer from its dataset
      dataset.layers.splice(dataset.layers.indexOf(lyr), 1);
      if (dataset.layers.length === 0) {
        this.removeDataset(dataset);
      }

      // remove layer from defaultTargets
      defaultTargets = defaultTargets.filter(function(targ) {
        var i = targ.layers.indexOf(lyr);
        if (i == -1) return true;
        targ.layers.splice(i, 1);
        return targ.layers.length > 0;
      });
    };

    // @arg: a layer object or a test function
    this.findLayer = function(arg) {
      var test = typeof arg == 'function' ? arg : null;
      var found = null;
      this.forEachLayer(function(lyr, dataset) {
        if (test ? test(lyr, dataset) : lyr == arg) {
          found = layerObject(lyr, dataset);
        }
      });
      return found;
    };

    this.findCommandTargets = function(pattern, type) {
      if (!pattern) return this.getDefaultTargets() || [];
      return findCommandTargets(this.getLayers(), pattern, type);
    };

    this.findSingleLayer = function(pattern) {
      var matches = findMatchingLayers(this.getLayers(), pattern);
      if (matches.length > 1) {
        stop('Ambiguous pattern (multiple layers were matched):', pattern);
      }
      return matches[0] || null;
    };

    this.removeDataset = function(dataset) {
      defaultTargets = defaultTargets.filter(function(targ) {
        return targ.dataset != dataset;
      });
      datasets = datasets.filter(function(d) {
        return d != dataset;
      });
    };

    this.getDatasets = function() {
      return datasets;
    };

    this.getLayers = function() {
      var layers = [];
      this.forEachLayer(function(lyr, dataset) {
        layers.push(layerObject(lyr, dataset));
      });
      return layers;
    };

    this.addDataset = function(dataset) {
      this.setDefaultTarget(dataset.layers, dataset);
      return this;
    };

    this.findNextLayer = function(lyr) {
      var layers = this.getLayers(),
          idx = indexOfLayer(lyr, layers);
      return idx > -1 ? layers[(idx + 1) % layers.length] : null;
    };

    this.findPrevLayer = function(lyr) {
      var layers = this.getLayers(),
          idx = indexOfLayer(lyr, layers);
      return idx > -1 ? layers[(idx - 1 + layers.length) % layers.length] : null;
    };

    this.isEmpty = function() {
      return datasets.length === 0;
    };

    this.getDefaultTargets = function() {
      if (defaultTargets.length === 0 && !this.isEmpty()) {
        defaultTargets = [{dataset: datasets[0], layers: datasets[0].layers.slice(0, 1)}];
      }
      return defaultTargets;
    };

    this.setDefaultTarget = function(layers, dataset) {
      if (datasets.indexOf(dataset) == -1) {
        datasets.push(dataset);
      }
      defaultTargets = [{
        // Copy layers array, in case layers is a reference to dataset.layers.
        // This prevents layers that are added to the dataset inside a command from
        //  being added to the next command's target, e.g. debugging layers added
        //  by '-join unmatched unjoined'.
        layers: layers.concat(),
        dataset: dataset
      }];
    };

    this.setDefaultTargets = function(arr) {
      defaultTargets = arr;
    };

    // should be in gui-model.js, moved here for testing
    this.getActiveLayer = function() {
      var targ = (this.getDefaultTargets() || [])[0];
      return targ ? {layer: targ.layers[0], dataset: targ.dataset} : null;
    };

    function layerObject(lyr, dataset) {
      return {
        layer: lyr,
        dataset: dataset
      };
    }

    function indexOfLayer(lyr, layers) {
      var idx = -1;
      layers.forEach(function(o, i) {
        if (o.layer == lyr) idx = i;
      });
      return idx;
    }
  }

  function getFormattedLayerList(catalog) {
    var lines = [];
    catalog.forEachLayer(function(lyr, dataset, i) {
      lines.push('  [' + (i+1) + ']  ' + (lyr.name || '[unnamed]'));
    });
    return lines.length > 0 ? lines.join('\n') : '[none]';
  }

  var Catalog$1 = /*#__PURE__*/Object.freeze({
    __proto__: null,
    Catalog: Catalog,
    getFormattedLayerList: getFormattedLayerList
  });

  const epsilon = 1.1102230246251565e-16;
  const splitter = 134217729;
  const resulterrbound = (3 + 8 * epsilon) * epsilon;

  // fast_expansion_sum_zeroelim routine from oritinal code
  function sum(elen, e, flen, f, h) {
      let Q, Qnew, hh, bvirt;
      let enow = e[0];
      let fnow = f[0];
      let eindex = 0;
      let findex = 0;
      if ((fnow > enow) === (fnow > -enow)) {
          Q = enow;
          enow = e[++eindex];
      } else {
          Q = fnow;
          fnow = f[++findex];
      }
      let hindex = 0;
      if (eindex < elen && findex < flen) {
          if ((fnow > enow) === (fnow > -enow)) {
              Qnew = enow + Q;
              hh = Q - (Qnew - enow);
              enow = e[++eindex];
          } else {
              Qnew = fnow + Q;
              hh = Q - (Qnew - fnow);
              fnow = f[++findex];
          }
          Q = Qnew;
          if (hh !== 0) {
              h[hindex++] = hh;
          }
          while (eindex < elen && findex < flen) {
              if ((fnow > enow) === (fnow > -enow)) {
                  Qnew = Q + enow;
                  bvirt = Qnew - Q;
                  hh = Q - (Qnew - bvirt) + (enow - bvirt);
                  enow = e[++eindex];
              } else {
                  Qnew = Q + fnow;
                  bvirt = Qnew - Q;
                  hh = Q - (Qnew - bvirt) + (fnow - bvirt);
                  fnow = f[++findex];
              }
              Q = Qnew;
              if (hh !== 0) {
                  h[hindex++] = hh;
              }
          }
      }
      while (eindex < elen) {
          Qnew = Q + enow;
          bvirt = Qnew - Q;
          hh = Q - (Qnew - bvirt) + (enow - bvirt);
          enow = e[++eindex];
          Q = Qnew;
          if (hh !== 0) {
              h[hindex++] = hh;
          }
      }
      while (findex < flen) {
          Qnew = Q + fnow;
          bvirt = Qnew - Q;
          hh = Q - (Qnew - bvirt) + (fnow - bvirt);
          fnow = f[++findex];
          Q = Qnew;
          if (hh !== 0) {
              h[hindex++] = hh;
          }
      }
      if (Q !== 0 || hindex === 0) {
          h[hindex++] = Q;
      }
      return hindex;
  }

  function sum_three(alen, a, blen, b, clen, c, tmp, out) {
      return sum(sum(alen, a, blen, b, tmp), tmp, clen, c, out);
  }

  // scale_expansion_zeroelim routine from oritinal code
  function scale(elen, e, b, h) {
      let Q, sum, hh, product1, product0;
      let bvirt, c, ahi, alo, bhi, blo;

      c = splitter * b;
      bhi = c - (c - b);
      blo = b - bhi;
      let enow = e[0];
      Q = enow * b;
      c = splitter * enow;
      ahi = c - (c - enow);
      alo = enow - ahi;
      hh = alo * blo - (Q - ahi * bhi - alo * bhi - ahi * blo);
      let hindex = 0;
      if (hh !== 0) {
          h[hindex++] = hh;
      }
      for (let i = 1; i < elen; i++) {
          enow = e[i];
          product1 = enow * b;
          c = splitter * enow;
          ahi = c - (c - enow);
          alo = enow - ahi;
          product0 = alo * blo - (product1 - ahi * bhi - alo * bhi - ahi * blo);
          sum = Q + product0;
          bvirt = sum - Q;
          hh = Q - (sum - bvirt) + (product0 - bvirt);
          if (hh !== 0) {
              h[hindex++] = hh;
          }
          Q = product1 + sum;
          hh = sum - (Q - product1);
          if (hh !== 0) {
              h[hindex++] = hh;
          }
      }
      if (Q !== 0 || hindex === 0) {
          h[hindex++] = Q;
      }
      return hindex;
  }

  function negate(elen, e) {
      for (let i = 0; i < elen; i++) e[i] = -e[i];
      return elen;
  }

  function estimate(elen, e) {
      let Q = e[0];
      for (let i = 1; i < elen; i++) Q += e[i];
      return Q;
  }

  function vec(n) {
      return new Float64Array(n);
  }

  const ccwerrboundA = (3 + 16 * epsilon) * epsilon;
  const ccwerrboundB = (2 + 12 * epsilon) * epsilon;
  const ccwerrboundC = (9 + 64 * epsilon) * epsilon * epsilon;

  const B$1 = vec(4);
  const C1 = vec(8);
  const C2 = vec(12);
  const D = vec(16);
  const u$2 = vec(4);

  function orient2dadapt(ax, ay, bx, by, cx, cy, detsum) {
      let acxtail, acytail, bcxtail, bcytail;
      let bvirt, c, ahi, alo, bhi, blo, _i, _j, _0, s1, s0, t1, t0, u3;

      const acx = ax - cx;
      const bcx = bx - cx;
      const acy = ay - cy;
      const bcy = by - cy;

      s1 = acx * bcy;
      c = splitter * acx;
      ahi = c - (c - acx);
      alo = acx - ahi;
      c = splitter * bcy;
      bhi = c - (c - bcy);
      blo = bcy - bhi;
      s0 = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
      t1 = acy * bcx;
      c = splitter * acy;
      ahi = c - (c - acy);
      alo = acy - ahi;
      c = splitter * bcx;
      bhi = c - (c - bcx);
      blo = bcx - bhi;
      t0 = alo * blo - (t1 - ahi * bhi - alo * bhi - ahi * blo);
      _i = s0 - t0;
      bvirt = s0 - _i;
      B$1[0] = s0 - (_i + bvirt) + (bvirt - t0);
      _j = s1 + _i;
      bvirt = _j - s1;
      _0 = s1 - (_j - bvirt) + (_i - bvirt);
      _i = _0 - t1;
      bvirt = _0 - _i;
      B$1[1] = _0 - (_i + bvirt) + (bvirt - t1);
      u3 = _j + _i;
      bvirt = u3 - _j;
      B$1[2] = _j - (u3 - bvirt) + (_i - bvirt);
      B$1[3] = u3;

      let det = estimate(4, B$1);
      let errbound = ccwerrboundB * detsum;
      if (det >= errbound || -det >= errbound) {
          return det;
      }

      bvirt = ax - acx;
      acxtail = ax - (acx + bvirt) + (bvirt - cx);
      bvirt = bx - bcx;
      bcxtail = bx - (bcx + bvirt) + (bvirt - cx);
      bvirt = ay - acy;
      acytail = ay - (acy + bvirt) + (bvirt - cy);
      bvirt = by - bcy;
      bcytail = by - (bcy + bvirt) + (bvirt - cy);

      if (acxtail === 0 && acytail === 0 && bcxtail === 0 && bcytail === 0) {
          return det;
      }

      errbound = ccwerrboundC * detsum + resulterrbound * Math.abs(det);
      det += (acx * bcytail + bcy * acxtail) - (acy * bcxtail + bcx * acytail);
      if (det >= errbound || -det >= errbound) return det;

      s1 = acxtail * bcy;
      c = splitter * acxtail;
      ahi = c - (c - acxtail);
      alo = acxtail - ahi;
      c = splitter * bcy;
      bhi = c - (c - bcy);
      blo = bcy - bhi;
      s0 = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
      t1 = acytail * bcx;
      c = splitter * acytail;
      ahi = c - (c - acytail);
      alo = acytail - ahi;
      c = splitter * bcx;
      bhi = c - (c - bcx);
      blo = bcx - bhi;
      t0 = alo * blo - (t1 - ahi * bhi - alo * bhi - ahi * blo);
      _i = s0 - t0;
      bvirt = s0 - _i;
      u$2[0] = s0 - (_i + bvirt) + (bvirt - t0);
      _j = s1 + _i;
      bvirt = _j - s1;
      _0 = s1 - (_j - bvirt) + (_i - bvirt);
      _i = _0 - t1;
      bvirt = _0 - _i;
      u$2[1] = _0 - (_i + bvirt) + (bvirt - t1);
      u3 = _j + _i;
      bvirt = u3 - _j;
      u$2[2] = _j - (u3 - bvirt) + (_i - bvirt);
      u$2[3] = u3;
      const C1len = sum(4, B$1, 4, u$2, C1);

      s1 = acx * bcytail;
      c = splitter * acx;
      ahi = c - (c - acx);
      alo = acx - ahi;
      c = splitter * bcytail;
      bhi = c - (c - bcytail);
      blo = bcytail - bhi;
      s0 = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
      t1 = acy * bcxtail;
      c = splitter * acy;
      ahi = c - (c - acy);
      alo = acy - ahi;
      c = splitter * bcxtail;
      bhi = c - (c - bcxtail);
      blo = bcxtail - bhi;
      t0 = alo * blo - (t1 - ahi * bhi - alo * bhi - ahi * blo);
      _i = s0 - t0;
      bvirt = s0 - _i;
      u$2[0] = s0 - (_i + bvirt) + (bvirt - t0);
      _j = s1 + _i;
      bvirt = _j - s1;
      _0 = s1 - (_j - bvirt) + (_i - bvirt);
      _i = _0 - t1;
      bvirt = _0 - _i;
      u$2[1] = _0 - (_i + bvirt) + (bvirt - t1);
      u3 = _j + _i;
      bvirt = u3 - _j;
      u$2[2] = _j - (u3 - bvirt) + (_i - bvirt);
      u$2[3] = u3;
      const C2len = sum(C1len, C1, 4, u$2, C2);

      s1 = acxtail * bcytail;
      c = splitter * acxtail;
      ahi = c - (c - acxtail);
      alo = acxtail - ahi;
      c = splitter * bcytail;
      bhi = c - (c - bcytail);
      blo = bcytail - bhi;
      s0 = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
      t1 = acytail * bcxtail;
      c = splitter * acytail;
      ahi = c - (c - acytail);
      alo = acytail - ahi;
      c = splitter * bcxtail;
      bhi = c - (c - bcxtail);
      blo = bcxtail - bhi;
      t0 = alo * blo - (t1 - ahi * bhi - alo * bhi - ahi * blo);
      _i = s0 - t0;
      bvirt = s0 - _i;
      u$2[0] = s0 - (_i + bvirt) + (bvirt - t0);
      _j = s1 + _i;
      bvirt = _j - s1;
      _0 = s1 - (_j - bvirt) + (_i - bvirt);
      _i = _0 - t1;
      bvirt = _0 - _i;
      u$2[1] = _0 - (_i + bvirt) + (bvirt - t1);
      u3 = _j + _i;
      bvirt = u3 - _j;
      u$2[2] = _j - (u3 - bvirt) + (_i - bvirt);
      u$2[3] = u3;
      const Dlen = sum(C2len, C2, 4, u$2, D);

      return D[Dlen - 1];
  }

  function orient2d(ax, ay, bx, by, cx, cy) {
      const detleft = (ay - cy) * (bx - cx);
      const detright = (ax - cx) * (by - cy);
      const det = detleft - detright;

      if (detleft === 0 || detright === 0 || (detleft > 0) !== (detright > 0)) return det;

      const detsum = Math.abs(detleft + detright);
      if (Math.abs(det) >= ccwerrboundA * detsum) return det;

      return -orient2dadapt(ax, ay, bx, by, cx, cy, detsum);
  }

  function orient2dfast(ax, ay, bx, by, cx, cy) {
      return (ay - cy) * (bx - cx) - (ax - cx) * (by - cy);
  }

  const o3derrboundA = (7 + 56 * epsilon) * epsilon;
  const o3derrboundB = (3 + 28 * epsilon) * epsilon;
  const o3derrboundC = (26 + 288 * epsilon) * epsilon * epsilon;

  const bc$2 = vec(4);
  const ca$1 = vec(4);
  const ab$2 = vec(4);
  const at_b = vec(4);
  const at_c = vec(4);
  const bt_c = vec(4);
  const bt_a = vec(4);
  const ct_a = vec(4);
  const ct_b = vec(4);
  const bct$1 = vec(8);
  const cat$1 = vec(8);
  const abt$1 = vec(8);
  const u$1 = vec(4);

  const _8$2 = vec(8);
  const _8b$1 = vec(8);
  const _16$2 = vec(8);
  const _12 = vec(12);

  let fin$2 = vec(192);
  let fin2$1 = vec(192);

  function finadd$1(finlen, alen, a) {
      finlen = sum(finlen, fin$2, alen, a, fin2$1);
      const tmp = fin$2; fin$2 = fin2$1; fin2$1 = tmp;
      return finlen;
  }

  function tailinit(xtail, ytail, ax, ay, bx, by, a, b) {
      let bvirt, c, ahi, alo, bhi, blo, _i, _j, _k, _0, s1, s0, t1, t0, u3, negate;
      if (xtail === 0) {
          if (ytail === 0) {
              a[0] = 0;
              b[0] = 0;
              return 1;
          } else {
              negate = -ytail;
              s1 = negate * ax;
              c = splitter * negate;
              ahi = c - (c - negate);
              alo = negate - ahi;
              c = splitter * ax;
              bhi = c - (c - ax);
              blo = ax - bhi;
              a[0] = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
              a[1] = s1;
              s1 = ytail * bx;
              c = splitter * ytail;
              ahi = c - (c - ytail);
              alo = ytail - ahi;
              c = splitter * bx;
              bhi = c - (c - bx);
              blo = bx - bhi;
              b[0] = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
              b[1] = s1;
              return 2;
          }
      } else {
          if (ytail === 0) {
              s1 = xtail * ay;
              c = splitter * xtail;
              ahi = c - (c - xtail);
              alo = xtail - ahi;
              c = splitter * ay;
              bhi = c - (c - ay);
              blo = ay - bhi;
              a[0] = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
              a[1] = s1;
              negate = -xtail;
              s1 = negate * by;
              c = splitter * negate;
              ahi = c - (c - negate);
              alo = negate - ahi;
              c = splitter * by;
              bhi = c - (c - by);
              blo = by - bhi;
              b[0] = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
              b[1] = s1;
              return 2;
          } else {
              s1 = xtail * ay;
              c = splitter * xtail;
              ahi = c - (c - xtail);
              alo = xtail - ahi;
              c = splitter * ay;
              bhi = c - (c - ay);
              blo = ay - bhi;
              s0 = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
              t1 = ytail * ax;
              c = splitter * ytail;
              ahi = c - (c - ytail);
              alo = ytail - ahi;
              c = splitter * ax;
              bhi = c - (c - ax);
              blo = ax - bhi;
              t0 = alo * blo - (t1 - ahi * bhi - alo * bhi - ahi * blo);
              _i = s0 - t0;
              bvirt = s0 - _i;
              a[0] = s0 - (_i + bvirt) + (bvirt - t0);
              _j = s1 + _i;
              bvirt = _j - s1;
              _0 = s1 - (_j - bvirt) + (_i - bvirt);
              _i = _0 - t1;
              bvirt = _0 - _i;
              a[1] = _0 - (_i + bvirt) + (bvirt - t1);
              u3 = _j + _i;
              bvirt = u3 - _j;
              a[2] = _j - (u3 - bvirt) + (_i - bvirt);
              a[3] = u3;
              s1 = ytail * bx;
              c = splitter * ytail;
              ahi = c - (c - ytail);
              alo = ytail - ahi;
              c = splitter * bx;
              bhi = c - (c - bx);
              blo = bx - bhi;
              s0 = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
              t1 = xtail * by;
              c = splitter * xtail;
              ahi = c - (c - xtail);
              alo = xtail - ahi;
              c = splitter * by;
              bhi = c - (c - by);
              blo = by - bhi;
              t0 = alo * blo - (t1 - ahi * bhi - alo * bhi - ahi * blo);
              _i = s0 - t0;
              bvirt = s0 - _i;
              b[0] = s0 - (_i + bvirt) + (bvirt - t0);
              _j = s1 + _i;
              bvirt = _j - s1;
              _0 = s1 - (_j - bvirt) + (_i - bvirt);
              _i = _0 - t1;
              bvirt = _0 - _i;
              b[1] = _0 - (_i + bvirt) + (bvirt - t1);
              u3 = _j + _i;
              bvirt = u3 - _j;
              b[2] = _j - (u3 - bvirt) + (_i - bvirt);
              b[3] = u3;
              return 4;
          }
      }
  }

  function tailadd(finlen, a, b, k, z) {
      let bvirt, c, ahi, alo, bhi, blo, _i, _j, _k, _0, s1, s0, u3;
      s1 = a * b;
      c = splitter * a;
      ahi = c - (c - a);
      alo = a - ahi;
      c = splitter * b;
      bhi = c - (c - b);
      blo = b - bhi;
      s0 = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
      c = splitter * k;
      bhi = c - (c - k);
      blo = k - bhi;
      _i = s0 * k;
      c = splitter * s0;
      ahi = c - (c - s0);
      alo = s0 - ahi;
      u$1[0] = alo * blo - (_i - ahi * bhi - alo * bhi - ahi * blo);
      _j = s1 * k;
      c = splitter * s1;
      ahi = c - (c - s1);
      alo = s1 - ahi;
      _0 = alo * blo - (_j - ahi * bhi - alo * bhi - ahi * blo);
      _k = _i + _0;
      bvirt = _k - _i;
      u$1[1] = _i - (_k - bvirt) + (_0 - bvirt);
      u3 = _j + _k;
      u$1[2] = _k - (u3 - _j);
      u$1[3] = u3;
      finlen = finadd$1(finlen, 4, u$1);
      if (z !== 0) {
          c = splitter * z;
          bhi = c - (c - z);
          blo = z - bhi;
          _i = s0 * z;
          c = splitter * s0;
          ahi = c - (c - s0);
          alo = s0 - ahi;
          u$1[0] = alo * blo - (_i - ahi * bhi - alo * bhi - ahi * blo);
          _j = s1 * z;
          c = splitter * s1;
          ahi = c - (c - s1);
          alo = s1 - ahi;
          _0 = alo * blo - (_j - ahi * bhi - alo * bhi - ahi * blo);
          _k = _i + _0;
          bvirt = _k - _i;
          u$1[1] = _i - (_k - bvirt) + (_0 - bvirt);
          u3 = _j + _k;
          u$1[2] = _k - (u3 - _j);
          u$1[3] = u3;
          finlen = finadd$1(finlen, 4, u$1);
      }
      return finlen;
  }

  function orient3dadapt(ax, ay, az, bx, by, bz, cx, cy, cz, dx, dy, dz, permanent) {
      let finlen;
      let adxtail, bdxtail, cdxtail;
      let adytail, bdytail, cdytail;
      let adztail, bdztail, cdztail;
      let bvirt, c, ahi, alo, bhi, blo, _i, _j, _k, _0, s1, s0, t1, t0, u3;

      const adx = ax - dx;
      const bdx = bx - dx;
      const cdx = cx - dx;
      const ady = ay - dy;
      const bdy = by - dy;
      const cdy = cy - dy;
      const adz = az - dz;
      const bdz = bz - dz;
      const cdz = cz - dz;

      s1 = bdx * cdy;
      c = splitter * bdx;
      ahi = c - (c - bdx);
      alo = bdx - ahi;
      c = splitter * cdy;
      bhi = c - (c - cdy);
      blo = cdy - bhi;
      s0 = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
      t1 = cdx * bdy;
      c = splitter * cdx;
      ahi = c - (c - cdx);
      alo = cdx - ahi;
      c = splitter * bdy;
      bhi = c - (c - bdy);
      blo = bdy - bhi;
      t0 = alo * blo - (t1 - ahi * bhi - alo * bhi - ahi * blo);
      _i = s0 - t0;
      bvirt = s0 - _i;
      bc$2[0] = s0 - (_i + bvirt) + (bvirt - t0);
      _j = s1 + _i;
      bvirt = _j - s1;
      _0 = s1 - (_j - bvirt) + (_i - bvirt);
      _i = _0 - t1;
      bvirt = _0 - _i;
      bc$2[1] = _0 - (_i + bvirt) + (bvirt - t1);
      u3 = _j + _i;
      bvirt = u3 - _j;
      bc$2[2] = _j - (u3 - bvirt) + (_i - bvirt);
      bc$2[3] = u3;
      s1 = cdx * ady;
      c = splitter * cdx;
      ahi = c - (c - cdx);
      alo = cdx - ahi;
      c = splitter * ady;
      bhi = c - (c - ady);
      blo = ady - bhi;
      s0 = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
      t1 = adx * cdy;
      c = splitter * adx;
      ahi = c - (c - adx);
      alo = adx - ahi;
      c = splitter * cdy;
      bhi = c - (c - cdy);
      blo = cdy - bhi;
      t0 = alo * blo - (t1 - ahi * bhi - alo * bhi - ahi * blo);
      _i = s0 - t0;
      bvirt = s0 - _i;
      ca$1[0] = s0 - (_i + bvirt) + (bvirt - t0);
      _j = s1 + _i;
      bvirt = _j - s1;
      _0 = s1 - (_j - bvirt) + (_i - bvirt);
      _i = _0 - t1;
      bvirt = _0 - _i;
      ca$1[1] = _0 - (_i + bvirt) + (bvirt - t1);
      u3 = _j + _i;
      bvirt = u3 - _j;
      ca$1[2] = _j - (u3 - bvirt) + (_i - bvirt);
      ca$1[3] = u3;
      s1 = adx * bdy;
      c = splitter * adx;
      ahi = c - (c - adx);
      alo = adx - ahi;
      c = splitter * bdy;
      bhi = c - (c - bdy);
      blo = bdy - bhi;
      s0 = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
      t1 = bdx * ady;
      c = splitter * bdx;
      ahi = c - (c - bdx);
      alo = bdx - ahi;
      c = splitter * ady;
      bhi = c - (c - ady);
      blo = ady - bhi;
      t0 = alo * blo - (t1 - ahi * bhi - alo * bhi - ahi * blo);
      _i = s0 - t0;
      bvirt = s0 - _i;
      ab$2[0] = s0 - (_i + bvirt) + (bvirt - t0);
      _j = s1 + _i;
      bvirt = _j - s1;
      _0 = s1 - (_j - bvirt) + (_i - bvirt);
      _i = _0 - t1;
      bvirt = _0 - _i;
      ab$2[1] = _0 - (_i + bvirt) + (bvirt - t1);
      u3 = _j + _i;
      bvirt = u3 - _j;
      ab$2[2] = _j - (u3 - bvirt) + (_i - bvirt);
      ab$2[3] = u3;

      finlen = sum(
          sum(
              scale(4, bc$2, adz, _8$2), _8$2,
              scale(4, ca$1, bdz, _8b$1), _8b$1, _16$2), _16$2,
          scale(4, ab$2, cdz, _8$2), _8$2, fin$2);

      let det = estimate(finlen, fin$2);
      let errbound = o3derrboundB * permanent;
      if (det >= errbound || -det >= errbound) {
          return det;
      }

      bvirt = ax - adx;
      adxtail = ax - (adx + bvirt) + (bvirt - dx);
      bvirt = bx - bdx;
      bdxtail = bx - (bdx + bvirt) + (bvirt - dx);
      bvirt = cx - cdx;
      cdxtail = cx - (cdx + bvirt) + (bvirt - dx);
      bvirt = ay - ady;
      adytail = ay - (ady + bvirt) + (bvirt - dy);
      bvirt = by - bdy;
      bdytail = by - (bdy + bvirt) + (bvirt - dy);
      bvirt = cy - cdy;
      cdytail = cy - (cdy + bvirt) + (bvirt - dy);
      bvirt = az - adz;
      adztail = az - (adz + bvirt) + (bvirt - dz);
      bvirt = bz - bdz;
      bdztail = bz - (bdz + bvirt) + (bvirt - dz);
      bvirt = cz - cdz;
      cdztail = cz - (cdz + bvirt) + (bvirt - dz);

      if (adxtail === 0 && bdxtail === 0 && cdxtail === 0 &&
          adytail === 0 && bdytail === 0 && cdytail === 0 &&
          adztail === 0 && bdztail === 0 && cdztail === 0) {
          return det;
      }

      errbound = o3derrboundC * permanent + resulterrbound * Math.abs(det);
      det +=
          adz * (bdx * cdytail + cdy * bdxtail - (bdy * cdxtail + cdx * bdytail)) + adztail * (bdx * cdy - bdy * cdx) +
          bdz * (cdx * adytail + ady * cdxtail - (cdy * adxtail + adx * cdytail)) + bdztail * (cdx * ady - cdy * adx) +
          cdz * (adx * bdytail + bdy * adxtail - (ady * bdxtail + bdx * adytail)) + cdztail * (adx * bdy - ady * bdx);
      if (det >= errbound || -det >= errbound) {
          return det;
      }

      const at_len = tailinit(adxtail, adytail, bdx, bdy, cdx, cdy, at_b, at_c);
      const bt_len = tailinit(bdxtail, bdytail, cdx, cdy, adx, ady, bt_c, bt_a);
      const ct_len = tailinit(cdxtail, cdytail, adx, ady, bdx, bdy, ct_a, ct_b);

      const bctlen = sum(bt_len, bt_c, ct_len, ct_b, bct$1);
      finlen = finadd$1(finlen, scale(bctlen, bct$1, adz, _16$2), _16$2);

      const catlen = sum(ct_len, ct_a, at_len, at_c, cat$1);
      finlen = finadd$1(finlen, scale(catlen, cat$1, bdz, _16$2), _16$2);

      const abtlen = sum(at_len, at_b, bt_len, bt_a, abt$1);
      finlen = finadd$1(finlen, scale(abtlen, abt$1, cdz, _16$2), _16$2);

      if (adztail !== 0) {
          finlen = finadd$1(finlen, scale(4, bc$2, adztail, _12), _12);
          finlen = finadd$1(finlen, scale(bctlen, bct$1, adztail, _16$2), _16$2);
      }
      if (bdztail !== 0) {
          finlen = finadd$1(finlen, scale(4, ca$1, bdztail, _12), _12);
          finlen = finadd$1(finlen, scale(catlen, cat$1, bdztail, _16$2), _16$2);
      }
      if (cdztail !== 0) {
          finlen = finadd$1(finlen, scale(4, ab$2, cdztail, _12), _12);
          finlen = finadd$1(finlen, scale(abtlen, abt$1, cdztail, _16$2), _16$2);
      }

      if (adxtail !== 0) {
          if (bdytail !== 0) {
              finlen = tailadd(finlen, adxtail, bdytail, cdz, cdztail);
          }
          if (cdytail !== 0) {
              finlen = tailadd(finlen, -adxtail, cdytail, bdz, bdztail);
          }
      }
      if (bdxtail !== 0) {
          if (cdytail !== 0) {
              finlen = tailadd(finlen, bdxtail, cdytail, adz, adztail);
          }
          if (adytail !== 0) {
              finlen = tailadd(finlen, -bdxtail, adytail, cdz, cdztail);
          }
      }
      if (cdxtail !== 0) {
          if (adytail !== 0) {
              finlen = tailadd(finlen, cdxtail, adytail, bdz, bdztail);
          }
          if (bdytail !== 0) {
              finlen = tailadd(finlen, -cdxtail, bdytail, adz, adztail);
          }
      }

      return fin$2[finlen - 1];
  }

  function orient3d(ax, ay, az, bx, by, bz, cx, cy, cz, dx, dy, dz) {
      const adx = ax - dx;
      const bdx = bx - dx;
      const cdx = cx - dx;
      const ady = ay - dy;
      const bdy = by - dy;
      const cdy = cy - dy;
      const adz = az - dz;
      const bdz = bz - dz;
      const cdz = cz - dz;

      const bdxcdy = bdx * cdy;
      const cdxbdy = cdx * bdy;

      const cdxady = cdx * ady;
      const adxcdy = adx * cdy;

      const adxbdy = adx * bdy;
      const bdxady = bdx * ady;

      const det =
          adz * (bdxcdy - cdxbdy) +
          bdz * (cdxady - adxcdy) +
          cdz * (adxbdy - bdxady);

      const permanent =
          (Math.abs(bdxcdy) + Math.abs(cdxbdy)) * Math.abs(adz) +
          (Math.abs(cdxady) + Math.abs(adxcdy)) * Math.abs(bdz) +
          (Math.abs(adxbdy) + Math.abs(bdxady)) * Math.abs(cdz);

      const errbound = o3derrboundA * permanent;
      if (det > errbound || -det > errbound) {
          return det;
      }

      return orient3dadapt(ax, ay, az, bx, by, bz, cx, cy, cz, dx, dy, dz, permanent);
  }

  function orient3dfast(ax, ay, az, bx, by, bz, cx, cy, cz, dx, dy, dz) {
      const adx = ax - dx;
      const bdx = bx - dx;
      const cdx = cx - dx;
      const ady = ay - dy;
      const bdy = by - dy;
      const cdy = cy - dy;
      const adz = az - dz;
      const bdz = bz - dz;
      const cdz = cz - dz;

      return adx * (bdy * cdz - bdz * cdy) +
          bdx * (cdy * adz - cdz * ady) +
          cdx * (ady * bdz - adz * bdy);
  }

  const iccerrboundA = (10 + 96 * epsilon) * epsilon;
  const iccerrboundB = (4 + 48 * epsilon) * epsilon;
  const iccerrboundC = (44 + 576 * epsilon) * epsilon * epsilon;

  const bc$1 = vec(4);
  const ca = vec(4);
  const ab$1 = vec(4);
  const aa = vec(4);
  const bb = vec(4);
  const cc = vec(4);
  const u = vec(4);
  const v = vec(4);
  const axtbc = vec(8);
  const aytbc = vec(8);
  const bxtca = vec(8);
  const bytca = vec(8);
  const cxtab = vec(8);
  const cytab = vec(8);
  const abt = vec(8);
  const bct = vec(8);
  const cat = vec(8);
  const abtt = vec(4);
  const bctt = vec(4);
  const catt = vec(4);

  const _8$1 = vec(8);
  const _16$1 = vec(16);
  const _16b = vec(16);
  const _16c = vec(16);
  const _32 = vec(32);
  const _32b = vec(32);
  const _48$1 = vec(48);
  const _64 = vec(64);

  let fin$1 = vec(1152);
  let fin2 = vec(1152);

  function finadd(finlen, a, alen) {
      finlen = sum(finlen, fin$1, a, alen, fin2);
      const tmp = fin$1; fin$1 = fin2; fin2 = tmp;
      return finlen;
  }

  function incircleadapt(ax, ay, bx, by, cx, cy, dx, dy, permanent) {
      let finlen;
      let adxtail, bdxtail, cdxtail, adytail, bdytail, cdytail;
      let axtbclen, aytbclen, bxtcalen, bytcalen, cxtablen, cytablen;
      let abtlen, bctlen, catlen;
      let abttlen, bcttlen, cattlen;
      let n1, n0;

      let bvirt, c, ahi, alo, bhi, blo, _i, _j, _0, s1, s0, t1, t0, u3;

      const adx = ax - dx;
      const bdx = bx - dx;
      const cdx = cx - dx;
      const ady = ay - dy;
      const bdy = by - dy;
      const cdy = cy - dy;

      s1 = bdx * cdy;
      c = splitter * bdx;
      ahi = c - (c - bdx);
      alo = bdx - ahi;
      c = splitter * cdy;
      bhi = c - (c - cdy);
      blo = cdy - bhi;
      s0 = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
      t1 = cdx * bdy;
      c = splitter * cdx;
      ahi = c - (c - cdx);
      alo = cdx - ahi;
      c = splitter * bdy;
      bhi = c - (c - bdy);
      blo = bdy - bhi;
      t0 = alo * blo - (t1 - ahi * bhi - alo * bhi - ahi * blo);
      _i = s0 - t0;
      bvirt = s0 - _i;
      bc$1[0] = s0 - (_i + bvirt) + (bvirt - t0);
      _j = s1 + _i;
      bvirt = _j - s1;
      _0 = s1 - (_j - bvirt) + (_i - bvirt);
      _i = _0 - t1;
      bvirt = _0 - _i;
      bc$1[1] = _0 - (_i + bvirt) + (bvirt - t1);
      u3 = _j + _i;
      bvirt = u3 - _j;
      bc$1[2] = _j - (u3 - bvirt) + (_i - bvirt);
      bc$1[3] = u3;
      s1 = cdx * ady;
      c = splitter * cdx;
      ahi = c - (c - cdx);
      alo = cdx - ahi;
      c = splitter * ady;
      bhi = c - (c - ady);
      blo = ady - bhi;
      s0 = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
      t1 = adx * cdy;
      c = splitter * adx;
      ahi = c - (c - adx);
      alo = adx - ahi;
      c = splitter * cdy;
      bhi = c - (c - cdy);
      blo = cdy - bhi;
      t0 = alo * blo - (t1 - ahi * bhi - alo * bhi - ahi * blo);
      _i = s0 - t0;
      bvirt = s0 - _i;
      ca[0] = s0 - (_i + bvirt) + (bvirt - t0);
      _j = s1 + _i;
      bvirt = _j - s1;
      _0 = s1 - (_j - bvirt) + (_i - bvirt);
      _i = _0 - t1;
      bvirt = _0 - _i;
      ca[1] = _0 - (_i + bvirt) + (bvirt - t1);
      u3 = _j + _i;
      bvirt = u3 - _j;
      ca[2] = _j - (u3 - bvirt) + (_i - bvirt);
      ca[3] = u3;
      s1 = adx * bdy;
      c = splitter * adx;
      ahi = c - (c - adx);
      alo = adx - ahi;
      c = splitter * bdy;
      bhi = c - (c - bdy);
      blo = bdy - bhi;
      s0 = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
      t1 = bdx * ady;
      c = splitter * bdx;
      ahi = c - (c - bdx);
      alo = bdx - ahi;
      c = splitter * ady;
      bhi = c - (c - ady);
      blo = ady - bhi;
      t0 = alo * blo - (t1 - ahi * bhi - alo * bhi - ahi * blo);
      _i = s0 - t0;
      bvirt = s0 - _i;
      ab$1[0] = s0 - (_i + bvirt) + (bvirt - t0);
      _j = s1 + _i;
      bvirt = _j - s1;
      _0 = s1 - (_j - bvirt) + (_i - bvirt);
      _i = _0 - t1;
      bvirt = _0 - _i;
      ab$1[1] = _0 - (_i + bvirt) + (bvirt - t1);
      u3 = _j + _i;
      bvirt = u3 - _j;
      ab$1[2] = _j - (u3 - bvirt) + (_i - bvirt);
      ab$1[3] = u3;

      finlen = sum(
          sum(
              sum(
                  scale(scale(4, bc$1, adx, _8$1), _8$1, adx, _16$1), _16$1,
                  scale(scale(4, bc$1, ady, _8$1), _8$1, ady, _16b), _16b, _32), _32,
              sum(
                  scale(scale(4, ca, bdx, _8$1), _8$1, bdx, _16$1), _16$1,
                  scale(scale(4, ca, bdy, _8$1), _8$1, bdy, _16b), _16b, _32b), _32b, _64), _64,
          sum(
              scale(scale(4, ab$1, cdx, _8$1), _8$1, cdx, _16$1), _16$1,
              scale(scale(4, ab$1, cdy, _8$1), _8$1, cdy, _16b), _16b, _32), _32, fin$1);

      let det = estimate(finlen, fin$1);
      let errbound = iccerrboundB * permanent;
      if (det >= errbound || -det >= errbound) {
          return det;
      }

      bvirt = ax - adx;
      adxtail = ax - (adx + bvirt) + (bvirt - dx);
      bvirt = ay - ady;
      adytail = ay - (ady + bvirt) + (bvirt - dy);
      bvirt = bx - bdx;
      bdxtail = bx - (bdx + bvirt) + (bvirt - dx);
      bvirt = by - bdy;
      bdytail = by - (bdy + bvirt) + (bvirt - dy);
      bvirt = cx - cdx;
      cdxtail = cx - (cdx + bvirt) + (bvirt - dx);
      bvirt = cy - cdy;
      cdytail = cy - (cdy + bvirt) + (bvirt - dy);
      if (adxtail === 0 && bdxtail === 0 && cdxtail === 0 && adytail === 0 && bdytail === 0 && cdytail === 0) {
          return det;
      }

      errbound = iccerrboundC * permanent + resulterrbound * Math.abs(det);
      det += ((adx * adx + ady * ady) * ((bdx * cdytail + cdy * bdxtail) - (bdy * cdxtail + cdx * bdytail)) +
          2 * (adx * adxtail + ady * adytail) * (bdx * cdy - bdy * cdx)) +
          ((bdx * bdx + bdy * bdy) * ((cdx * adytail + ady * cdxtail) - (cdy * adxtail + adx * cdytail)) +
          2 * (bdx * bdxtail + bdy * bdytail) * (cdx * ady - cdy * adx)) +
          ((cdx * cdx + cdy * cdy) * ((adx * bdytail + bdy * adxtail) - (ady * bdxtail + bdx * adytail)) +
          2 * (cdx * cdxtail + cdy * cdytail) * (adx * bdy - ady * bdx));

      if (det >= errbound || -det >= errbound) {
          return det;
      }

      if (bdxtail !== 0 || bdytail !== 0 || cdxtail !== 0 || cdytail !== 0) {
          s1 = adx * adx;
          c = splitter * adx;
          ahi = c - (c - adx);
          alo = adx - ahi;
          s0 = alo * alo - (s1 - ahi * ahi - (ahi + ahi) * alo);
          t1 = ady * ady;
          c = splitter * ady;
          ahi = c - (c - ady);
          alo = ady - ahi;
          t0 = alo * alo - (t1 - ahi * ahi - (ahi + ahi) * alo);
          _i = s0 + t0;
          bvirt = _i - s0;
          aa[0] = s0 - (_i - bvirt) + (t0 - bvirt);
          _j = s1 + _i;
          bvirt = _j - s1;
          _0 = s1 - (_j - bvirt) + (_i - bvirt);
          _i = _0 + t1;
          bvirt = _i - _0;
          aa[1] = _0 - (_i - bvirt) + (t1 - bvirt);
          u3 = _j + _i;
          bvirt = u3 - _j;
          aa[2] = _j - (u3 - bvirt) + (_i - bvirt);
          aa[3] = u3;
      }
      if (cdxtail !== 0 || cdytail !== 0 || adxtail !== 0 || adytail !== 0) {
          s1 = bdx * bdx;
          c = splitter * bdx;
          ahi = c - (c - bdx);
          alo = bdx - ahi;
          s0 = alo * alo - (s1 - ahi * ahi - (ahi + ahi) * alo);
          t1 = bdy * bdy;
          c = splitter * bdy;
          ahi = c - (c - bdy);
          alo = bdy - ahi;
          t0 = alo * alo - (t1 - ahi * ahi - (ahi + ahi) * alo);
          _i = s0 + t0;
          bvirt = _i - s0;
          bb[0] = s0 - (_i - bvirt) + (t0 - bvirt);
          _j = s1 + _i;
          bvirt = _j - s1;
          _0 = s1 - (_j - bvirt) + (_i - bvirt);
          _i = _0 + t1;
          bvirt = _i - _0;
          bb[1] = _0 - (_i - bvirt) + (t1 - bvirt);
          u3 = _j + _i;
          bvirt = u3 - _j;
          bb[2] = _j - (u3 - bvirt) + (_i - bvirt);
          bb[3] = u3;
      }
      if (adxtail !== 0 || adytail !== 0 || bdxtail !== 0 || bdytail !== 0) {
          s1 = cdx * cdx;
          c = splitter * cdx;
          ahi = c - (c - cdx);
          alo = cdx - ahi;
          s0 = alo * alo - (s1 - ahi * ahi - (ahi + ahi) * alo);
          t1 = cdy * cdy;
          c = splitter * cdy;
          ahi = c - (c - cdy);
          alo = cdy - ahi;
          t0 = alo * alo - (t1 - ahi * ahi - (ahi + ahi) * alo);
          _i = s0 + t0;
          bvirt = _i - s0;
          cc[0] = s0 - (_i - bvirt) + (t0 - bvirt);
          _j = s1 + _i;
          bvirt = _j - s1;
          _0 = s1 - (_j - bvirt) + (_i - bvirt);
          _i = _0 + t1;
          bvirt = _i - _0;
          cc[1] = _0 - (_i - bvirt) + (t1 - bvirt);
          u3 = _j + _i;
          bvirt = u3 - _j;
          cc[2] = _j - (u3 - bvirt) + (_i - bvirt);
          cc[3] = u3;
      }

      if (adxtail !== 0) {
          axtbclen = scale(4, bc$1, adxtail, axtbc);
          finlen = finadd(finlen, sum_three(
              scale(axtbclen, axtbc, 2 * adx, _16$1), _16$1,
              scale(scale(4, cc, adxtail, _8$1), _8$1, bdy, _16b), _16b,
              scale(scale(4, bb, adxtail, _8$1), _8$1, -cdy, _16c), _16c, _32, _48$1), _48$1);
      }
      if (adytail !== 0) {
          aytbclen = scale(4, bc$1, adytail, aytbc);
          finlen = finadd(finlen, sum_three(
              scale(aytbclen, aytbc, 2 * ady, _16$1), _16$1,
              scale(scale(4, bb, adytail, _8$1), _8$1, cdx, _16b), _16b,
              scale(scale(4, cc, adytail, _8$1), _8$1, -bdx, _16c), _16c, _32, _48$1), _48$1);
      }
      if (bdxtail !== 0) {
          bxtcalen = scale(4, ca, bdxtail, bxtca);
          finlen = finadd(finlen, sum_three(
              scale(bxtcalen, bxtca, 2 * bdx, _16$1), _16$1,
              scale(scale(4, aa, bdxtail, _8$1), _8$1, cdy, _16b), _16b,
              scale(scale(4, cc, bdxtail, _8$1), _8$1, -ady, _16c), _16c, _32, _48$1), _48$1);
      }
      if (bdytail !== 0) {
          bytcalen = scale(4, ca, bdytail, bytca);
          finlen = finadd(finlen, sum_three(
              scale(bytcalen, bytca, 2 * bdy, _16$1), _16$1,
              scale(scale(4, cc, bdytail, _8$1), _8$1, adx, _16b), _16b,
              scale(scale(4, aa, bdytail, _8$1), _8$1, -cdx, _16c), _16c, _32, _48$1), _48$1);
      }
      if (cdxtail !== 0) {
          cxtablen = scale(4, ab$1, cdxtail, cxtab);
          finlen = finadd(finlen, sum_three(
              scale(cxtablen, cxtab, 2 * cdx, _16$1), _16$1,
              scale(scale(4, bb, cdxtail, _8$1), _8$1, ady, _16b), _16b,
              scale(scale(4, aa, cdxtail, _8$1), _8$1, -bdy, _16c), _16c, _32, _48$1), _48$1);
      }
      if (cdytail !== 0) {
          cytablen = scale(4, ab$1, cdytail, cytab);
          finlen = finadd(finlen, sum_three(
              scale(cytablen, cytab, 2 * cdy, _16$1), _16$1,
              scale(scale(4, aa, cdytail, _8$1), _8$1, bdx, _16b), _16b,
              scale(scale(4, bb, cdytail, _8$1), _8$1, -adx, _16c), _16c, _32, _48$1), _48$1);
      }

      if (adxtail !== 0 || adytail !== 0) {
          if (bdxtail !== 0 || bdytail !== 0 || cdxtail !== 0 || cdytail !== 0) {
              s1 = bdxtail * cdy;
              c = splitter * bdxtail;
              ahi = c - (c - bdxtail);
              alo = bdxtail - ahi;
              c = splitter * cdy;
              bhi = c - (c - cdy);
              blo = cdy - bhi;
              s0 = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
              t1 = bdx * cdytail;
              c = splitter * bdx;
              ahi = c - (c - bdx);
              alo = bdx - ahi;
              c = splitter * cdytail;
              bhi = c - (c - cdytail);
              blo = cdytail - bhi;
              t0 = alo * blo - (t1 - ahi * bhi - alo * bhi - ahi * blo);
              _i = s0 + t0;
              bvirt = _i - s0;
              u[0] = s0 - (_i - bvirt) + (t0 - bvirt);
              _j = s1 + _i;
              bvirt = _j - s1;
              _0 = s1 - (_j - bvirt) + (_i - bvirt);
              _i = _0 + t1;
              bvirt = _i - _0;
              u[1] = _0 - (_i - bvirt) + (t1 - bvirt);
              u3 = _j + _i;
              bvirt = u3 - _j;
              u[2] = _j - (u3 - bvirt) + (_i - bvirt);
              u[3] = u3;
              s1 = cdxtail * -bdy;
              c = splitter * cdxtail;
              ahi = c - (c - cdxtail);
              alo = cdxtail - ahi;
              c = splitter * -bdy;
              bhi = c - (c - -bdy);
              blo = -bdy - bhi;
              s0 = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
              t1 = cdx * -bdytail;
              c = splitter * cdx;
              ahi = c - (c - cdx);
              alo = cdx - ahi;
              c = splitter * -bdytail;
              bhi = c - (c - -bdytail);
              blo = -bdytail - bhi;
              t0 = alo * blo - (t1 - ahi * bhi - alo * bhi - ahi * blo);
              _i = s0 + t0;
              bvirt = _i - s0;
              v[0] = s0 - (_i - bvirt) + (t0 - bvirt);
              _j = s1 + _i;
              bvirt = _j - s1;
              _0 = s1 - (_j - bvirt) + (_i - bvirt);
              _i = _0 + t1;
              bvirt = _i - _0;
              v[1] = _0 - (_i - bvirt) + (t1 - bvirt);
              u3 = _j + _i;
              bvirt = u3 - _j;
              v[2] = _j - (u3 - bvirt) + (_i - bvirt);
              v[3] = u3;
              bctlen = sum(4, u, 4, v, bct);
              s1 = bdxtail * cdytail;
              c = splitter * bdxtail;
              ahi = c - (c - bdxtail);
              alo = bdxtail - ahi;
              c = splitter * cdytail;
              bhi = c - (c - cdytail);
              blo = cdytail - bhi;
              s0 = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
              t1 = cdxtail * bdytail;
              c = splitter * cdxtail;
              ahi = c - (c - cdxtail);
              alo = cdxtail - ahi;
              c = splitter * bdytail;
              bhi = c - (c - bdytail);
              blo = bdytail - bhi;
              t0 = alo * blo - (t1 - ahi * bhi - alo * bhi - ahi * blo);
              _i = s0 - t0;
              bvirt = s0 - _i;
              bctt[0] = s0 - (_i + bvirt) + (bvirt - t0);
              _j = s1 + _i;
              bvirt = _j - s1;
              _0 = s1 - (_j - bvirt) + (_i - bvirt);
              _i = _0 - t1;
              bvirt = _0 - _i;
              bctt[1] = _0 - (_i + bvirt) + (bvirt - t1);
              u3 = _j + _i;
              bvirt = u3 - _j;
              bctt[2] = _j - (u3 - bvirt) + (_i - bvirt);
              bctt[3] = u3;
              bcttlen = 4;
          } else {
              bct[0] = 0;
              bctlen = 1;
              bctt[0] = 0;
              bcttlen = 1;
          }
          if (adxtail !== 0) {
              const len = scale(bctlen, bct, adxtail, _16c);
              finlen = finadd(finlen, sum(
                  scale(axtbclen, axtbc, adxtail, _16$1), _16$1,
                  scale(len, _16c, 2 * adx, _32), _32, _48$1), _48$1);

              const len2 = scale(bcttlen, bctt, adxtail, _8$1);
              finlen = finadd(finlen, sum_three(
                  scale(len2, _8$1, 2 * adx, _16$1), _16$1,
                  scale(len2, _8$1, adxtail, _16b), _16b,
                  scale(len, _16c, adxtail, _32), _32, _32b, _64), _64);

              if (bdytail !== 0) {
                  finlen = finadd(finlen, scale(scale(4, cc, adxtail, _8$1), _8$1, bdytail, _16$1), _16$1);
              }
              if (cdytail !== 0) {
                  finlen = finadd(finlen, scale(scale(4, bb, -adxtail, _8$1), _8$1, cdytail, _16$1), _16$1);
              }
          }
          if (adytail !== 0) {
              const len = scale(bctlen, bct, adytail, _16c);
              finlen = finadd(finlen, sum(
                  scale(aytbclen, aytbc, adytail, _16$1), _16$1,
                  scale(len, _16c, 2 * ady, _32), _32, _48$1), _48$1);

              const len2 = scale(bcttlen, bctt, adytail, _8$1);
              finlen = finadd(finlen, sum_three(
                  scale(len2, _8$1, 2 * ady, _16$1), _16$1,
                  scale(len2, _8$1, adytail, _16b), _16b,
                  scale(len, _16c, adytail, _32), _32, _32b, _64), _64);
          }
      }
      if (bdxtail !== 0 || bdytail !== 0) {
          if (cdxtail !== 0 || cdytail !== 0 || adxtail !== 0 || adytail !== 0) {
              s1 = cdxtail * ady;
              c = splitter * cdxtail;
              ahi = c - (c - cdxtail);
              alo = cdxtail - ahi;
              c = splitter * ady;
              bhi = c - (c - ady);
              blo = ady - bhi;
              s0 = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
              t1 = cdx * adytail;
              c = splitter * cdx;
              ahi = c - (c - cdx);
              alo = cdx - ahi;
              c = splitter * adytail;
              bhi = c - (c - adytail);
              blo = adytail - bhi;
              t0 = alo * blo - (t1 - ahi * bhi - alo * bhi - ahi * blo);
              _i = s0 + t0;
              bvirt = _i - s0;
              u[0] = s0 - (_i - bvirt) + (t0 - bvirt);
              _j = s1 + _i;
              bvirt = _j - s1;
              _0 = s1 - (_j - bvirt) + (_i - bvirt);
              _i = _0 + t1;
              bvirt = _i - _0;
              u[1] = _0 - (_i - bvirt) + (t1 - bvirt);
              u3 = _j + _i;
              bvirt = u3 - _j;
              u[2] = _j - (u3 - bvirt) + (_i - bvirt);
              u[3] = u3;
              n1 = -cdy;
              n0 = -cdytail;
              s1 = adxtail * n1;
              c = splitter * adxtail;
              ahi = c - (c - adxtail);
              alo = adxtail - ahi;
              c = splitter * n1;
              bhi = c - (c - n1);
              blo = n1 - bhi;
              s0 = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
              t1 = adx * n0;
              c = splitter * adx;
              ahi = c - (c - adx);
              alo = adx - ahi;
              c = splitter * n0;
              bhi = c - (c - n0);
              blo = n0 - bhi;
              t0 = alo * blo - (t1 - ahi * bhi - alo * bhi - ahi * blo);
              _i = s0 + t0;
              bvirt = _i - s0;
              v[0] = s0 - (_i - bvirt) + (t0 - bvirt);
              _j = s1 + _i;
              bvirt = _j - s1;
              _0 = s1 - (_j - bvirt) + (_i - bvirt);
              _i = _0 + t1;
              bvirt = _i - _0;
              v[1] = _0 - (_i - bvirt) + (t1 - bvirt);
              u3 = _j + _i;
              bvirt = u3 - _j;
              v[2] = _j - (u3 - bvirt) + (_i - bvirt);
              v[3] = u3;
              catlen = sum(4, u, 4, v, cat);
              s1 = cdxtail * adytail;
              c = splitter * cdxtail;
              ahi = c - (c - cdxtail);
              alo = cdxtail - ahi;
              c = splitter * adytail;
              bhi = c - (c - adytail);
              blo = adytail - bhi;
              s0 = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
              t1 = adxtail * cdytail;
              c = splitter * adxtail;
              ahi = c - (c - adxtail);
              alo = adxtail - ahi;
              c = splitter * cdytail;
              bhi = c - (c - cdytail);
              blo = cdytail - bhi;
              t0 = alo * blo - (t1 - ahi * bhi - alo * bhi - ahi * blo);
              _i = s0 - t0;
              bvirt = s0 - _i;
              catt[0] = s0 - (_i + bvirt) + (bvirt - t0);
              _j = s1 + _i;
              bvirt = _j - s1;
              _0 = s1 - (_j - bvirt) + (_i - bvirt);
              _i = _0 - t1;
              bvirt = _0 - _i;
              catt[1] = _0 - (_i + bvirt) + (bvirt - t1);
              u3 = _j + _i;
              bvirt = u3 - _j;
              catt[2] = _j - (u3 - bvirt) + (_i - bvirt);
              catt[3] = u3;
              cattlen = 4;
          } else {
              cat[0] = 0;
              catlen = 1;
              catt[0] = 0;
              cattlen = 1;
          }
          if (bdxtail !== 0) {
              const len = scale(catlen, cat, bdxtail, _16c);
              finlen = finadd(finlen, sum(
                  scale(bxtcalen, bxtca, bdxtail, _16$1), _16$1,
                  scale(len, _16c, 2 * bdx, _32), _32, _48$1), _48$1);

              const len2 = scale(cattlen, catt, bdxtail, _8$1);
              finlen = finadd(finlen, sum_three(
                  scale(len2, _8$1, 2 * bdx, _16$1), _16$1,
                  scale(len2, _8$1, bdxtail, _16b), _16b,
                  scale(len, _16c, bdxtail, _32), _32, _32b, _64), _64);

              if (cdytail !== 0) {
                  finlen = finadd(finlen, scale(scale(4, aa, bdxtail, _8$1), _8$1, cdytail, _16$1), _16$1);
              }
              if (adytail !== 0) {
                  finlen = finadd(finlen, scale(scale(4, cc, -bdxtail, _8$1), _8$1, adytail, _16$1), _16$1);
              }
          }
          if (bdytail !== 0) {
              const len = scale(catlen, cat, bdytail, _16c);
              finlen = finadd(finlen, sum(
                  scale(bytcalen, bytca, bdytail, _16$1), _16$1,
                  scale(len, _16c, 2 * bdy, _32), _32, _48$1), _48$1);

              const len2 = scale(cattlen, catt, bdytail, _8$1);
              finlen = finadd(finlen, sum_three(
                  scale(len2, _8$1, 2 * bdy, _16$1), _16$1,
                  scale(len2, _8$1, bdytail, _16b), _16b,
                  scale(len, _16c, bdytail, _32), _32,  _32b, _64), _64);
          }
      }
      if (cdxtail !== 0 || cdytail !== 0) {
          if (adxtail !== 0 || adytail !== 0 || bdxtail !== 0 || bdytail !== 0) {
              s1 = adxtail * bdy;
              c = splitter * adxtail;
              ahi = c - (c - adxtail);
              alo = adxtail - ahi;
              c = splitter * bdy;
              bhi = c - (c - bdy);
              blo = bdy - bhi;
              s0 = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
              t1 = adx * bdytail;
              c = splitter * adx;
              ahi = c - (c - adx);
              alo = adx - ahi;
              c = splitter * bdytail;
              bhi = c - (c - bdytail);
              blo = bdytail - bhi;
              t0 = alo * blo - (t1 - ahi * bhi - alo * bhi - ahi * blo);
              _i = s0 + t0;
              bvirt = _i - s0;
              u[0] = s0 - (_i - bvirt) + (t0 - bvirt);
              _j = s1 + _i;
              bvirt = _j - s1;
              _0 = s1 - (_j - bvirt) + (_i - bvirt);
              _i = _0 + t1;
              bvirt = _i - _0;
              u[1] = _0 - (_i - bvirt) + (t1 - bvirt);
              u3 = _j + _i;
              bvirt = u3 - _j;
              u[2] = _j - (u3 - bvirt) + (_i - bvirt);
              u[3] = u3;
              n1 = -ady;
              n0 = -adytail;
              s1 = bdxtail * n1;
              c = splitter * bdxtail;
              ahi = c - (c - bdxtail);
              alo = bdxtail - ahi;
              c = splitter * n1;
              bhi = c - (c - n1);
              blo = n1 - bhi;
              s0 = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
              t1 = bdx * n0;
              c = splitter * bdx;
              ahi = c - (c - bdx);
              alo = bdx - ahi;
              c = splitter * n0;
              bhi = c - (c - n0);
              blo = n0 - bhi;
              t0 = alo * blo - (t1 - ahi * bhi - alo * bhi - ahi * blo);
              _i = s0 + t0;
              bvirt = _i - s0;
              v[0] = s0 - (_i - bvirt) + (t0 - bvirt);
              _j = s1 + _i;
              bvirt = _j - s1;
              _0 = s1 - (_j - bvirt) + (_i - bvirt);
              _i = _0 + t1;
              bvirt = _i - _0;
              v[1] = _0 - (_i - bvirt) + (t1 - bvirt);
              u3 = _j + _i;
              bvirt = u3 - _j;
              v[2] = _j - (u3 - bvirt) + (_i - bvirt);
              v[3] = u3;
              abtlen = sum(4, u, 4, v, abt);
              s1 = adxtail * bdytail;
              c = splitter * adxtail;
              ahi = c - (c - adxtail);
              alo = adxtail - ahi;
              c = splitter * bdytail;
              bhi = c - (c - bdytail);
              blo = bdytail - bhi;
              s0 = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
              t1 = bdxtail * adytail;
              c = splitter * bdxtail;
              ahi = c - (c - bdxtail);
              alo = bdxtail - ahi;
              c = splitter * adytail;
              bhi = c - (c - adytail);
              blo = adytail - bhi;
              t0 = alo * blo - (t1 - ahi * bhi - alo * bhi - ahi * blo);
              _i = s0 - t0;
              bvirt = s0 - _i;
              abtt[0] = s0 - (_i + bvirt) + (bvirt - t0);
              _j = s1 + _i;
              bvirt = _j - s1;
              _0 = s1 - (_j - bvirt) + (_i - bvirt);
              _i = _0 - t1;
              bvirt = _0 - _i;
              abtt[1] = _0 - (_i + bvirt) + (bvirt - t1);
              u3 = _j + _i;
              bvirt = u3 - _j;
              abtt[2] = _j - (u3 - bvirt) + (_i - bvirt);
              abtt[3] = u3;
              abttlen = 4;
          } else {
              abt[0] = 0;
              abtlen = 1;
              abtt[0] = 0;
              abttlen = 1;
          }
          if (cdxtail !== 0) {
              const len = scale(abtlen, abt, cdxtail, _16c);
              finlen = finadd(finlen, sum(
                  scale(cxtablen, cxtab, cdxtail, _16$1), _16$1,
                  scale(len, _16c, 2 * cdx, _32), _32, _48$1), _48$1);

              const len2 = scale(abttlen, abtt, cdxtail, _8$1);
              finlen = finadd(finlen, sum_three(
                  scale(len2, _8$1, 2 * cdx, _16$1), _16$1,
                  scale(len2, _8$1, cdxtail, _16b), _16b,
                  scale(len, _16c, cdxtail, _32), _32, _32b, _64), _64);

              if (adytail !== 0) {
                  finlen = finadd(finlen, scale(scale(4, bb, cdxtail, _8$1), _8$1, adytail, _16$1), _16$1);
              }
              if (bdytail !== 0) {
                  finlen = finadd(finlen, scale(scale(4, aa, -cdxtail, _8$1), _8$1, bdytail, _16$1), _16$1);
              }
          }
          if (cdytail !== 0) {
              const len = scale(abtlen, abt, cdytail, _16c);
              finlen = finadd(finlen, sum(
                  scale(cytablen, cytab, cdytail, _16$1), _16$1,
                  scale(len, _16c, 2 * cdy, _32), _32, _48$1), _48$1);

              const len2 = scale(abttlen, abtt, cdytail, _8$1);
              finlen = finadd(finlen, sum_three(
                  scale(len2, _8$1, 2 * cdy, _16$1), _16$1,
                  scale(len2, _8$1, cdytail, _16b), _16b,
                  scale(len, _16c, cdytail, _32), _32, _32b, _64), _64);
          }
      }

      return fin$1[finlen - 1];
  }

  function incircle(ax, ay, bx, by, cx, cy, dx, dy) {
      const adx = ax - dx;
      const bdx = bx - dx;
      const cdx = cx - dx;
      const ady = ay - dy;
      const bdy = by - dy;
      const cdy = cy - dy;

      const bdxcdy = bdx * cdy;
      const cdxbdy = cdx * bdy;
      const alift = adx * adx + ady * ady;

      const cdxady = cdx * ady;
      const adxcdy = adx * cdy;
      const blift = bdx * bdx + bdy * bdy;

      const adxbdy = adx * bdy;
      const bdxady = bdx * ady;
      const clift = cdx * cdx + cdy * cdy;

      const det =
          alift * (bdxcdy - cdxbdy) +
          blift * (cdxady - adxcdy) +
          clift * (adxbdy - bdxady);

      const permanent =
          (Math.abs(bdxcdy) + Math.abs(cdxbdy)) * alift +
          (Math.abs(cdxady) + Math.abs(adxcdy)) * blift +
          (Math.abs(adxbdy) + Math.abs(bdxady)) * clift;

      const errbound = iccerrboundA * permanent;

      if (det > errbound || -det > errbound) {
          return det;
      }
      return incircleadapt(ax, ay, bx, by, cx, cy, dx, dy, permanent);
  }

  function incirclefast(ax, ay, bx, by, cx, cy, dx, dy) {
      const adx = ax - dx;
      const ady = ay - dy;
      const bdx = bx - dx;
      const bdy = by - dy;
      const cdx = cx - dx;
      const cdy = cy - dy;

      const abdet = adx * bdy - bdx * ady;
      const bcdet = bdx * cdy - cdx * bdy;
      const cadet = cdx * ady - adx * cdy;
      const alift = adx * adx + ady * ady;
      const blift = bdx * bdx + bdy * bdy;
      const clift = cdx * cdx + cdy * cdy;

      return alift * bcdet + blift * cadet + clift * abdet;
  }

  const isperrboundA = (16 + 224 * epsilon) * epsilon;
  const isperrboundB = (5 + 72 * epsilon) * epsilon;
  const isperrboundC = (71 + 1408 * epsilon) * epsilon * epsilon;

  const ab = vec(4);
  const bc = vec(4);
  const cd = vec(4);
  const de = vec(4);
  const ea = vec(4);
  const ac = vec(4);
  const bd = vec(4);
  const ce = vec(4);
  const da = vec(4);
  const eb = vec(4);

  const abc = vec(24);
  const bcd = vec(24);
  const cde = vec(24);
  const dea = vec(24);
  const eab = vec(24);
  const abd = vec(24);
  const bce = vec(24);
  const cda = vec(24);
  const deb = vec(24);
  const eac = vec(24);

  const adet = vec(1152);
  const bdet = vec(1152);
  const cdet = vec(1152);
  const ddet = vec(1152);
  const edet = vec(1152);
  const abdet = vec(2304);
  const cddet = vec(2304);
  const cdedet = vec(3456);
  const deter = vec(5760);

  const _8 = vec(8);
  const _8b = vec(8);
  const _8c = vec(8);
  const _16 = vec(16);
  const _24 = vec(24);
  const _48 = vec(48);
  const _48b = vec(48);
  const _96 = vec(96);
  const _192 = vec(192);
  const _384x = vec(384);
  const _384y = vec(384);
  const _384z = vec(384);
  const _768 = vec(768);

  function sum_three_scale(a, b, c, az, bz, cz, out) {
      return sum_three(
          scale(4, a, az, _8), _8,
          scale(4, b, bz, _8b), _8b,
          scale(4, c, cz, _8c), _8c, _16, out);
  }

  function liftexact(alen, a, blen, b, clen, c, dlen, d, x, y, z, out) {
      const len = sum(
          sum(alen, a, blen, b, _48), _48,
          negate(sum(clen, c, dlen, d, _48b), _48b), _48b, _96);

      return sum_three(
          scale(scale(len, _96, x, _192), _192, x, _384x), _384x,
          scale(scale(len, _96, y, _192), _192, y, _384y), _384y,
          scale(scale(len, _96, z, _192), _192, z, _384z), _384z, _768, out);
  }

  function insphereexact(ax, ay, az, bx, by, bz, cx, cy, cz, dx, dy, dz, ex, ey, ez) {
      let bvirt, c, ahi, alo, bhi, blo, _i, _j, _0, s1, s0, t1, t0, u3;

      s1 = ax * by;
      c = splitter * ax;
      ahi = c - (c - ax);
      alo = ax - ahi;
      c = splitter * by;
      bhi = c - (c - by);
      blo = by - bhi;
      s0 = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
      t1 = bx * ay;
      c = splitter * bx;
      ahi = c - (c - bx);
      alo = bx - ahi;
      c = splitter * ay;
      bhi = c - (c - ay);
      blo = ay - bhi;
      t0 = alo * blo - (t1 - ahi * bhi - alo * bhi - ahi * blo);
      _i = s0 - t0;
      bvirt = s0 - _i;
      ab[0] = s0 - (_i + bvirt) + (bvirt - t0);
      _j = s1 + _i;
      bvirt = _j - s1;
      _0 = s1 - (_j - bvirt) + (_i - bvirt);
      _i = _0 - t1;
      bvirt = _0 - _i;
      ab[1] = _0 - (_i + bvirt) + (bvirt - t1);
      u3 = _j + _i;
      bvirt = u3 - _j;
      ab[2] = _j - (u3 - bvirt) + (_i - bvirt);
      ab[3] = u3;
      s1 = bx * cy;
      c = splitter * bx;
      ahi = c - (c - bx);
      alo = bx - ahi;
      c = splitter * cy;
      bhi = c - (c - cy);
      blo = cy - bhi;
      s0 = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
      t1 = cx * by;
      c = splitter * cx;
      ahi = c - (c - cx);
      alo = cx - ahi;
      c = splitter * by;
      bhi = c - (c - by);
      blo = by - bhi;
      t0 = alo * blo - (t1 - ahi * bhi - alo * bhi - ahi * blo);
      _i = s0 - t0;
      bvirt = s0 - _i;
      bc[0] = s0 - (_i + bvirt) + (bvirt - t0);
      _j = s1 + _i;
      bvirt = _j - s1;
      _0 = s1 - (_j - bvirt) + (_i - bvirt);
      _i = _0 - t1;
      bvirt = _0 - _i;
      bc[1] = _0 - (_i + bvirt) + (bvirt - t1);
      u3 = _j + _i;
      bvirt = u3 - _j;
      bc[2] = _j - (u3 - bvirt) + (_i - bvirt);
      bc[3] = u3;
      s1 = cx * dy;
      c = splitter * cx;
      ahi = c - (c - cx);
      alo = cx - ahi;
      c = splitter * dy;
      bhi = c - (c - dy);
      blo = dy - bhi;
      s0 = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
      t1 = dx * cy;
      c = splitter * dx;
      ahi = c - (c - dx);
      alo = dx - ahi;
      c = splitter * cy;
      bhi = c - (c - cy);
      blo = cy - bhi;
      t0 = alo * blo - (t1 - ahi * bhi - alo * bhi - ahi * blo);
      _i = s0 - t0;
      bvirt = s0 - _i;
      cd[0] = s0 - (_i + bvirt) + (bvirt - t0);
      _j = s1 + _i;
      bvirt = _j - s1;
      _0 = s1 - (_j - bvirt) + (_i - bvirt);
      _i = _0 - t1;
      bvirt = _0 - _i;
      cd[1] = _0 - (_i + bvirt) + (bvirt - t1);
      u3 = _j + _i;
      bvirt = u3 - _j;
      cd[2] = _j - (u3 - bvirt) + (_i - bvirt);
      cd[3] = u3;
      s1 = dx * ey;
      c = splitter * dx;
      ahi = c - (c - dx);
      alo = dx - ahi;
      c = splitter * ey;
      bhi = c - (c - ey);
      blo = ey - bhi;
      s0 = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
      t1 = ex * dy;
      c = splitter * ex;
      ahi = c - (c - ex);
      alo = ex - ahi;
      c = splitter * dy;
      bhi = c - (c - dy);
      blo = dy - bhi;
      t0 = alo * blo - (t1 - ahi * bhi - alo * bhi - ahi * blo);
      _i = s0 - t0;
      bvirt = s0 - _i;
      de[0] = s0 - (_i + bvirt) + (bvirt - t0);
      _j = s1 + _i;
      bvirt = _j - s1;
      _0 = s1 - (_j - bvirt) + (_i - bvirt);
      _i = _0 - t1;
      bvirt = _0 - _i;
      de[1] = _0 - (_i + bvirt) + (bvirt - t1);
      u3 = _j + _i;
      bvirt = u3 - _j;
      de[2] = _j - (u3 - bvirt) + (_i - bvirt);
      de[3] = u3;
      s1 = ex * ay;
      c = splitter * ex;
      ahi = c - (c - ex);
      alo = ex - ahi;
      c = splitter * ay;
      bhi = c - (c - ay);
      blo = ay - bhi;
      s0 = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
      t1 = ax * ey;
      c = splitter * ax;
      ahi = c - (c - ax);
      alo = ax - ahi;
      c = splitter * ey;
      bhi = c - (c - ey);
      blo = ey - bhi;
      t0 = alo * blo - (t1 - ahi * bhi - alo * bhi - ahi * blo);
      _i = s0 - t0;
      bvirt = s0 - _i;
      ea[0] = s0 - (_i + bvirt) + (bvirt - t0);
      _j = s1 + _i;
      bvirt = _j - s1;
      _0 = s1 - (_j - bvirt) + (_i - bvirt);
      _i = _0 - t1;
      bvirt = _0 - _i;
      ea[1] = _0 - (_i + bvirt) + (bvirt - t1);
      u3 = _j + _i;
      bvirt = u3 - _j;
      ea[2] = _j - (u3 - bvirt) + (_i - bvirt);
      ea[3] = u3;
      s1 = ax * cy;
      c = splitter * ax;
      ahi = c - (c - ax);
      alo = ax - ahi;
      c = splitter * cy;
      bhi = c - (c - cy);
      blo = cy - bhi;
      s0 = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
      t1 = cx * ay;
      c = splitter * cx;
      ahi = c - (c - cx);
      alo = cx - ahi;
      c = splitter * ay;
      bhi = c - (c - ay);
      blo = ay - bhi;
      t0 = alo * blo - (t1 - ahi * bhi - alo * bhi - ahi * blo);
      _i = s0 - t0;
      bvirt = s0 - _i;
      ac[0] = s0 - (_i + bvirt) + (bvirt - t0);
      _j = s1 + _i;
      bvirt = _j - s1;
      _0 = s1 - (_j - bvirt) + (_i - bvirt);
      _i = _0 - t1;
      bvirt = _0 - _i;
      ac[1] = _0 - (_i + bvirt) + (bvirt - t1);
      u3 = _j + _i;
      bvirt = u3 - _j;
      ac[2] = _j - (u3 - bvirt) + (_i - bvirt);
      ac[3] = u3;
      s1 = bx * dy;
      c = splitter * bx;
      ahi = c - (c - bx);
      alo = bx - ahi;
      c = splitter * dy;
      bhi = c - (c - dy);
      blo = dy - bhi;
      s0 = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
      t1 = dx * by;
      c = splitter * dx;
      ahi = c - (c - dx);
      alo = dx - ahi;
      c = splitter * by;
      bhi = c - (c - by);
      blo = by - bhi;
      t0 = alo * blo - (t1 - ahi * bhi - alo * bhi - ahi * blo);
      _i = s0 - t0;
      bvirt = s0 - _i;
      bd[0] = s0 - (_i + bvirt) + (bvirt - t0);
      _j = s1 + _i;
      bvirt = _j - s1;
      _0 = s1 - (_j - bvirt) + (_i - bvirt);
      _i = _0 - t1;
      bvirt = _0 - _i;
      bd[1] = _0 - (_i + bvirt) + (bvirt - t1);
      u3 = _j + _i;
      bvirt = u3 - _j;
      bd[2] = _j - (u3 - bvirt) + (_i - bvirt);
      bd[3] = u3;
      s1 = cx * ey;
      c = splitter * cx;
      ahi = c - (c - cx);
      alo = cx - ahi;
      c = splitter * ey;
      bhi = c - (c - ey);
      blo = ey - bhi;
      s0 = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
      t1 = ex * cy;
      c = splitter * ex;
      ahi = c - (c - ex);
      alo = ex - ahi;
      c = splitter * cy;
      bhi = c - (c - cy);
      blo = cy - bhi;
      t0 = alo * blo - (t1 - ahi * bhi - alo * bhi - ahi * blo);
      _i = s0 - t0;
      bvirt = s0 - _i;
      ce[0] = s0 - (_i + bvirt) + (bvirt - t0);
      _j = s1 + _i;
      bvirt = _j - s1;
      _0 = s1 - (_j - bvirt) + (_i - bvirt);
      _i = _0 - t1;
      bvirt = _0 - _i;
      ce[1] = _0 - (_i + bvirt) + (bvirt - t1);
      u3 = _j + _i;
      bvirt = u3 - _j;
      ce[2] = _j - (u3 - bvirt) + (_i - bvirt);
      ce[3] = u3;
      s1 = dx * ay;
      c = splitter * dx;
      ahi = c - (c - dx);
      alo = dx - ahi;
      c = splitter * ay;
      bhi = c - (c - ay);
      blo = ay - bhi;
      s0 = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
      t1 = ax * dy;
      c = splitter * ax;
      ahi = c - (c - ax);
      alo = ax - ahi;
      c = splitter * dy;
      bhi = c - (c - dy);
      blo = dy - bhi;
      t0 = alo * blo - (t1 - ahi * bhi - alo * bhi - ahi * blo);
      _i = s0 - t0;
      bvirt = s0 - _i;
      da[0] = s0 - (_i + bvirt) + (bvirt - t0);
      _j = s1 + _i;
      bvirt = _j - s1;
      _0 = s1 - (_j - bvirt) + (_i - bvirt);
      _i = _0 - t1;
      bvirt = _0 - _i;
      da[1] = _0 - (_i + bvirt) + (bvirt - t1);
      u3 = _j + _i;
      bvirt = u3 - _j;
      da[2] = _j - (u3 - bvirt) + (_i - bvirt);
      da[3] = u3;
      s1 = ex * by;
      c = splitter * ex;
      ahi = c - (c - ex);
      alo = ex - ahi;
      c = splitter * by;
      bhi = c - (c - by);
      blo = by - bhi;
      s0 = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
      t1 = bx * ey;
      c = splitter * bx;
      ahi = c - (c - bx);
      alo = bx - ahi;
      c = splitter * ey;
      bhi = c - (c - ey);
      blo = ey - bhi;
      t0 = alo * blo - (t1 - ahi * bhi - alo * bhi - ahi * blo);
      _i = s0 - t0;
      bvirt = s0 - _i;
      eb[0] = s0 - (_i + bvirt) + (bvirt - t0);
      _j = s1 + _i;
      bvirt = _j - s1;
      _0 = s1 - (_j - bvirt) + (_i - bvirt);
      _i = _0 - t1;
      bvirt = _0 - _i;
      eb[1] = _0 - (_i + bvirt) + (bvirt - t1);
      u3 = _j + _i;
      bvirt = u3 - _j;
      eb[2] = _j - (u3 - bvirt) + (_i - bvirt);
      eb[3] = u3;

      const abclen = sum_three_scale(ab, bc, ac, cz, az, -bz, abc);
      const bcdlen = sum_three_scale(bc, cd, bd, dz, bz, -cz, bcd);
      const cdelen = sum_three_scale(cd, de, ce, ez, cz, -dz, cde);
      const dealen = sum_three_scale(de, ea, da, az, dz, -ez, dea);
      const eablen = sum_three_scale(ea, ab, eb, bz, ez, -az, eab);
      const abdlen = sum_three_scale(ab, bd, da, dz, az, bz, abd);
      const bcelen = sum_three_scale(bc, ce, eb, ez, bz, cz, bce);
      const cdalen = sum_three_scale(cd, da, ac, az, cz, dz, cda);
      const deblen = sum_three_scale(de, eb, bd, bz, dz, ez, deb);
      const eaclen = sum_three_scale(ea, ac, ce, cz, ez, az, eac);

      const deterlen = sum_three(
          liftexact(cdelen, cde, bcelen, bce, deblen, deb, bcdlen, bcd, ax, ay, az, adet), adet,
          liftexact(dealen, dea, cdalen, cda, eaclen, eac, cdelen, cde, bx, by, bz, bdet), bdet,
          sum_three(
              liftexact(eablen, eab, deblen, deb, abdlen, abd, dealen, dea, cx, cy, cz, cdet), cdet,
              liftexact(abclen, abc, eaclen, eac, bcelen, bce, eablen, eab, dx, dy, dz, ddet), ddet,
              liftexact(bcdlen, bcd, abdlen, abd, cdalen, cda, abclen, abc, ex, ey, ez, edet), edet, cddet, cdedet), cdedet, abdet, deter);

      return deter[deterlen - 1];
  }

  const xdet = vec(96);
  const ydet = vec(96);
  const zdet = vec(96);
  const fin = vec(1152);

  function liftadapt(a, b, c, az, bz, cz, x, y, z, out) {
      const len = sum_three_scale(a, b, c, az, bz, cz, _24);
      return sum_three(
          scale(scale(len, _24, x, _48), _48, x, xdet), xdet,
          scale(scale(len, _24, y, _48), _48, y, ydet), ydet,
          scale(scale(len, _24, z, _48), _48, z, zdet), zdet, _192, out);
  }

  function insphereadapt(ax, ay, az, bx, by, bz, cx, cy, cz, dx, dy, dz, ex, ey, ez, permanent) {
      let ab3, bc3, cd3, da3, ac3, bd3;

      let aextail, bextail, cextail, dextail;
      let aeytail, beytail, ceytail, deytail;
      let aeztail, beztail, ceztail, deztail;

      let bvirt, c, ahi, alo, bhi, blo, _i, _j, _0, s1, s0, t1, t0;

      const aex = ax - ex;
      const bex = bx - ex;
      const cex = cx - ex;
      const dex = dx - ex;
      const aey = ay - ey;
      const bey = by - ey;
      const cey = cy - ey;
      const dey = dy - ey;
      const aez = az - ez;
      const bez = bz - ez;
      const cez = cz - ez;
      const dez = dz - ez;

      s1 = aex * bey;
      c = splitter * aex;
      ahi = c - (c - aex);
      alo = aex - ahi;
      c = splitter * bey;
      bhi = c - (c - bey);
      blo = bey - bhi;
      s0 = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
      t1 = bex * aey;
      c = splitter * bex;
      ahi = c - (c - bex);
      alo = bex - ahi;
      c = splitter * aey;
      bhi = c - (c - aey);
      blo = aey - bhi;
      t0 = alo * blo - (t1 - ahi * bhi - alo * bhi - ahi * blo);
      _i = s0 - t0;
      bvirt = s0 - _i;
      ab[0] = s0 - (_i + bvirt) + (bvirt - t0);
      _j = s1 + _i;
      bvirt = _j - s1;
      _0 = s1 - (_j - bvirt) + (_i - bvirt);
      _i = _0 - t1;
      bvirt = _0 - _i;
      ab[1] = _0 - (_i + bvirt) + (bvirt - t1);
      ab3 = _j + _i;
      bvirt = ab3 - _j;
      ab[2] = _j - (ab3 - bvirt) + (_i - bvirt);
      ab[3] = ab3;
      s1 = bex * cey;
      c = splitter * bex;
      ahi = c - (c - bex);
      alo = bex - ahi;
      c = splitter * cey;
      bhi = c - (c - cey);
      blo = cey - bhi;
      s0 = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
      t1 = cex * bey;
      c = splitter * cex;
      ahi = c - (c - cex);
      alo = cex - ahi;
      c = splitter * bey;
      bhi = c - (c - bey);
      blo = bey - bhi;
      t0 = alo * blo - (t1 - ahi * bhi - alo * bhi - ahi * blo);
      _i = s0 - t0;
      bvirt = s0 - _i;
      bc[0] = s0 - (_i + bvirt) + (bvirt - t0);
      _j = s1 + _i;
      bvirt = _j - s1;
      _0 = s1 - (_j - bvirt) + (_i - bvirt);
      _i = _0 - t1;
      bvirt = _0 - _i;
      bc[1] = _0 - (_i + bvirt) + (bvirt - t1);
      bc3 = _j + _i;
      bvirt = bc3 - _j;
      bc[2] = _j - (bc3 - bvirt) + (_i - bvirt);
      bc[3] = bc3;
      s1 = cex * dey;
      c = splitter * cex;
      ahi = c - (c - cex);
      alo = cex - ahi;
      c = splitter * dey;
      bhi = c - (c - dey);
      blo = dey - bhi;
      s0 = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
      t1 = dex * cey;
      c = splitter * dex;
      ahi = c - (c - dex);
      alo = dex - ahi;
      c = splitter * cey;
      bhi = c - (c - cey);
      blo = cey - bhi;
      t0 = alo * blo - (t1 - ahi * bhi - alo * bhi - ahi * blo);
      _i = s0 - t0;
      bvirt = s0 - _i;
      cd[0] = s0 - (_i + bvirt) + (bvirt - t0);
      _j = s1 + _i;
      bvirt = _j - s1;
      _0 = s1 - (_j - bvirt) + (_i - bvirt);
      _i = _0 - t1;
      bvirt = _0 - _i;
      cd[1] = _0 - (_i + bvirt) + (bvirt - t1);
      cd3 = _j + _i;
      bvirt = cd3 - _j;
      cd[2] = _j - (cd3 - bvirt) + (_i - bvirt);
      cd[3] = cd3;
      s1 = dex * aey;
      c = splitter * dex;
      ahi = c - (c - dex);
      alo = dex - ahi;
      c = splitter * aey;
      bhi = c - (c - aey);
      blo = aey - bhi;
      s0 = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
      t1 = aex * dey;
      c = splitter * aex;
      ahi = c - (c - aex);
      alo = aex - ahi;
      c = splitter * dey;
      bhi = c - (c - dey);
      blo = dey - bhi;
      t0 = alo * blo - (t1 - ahi * bhi - alo * bhi - ahi * blo);
      _i = s0 - t0;
      bvirt = s0 - _i;
      da[0] = s0 - (_i + bvirt) + (bvirt - t0);
      _j = s1 + _i;
      bvirt = _j - s1;
      _0 = s1 - (_j - bvirt) + (_i - bvirt);
      _i = _0 - t1;
      bvirt = _0 - _i;
      da[1] = _0 - (_i + bvirt) + (bvirt - t1);
      da3 = _j + _i;
      bvirt = da3 - _j;
      da[2] = _j - (da3 - bvirt) + (_i - bvirt);
      da[3] = da3;
      s1 = aex * cey;
      c = splitter * aex;
      ahi = c - (c - aex);
      alo = aex - ahi;
      c = splitter * cey;
      bhi = c - (c - cey);
      blo = cey - bhi;
      s0 = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
      t1 = cex * aey;
      c = splitter * cex;
      ahi = c - (c - cex);
      alo = cex - ahi;
      c = splitter * aey;
      bhi = c - (c - aey);
      blo = aey - bhi;
      t0 = alo * blo - (t1 - ahi * bhi - alo * bhi - ahi * blo);
      _i = s0 - t0;
      bvirt = s0 - _i;
      ac[0] = s0 - (_i + bvirt) + (bvirt - t0);
      _j = s1 + _i;
      bvirt = _j - s1;
      _0 = s1 - (_j - bvirt) + (_i - bvirt);
      _i = _0 - t1;
      bvirt = _0 - _i;
      ac[1] = _0 - (_i + bvirt) + (bvirt - t1);
      ac3 = _j + _i;
      bvirt = ac3 - _j;
      ac[2] = _j - (ac3 - bvirt) + (_i - bvirt);
      ac[3] = ac3;
      s1 = bex * dey;
      c = splitter * bex;
      ahi = c - (c - bex);
      alo = bex - ahi;
      c = splitter * dey;
      bhi = c - (c - dey);
      blo = dey - bhi;
      s0 = alo * blo - (s1 - ahi * bhi - alo * bhi - ahi * blo);
      t1 = dex * bey;
      c = splitter * dex;
      ahi = c - (c - dex);
      alo = dex - ahi;
      c = splitter * bey;
      bhi = c - (c - bey);
      blo = bey - bhi;
      t0 = alo * blo - (t1 - ahi * bhi - alo * bhi - ahi * blo);
      _i = s0 - t0;
      bvirt = s0 - _i;
      bd[0] = s0 - (_i + bvirt) + (bvirt - t0);
      _j = s1 + _i;
      bvirt = _j - s1;
      _0 = s1 - (_j - bvirt) + (_i - bvirt);
      _i = _0 - t1;
      bvirt = _0 - _i;
      bd[1] = _0 - (_i + bvirt) + (bvirt - t1);
      bd3 = _j + _i;
      bvirt = bd3 - _j;
      bd[2] = _j - (bd3 - bvirt) + (_i - bvirt);
      bd[3] = bd3;

      const finlen = sum(
          sum(
              negate(liftadapt(bc, cd, bd, dez, bez, -cez, aex, aey, aez, adet), adet), adet,
              liftadapt(cd, da, ac, aez, cez, dez, bex, bey, bez, bdet), bdet, abdet), abdet,
          sum(
              negate(liftadapt(da, ab, bd, bez, dez, aez, cex, cey, cez, cdet), cdet), cdet,
              liftadapt(ab, bc, ac, cez, aez, -bez, dex, dey, dez, ddet), ddet, cddet), cddet, fin);

      let det = estimate(finlen, fin);
      let errbound = isperrboundB * permanent;
      if (det >= errbound || -det >= errbound) {
          return det;
      }

      bvirt = ax - aex;
      aextail = ax - (aex + bvirt) + (bvirt - ex);
      bvirt = ay - aey;
      aeytail = ay - (aey + bvirt) + (bvirt - ey);
      bvirt = az - aez;
      aeztail = az - (aez + bvirt) + (bvirt - ez);
      bvirt = bx - bex;
      bextail = bx - (bex + bvirt) + (bvirt - ex);
      bvirt = by - bey;
      beytail = by - (bey + bvirt) + (bvirt - ey);
      bvirt = bz - bez;
      beztail = bz - (bez + bvirt) + (bvirt - ez);
      bvirt = cx - cex;
      cextail = cx - (cex + bvirt) + (bvirt - ex);
      bvirt = cy - cey;
      ceytail = cy - (cey + bvirt) + (bvirt - ey);
      bvirt = cz - cez;
      ceztail = cz - (cez + bvirt) + (bvirt - ez);
      bvirt = dx - dex;
      dextail = dx - (dex + bvirt) + (bvirt - ex);
      bvirt = dy - dey;
      deytail = dy - (dey + bvirt) + (bvirt - ey);
      bvirt = dz - dez;
      deztail = dz - (dez + bvirt) + (bvirt - ez);
      if (aextail === 0 && aeytail === 0 && aeztail === 0 &&
          bextail === 0 && beytail === 0 && beztail === 0 &&
          cextail === 0 && ceytail === 0 && ceztail === 0 &&
          dextail === 0 && deytail === 0 && deztail === 0) {
          return det;
      }

      errbound = isperrboundC * permanent + resulterrbound * Math.abs(det);

      const abeps = (aex * beytail + bey * aextail) - (aey * bextail + bex * aeytail);
      const bceps = (bex * ceytail + cey * bextail) - (bey * cextail + cex * beytail);
      const cdeps = (cex * deytail + dey * cextail) - (cey * dextail + dex * ceytail);
      const daeps = (dex * aeytail + aey * dextail) - (dey * aextail + aex * deytail);
      const aceps = (aex * ceytail + cey * aextail) - (aey * cextail + cex * aeytail);
      const bdeps = (bex * deytail + dey * bextail) - (bey * dextail + dex * beytail);
      det +=
          (((bex * bex + bey * bey + bez * bez) * ((cez * daeps + dez * aceps + aez * cdeps) +
          (ceztail * da3 + deztail * ac3 + aeztail * cd3)) + (dex * dex + dey * dey + dez * dez) *
          ((aez * bceps - bez * aceps + cez * abeps) + (aeztail * bc3 - beztail * ac3 + ceztail * ab3))) -
          ((aex * aex + aey * aey + aez * aez) * ((bez * cdeps - cez * bdeps + dez * bceps) +
          (beztail * cd3 - ceztail * bd3 + deztail * bc3)) + (cex * cex + cey * cey + cez * cez) *
          ((dez * abeps + aez * bdeps + bez * daeps) + (deztail * ab3 + aeztail * bd3 + beztail * da3)))) +
          2 * (((bex * bextail + bey * beytail + bez * beztail) * (cez * da3 + dez * ac3 + aez * cd3) +
          (dex * dextail + dey * deytail + dez * deztail) * (aez * bc3 - bez * ac3 + cez * ab3)) -
          ((aex * aextail + aey * aeytail + aez * aeztail) * (bez * cd3 - cez * bd3 + dez * bc3) +
          (cex * cextail + cey * ceytail + cez * ceztail) * (dez * ab3 + aez * bd3 + bez * da3)));

      if (det >= errbound || -det >= errbound) {
          return det;
      }

      return insphereexact(ax, ay, az, bx, by, bz, cx, cy, cz, dx, dy, dz, ex, ey, ez);
  }

  function insphere(ax, ay, az, bx, by, bz, cx, cy, cz, dx, dy, dz, ex, ey, ez) {
      const aex = ax - ex;
      const bex = bx - ex;
      const cex = cx - ex;
      const dex = dx - ex;
      const aey = ay - ey;
      const bey = by - ey;
      const cey = cy - ey;
      const dey = dy - ey;
      const aez = az - ez;
      const bez = bz - ez;
      const cez = cz - ez;
      const dez = dz - ez;

      const aexbey = aex * bey;
      const bexaey = bex * aey;
      const ab = aexbey - bexaey;
      const bexcey = bex * cey;
      const cexbey = cex * bey;
      const bc = bexcey - cexbey;
      const cexdey = cex * dey;
      const dexcey = dex * cey;
      const cd = cexdey - dexcey;
      const dexaey = dex * aey;
      const aexdey = aex * dey;
      const da = dexaey - aexdey;
      const aexcey = aex * cey;
      const cexaey = cex * aey;
      const ac = aexcey - cexaey;
      const bexdey = bex * dey;
      const dexbey = dex * bey;
      const bd = bexdey - dexbey;

      const abc = aez * bc - bez * ac + cez * ab;
      const bcd = bez * cd - cez * bd + dez * bc;
      const cda = cez * da + dez * ac + aez * cd;
      const dab = dez * ab + aez * bd + bez * da;

      const alift = aex * aex + aey * aey + aez * aez;
      const blift = bex * bex + bey * bey + bez * bez;
      const clift = cex * cex + cey * cey + cez * cez;
      const dlift = dex * dex + dey * dey + dez * dez;

      const det = (clift * dab - dlift * abc) + (alift * bcd - blift * cda);

      const aezplus = Math.abs(aez);
      const bezplus = Math.abs(bez);
      const cezplus = Math.abs(cez);
      const dezplus = Math.abs(dez);
      const aexbeyplus = Math.abs(aexbey);
      const bexaeyplus = Math.abs(bexaey);
      const bexceyplus = Math.abs(bexcey);
      const cexbeyplus = Math.abs(cexbey);
      const cexdeyplus = Math.abs(cexdey);
      const dexceyplus = Math.abs(dexcey);
      const dexaeyplus = Math.abs(dexaey);
      const aexdeyplus = Math.abs(aexdey);
      const aexceyplus = Math.abs(aexcey);
      const cexaeyplus = Math.abs(cexaey);
      const bexdeyplus = Math.abs(bexdey);
      const dexbeyplus = Math.abs(dexbey);
      const permanent =
          ((cexdeyplus + dexceyplus) * bezplus + (dexbeyplus + bexdeyplus) * cezplus + (bexceyplus + cexbeyplus) * dezplus) * alift +
          ((dexaeyplus + aexdeyplus) * cezplus + (aexceyplus + cexaeyplus) * dezplus + (cexdeyplus + dexceyplus) * aezplus) * blift +
          ((aexbeyplus + bexaeyplus) * dezplus + (bexdeyplus + dexbeyplus) * aezplus + (dexaeyplus + aexdeyplus) * bezplus) * clift +
          ((bexceyplus + cexbeyplus) * aezplus + (cexaeyplus + aexceyplus) * bezplus + (aexbeyplus + bexaeyplus) * cezplus) * dlift;

      const errbound = isperrboundA * permanent;
      if (det > errbound || -det > errbound) {
          return det;
      }
      return -insphereadapt(ax, ay, az, bx, by, bz, cx, cy, cz, dx, dy, dz, ex, ey, ez, permanent);
  }

  function inspherefast(pax, pay, paz, pbx, pby, pbz, pcx, pcy, pcz, pdx, pdy, pdz, pex, pey, pez) {
      const aex = pax - pex;
      const bex = pbx - pex;
      const cex = pcx - pex;
      const dex = pdx - pex;
      const aey = pay - pey;
      const bey = pby - pey;
      const cey = pcy - pey;
      const dey = pdy - pey;
      const aez = paz - pez;
      const bez = pbz - pez;
      const cez = pcz - pez;
      const dez = pdz - pez;

      const ab = aex * bey - bex * aey;
      const bc = bex * cey - cex * bey;
      const cd = cex * dey - dex * cey;
      const da = dex * aey - aex * dey;
      const ac = aex * cey - cex * aey;
      const bd = bex * dey - dex * bey;

      const abc = aez * bc - bez * ac + cez * ab;
      const bcd = bez * cd - cez * bd + dez * bc;
      const cda = cez * da + dez * ac + aez * cd;
      const dab = dez * ab + aez * bd + bez * da;

      const alift = aex * aex + aey * aey + aez * aez;
      const blift = bex * bex + bey * bey + bez * bez;
      const clift = cex * cex + cey * cey + cez * cez;
      const dlift = dex * dex + dey * dey + dez * dez;

      return (clift * dab - dlift * abc) + (alift * bcd - blift * cda);
  }

  const EPSILON = Math.pow(2, -52);
  const EDGE_STACK = new Uint32Array(512);

  class Delaunator {

      static from(points, getX = defaultGetX, getY = defaultGetY) {
          const n = points.length;
          const coords = new Float64Array(n * 2);

          for (let i = 0; i < n; i++) {
              const p = points[i];
              coords[2 * i] = getX(p);
              coords[2 * i + 1] = getY(p);
          }

          return new Delaunator(coords);
      }

      constructor(coords) {
          const n = coords.length >> 1;
          if (n > 0 && typeof coords[0] !== 'number') throw new Error('Expected coords to contain numbers.');

          this.coords = coords;

          // arrays that will store the triangulation graph
          const maxTriangles = Math.max(2 * n - 5, 0);
          this._triangles = new Uint32Array(maxTriangles * 3);
          this._halfedges = new Int32Array(maxTriangles * 3);

          // temporary arrays for tracking the edges of the advancing convex hull
          this._hashSize = Math.ceil(Math.sqrt(n));
          this._hullPrev = new Uint32Array(n); // edge to prev edge
          this._hullNext = new Uint32Array(n); // edge to next edge
          this._hullTri = new Uint32Array(n); // edge to adjacent triangle
          this._hullHash = new Int32Array(this._hashSize).fill(-1); // angular edge hash

          // temporary arrays for sorting points
          this._ids = new Uint32Array(n);
          this._dists = new Float64Array(n);

          this.update();
      }

      update() {
          const {coords, _hullPrev: hullPrev, _hullNext: hullNext, _hullTri: hullTri, _hullHash: hullHash} =  this;
          const n = coords.length >> 1;

          // populate an array of point indices; calculate input data bbox
          let minX = Infinity;
          let minY = Infinity;
          let maxX = -Infinity;
          let maxY = -Infinity;

          for (let i = 0; i < n; i++) {
              const x = coords[2 * i];
              const y = coords[2 * i + 1];
              if (x < minX) minX = x;
              if (y < minY) minY = y;
              if (x > maxX) maxX = x;
              if (y > maxY) maxY = y;
              this._ids[i] = i;
          }
          const cx = (minX + maxX) / 2;
          const cy = (minY + maxY) / 2;

          let minDist = Infinity;
          let i0, i1, i2;

          // pick a seed point close to the center
          for (let i = 0; i < n; i++) {
              const d = dist(cx, cy, coords[2 * i], coords[2 * i + 1]);
              if (d < minDist) {
                  i0 = i;
                  minDist = d;
              }
          }
          const i0x = coords[2 * i0];
          const i0y = coords[2 * i0 + 1];

          minDist = Infinity;

          // find the point closest to the seed
          for (let i = 0; i < n; i++) {
              if (i === i0) continue;
              const d = dist(i0x, i0y, coords[2 * i], coords[2 * i + 1]);
              if (d < minDist && d > 0) {
                  i1 = i;
                  minDist = d;
              }
          }
          let i1x = coords[2 * i1];
          let i1y = coords[2 * i1 + 1];

          let minRadius = Infinity;

          // find the third point which forms the smallest circumcircle with the first two
          for (let i = 0; i < n; i++) {
              if (i === i0 || i === i1) continue;
              const r = circumradius(i0x, i0y, i1x, i1y, coords[2 * i], coords[2 * i + 1]);
              if (r < minRadius) {
                  i2 = i;
                  minRadius = r;
              }
          }
          let i2x = coords[2 * i2];
          let i2y = coords[2 * i2 + 1];

          if (minRadius === Infinity) {
              // order collinear points by dx (or dy if all x are identical)
              // and return the list as a hull
              for (let i = 0; i < n; i++) {
                  this._dists[i] = (coords[2 * i] - coords[0]) || (coords[2 * i + 1] - coords[1]);
              }
              quicksort(this._ids, this._dists, 0, n - 1);
              const hull = new Uint32Array(n);
              let j = 0;
              for (let i = 0, d0 = -Infinity; i < n; i++) {
                  const id = this._ids[i];
                  if (this._dists[id] > d0) {
                      hull[j++] = id;
                      d0 = this._dists[id];
                  }
              }
              this.hull = hull.subarray(0, j);
              this.triangles = new Uint32Array(0);
              this.halfedges = new Uint32Array(0);
              return;
          }

          // swap the order of the seed points for counter-clockwise orientation
          if (orient2d(i0x, i0y, i1x, i1y, i2x, i2y) < 0) {
              const i = i1;
              const x = i1x;
              const y = i1y;
              i1 = i2;
              i1x = i2x;
              i1y = i2y;
              i2 = i;
              i2x = x;
              i2y = y;
          }

          const center = circumcenter(i0x, i0y, i1x, i1y, i2x, i2y);
          this._cx = center.x;
          this._cy = center.y;

          for (let i = 0; i < n; i++) {
              this._dists[i] = dist(coords[2 * i], coords[2 * i + 1], center.x, center.y);
          }

          // sort the points by distance from the seed triangle circumcenter
          quicksort(this._ids, this._dists, 0, n - 1);

          // set up the seed triangle as the starting hull
          this._hullStart = i0;
          let hullSize = 3;

          hullNext[i0] = hullPrev[i2] = i1;
          hullNext[i1] = hullPrev[i0] = i2;
          hullNext[i2] = hullPrev[i1] = i0;

          hullTri[i0] = 0;
          hullTri[i1] = 1;
          hullTri[i2] = 2;

          hullHash.fill(-1);
          hullHash[this._hashKey(i0x, i0y)] = i0;
          hullHash[this._hashKey(i1x, i1y)] = i1;
          hullHash[this._hashKey(i2x, i2y)] = i2;

          this.trianglesLen = 0;
          this._addTriangle(i0, i1, i2, -1, -1, -1);

          for (let k = 0, xp, yp; k < this._ids.length; k++) {
              const i = this._ids[k];
              const x = coords[2 * i];
              const y = coords[2 * i + 1];

              // skip near-duplicate points
              if (k > 0 && Math.abs(x - xp) <= EPSILON && Math.abs(y - yp) <= EPSILON) continue;
              xp = x;
              yp = y;

              // skip seed triangle points
              if (i === i0 || i === i1 || i === i2) continue;

              // find a visible edge on the convex hull using edge hash
              let start = 0;
              for (let j = 0, key = this._hashKey(x, y); j < this._hashSize; j++) {
                  start = hullHash[(key + j) % this._hashSize];
                  if (start !== -1 && start !== hullNext[start]) break;
              }

              start = hullPrev[start];
              let e = start, q;
              while (q = hullNext[e], orient2d(x, y, coords[2 * e], coords[2 * e + 1], coords[2 * q], coords[2 * q + 1]) >= 0) {
                  e = q;
                  if (e === start) {
                      e = -1;
                      break;
                  }
              }
              if (e === -1) continue; // likely a near-duplicate point; skip it

              // add the first triangle from the point
              let t = this._addTriangle(e, i, hullNext[e], -1, -1, hullTri[e]);

              // recursively flip triangles from the point until they satisfy the Delaunay condition
              hullTri[i] = this._legalize(t + 2);
              hullTri[e] = t; // keep track of boundary triangles on the hull
              hullSize++;

              // walk forward through the hull, adding more triangles and flipping recursively
              let n = hullNext[e];
              while (q = hullNext[n], orient2d(x, y, coords[2 * n], coords[2 * n + 1], coords[2 * q], coords[2 * q + 1]) < 0) {
                  t = this._addTriangle(n, i, q, hullTri[i], -1, hullTri[n]);
                  hullTri[i] = this._legalize(t + 2);
                  hullNext[n] = n; // mark as removed
                  hullSize--;
                  n = q;
              }

              // walk backward from the other side, adding more triangles and flipping
              if (e === start) {
                  while (q = hullPrev[e], orient2d(x, y, coords[2 * q], coords[2 * q + 1], coords[2 * e], coords[2 * e + 1]) < 0) {
                      t = this._addTriangle(q, i, e, -1, hullTri[e], hullTri[q]);
                      this._legalize(t + 2);
                      hullTri[q] = t;
                      hullNext[e] = e; // mark as removed
                      hullSize--;
                      e = q;
                  }
              }

              // update the hull indices
              this._hullStart = hullPrev[i] = e;
              hullNext[e] = hullPrev[n] = i;
              hullNext[i] = n;

              // save the two new edges in the hash table
              hullHash[this._hashKey(x, y)] = i;
              hullHash[this._hashKey(coords[2 * e], coords[2 * e + 1])] = e;
          }

          this.hull = new Uint32Array(hullSize);
          for (let i = 0, e = this._hullStart; i < hullSize; i++) {
              this.hull[i] = e;
              e = hullNext[e];
          }

          // trim typed triangle mesh arrays
          this.triangles = this._triangles.subarray(0, this.trianglesLen);
          this.halfedges = this._halfedges.subarray(0, this.trianglesLen);
      }

      _hashKey(x, y) {
          return Math.floor(pseudoAngle(x - this._cx, y - this._cy) * this._hashSize) % this._hashSize;
      }

      _legalize(a) {
          const {_triangles: triangles, _halfedges: halfedges, coords} = this;

          let i = 0;
          let ar = 0;

          // recursion eliminated with a fixed-size stack
          while (true) {
              const b = halfedges[a];

              /* if the pair of triangles doesn't satisfy the Delaunay condition
               * (p1 is inside the circumcircle of [p0, pl, pr]), flip them,
               * then do the same check/flip recursively for the new pair of triangles
               *
               *           pl                    pl
               *          /||\                  /  \
               *       al/ || \bl            al/    \a
               *        /  ||  \              /      \
               *       /  a||b  \    flip    /___ar___\
               *     p0\   ||   /p1   =>   p0\---bl---/p1
               *        \  ||  /              \      /
               *       ar\ || /br             b\    /br
               *          \||/                  \  /
               *           pr                    pr
               */
              const a0 = a - a % 3;
              ar = a0 + (a + 2) % 3;

              if (b === -1) { // convex hull edge
                  if (i === 0) break;
                  a = EDGE_STACK[--i];
                  continue;
              }

              const b0 = b - b % 3;
              const al = a0 + (a + 1) % 3;
              const bl = b0 + (b + 2) % 3;

              const p0 = triangles[ar];
              const pr = triangles[a];
              const pl = triangles[al];
              const p1 = triangles[bl];

              const illegal = inCircle(
                  coords[2 * p0], coords[2 * p0 + 1],
                  coords[2 * pr], coords[2 * pr + 1],
                  coords[2 * pl], coords[2 * pl + 1],
                  coords[2 * p1], coords[2 * p1 + 1]);

              if (illegal) {
                  triangles[a] = p1;
                  triangles[b] = p0;

                  const hbl = halfedges[bl];

                  // edge swapped on the other side of the hull (rare); fix the halfedge reference
                  if (hbl === -1) {
                      let e = this._hullStart;
                      do {
                          if (this._hullTri[e] === bl) {
                              this._hullTri[e] = a;
                              break;
                          }
                          e = this._hullPrev[e];
                      } while (e !== this._hullStart);
                  }
                  this._link(a, hbl);
                  this._link(b, halfedges[ar]);
                  this._link(ar, bl);

                  const br = b0 + (b + 1) % 3;

                  // don't worry about hitting the cap: it can only happen on extremely degenerate input
                  if (i < EDGE_STACK.length) {
                      EDGE_STACK[i++] = br;
                  }
              } else {
                  if (i === 0) break;
                  a = EDGE_STACK[--i];
              }
          }

          return ar;
      }

      _link(a, b) {
          this._halfedges[a] = b;
          if (b !== -1) this._halfedges[b] = a;
      }

      // add a new triangle given vertex indices and adjacent half-edge ids
      _addTriangle(i0, i1, i2, a, b, c) {
          const t = this.trianglesLen;

          this._triangles[t] = i0;
          this._triangles[t + 1] = i1;
          this._triangles[t + 2] = i2;

          this._link(t, a);
          this._link(t + 1, b);
          this._link(t + 2, c);

          this.trianglesLen += 3;

          return t;
      }
  }

  // monotonically increases with real angle, but doesn't need expensive trigonometry
  function pseudoAngle(dx, dy) {
      const p = dx / (Math.abs(dx) + Math.abs(dy));
      return (dy > 0 ? 3 - p : 1 + p) / 4; // [0..1]
  }

  function dist(ax, ay, bx, by) {
      const dx = ax - bx;
      const dy = ay - by;
      return dx * dx + dy * dy;
  }

  function inCircle(ax, ay, bx, by, cx, cy, px, py) {
      const dx = ax - px;
      const dy = ay - py;
      const ex = bx - px;
      const ey = by - py;
      const fx = cx - px;
      const fy = cy - py;

      const ap = dx * dx + dy * dy;
      const bp = ex * ex + ey * ey;
      const cp = fx * fx + fy * fy;

      return dx * (ey * cp - bp * fy) -
             dy * (ex * cp - bp * fx) +
             ap * (ex * fy - ey * fx) < 0;
  }

  function circumradius(ax, ay, bx, by, cx, cy) {
      const dx = bx - ax;
      const dy = by - ay;
      const ex = cx - ax;
      const ey = cy - ay;

      const bl = dx * dx + dy * dy;
      const cl = ex * ex + ey * ey;
      const d = 0.5 / (dx * ey - dy * ex);

      const x = (ey * bl - dy * cl) * d;
      const y = (dx * cl - ex * bl) * d;

      return x * x + y * y;
  }

  function circumcenter(ax, ay, bx, by, cx, cy) {
      const dx = bx - ax;
      const dy = by - ay;
      const ex = cx - ax;
      const ey = cy - ay;

      const bl = dx * dx + dy * dy;
      const cl = ex * ex + ey * ey;
      const d = 0.5 / (dx * ey - dy * ex);

      const x = ax + (ey * bl - dy * cl) * d;
      const y = ay + (dx * cl - ex * bl) * d;

      return {x, y};
  }

  function quicksort(ids, dists, left, right) {
      if (right - left <= 20) {
          for (let i = left + 1; i <= right; i++) {
              const temp = ids[i];
              const tempDist = dists[temp];
              let j = i - 1;
              while (j >= left && dists[ids[j]] > tempDist) ids[j + 1] = ids[j--];
              ids[j + 1] = temp;
          }
      } else {
          const median = (left + right) >> 1;
          let i = left + 1;
          let j = right;
          swap(ids, median, i);
          if (dists[ids[left]] > dists[ids[right]]) swap(ids, left, right);
          if (dists[ids[i]] > dists[ids[right]]) swap(ids, i, right);
          if (dists[ids[left]] > dists[ids[i]]) swap(ids, left, i);

          const temp = ids[i];
          const tempDist = dists[temp];
          while (true) {
              do i++; while (dists[ids[i]] < tempDist);
              do j--; while (dists[ids[j]] > tempDist);
              if (j < i) break;
              swap(ids, i, j);
          }
          ids[left + 1] = ids[j];
          ids[j] = temp;

          if (right - i + 1 >= j - left) {
              quicksort(ids, dists, i, right);
              quicksort(ids, dists, left, j - 1);
          } else {
              quicksort(ids, dists, left, j - 1);
              quicksort(ids, dists, i, right);
          }
      }
  }

  function swap(arr, i, j) {
      const tmp = arr[i];
      arr[i] = arr[j];
      arr[j] = tmp;
  }

  function defaultGetX(p) {
      return p[0];
  }
  function defaultGetY(p) {
      return p[1];
  }

  cmd.alphaShapes = function(pointLyr, targetDataset, opts) {
    requirePointLayer(pointLyr);
    if (opts.interval > 0 === false) {
      stop('Expected a non-negative interval parameter');
    }
    var filter = getAlphaDistanceFilter(targetDataset, opts.interval);
    var dataset = getPolygonDataset$2(pointLyr, filter, opts);
    var merged = mergeDatasets([targetDataset, dataset]);
    var lyr = merged.layers.pop();
    targetDataset.arcs = merged.arcs;
    setOutputLayerName(lyr, pointLyr, null, opts);
    return lyr;
  };

  function getAlphaDistanceFilter(dataset, interval) {
    return isLatLngDataset(dataset) ? getSphericalFilter(interval) : getPlanarFilter(interval);
  }

  function getPlanarFilter(interval) {
    return function(a, b) {
      return distance2D(a[0], a[1], b[0], b[1]) <= interval;
    };
  }

  // TODO: switch to real distance metric (don't assume meters, use CRS data)
  function getSphericalFilter(interval) {
    return function(a, b) {
      return greatCircleDistance(a[0], a[1], b[0], b[1]) <= interval;
    };
  }


  function getTriangleDataset(lyr, filter, opts) {
    var points = getPointsInLayer(lyr);
    var del = Delaunator.from(points);
    var index = opts.keep_points ? new Uint8Array(points.length) : null;
    var triangles = del.triangles;
    var geojson = {
      type: 'MultiPolygon',
      coordinates: []
    };
    var a, b, c, ai, bi, ci;
    for (var i=0, n=triangles.length; i<n; i+=3) {
      // a, b, c: triangle verticies in CCW order
      ai = triangles[i];
      bi = triangles[i+1];
      ci = triangles[i+2];
      a = points[ai];
      b = points[bi];
      c = points[ci];
      if (!(filter(a, b) && filter(b, c) && filter(a, c))) continue;
      geojson.coordinates.push([[c, b, a, c]]);
      if (index) {
        index[ai] = 1;
        index[bi] = 1;
        index[ci] = 1;
      }
    }
    if (index) {
      addPointSymbols(geojson, points, index);
    }
    return importGeoJSON(geojson);
  }

  function addPointSymbols(geom, points, index) {
    var p;
    for (var i=0, n=index.length; i<n; i++) {
      if (index[i] === 0) {
        geom.coordinates.push(getPointSymbolCoords(points[i]));
      }
    }
  }

  function getPointSymbolCoords(p) {
    var d = 0.0001,
        x = p[0],
        y = p[1];
    return [[[x, y], [x, y+d], [x+d, y+d], [x+d, y], [x, y]]];
  }

  function getPolygonDataset$2(lyr, filter, opts) {
    var dataset = getTriangleDataset(lyr, filter, opts);
    buildTopology(dataset);
    if (!opts.debug) {
      cleanLayers(dataset.layers, dataset, {quiet: true});
    }
    return dataset;
  }

  function dissolveBufferDataset(dataset, optsArg) {
    var opts = optsArg || {};
    var lyr = dataset.layers[0];
    var tmp;
    var nodes = addIntersectionCuts(dataset, {});
    if (opts.debug_division) {
      return debugBufferDivision(lyr, nodes);
    }
    var mosaicIndex = new MosaicIndex(lyr, nodes, {flat: false, no_holes: false});
    if (opts.debug_mosaic) {
      tmp = composeMosaicLayer(lyr, mosaicIndex.mosaic);
      lyr.shapes = tmp.shapes;
      lyr.data = tmp.data;
      return;
    }
    var pathfind = getRingIntersector(mosaicIndex.nodes);
    var shapes2 = lyr.shapes.map(function(shp, shapeId) {
      var tiles = mosaicIndex.getTilesByShapeIds([shapeId]);
      var rings = [];
      for (var i=0; i<tiles.length; i++) {
        rings.push(tiles[i][0]);
      }
      return pathfind(rings, 'dissolve');
    });
    lyr.shapes = shapes2;
    if (!opts.no_dissolve) {
      dissolveArcs(dataset);
    }
  }

  function debugBufferDivision(lyr, nodes) {
    var divide = getHoleDivider(nodes);
    var shapes2 = [];
    var records = [];
    lyr.shapes.forEach(divideShape);
    lyr.shapes = shapes2;
    lyr.data = new DataTable(records);
    return lyr;

    function divideShape(shp) {
      var cw = [], ccw = [];
      divide(shp, cw, ccw);
      cw.forEach(function(ring) {
        shapes2.push([ring]);
        records.push({type: 'ring'});
      });
      ccw.forEach(function(hole) {
        shapes2.push([reversePath(hole)]);
        records.push({type: 'hole'});
      });
    }
  }

  // n = number of segments used to approximate a circle
  // Returns tolerance as a percent of circle radius
  function getBufferToleranceFromCircleSegments(n) {
    return 1 - Math.cos(Math.PI / n);
  }

  function getArcDegreesFromTolerancePct(pct) {
    return 360 * Math.acos(1 - pct) / Math.PI;
  }

  // n = number of segments used to approximate a circle
  // Returns tolerance as a percent of circle radius
  function getBufferToleranceFromCircleSegments2(n) {
    return 1 / Math.cos(Math.PI / n) - 1;
  }

  function getArcDegreesFromTolerancePct2(pct) {
    return 360 * Math.acos(1 / (pct + 1)) / Math.PI;
  }

  // return constant distance in meters, or return null if unparsable
  function parseConstantBufferDistance(str, crs) {
    var parsed = parseMeasure2(str);
    if (!parsed.value) return null;
    return convertDistanceParam(str, crs) || null;
  }

  function getBufferToleranceFunction(dataset, opts) {
    var crs = getDatasetCRS(dataset);
    var constTol = opts.tolerance ? parseConstantBufferDistance(opts.tolerance, crs) : 0;
    var pctOfRadius = 1/100;
    return function(meterDist) {
      if (constTol) return constTol;
      return constTol ? constTol : meterDist * pctOfRadius;
    };
  }

  function getBufferDistanceFunction(lyr, dataset, opts) {
    if (!opts.radius) {
      stop('Missing expected radius parameter');
    }
    var unitStr = opts.units || '';
    var crs = getDatasetCRS(dataset);
    var constDist = parseConstantBufferDistance(opts.radius + unitStr, crs);
    if (constDist) return function() {return constDist;};
    var expr = compileValueExpression(opts.radius, lyr, null, {}); // no arcs
    return function(shpId) {
      var val = expr(shpId);
      if (!val) return 0;
      // TODO: optimize common case that expression returns a number
      var dist = parseConstantBufferDistance(val + unitStr, crs);
      return dist || 0;
    };
  }

  var BufferCommon = /*#__PURE__*/Object.freeze({
    __proto__: null,
    dissolveBufferDataset: dissolveBufferDataset,
    getBufferToleranceFromCircleSegments: getBufferToleranceFromCircleSegments,
    getArcDegreesFromTolerancePct: getArcDegreesFromTolerancePct,
    getBufferToleranceFromCircleSegments2: getBufferToleranceFromCircleSegments2,
    getArcDegreesFromTolerancePct2: getArcDegreesFromTolerancePct2,
    parseConstantBufferDistance: parseConstantBufferDistance,
    getBufferToleranceFunction: getBufferToleranceFunction,
    getBufferDistanceFunction: getBufferDistanceFunction
  });

  // Returns a function for generating GeoJSON geometries (MultiLineString or MultiPolygon)
  function getPolylineBufferMaker(arcs, geod, getBearing, opts) {
    var maker = getPathBufferMaker(arcs, geod, getBearing, opts);
    var geomType = opts.geometry_type;
    // polyline output could be used for debugging
    var outputGeom = opts.output_geometry == 'polyline' ? 'polyline' : 'polygon';

    function polygonCoords(ring) {
      return [ring];
    }

    function pathBufferCoords(pathArcs, dist) {
      var pathCoords = maker(pathArcs, dist);
      var revPathArcs;
      if (geomType == 'polyline') {
        revPathArcs = reversePath(pathArcs.concat());
        pathCoords = pathCoords.concat(maker(revPathArcs, dist));
      }
      pathCoords.push(pathCoords[0]); // close path
      return outputGeom == 'polyline' ? pathCoords : [pathCoords];
    }

    return function(shape, dist) {
      var geom = {
        type: outputGeom == 'polyline' ? 'MultiLineString' : 'MultiPolygon',
        coordinates: []
      };
      for (var i=0; i<shape.length; i++) {
        geom.coordinates.push(pathBufferCoords(shape[i], dist));
      }
      return geom.coordinates.length == 0 ? null : geom;
    };
  }


  function getPathBufferMaker(arcs, geod, getBearing, opts) {

    var backtrackSteps = opts.backtrack >= 0 ? opts.backtrack : 50;
    var pathIter = new ShapeIter(arcs);
    var capStyle = opts.cap_style || 'round'; // expect 'round' or 'flat'
    var tolerance;
    // TODO: implement other join styles than round

    function updateTolerance(dist) {

    }

    function addRoundJoin(arr, x, y, startDir, angle, dist) {
      var increment = 10;
      var endDir = startDir + angle;
      var dir = startDir + increment;
      while (dir < endDir) {
        addBufferVertex(arr, geod(x, y, dir, dist), backtrackSteps);
        dir += increment;
      }
    }

    function addRoundJoin2(arr, x, y, startDir, angle, dist) {
      var increment = 10;
      var endDir = startDir + angle;
      var dir = startDir + increment;
      while (dir < endDir) {
        addBufferVertex(arr, geod(x, y, dir, dist), backtrackSteps);
        dir += increment;
      }
    }

    // Test if two points are within a snapping tolerance
    // TODO: calculate the tolerance more sensibly
    function veryClose(x1, y1, x2, y2, tol) {
      var dist = geom.distance2D(x1, y1, x2, y2);
      return dist < tol;
    }

    function veryCloseToPrevPoint(arr, x, y) {
      var prev = arr[arr.length - 1];
      return veryClose(prev[0], prev[1], x, y, 0.000001);
    }

    function appendPoint(arr, p) {
      var prev = arr[arr.length - 1];
      if (!veryClose(prev[0], prev[1], p[0], p[1], 1e-10)) {
        arr.push(p);
      } else {
        //var dist = geom.distance2D(prev[0], prev[1], p[0], p[1]);
        //console.log(dist)
      }
    }

    function makeCap(x, y, direction, dist) {
      if (capStyle == 'flat') {
        return [[x, y]];
      }
      return makeRoundCap(x, y, direction, dist);
    }

    function makeRoundCap(x, y, segmentDir, dist) {
      var points = [];
      var increment = 10;
      var startDir = segmentDir - 90;
      var angle = increment;
      while (angle < 180) {
        points.push(geod(x, y, startDir + angle, dist));
        angle += increment;
      }
      return points;
    }

    // get angle between two extruded segments in degrees
    // positive angle means join in convex (range: 0-180 degrees)
    // negative angle means join is concave (range: -180-0 degrees)
    function getJoinAngle(direction1, direction2) {
      var delta = direction2 - direction1;
      if (delta > 180) {
        delta -= 360;
      }
      if (delta < -180) {
        delta += 360;
      }
      return delta;
    }

    function addBufferVertex(arr, d, maxBacktrack) {
      var a, b, c, hit;
      for (var i=0, idx = arr.length - 3; i<maxBacktrack && idx >= 0; i++, idx--) {
        c = arr[arr.length - 1];
        a = arr[idx];
        b = arr[idx + 1];
        // TODO: consider using a geodetic intersection function for lat-long datasets
        hit = bufferIntersection(a[0], a[1], b[0], b[1], c[0], c[1], d[0], d[1]);
        if (hit) {
          // TODO: handle collinear segments
          // if (hit.length != 2) console.log('COLLINEAR', hit)
          // segments intersect -- replace two internal segment endpoints with xx point
          while (arr.length > idx + 1) arr.pop();
          appendPoint(arr, hit);
        }
      }

      appendPoint(arr, d);
    }

    return function(path, dist) {
      var left = [];
      var x0, y0, x1, y1, x2, y2;
      var p1, p2;
      var bearing, prevBearing, firstBearing, joinAngle;
      var i = 0;
      pathIter.init(path);

      while (pathIter.hasNext()) {
        // TODO: use a tolerance
        if (pathIter.x === x2 && pathIter.y === y2) continue; // skip duplicate points
        x1 = x2;
        y1 = y2;
        x2 = pathIter.x;
        y2 = pathIter.y;
        if (i >= 1) {
          prevBearing = bearing;
          bearing = getBearing(x1, y1, x2, y2);
          p1 = geod(x1, y1, bearing - 90, dist);
          p2 = geod(x2, y2, bearing - 90, dist);
          // left.push([x1, y1], p1) // debug extrusion lines
          // left.push([x2, y2], p2) // debug extrusion lines
        }
        if (i == 1) {
          firstBearing = bearing;
          x0 = x1;
          y0 = y1;
          left.push(p1, p2);
        }
        if (i > 1) {
          joinAngle = getJoinAngle(prevBearing, bearing);
          if (veryCloseToPrevPoint(left, p1[0], p1[1])) {
            // skip first point
            addBufferVertex(left, p2, backtrackSteps);
          } else if (joinAngle > 0) {
            addRoundJoin(left, x1, y1, prevBearing - 90, joinAngle, dist);
            addBufferVertex(left, p1, backtrackSteps);
            addBufferVertex(left, p2, backtrackSteps);
          } else {
            addBufferVertex(left, p1, backtrackSteps);
            addBufferVertex(left, p2, backtrackSteps);
          }
        }
        i++;
      }
      // TODO: handle defective polylines

      if (x2 == x0 && y2 == y0) {
        // add join to finish closed path
        joinAngle = getJoinAngle(bearing, firstBearing);
        if (joinAngle > 0) {
          addRoundJoin(left, x2, y2, bearing - 90, joinAngle, dist);
        }
      } else {
        // add a cap to finish open path
        left.push.apply(left, makeCap(x2, y2, bearing, dist));
      }
      return left;
    };
  }

  function addBufferVertex(arr, d, maxBacktrack) {
    var a, b, c, hit;
    for (var i=0, idx = arr.length - 3; i<maxBacktrack && idx >= 0; i++, idx--) {
      c = arr[arr.length - 1];
      a = arr[idx];
      b = arr[idx + 1];
      // TODO: consider using a geodetic intersection function for lat-long datasets
      hit = bufferIntersection(a[0], a[1], b[0], b[1], c[0], c[1], d[0], d[1]);
      if (hit) {
        // TODO: handle collinear segments
        if (hit.length != 2) {
          // console.log("COLLINEAR", hit)
        }
        // segments intersect -- replace two internal segment endpoints with xx point
        while (arr.length > idx + 1) arr.pop();
        // TODO: check proximity of hit to several points
        arr.push(hit);
      }
    }

    // TODO: check proximity to previous point
    arr.push(d); // add new point
  }

  // Exclude segments with non-intersecting bounding boxes before
  // calling intersection function
  // Possibly slightly faster than direct call... not worth it?
  function bufferIntersection(ax, ay, bx, by, cx, cy, dx, dy) {
    if (ax < cx && ax < dx && bx < cx && bx < dx ||
        ax > cx && ax > dx && bx > cx && bx > dx ||
        ay < cy && ay < dy && by < cy && by < dy ||
        ay > cy && ay > dy && by > cy && by > dy) return null;
    return geom.segmentIntersection(ax, ay, bx, by, cx, cy, dx, dy);
  }

  var PathBuffer = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getPolylineBufferMaker: getPolylineBufferMaker,
    addBufferVertex: addBufferVertex,
    bufferIntersection: bufferIntersection
  });

  function testSegmentBoundsIntersection(a, b, bb) {
    if (bb.containsPoint(a[0], a[1])) {
      return true;
    }
    return !!(
      geom.segmentIntersection(a[0], a[1], b[0], b[1], bb.xmin, bb.ymin, bb.xmin, bb.ymax) ||
      geom.segmentIntersection(a[0], a[1], b[0], b[1], bb.xmin, bb.ymax, bb.xmax, bb.ymax) ||
      geom.segmentIntersection(a[0], a[1], b[0], b[1], bb.xmax, bb.ymax, bb.xmax, bb.ymin) ||
      geom.segmentIntersection(a[0], a[1], b[0], b[1], bb.xmax, bb.ymin, bb.xmin, bb.ymin));
  }

  function getPolylineBufferMaker2(arcs, geod, getBearing, opts) {
    var makeLeftBuffer = getPathBufferMaker2(arcs, geod, getBearing, opts);
    var geomType = opts.geometry_type;

    function polygonCoords(ring) {
      return [ring];
    }

    function needLeftBuffer(path, arcs) {
      if (geomType == 'polyline') {
        return opts.type != 'right';
      }
      // assume polygon type
      if (opts.type == 'outer') {
        return geom.getPathWinding(path, arcs) == 1;
      }
      if (opts.type == 'inner') {
        return geom.getPathWinding(path, arcs) == -1;
      }
      return true;
    }

    function needRightBuffer() {
      return geomType == 'polyline' && opts.type != 'left';
    }

    function makeBufferParts(pathArcs, dist) {
      var leftPartials, rightPartials, parts, revPathArcs;

      if (needLeftBuffer(pathArcs, arcs)) {
        leftPartials = makeLeftBuffer(pathArcs, dist);
      }
      if (needRightBuffer()) {
        revPathArcs = reversePath(pathArcs.concat());
        rightPartials = makeLeftBuffer(revPathArcs, dist);
      }
      parts = (leftPartials || []).concat(rightPartials || []);
      return parts.map(polygonCoords);
    }

    // Returns a GeoJSON Geometry (MultiLineString or MultiPolygon) or null
    return function(shape, dist) {
      var geom = {
        type: 'MultiPolygon',
        coordinates: []
      };
      for (var i=0; i<shape.length; i++) {
        geom.coordinates = geom.coordinates.concat(makeBufferParts(shape[i], dist));
      }
      return geom.coordinates.length == 0 ? null : geom;
    };
  }

  function getPathBufferMaker2(arcs, geod, getBearing, opts) {
    var backtrackSteps = opts.backtrack >= 0 ? opts.backtrack : 50;
    var pathIter = new ShapeIter(arcs);
    var capStyle = opts.cap_style || 'round'; // expect 'round' or 'flat'
    var tolerance;
    var partials, left, center;
    var bounds;
    // TODO: implement other join styles than round

    function updateTolerance(dist) {

    }

    function addRoundJoin(x, y, startDir, angle, dist) {
      var increment = 10;
      var endDir = startDir + angle;
      var dir = startDir + increment;
      while (dir < endDir) {
        addBufferVertex(geod(x, y, dir, dist));
        dir += increment;
      }
    }

    // function addRoundJoin2(arr, x, y, startDir, angle, dist) {
    //   var increment = 10;
    //   var endDir = startDir + angle;
    //   var dir = startDir + increment;
    //   while (dir < endDir) {
    //     addBufferVertex(arr, geod(x, y, dir, dist));
    //     dir += increment;
    //   }
    // }

    // Test if two points are within a snapping tolerance
    // TODO: calculate the tolerance more sensibly
    function veryClose(x1, y1, x2, y2, tol) {
      var dist = geom.distance2D(x1, y1, x2, y2);
      return dist < tol;
    }

    function veryCloseToPrevPoint(arr, x, y) {
      var prev = arr[arr.length - 1];
      return veryClose(prev[0], prev[1], x, y, 0.000001);
    }

    function appendPoint(arr, p) {
      var prev = arr[arr.length - 1];
      if (!veryClose(prev[0], prev[1], p[0], p[1], 1e-10)) {
        arr.push(p);
      } else {
        //var dist = geom.distance2D(prev[0], prev[1], p[0], p[1]);
        //console.log(dist)
      }
    }

    function makeCap(x, y, direction, dist) {
      if (capStyle == 'flat') {
        return [[x, y]];
      }
      return makeRoundCap(x, y, direction, dist);
    }

    function makeRoundCap(x, y, segmentDir, dist) {
      var points = [];
      var increment = 10;
      var startDir = segmentDir - 90;
      var angle = increment;
      while (angle < 180) {
        points.push(geod(x, y, startDir + angle, dist));
        angle += increment;
      }
      return points;
    }

    // get angle between two extruded segments in degrees
    // positive angle means join in convex (range: 0-180 degrees)
    // negative angle means join is concave (range: -180-0 degrees)
    function getJoinAngle(direction1, direction2) {
      var delta = direction2 - direction1;
      if (delta > 180) {
        delta -= 360;
      }
      if (delta < -180) {
        delta += 360;
      }
      return delta;
    }


    // TODO: handle polygon holes
    function addBufferVertex(d) {
      var arr = left;
      var a, b, c, c0, hit;
      // c is the start point of the segment formed by appending point d to the polyline.
      c0 = c = arr[arr.length - 1];
      for (var i=0, idx = arr.length - 3; idx >= 0; i++, idx--) {
        a = arr[idx];
        b = arr[idx + 1];
        // TODO: consider using a geodetic intersection function for lat-long datasets
        hit = bufferIntersection(a[0], a[1], b[0], b[1], c[0], c[1], d[0], d[1]);
        if (hit) {
          if (segmentTurn(a, b, c, d) == 1) {
            // interpretation: segment cd crosses segment ab from outside to inside
            // the buffer -- we need to start a new partial; otherwise,
            // the following code would likely remove a loop representing
            // an oxbow-type hole in the buffer.
            //
            finishPartial();
            break;
          } else {
            // console.log('HIT', internal.segmentTurn(a, b, c, d))
          }
          // TODO: handle collinear segments (consider creating new partial)
          // if (hit.length != 2) console.log('COLLINEAR', hit)

          // segments intersect, indicating a spurious loop: remove the loop and
          // replace the endpoints of the intersecting segments with the intersection point.
          while (arr.length > idx + 1) arr.pop();
          appendPoint(arr, hit);
          c = hit; // update starting point of the newly added segment
        }

        // Maintain a bounding box around vertices before the backtrack limit.
        // If the latest segment intersects this bounding box, there could be a self-
        // intersection -- start a new partial to prevent self-intersection.
        //
        if (i >= backtrackSteps) {
          if (!bounds) {
            bounds = new Bounds();
            bounds.mergePoint(a[0], a[1]);
          }
          bounds.mergePoint(b[0], b[1]);
          if (testSegmentBoundsIntersection(c0, d, bounds)) {
            finishPartial();
          }
          break;
        }
      }

      appendPoint(arr, d);
    }

    function finishPartial() {
      // Get endpoints of the two polylines, for starting the next partial
      var leftEP = left[left.length - 1];
      var centerEP = center[center.length - 1];

      // Make a polygon ring
      var ring = [];
      extendArray(ring, left);
      center.reverse();
      extendArray(ring, center);
      ring.push(ring[0]); // close ring
      partials.push(ring);

      // Start next partial
      left.push(leftEP);
      center.push(centerEP);

      // clear bbox
      // bbox = null;
    }

    function extendArray(arr, arr2) {
      arr2.reverse();
      while(arr2.length > 0) arr.push(arr2.pop());
    }

    return function(path, dist) {
      var x0, y0, x1, y1, x2, y2;
      var p1, p2;
      var bearing, prevBearing, firstBearing, joinAngle;
      partials = [];
      left = [];
      center = [];
      pathIter.init(path);

      if (pathIter.hasNext()) {
        x0 = x2 = pathIter.x;
        y0 = y2 = pathIter.y;
      }
      while (pathIter.hasNext()) {
        // TODO: use a tolerance
        if (pathIter.x === x2 && pathIter.y === y2) continue; // skip duplicate points
        x1 = x2;
        y1 = y2;
        x2 = pathIter.x;
        y2 = pathIter.y;

        prevBearing = bearing;
        bearing = getBearing(x1, y1, x2, y2);
        // shift original polyline segment to the left by buffer distance
        p1 = geod(x1, y1, bearing - 90, dist);
        p2 = geod(x2, y2, bearing - 90, dist);

        if (center.length === 0) {
          // first loop, second point in this partial
          if (partials.length === 0) {
            firstBearing = bearing;
          }
          left.push(p1, p2);
          center.push([x1, y1], [x2, y2]);
        } else {
          //
          joinAngle = getJoinAngle(prevBearing, bearing);
          if (veryCloseToPrevPoint(left, p1[0], p1[1])) {
            // skip first point
            addBufferVertex(p2);
          } else if (joinAngle > 0) {
            addRoundJoin(x1, y1, prevBearing - 90, joinAngle, dist);
            addBufferVertex(p1);
            addBufferVertex(p2);
          } else {
            addBufferVertex(p1);
            addBufferVertex(p2);
          }
          center.push([x2, y2]);
        }
      }

      if (center.length > 1) {
        finishPartial();
      }
      // TODO: handle defective polylines

      // if (x2 == x0 && y2 == y0) {
      //   // add join to finish closed path
      //   joinAngle = getJoinAngle(bearing, firstBearing);
      //   if (joinAngle > 0) {
      //     addRoundJoin(leftpart, x2, y2, bearing - 90, joinAngle, dist);
      //   }
      // } else {
      //   // add a cap to finish open path
      //   leftpart.push.apply(leftpart, makeCap(x2, y2, bearing, dist));
      // }

      return partials;
    };
  }

  // GeographicLib docs: https://geographiclib.sourceforge.io/html/js/
  //   https://geographiclib.sourceforge.io/html/js/module-GeographicLib_Geodesic.Geodesic.html
  //   https://geographiclib.sourceforge.io/html/js/tutorial-2-interface.html
  function getGeodesic(P) {
    if (!isLatLngCRS(P)) error('Expected an unprojected CRS');
    var f = P.es / (1 + Math.sqrt(P.one_es));
    var GeographicLib = require('mproj').internal.GeographicLib;
    return new GeographicLib.Geodesic.Geodesic(P.a, f);
  }

  function interpolatePoint2D(ax, ay, bx, by, k) {
    var j = 1 - k;
    return [ax * j + bx * k, ay * j + by * k];
  }

  function getInterpolationFunction(P) {
    var spherical = P && isLatLngCRS(P);
    if (!spherical) return interpolatePoint2D;
    var geod = getGeodesic(P);
    return function(lng, lat, lng2, lat2, k) {
      var r = geod.Inverse(lat, lng, lat2, lng2);
      var dist = r.s12 * k;
      var r2 = geod.Direct(lat, lng, r.azi1, dist);
      return [r2.lon2, r2.lat2];
    };
  }

  function getPlanarSegmentEndpoint(x, y, bearing, meterDist) {
    var rad = bearing / 180 * Math.PI;
    var dx = Math.sin(rad) * meterDist;
    var dy = Math.cos(rad) * meterDist;
    return [x + dx, y + dy];
  }

  // source: https://github.com/mapbox/cheap-ruler/blob/master/index.js
  function fastGeodeticSegmentFunction(lng, lat, bearing, meterDist) {
    var D2R = Math.PI / 180;
    var cos = Math.cos(lat * D2R);
    var cos2 = 2 * cos * cos - 1;
    var cos3 = 2 * cos * cos2 - cos;
    var cos4 = 2 * cos * cos3 - cos2;
    var cos5 = 2 * cos * cos4 - cos3;
    var kx = (111.41513 * cos - 0.09455 * cos3 + 0.00012 * cos5) * 1000;
    var ky = (111.13209 - 0.56605 * cos2 + 0.0012 * cos4) * 1000;
    var bearingRad = bearing * D2R;
    var lat2 = lat + Math.cos(bearingRad) * meterDist / ky;
    var lng2 = lng + Math.sin(bearingRad) * meterDist / kx;
    return [lng2, lat2];
  }

  function getGeodeticSegmentFunction(P) {
    if (!isLatLngCRS(P)) {
      return getPlanarSegmentEndpoint;
    }
    var g = getGeodesic(P);
    return function(lng, lat, bearing, meterDist) {
      var o = g.Direct(lat, lng, bearing, meterDist);
      var p = [o.lon2, o.lat2];
      return p;
    };
  }

  function getFastGeodeticSegmentFunction(P) {
    // CAREFUL: this function has higher error at very large distances and at the poles
    // also, it wouldn't work for other planets than Earth
    return isLatLngCRS(P) ? fastGeodeticSegmentFunction : getPlanarSegmentEndpoint;
  }


  function bearingDegrees(a, b, c, d) {
    return geom.bearing(a, b, c, d) * 180 / Math.PI;
  }

  function bearingDegrees2D(a, b, c, d) {
    return geom.bearing2D(a, b, c, d) * 180 / Math.PI;
  }

  // return function to calculate bearing of a segment in degrees
  function getBearingFunction(dataset) {
    var P = getDatasetCRS(dataset);
    return isLatLngCRS(P) ? bearingDegrees : bearingDegrees2D;
  }

  var Geodesic = /*#__PURE__*/Object.freeze({
    __proto__: null,
    interpolatePoint2D: interpolatePoint2D,
    getInterpolationFunction: getInterpolationFunction,
    getPlanarSegmentEndpoint: getPlanarSegmentEndpoint,
    getGeodeticSegmentFunction: getGeodeticSegmentFunction,
    getFastGeodeticSegmentFunction: getFastGeodeticSegmentFunction,
    bearingDegrees: bearingDegrees,
    bearingDegrees2D: bearingDegrees2D,
    getBearingFunction: getBearingFunction
  });

  function makePolylineBuffer(lyr, dataset, opts) {
    var geojson = makeShapeBufferGeoJSON(lyr, dataset, opts);
    var dataset2 = importGeoJSON(geojson, {});
    dissolveBufferDataset(dataset2, opts);
    return dataset2;
  }

  function makeShapeBufferGeoJSON(lyr, dataset, opts) {
    var distanceFn = getBufferDistanceFunction(lyr, dataset, opts);
    var toleranceFn = getBufferToleranceFunction(dataset, opts);
    var geod = getFastGeodeticSegmentFunction(getDatasetCRS(dataset));
    var getBearing = getBearingFunction(dataset);
    var makerOpts = Object.assign({geometry_type: lyr.geometry_type}, opts);
    var factory = opts.v2 ? getPolylineBufferMaker2 : getPolylineBufferMaker;
    var makeShapeBuffer = factory(dataset.arcs, geod, getBearing, makerOpts);
    var records = lyr.data ? lyr.data.getRecords() : null;
    var geometries = lyr.shapes.map(function(shape, i) {
      var dist = distanceFn(i);
      if (!dist || !shape) return null;
      return makeShapeBuffer(shape, dist, lyr.geometry_type);
    });
    // TODO: make sure that importer supports null geometries (not standard GeoJSON);
    return {
      type: 'GeometryCollection',
      geometries: geometries
    };
  }

  function makePolygonBuffer(lyr, dataset, opts) {
    var geojson = makeShapeBufferGeoJSON(lyr, dataset, opts);
    var dataset2 = importGeoJSON(geojson, {});
    dissolveBufferDataset(dataset2);
    return dataset2;
  }

  // Utility functions for GeoJSON-style lat-long [x,y] coordinates and arrays of coords

  var e = 1e-10;
  var T = 90 - e;
  var L = -180 + e;
  var B = -90 + e;
  var R = 180 - e;

  function lastEl(arr) {
    return arr[arr.length - 1];
  }

  function samePoint(a, b) {
    return a[0] === b[0] && a[1] === b[1];
  }

  function isClosedPath(arr) {
    return samePoint(arr[0], lastEl(arr));
  }

  // duplicate points occur if a vertex is on the antimeridan
  function dedup(ring) {
    return ring.reduce(function(memo, p, i) {
      var pp = memo.length > 0 ? memo[memo.length-1] : null;
      if (!pp || pp[0] != p[0] || pp[1] != p[1]) memo.push(p);
      return memo;
    }, []);
  }

  // remove likely rounding errors
  function snapToEdge(p) {
    if (p[0] <= L) p[0] = -180;
    if (p[0] >= R) p[0] = 180;
    if (p[1] <= B) p[1] = -90;
    if (p[1] >= T) p[1] = 90;
  }

  function onPole(p) {
    return p[1] >= T || p[1] <= B;
  }

  function isWholeWorld(coords) {
    // TODO: check that l,r,t,b are all reached
    for (var i=0, n=coords.length; i<n; i++) {
      if (!isEdgePoint(coords[i])) return false;
    }
    return true;
  }

  function touchesEdge(coords) {
    for (var i=0, n=coords.length; i<n; i++) {
      if (isEdgePoint(coords[i])) return true;
    }
    return false;
  }

  function isEdgeSegment(a, b) {
    // TODO: handle segments between pole and non-edge point
    // (these shoudn't exist in a properly clipped path)
    return (onPole(a) || onPole(b)) ||
      a[0] <= L && b[0] <= L || a[0] >= R && b[0] >= R;
  }

  function isEdgePoint(p) {
    return p[1] <= B || p[1] >= T || p[0] <= L || p[0] >= R;
  }

  // Remove segments that belong solely to cut points
  // TODO: verify that antimeridian crosses have matching y coords
  // TODO: stitch together split-apart polygons ?
  //
  function removeCutSegments(coords) {
    if (!touchesEdge(coords)) return coords;
    var coords2 = [];
    var a, b, c, x, y;
    var skipped = false;
    coords.pop(); // remove duplicate point
    a = coords[coords.length-1];
    b = coords[0];
    for (var ci=1, n=coords.length; ci <= n; ci++) {
      c = ci == n ? coords2[0] : coords[ci];
      if (!c) continue; // undefined c could occur in a defective path
      if ((skipped || isEdgeSegment(a, b)) && isEdgeSegment(b, c)) {
        // skip b
        // console.log("skipping b:", ci, a, b, c)
        skipped = true;
      } else {
        if (skipped === true) {
          skipped = false;
        }
        coords2.push(b);
        a = b;
      }
      b = c;
    }
    if (coords2.length > 0) {
      coords2.push(coords2[0].concat()); // close the path
    }
    // TODO: handle runs that are split at the array boundary
    return coords2;
  }


  function removePolylineCrosses(path) {
    return splitPathAtAntimeridian(path);
  }

  function isAntimeridianPoint(p) {
    // return p[0] <= L || p[0] >= R;
    return p[0] == -180 || p[0] == 180;
  }

  // Removes antimeridian crossings from an array of polygon rings
  // TODO: handle edge case: segment is collinear with antimeridian
  // TODO: handle edge case: path coordinates exceed the standard lat-long range
  //
  // rings: array of rings of [x,y] points.
  // Returns array of split-apart rings
  function removePolygonCrosses(rings) {
    var rings2 = [];
    var splitRings = [];
    var ring;
    for (var i=0; i<rings.length; i++) {
      ring = rings[i];
      if (!isClosedPath(ring)) {
        error('Received an open path');
      }
      if (countCrosses(ring) === 0) {
        rings2.push(ring);
      } else {
        splitRings = splitRings.concat(splitPathAtAntimeridian(ring));
      }
    }
    if (splitRings.length > 0) {
      rings2 = rings2.concat(reconnectSplitParts(splitRings));
    }
    return rings2;
  }

  // Stitch an array of split-apart paths into coordinate rings
  // Assumes that the first and last point of each split-apart path is 180 or -180
  // parts: array of paths that have been split at the antimeridian
  function reconnectSplitParts(parts) {
    var yy = getSortedIntersections(parts);
    var rings = [];
    var usedParts = [];
    var errors = 0;
    parts.forEach(function(part, i) {
      if (usedParts[i]) return;
      if (!isValidSplitPart(part)) {
        error('Geometry error');
      }
      var ring = addPartToRing(part, []);
      if (ring) {
        if (!isClosedPath(ring)) {
          error('Generated an open ring');
        }
        rings.push(ring);
      } else {
        errors++;
      }
    });

    return rings;

    function addPartToRing(part, ring) {
      var lastPoint = lastEl(part);
      var i = parts.indexOf(part);
      if (usedParts[i]) {
        debug('Tried to use a previously used path');
        return null;
      }
      usedParts[i] = true;
      ring = ring.concat(part);
      var nextPoint = findNextPoint(parts, lastPoint, yy);
      if (!nextPoint) {
        return null;
      }
      if (lastPoint[0] != nextPoint[0]) {
        // add polar line to switch from east to west or west to east
        // coming from east -> turn south
        // coming from west -> turn north
        var poleY = lastPoint[0] == 180 ? -90 : 90;
        // need a center point (lines longer than 90 degrees cause confusion when rotating)
        ring.push([lastPoint[0], poleY], [0, poleY], [nextPoint[0], poleY]);
      }
      var nextPart = findPartStartingAt(parts, nextPoint);
      if (!nextPart) {
        return null;
      }
      if (samePoint(ring[0], nextPart[0])) {
        // done!
        ring.push(ring[0]); // close the ring
        return ring;
      }
      return addPartToRing(nextPart, ring);
    }
  }

  function addSubPath(paths, path) {
    if (path.length > 1) paths.push(path);
  }

  function isValidSplitPart(part) {
    var lastX = lastEl(part)[0];
    var firstX = part[0][0];
    return (lastX == 180 || lastX == -180) && (firstX == 180 || firstX == -180);
  }

  // p: last point of previous part
  function findNextPoint(parts, p, yy) {
    var x = p[0];
    var y = p[1];
    var i = yy.indexOf(y);
    var xOpp = x == -180 ? 180 : -180;
    var turnSouth = x == 180; // intersecting from the east -> turn south
    var iNext = turnSouth ? i - 1 : i + 1;
    var nextPoint;
    if (x != 180 && x != -180) {
      debug('Unexpected error');
      return null;
    }
    if (i == -1) {
      debug('Point missing from intersection table:', p);
      return null;
    }
    if (iNext < 0 || iNext >= yy.length) {
      // no path to traverse to along the antimeridian --
      // assume the path surrounds one of the poles
      // enclose south pole
      nextPoint = [xOpp, y];
    } else {
      nextPoint = [x, yy[iNext]];
    }
    return nextPoint;
  }

  function findPartStartingAt(parts, firstPoint) {
    for (var i=0; i<parts.length; i++) {
      if (samePoint(parts[i][0], firstPoint)) {
        return parts[i];
      }
    }
    return null;
  }

  function countCrosses(path) {
    var c = 0, pp, p;
    for (var i=0, n=path.length; i<n; i++) {
      p = path[i];
      if (i>0 && Math.abs(pp[0] - p[0]) > 180) {
        c++;
      }
      pp = p;
    }
    return c;
  }

  function splitPathAtAntimeridian(path) {
    var parts = [];
    var part = [];
    var firstPoint = path[0];
    var lastPoint = lastEl(path);
    var closed = samePoint(firstPoint, lastPoint);
    var p, pp, y, y2;
    for (var i=0, n=path.length; i<n; i++) {
      p = path[i];
      if (i>0 && segmentCrossesAntimeridian(pp, p)) {
        // y = sphericalIntercept(pp, p);
        y = planarIntercept(pp, p);
        addIntersectionPoint(part, pp, y);
        addSubPath(parts, part);
        part = [];
        addIntersectionPoint(part, p, y);
        // console.log(y, y2)
      }
      part.push(p);
      pp = p;
    }
    addSubPath(parts, part);

    // join first and last parts of a split-apart ring, so that the first part
    // originates at the antimeridian
    if (closed && parts.length > 1 && !isAntimeridianPoint(firstPoint)) {
      part = parts.pop();
      part.pop(); // remove duplicate point
      parts[0] = part.concat(parts[0]);
    }
    return parts;
  }

  function segmentCrossesAntimeridian(a, b) {
    return Math.abs(a[0] - b[0]) > 180;
  }

  function getSortedIntersections(parts) {
    var values = parts.map(function(p) {
      return p[0][1];
    });
    return utils.genericSort(values, true);
  }


  function addIntersectionPoint(part, p, yint) {
    var xint = p[0] < 0 ? -180 : 180;
    if (!isAntimeridianPoint(p)) { // don't a point if p is already on the antimeridian
      part.push([xint, yint]);
    }
  }


  // p1, p2: two vertices on different sides of the antimeridian
  // Returns y-intercept of the segment connecting p1, p2
  // TODO: consider using the great-circle intersection, instead of
  // the planar intersection.
  // (Planar should be fine if p1 and p2 are close to lon. 180)
  function planarIntercept(p1, p2) {
    var dx = p2[0] - p1[0]; // pos: crosses antimeridian w->e, neg: e->w
    var dx1, dx2;
    if (dx > 0) {
      dx1 = p1[0] + 180;
      dx2 = 180 - p2[0];
    } else {
      dx1 = 180 - p1[0];
      dx2 = p2[0] + 180;
    }
    // avoid fp rounding error if a point is on antimeridian
    if (dx1 === 0) return p1[1];
    if (dx2 === 0) return p2[1];
    return (dx2 * p1[1] + dx1 * p2[1]) / (dx1 + dx2);
  }

  // From: https://github.com/d3/d3-geo/blob/master/src/clip/antimeridian.js
  function sphericalIntercept(p1, p2) {
    var lam1 = p1[0] * D2R,
        phi1 = p1[1] * D2R,
        lam2 = p2[0] * D2R,
        phi2 = p2[1] * D2R,
        sinLam1Lam2 = Math.sin(lam1 - lam2),
        cosPhi2 = Math.cos(phi2),
        cosPhi1 = Math.cos(phi1),
        phi;
    if (Math.abs(sinLam1Lam2) > 1e-6) {
      phi = Math.atan((Math.sin(phi1) * cosPhi2 * Math.sin(lam2) -
        Math.sin(phi2) * cosPhi1) * Math.sin(lam1)) / (cosPhi1 * cosPhi2 * sinLam1Lam2);
    } else {
      phi = (phi1 + phi2) / 2;
    }
    return phi * R2D;
  }

  function ringArea(ring) {
    var iter = new PointIter(ring);
    return getSphericalPathArea2(iter);
  }

  function makePointBuffer(lyr, dataset, opts) {
    var geojson = makePointBufferGeoJSON(lyr, dataset, opts);
    return importGeoJSON(geojson, {});
  }

  // Make a single geodetic circle
  function getCircleGeoJSON(center, radius, vertices, opts) {
    var n = vertices || 360;
    var geod = getGeodeticSegmentFunction(getCRS('wgs84')); // ?
    if (opts.inset) {
      radius -= opts.inset;
    }
    return opts.geometry_type == 'polyline' ?
      getPointBufferLineString([center], radius, n, geod) :
      getPointBufferPolygon([center], radius, n, geod, true);
  }

  // Convert a point layer to circles
  function makePointBufferGeoJSON(lyr, dataset, opts) {
    var vertices = opts.vertices || 72;
    var distanceFn = getBufferDistanceFunction(lyr, dataset, opts);
    var crs = getDatasetCRS(dataset);
    var spherical = isLatLngCRS(crs);
    var geod = getGeodeticSegmentFunction(crs);
    var geometries = lyr.shapes.map(function(shape, i) {
      var dist = distanceFn(i);
      if (!dist || !shape) return null;
      return getPointBufferPolygon(shape, dist, vertices, geod, spherical);
    });
    // TODO: make sure that importer supports null geometries (nonstandard GeoJSON);
    return {
      type: 'GeometryCollection',
      geometries: geometries
    };
  }

  function getPointBufferPolygon(points, distance, vertices, geod, spherical) {
    var rings = [], coords, coords2;
    if (!points || !points.length) return null;
    for (var i=0; i<points.length; i++) {
      coords = getPointBufferCoordinates(points[i], distance, vertices, geod);
      if (!spherical) {
        rings.push([coords]);
      } else if (countCrosses(coords) > 0) {
        coords2 = removePolygonCrosses([coords]);
        while (coords2.length > 0) rings.push([coords2.pop()]); // geojson polygon coords, no hole
      } else if (ringArea(coords) < 0) {
        // negative spherical area: CCW ring, indicating a circle of >180 degrees
        // that fully encloses both poles and the antimeridian.
        // need to add an enclosure around the entire sphere
        // TODO: compare to distance param as a sanity check
        rings.push([
          [[180, 90], [180, -90], [0, -90], [-180, -90], [-180, 90], [0, 90], [180, 90]],
          coords
          ]);
      } else {
        rings.push([coords]);
      }
    }
    return {
      type: 'MultiPolygon',
      coordinates: rings
    };
  }

  function getPointBufferLineString(points, distance, vertices, geod) {
    var rings = [], coords;
    if (!points || !points.length) return null;
    for (var i=0; i<points.length; i++) {
      coords = getPointBufferCoordinates(points[i], distance, vertices, geod);
      coords = removePolylineCrosses(coords);
      while (coords.length > 0) rings.push(coords.pop());
    }
    return rings.length == 1 ? {
      type: 'LineString',
      coordinates: rings[0]
    } : {
      type: 'MultiLineString',
      coordinates: rings
    };
  }

  // Returns array of [x, y] coordinates in a closed ring
  function getPointBufferCoordinates(center, meterDist, vertices, geod) {
    var coords = [],
        angle = 360 / vertices,
        theta;
    for (var i=0; i<vertices; i++) {
      // offsetting by half a step so 4 sides are flat, not pointy
      // (looks better on low-vertex circles)
      theta = (i + 0.5) * angle % 360;
      coords.push(geod(center[0], center[1], theta, meterDist));
    }
    coords.push(coords[0].concat());
    return coords;
  }

  // TODO: consider if layers should be buffered together
  // cmd.buffer = function(layers, dataset, opts) {
  //   return makeBufferLayer(layers[0], dataset, opts);
  // };

  cmd.buffer = makeBufferLayer;

  function makeBufferLayer(lyr, dataset, opts) {
    var dataset2;
    if (lyr.geometry_type == 'point') {
      dataset2 = makePointBuffer(lyr, dataset, opts);
    } else if (lyr.geometry_type == 'polyline') {
      dataset2 = makePolylineBuffer(lyr, dataset, opts);
    } else if (lyr.geometry_type == 'polygon') {
      dataset2 = makePolygonBuffer(lyr, dataset, opts);
    } else {
      stop("Unsupported geometry type");
    }

    var lyr2 = mergeOutputLayerIntoDataset(lyr, dataset, dataset2, opts);
    return [lyr2];
  }

  // TODO: support three or more stops
  function getGradientFunction(stops) {
    var min = stops[0] / 100,
        max = stops[1] / 100;
    if (stops.length != 2) {
      stop('Only two stops are currently supported');
    }
    if (!(min >= 0 && max <= 1 && min < max)) {
      stop('Invalid gradient stops:', stops);
    }
    return function(t) {
      return t * (max - min) + min;
    };
  }

  function getStoppedValues(values, stops) {
    var interpolate = getInterpolatedValueGetter(values, null);
    var n = values.length;
    var fstop = getGradientFunction(stops);
    var values2 = [];
    var t, val;
    for (var i=0; i<n; i++) {
      t = fstop(i / (n - 1));
      val = interpolate(t * (n - 1));
      values2.push(val);
    }
    return values2;
  }

  // convert a continuous index ([0, n-1], -1) to a corresponding interpolated value
  function getInterpolatedValueGetter(values, nullValue) {
    var d3 = require('d3-interpolate');
    var interpolators = [];
    var tmax = values.length - 1;
    for (var i=1; i<values.length; i++) {
      interpolators.push(d3.interpolate(values[i-1], values[i]));
    }
    return function(t) {
      if (t == -1) return nullValue;
      if ((t >= 0 && t <= tmax) === false) {
        error('Range error');
      }
      var i = t == tmax ? tmax - 1 : Math.floor(t);
      var j = t == tmax ? 1 : t % 1;
      return interpolators[i](j);
    };
  }

  // return an array of n values
  // assumes that values can be interpolated by d3-interpolate
  // (colors and numbers should work)
  function interpolateValuesToClasses(values, n, stops) {
    if (values.length == n && !stops) return values;
    var d3 = require('d3-interpolate');
    var numPairs = values.length - 1;
    var output = [values[0]];
    var k, j, t, intVal;
    for (var i=1; i<n-1; i++) {
      k = i / (n-1) * numPairs;
      j = Math.floor(k);
      t = k - j;
      // if (convert) t = convert(t);
      intVal = d3.interpolate(values[j], values[j+1])(t);
      output.push(intVal);
    }
    output.push(values[values.length - 1]);
    if (stops) {
      output = getStoppedValues(output, stops);
    }
    return output;
  }

  var index = {
    categorical: [],
    sequential: [],
    rainbow: [],
    diverging: []
  };
  var ramps;

  function initSchemes() {
    if (ramps) return;
    ramps = {};
    addSchemesFromD3('categorical', 'Category10,Accent,Dark2,Paired,Pastel1,Pastel2,Set1,Set2,Set3,Tableau10');
    addSchemesFromD3('sequential', 'Blues,Greens,Greys,Purples,Reds,Oranges,BuGn,BuPu,GnBu,OrRd,PuBuGn,PuBu,PuRd,RdPu,YlGnBu,YlGn,YlOrBr,YlOrRd');
    addSchemesFromD3('rainbow', 'Cividis,CubehelixDefault,Rainbow,Warm,Cool,Sinebow,Turbo,Viridis,Magma,Inferno,Plasma');
    addSchemesFromD3('diverging', 'BrBG,PRGn,PRGn,PiYG,PuOr,RdBu,RdGy,RdYlBu,RdYlGn,Spectral');
    testLib(); // make sure these schemes are all available
    addCategoricalScheme('Category20',
      '1f77b4aec7e8ff7f0effbb782ca02c98df8ad62728ff98969467bdc5b0d58c564bc49c94e377c2f7b6d27f7f7fc7c7c7bcbd22dbdb8d17becf9edae5');
    addCategoricalScheme('Category20b',
      '393b795254a36b6ecf9c9ede6379398ca252b5cf6bcedb9c8c6d31bd9e39e7ba52e7cb94843c39ad494ad6616be7969c7b4173a55194ce6dbdde9ed6');
    addCategoricalScheme('Category20c',
      '3182bd6baed69ecae1c6dbefe6550dfd8d3cfdae6bfdd0a231a35474c476a1d99bc7e9c0756bb19e9ac8bcbddcdadaeb636363969696bdbdbdd9d9d9');
    addCategoricalScheme('Tableau20',
      '4c78a89ecae9f58518ffbf7954a24b88d27ab79a20f2cf5b43989483bcb6e45756ff9d9879706ebab0acd67195fcbfd2b279a2d6a5c99e765fd8b5a5');
  }

  function addSchemesFromD3(type, names) {
    index[type] = index[type].concat(names.split(','));
  }

  function addCategoricalScheme(name, str) {
    index.categorical.push(name);
    ramps[name] = unpackRamp(str);
  }

  function unpackRamp(str) {
    var colors = [];
    for (var i=0, n=str.length; i<n; i+=6) {
      colors.push('#' + str.substr(i, 6));
    }
    return colors;
  }

  function testLib() {
    var lib = require('d3-scale-chromatic');
    schemes(index.categorical);
    schemes(index.sequential);
    schemes(index.diverging);
    interpolators(index.sequential);
    interpolators(index.rainbow);
    interpolators(index.diverging);

    function schemes(arr) {
      arr.forEach(function(name) {
        if (!lib['scheme' + name]) {
          message('Warning: missing data for', name);
        }
      });
    }

    function interpolators(arr) {
      arr.forEach(function(name) {
        if (!lib['interpolate' + name]) {
          message('Missing interpolator for', name);
        }
      });
    }
  }

  function printColorSchemeNames() {
    initSchemes();
    print('Built-in color schemes (from d3):');
    print ('Categorical\n' + formatStringsAsGrid(index.categorical));
    print ('\nSequential\n' + formatStringsAsGrid(index.sequential));
    print ('\nDiverging\n' + formatStringsAsGrid(index.diverging));
    print ('\nMulti-hue/rainbow\n' + formatStringsAsGrid(index.rainbow));
  }

  function getCategoricalColorScheme(name, n) {
    initSchemes();
    if (index.categorical.includes(name) === false) {
      stop(name, 'is not a categorical color scheme');
    }
    var colors = ramps[name] || require('d3-scale-chromatic')['scheme' + name];
    if (n > colors.length) {
      stop(name, 'does not contain', n, 'colors');
    }
    return colors.slice(0, n);
  }

  function isColorSchemeName(name) {
    initSchemes();
    return index.categorical.includes(name) || index.sequential.includes(name) ||
      index.diverging.includes(name) || index.rainbow.includes(name);
  }

  function getColorRamp(name, n, stops) {
    initSchemes();
    var lib = require('d3-scale-chromatic');
    var ramps = lib['scheme' + name];
    var interpolate = lib['interpolate' + name];
    var ramp;
    if (!ramps && !interpolate) {
      stop('Unknown color scheme name:', name);
    }
    if (index.categorical.includes(name)) {
      stop(name, ' is a categorical color scheme (expected a sequential color scheme)');
    }
    if (ramps && ramps[n]) {
      ramp = ramps[n];
    } else {
      ramp = getInterpolatedRamp(interpolate, n);
    }
    if (stops) {
      ramp = getStoppedValues(ramp, stops);
    }
    return ramp;
  }

  function getInterpolatedRamp(interpolate, n) {
    if (n > 0 === false || !utils.isInteger(n)) {
      error('Expected a positive integer');
    }
    var ramp = [];
    for (var i=0; i<n; i++) {
      ramp.push(interpolate(i / (n - 1)));
    }
    return ramp;
  }

  var scaledIntervals =
    [10,12,15,18,20,22,25,30,35,40,45,50,60,70,80,90,100];
  var precisions =
    [10, 2, 5, 2,10, 2, 5,10, 5,10, 5,50,10,10,10,10,10];


  function getNormalPrecision(scaledInterval) {
    var i = scaledIntervals.indexOf(scaledInterval);
    return precisions[i] || error('Unknown error');
  }

  // return a weighting (0-1) to add strength to classifications that use
  // rounder numbers
  function getRoundnessScore(interval, precision) {
    return precision >= 50 && 1 || precision >= 10 && 0.9 || precision >= 5 && 0.8 || 0.7;
  }

  function getNiceBreaks(values, numBreaks) {
    var quantileBreaks = getQuantileBreaks(values, numBreaks);
    var lowerBreak = quantileBreaks[0];
    var upperBreak = quantileBreaks[quantileBreaks.length-1];
    var data = getCandidateBreaks(lowerBreak, upperBreak, numBreaks);
    // add distribution data and quality metric to each candidate
    data.forEach(function(o) {
      var distribution = getDistributionData(o.breaks, values);
      o.distribution = getDistributionData(o.breaks, values);
      o.quality = o.roundness * evaluateDistribution(o.distribution);
    });
    utils.sortOn(data, 'quality', false);
    return data[0].breaks;
  }


  function evaluateDistribution(distribution) {
    var ideal = utils.sum(distribution) / distribution.length;
    var first = distribution[0];
    var last = distribution[distribution.length - 1];
    var q = (bucketScore(ideal, first) + bucketScore(ideal, last)) / 2;
    return q;
  }

  // downweight buckets the more they deviate from an ideal size
  function bucketScore(ideal, actual) {
    if (actual > ideal) {
      return ideal / actual;
    } else {
      return ideal / (2 * ideal - actual);
    }
  }

  // kludge to avoid rounding errors in break values
  function applyScale(normalVal, scale) {
    if (scale < 1) {
      return normalVal * Math.round(1 / scale);
    }
    return normalVal / scale;
  }

  function getCandidateBreaks(lowerBreak, upperBreak, numBreaks) {
    var cands = [];
    // calculate rounding using equal interval, when possible
    var maxBreak = Math.max(Math.abs(lowerBreak), Math.abs(upperBreak));
    var subRange = numBreaks >= 2 ?
        (upperBreak - lowerBreak) / (numBreaks - 1) : maxBreak;
    var scale = getRangeScale(subRange);
    var scaledRange = scale * subRange;
    var scaledIntervals = getNiceIntervals(scaledRange);
    scaledIntervals.forEach(function(scaledInterval) {
      var scaledPrecision = getNormalPrecision(scaledInterval);
      var interval = applyScale(scaledInterval, scale);
      var precision = applyScale(scaledPrecision, scale);
      var fenceposts = getBreakFenceposts(lowerBreak, precision);
      fenceposts.forEach(function(lowBound) {
        cands.push({
          interval: interval,
          precision: precision,
          roundness: getRoundnessScore(scaledInterval, scaledPrecision),
          breaks: getRoundBreaks(lowBound, interval, numBreaks)
        });
      });
    });
    return cands;
  }


  function getRoundBreaks(lowerBreak, interval, numBreaks) {
    var breaks = [lowerBreak];
    for (var i=1; i<numBreaks; i++) {
      breaks.push(lowerBreak + interval * i);
    }
    return breaks;
  }

  function getBreakFenceposts(val, precision) {
    var boundVal = getRoundingFunction(precision)(val);
    var boundVal2 = boundVal + (val > boundVal ? precision : -precision);
    var fenceposts = boundVal < boundVal2 ? [boundVal, boundVal2] : [boundVal2, boundVal];
    return fenceposts;
  }

  function getNiceIntervals(scaledRange) {
    var intervals = scaledIntervals;
    var lower, upper;
    for (var i=1; i<intervals.length; i++) {
      lower = intervals[i-1];
      upper = intervals[i];
      if (scaledRange >= lower && scaledRange <= upper) {
        return [lower, upper];
      }
    }
    error('Range error');
  }

  function getRangeScale(range) {
    var s = 1;
    if (range > 0.0001 === false || range < 1e9 === false) {
      stop('Data range error');
    }
    while (range > 100) {
      range /= 10;
      s /= 10;
    }
    while (range < 10) {
      range *= 10;
      s *= 10;
    }
    return s;
  }

  // convert an index (0 ... n-1, -1, -2) to a corresponding discreet value
  function getDiscreteValueGetter(values, nullValue, otherValue) {
    var n = values.length;
    return function(i) {
      if (i >= 0 && i < n) {
        return values[i];
      }
      if (i == -2) {
        return otherValue === undefined ? nullValue : otherValue;
      }
      return nullValue;
    };
  }

  function getOutputFunction(classValues, nullValue, opts) {
    // get a function to convert class indexes to output values
    //
    if (opts.continuous) {
      return getInterpolatedValueGetter(classValues, nullValue);
    } else {
      return  getDiscreteValueGetter(classValues, nullValue, opts.other);
    }
  }

  function getKeyStyle(type, opts) {
    return {
      width: opts.key_width || type == 'dataviz' && 500 || 300,
      tileHeight: opts.key_tile_height || 10,
      labelSuffix: opts.key_label_suffix || '',
      lastSuffix: opts.key_last_suffix || '',
      chartHeight: 90,
      chartColor: '#ddd',
      ticColor: 'rgba(0,0,0,0.3)',
      ticLen: opts.key_tic_length >= 0 ? +opts.key_tic_length : 6,
      fontFamily: 'sans-serif',
      fontSize: opts.key_font_size || 13,
      textColor: '#555'
    };
  }

  function makeSimpleKey(colors, breaks, minVal, maxVal, opts) {
    var style = getKeyStyle('simple', opts);
    var tileWidth = style.width / colors.length;
    var tileData = makeEqualTiles(tileWidth, style.tileHeight, colors);
    var layers = [tileData];
    var labels, tics, ticBreaks;
    if (colors.length == breaks.length + 1) {
      ticBreaks = getEvenlySpacedTicOffsets(breaks.length, style.width);
      labels = getTicLabels(breaks, ticBreaks, 0, style.width, style);
      tics = getTics(ticBreaks, 0, style.width, style);
      layers.push(tics, labels);
    } else if (colors.length == breaks.length + 2) {
      style.ticLen = 2; // kludge for label spacing
      labels = getInlineLabels(getFullBreaks(breaks, minVal, maxVal), style);
      layers.push(labels);
    }
    exportKey(opts.key_name || 'simple-key', layers, style.width);
  }

  function makeDatavizKey(colors, breaks, ascending, opts) {
    var style = getKeyStyle('dataviz', opts);
    var minVal = ascending[0];
    var maxVal = ascending[ascending.length - 1];
    var partitions = getFullBreaks(breaks, minVal, maxVal);
    var chart = getReferenceChart(ascending, style);
    var tiles = getProportionalTiles(colors, breaks, minVal, maxVal, style);
    var labels = getTicLabels(partitions, partitions, minVal, maxVal, style);
    var tics = getTics(partitions, minVal, maxVal, style);
    exportKey(opts.key_name || 'dataviz-key', [chart, tiles, tics, labels], style.width);
  }

  function makeGradientKey(classify, breaks, minVal, maxVal, opts) {
    var style = getKeyStyle('gradient', opts);
    var partitions = getFullBreaks(breaks, minVal, maxVal);
    var gradient = makeGradient(classify, partitions, style);
    var ticBreaks = getEvenlySpacedTicOffsets(breaks.length, style.width);
    var labels = getTicLabels(breaks, ticBreaks, 0, style.width, style);
    var tics = getTics(ticBreaks, 0, style.width, style);
    var layers = [gradient, tics, labels];
    exportKey(opts.key_name || 'gradient-key', layers, style.width);
  }

  // export function makeGradientDatavizKey(classify, breaks, ascending, opts) {
  //   var style = getKeyStyle('dataviz', opts);
  //   var minVal = ascending[0];
  //   var maxVal = ascending[ascending.length - 1];
  //   var partitions = getFullBreaks(breaks, minVal, maxVal);
  //   var chart = getReferenceChart(ascending, style);
  //   var gradient = makeGradient(classify, partitions, style);
  //   // var tiles = getProportionalTiles(colors, breaks, minVal, maxVal, style);
  //   var labels = getTicLabels(partitions, partitions, minVal, maxVal, style);
  //   var tics = getTics(partitions, minVal, maxVal, style);
  //   exportKey(opts.key_name || 'dataviz-key', [chart, gradient, tics, labels], style.width);
  // }

  function getXScale(keyWidth, minVal, maxVal) {
    return function(val) {
      return (val - minVal) / (maxVal - minVal) * keyWidth;
    };
  }

  function getLabelTexts(values, style) {
    var digits = getLabelDigits(values);
    return values.map(function(val, i) {
      var isLast = i == values.length - 1;
      var suffix = isLast && style.lastSuffix || style.labelSuffix || '';
      return roundToDigits(val, digits) + suffix;
    });
  }

  function getLabelDigits(values) {
    var min = values[0];
    var max = values[values.length - 1];
    var avg = (max - min) / values.length;
    var d = 0;
    if (avg < 1) d = 2;
    else if (avg < 10) d = 1;
    return d;
  }

  function getEvenlySpacedTicOffsets(n, width) {
    var arr = [];
    for (var i=0; i<n; i++) {
      arr.push((i + 1) / (n + 1) * width);
    }
    return arr;
  }

  function getTics(breaks, minVal, maxVal, style) {
    var getX = getXScale(style.width, minVal, maxVal);
    var tics = [];
    for (var i=0; i<breaks.length; i++) {
      tics.push(makeTic(getX(breaks[i]), style));
    }
    return featuresToDataset(tics);
  }

  function getInlineLabels(values, style) {
    var labels = [];
    var texts = getLabelTexts(values, style);
    var dx = getLabelShift(style);
    var x;
    for (var i=0; i<texts.length; i++) {
      x = (i + 0.5) * style.width / texts.length;
      labels.push(makeLabel(texts[i], x, style));
    }
    return featuresToDataset(labels);
  }

  function getLabelShift(style) {
    // kludge to nudge numbers towards the tic
    return style.labelSuffix ? 3 : 0;
  }

  function getFullBreaks(innerBreaks, minVal, maxVal) {
    return [minVal].concat(innerBreaks, maxVal);
  }

  function getTicLabels(values, breaks, minVal, maxVal, style) {
    var texts = getLabelTexts(values, style);
    var getX = getXScale(style.width, minVal, maxVal);
    var labels = [];
    for (var i=0; i<breaks.length; i++) {
      labels.push(makeLabel(texts[i], getX(breaks[i]), style));
    }
    return featuresToDataset(labels);
  }

  function getProportionalTiles(colors, breaks, minVal, maxVal, style) {
    var arr = getFullBreaks(breaks, minVal, maxVal);
    var getX = getXScale(style.width, minVal, maxVal);
    var tiles = [];
    var x, w;
    for (var i=0; i<arr.length; i++) {
      x = getX(arr[i]);
      w = getX(arr[i+1]) - x;
      tiles.push(makeTile(x, 0, w, style.tileHeight, colors[i]));
    }
    return featuresToDataset(tiles);
  }

  function getReferenceChart(ascending, style) {
    var barWidth = 5;
    var numBars = Math.floor(style.width / barWidth);
    var breaks = getEqualIntervalBreaks(ascending, numBars - 1);
    var counts = getDistributionData(breaks, ascending);
    var maxCount = Math.max.apply(counts, counts);
    var bars = [];
    var y0 = style.tileHeight; // shift chart above the tiles
    var c, h;
    for (var i=0; i<numBars; i++) {
      c = counts[i];
      if (!c) continue;
      h = c / maxCount * style.chartHeight;
      bars.push(makeTile(i*barWidth, y0, barWidth, h , style.chartColor));
    }
    return featuresToDataset(bars);
  }

  function exportKey(name, datasets, width) {
    var svgOpts = {
      width: width,
      crisp_paths: true,
      default_linecap: 'butt'
    };
    var filename = name + (name.endsWith('.svg') ? '' : '.svg');
    var dataset = datasets.length == 1 ? datasets[0] : mergeDatasets(datasets);
    var output = exportSVG(dataset, svgOpts);
    output[0].filename = filename;
    writeFiles(output, {});
  }

  function featuresToDataset(features) {
    var json = {
      type: 'FeatureCollection',
      features: features
    };
    return importGeoJSON(json);
  }

  function makeGradient(classify, partitions, style) {
    var tiles = [];
    var getVal = pixToValue(partitions, style.width);
    var w = 2;
    for (var x=0; x<style.width; x += w) {
      tiles.push(makeTile(x, 0, w, style.tileHeight, classify(getVal(x))));
    }
    return featuresToDataset(tiles);
  }

  function pixToValue(partitions, keyWidth) {
    var classes = partitions.length - 1;
    var sectionWidth = keyWidth / classes;
    return function(x) {
      var i = Math.min(Math.floor(x / sectionWidth), classes - 1); // clamp
      var k = (x - i * sectionWidth) / sectionWidth;
      return partitions[i] * (1 - k) + partitions[i+1] * k;
    };
  }

  function pixToValue2(partitions, keyWidth) {
    var classes = partitions.length - 1;
    var dataRange = partitions[classes] - partitions[0];
    var pixBreaks = partitions.reduce(function(memo, val, i) {
      var x;
      if (i === 0) {
        x = 0;
      } else {
        x = (partitions[i] - partitions[0]) / dataRange * keyWidth;
      }
      memo.push(x);
      return memo;
    }, []);
    var sectionWidth = keyWidth / classes;
    return function(x) {
      var i = Math.min(Math.floor(x / sectionWidth), classes - 1); // clamp
      var k = (x - i * sectionWidth) / sectionWidth;
      return partitions[i] * (1 - k) + partitions[i+1] * k;
    };
  }


  function makeEqualTiles(w, h, colors) {
    var tiles = [];
    for (var i=0; i<colors.length; i++) {
      tiles.push(makeTile(i * w, 0, w, h, colors[i]));
    }
    return featuresToDataset(tiles);
  }

  function getRectangle(x, y, w, h) {
    return [[x, y], [x, y+h], [x+w, y+h], [x+w, y], [x, y]];
  }

  function makeLabel(str, x, style) {
    var y = -(style.ticLen + style.fontSize * 0.7 + 4);
    var align;
    if (x <= 0) {
      align = 'start';
    } else if (x >= style.width) {
      align = 'end';
    } else {
      align = 'middle';
      x += getLabelShift(style);
    }
    return {
      type: 'Feature',
      properties: {
        'label-text': str,
        'font-family': style.fontFamily,
        'font-size': style.fontSize,
        'text-anchor': align,
        fill: style.textColor
      },
      geometry: {
        type: 'Point',
        coordinates: [x, y]
      }
    };
  }

  function makeTic(x, style) {
    var y = style.tileHeight;
    var h = style.tileHeight + style.ticLen;
    return {
      type: 'Feature',
      properties: { stroke: style.ticColor },
      geometry: {
        type: 'LineString',
        coordinates: [[x, y], [x, y - h]]
      }
    };
  }

  function makeTile(x, y, w, h, fill) {
    var coords = getRectangle(x, y, w, h);
    return {
      type: 'Feature',
      properties: {fill: fill},
      geometry: {
        type: 'Polygon',
        coordinates: [coords]
      }
    };
  }

  function getSequentialClassifier$1(classValues, nullValue, dataValues, opts) {
    var numValues = classValues.length;
    var numBuckets = opts.continuous ? numValues - 1 : numValues;

    // continuously interpolated colors/values use one fewer breakpoint than
    // discreetly classed values
    var numBreaks = numBuckets - 1;
    var round = opts.precision ? getRoundingFunction(opts.precision) : null;
    var method = opts.method || 'quantile';
    var breaks, classifier, dataToClass, classToValue;

    if (round) {
      dataValues = dataValues.map(round);
    }

    var ascending = getAscendingNumbers(dataValues);
    var nullCount = dataValues.length - ascending.length;
    var minVal = ascending[0];
    var maxVal = ascending[ascending.length - 1];

    if (numBreaks === 0) {
      breaks = [];
    } else if (opts.breaks) {
      // user-defined breaks
      breaks = opts.breaks;
    } else if (method == 'equal-interval') {
      breaks = getEqualIntervalBreaks(ascending, numBreaks);
    } else if (method == 'quantile') {
      breaks = getQuantileBreaks(ascending, numBreaks);
    } else if (method == 'hybrid') {
      breaks = getHybridBreaks(ascending, numBreaks);
    } else if (method == 'nice') {
      breaks = getNiceBreaks(ascending, numBreaks);
      message('Nice breaks:', breaks);
    } else {
      stop('Unknown classification method:', method);
    }

    printDistributionInfo(ascending, breaks, nullCount);

    if (opts.continuous) {
      dataToClass = getContinuousClassifier(breaks, minVal, maxVal);
    } else {
      dataToClass = getDiscreteClassifier(breaks, round);
    }
    classToValue = getOutputFunction(classValues, nullValue, opts);
    classifier = function(val) {
      return classToValue(dataToClass(val));
    };

    // generate a key if we've got colors and a key style
    if (opts.colors && (opts.key || opts.key_style)) {
      if (opts.key_style == 'gradient' && opts.continuous) {
        makeGradientKey(classifier, breaks, minVal, maxVal, opts);
      // } else if (opts.key_style == 'dataviz' && opts.continuous) {
      //   makeGradientDatavizKey(classifier, breaks, ascending, opts);
      } else if (opts.key_style == 'dataviz') {
        makeDatavizKey(classValues, breaks, ascending, opts);
      } else if (opts.key || opts.key_style == 'simple') {
        makeSimpleKey(classValues, breaks, minVal, maxVal, opts);
      }
    }

    return classifier;
  }

  function getClassRanges(breaks, ascending) {
    var ranges = [];
    var ids, geBound, ltBound, limit, range;
    for (var breakId=0, i=0; breakId <= breaks.length; breakId++) {
      geBound = breakId === 0 ? -Infinity : breaks[breakId-1];
      ltBound = breakId < breaks.length ? breaks[breakId] : Infinity;
      ids = getClassRange(ascending, geBound, ltBound, i);
      if (ids) {
        // the usual case: a bucket containing >0 values
        range = [ascending[ids[0]], ascending[ids[1]]];
        i = ids[1];
      } else if (breakId === 0) {
        // left-most bucket, empty
        range = [ltBound, ltBound];
      } else if (breakId < breaks.length) {
        // internal bucket, empty
        range = [geBound, ltBound];
      } else {
        // right-most bucket, empty
        range = [geBound, geBound];
      }
      ranges.push(range);
    }
    return ranges;
  }

  // Gets the first and last value in a sequential class (bucket)
  // Returns null if bucket is empty
  // i: an index into the array of sorted numbers,
  //    at or before the first number in the bucket
  function getClassRange(ascending, geBound, ltBound, i) {
    var n = ascending.length;
    var rangeStart = -1, rangeEnd = -1;
    var val;
    while (i < n) {
      val = ascending[i];
      if (val >= ltBound) break;
      if (rangeStart == -1 && val >= geBound) {
        rangeStart = i;
      }
      rangeEnd = i;
      i++;
    }
    return rangeStart > -1 && rangeEnd > -1 ? [rangeStart, rangeEnd] : null;
  }

  function printDistributionInfo(ascending, breaks, nulls) {
    var dist = getDistributionData(breaks, ascending);
    var tableRows = getClassRanges(breaks, ascending).map(function(range, i) {
      return [`${range[0]} - ${range[1]}`, `(${dist[i]})`];
    });
    tableRows.push(['null or non-numeric values', `(${nulls})`]);
    // message('Computed breaks:', breaks);
    // message('Distribution:', dist.join(','));
    message('Data ranges and (feature counts):\n' + formatColumns(tableRows, ['left', 'right']));
    if (nulls) {
      // message('Null values:', nulls);
    }
  }

  function getDiscreteClassifier(breaks, round) {
    var inverted = false; // breaks are in descending sequence
    // if (values.length != breaks.length + 1) {
    //   stop("Number of values should be one more than number of class breaks");
    // }
    // validate breaks
    // Accepts repeated values -- should this be allowed?
    if (testAscendingNumbers(breaks)) {
      // normal state
    } else if (testDescendingNumbers(breaks)) {
      breaks = breaks.concat().reverse();
      inverted = true;
    } else {
      stop('Invalid class breaks:', breaks.join(','));
    }
    return function(val) {
      var i = -1;
      if (Number(val) === val) { // exclude null, NaN, strings, etc.
        if (round) val = val(round);
        i = getClassId(val, breaks);
      }
      if (inverted && i > -1) {
        i = breaks.length - i;
      }
      return i;
    };
  }

  // uses linear interpolation between breakpoints
  // (perhaps not ideal for long-tail distributions)
  // breaks: array of (0 or more) inner breakpoints
  function getContinuousClassifier(breaks, minVal, maxVal) {
    return function(val) {
      var n = breaks.length;
      var min, max, j;
      if (!utils.isValidNumber(val) || val < minVal || val > maxVal){
        return -1;
      }
      for (var i=0; i<=n; i++) {
        max = i === n ? maxVal : breaks[i];
        if (i === n || val < max) {
          min = i === 0 ? minVal : breaks[i-1];
          j = (val - min) / (max - min);
          return i + j;
        }
      }
      error('Range error');
    };
  }

  function getEqualIntervalBreaks(ascending, numBreaks) {
    var numRanges = numBreaks + 1,
        minVal = ascending[0],
        maxVal = ascending[ascending.length - 1],
        interval = (maxVal - minVal) / numRanges,
        breaks = [],
        i;
    for (i = 1; i<numRanges; i++) {
      breaks.push(minVal + i * interval);
    }
    return breaks;
  }

  function getQuantileBreaks(ascending, numBreaks) {
    var numRanges = numBreaks + 1;
    var n = ascending.length / numRanges;
    var breaks = [];
    var i, j;
    for (i = 1; i<numRanges; i++) {
      j = Math.floor(i * n);
      breaks.push(ascending[j]);
    }
    return breaks;
  }

  // inner breaks have equal-interval spacing
  // first and last bucket are sized like quantiles (they are sized to contain
  // a proportional share of the data)
  function getHybridBreaks(ascending, numBreaks) {
    var quantileBreaks = getQuantileBreaks(ascending, numBreaks);
    if (numBreaks < 3) return quantileBreaks;
    var lowerBreak = quantileBreaks[0];
    var upperBreak = quantileBreaks[quantileBreaks.length-1];
    var innerValues = ascending.filter(function(val) {
      return val >= lowerBreak && val < upperBreak;
    });
    var innerBreaks = getEqualIntervalBreaks(innerValues, numBreaks - 2);
    var breaks = [lowerBreak].concat(innerBreaks).concat(upperBreak);
    return breaks;
  }

  function getDistributionData(breaks, ascending) {
    var arr = utils.initializeArray(new Array(breaks.length + 1), 0);
    var nulls = 0;
    ascending.forEach(function(val) {
      var i = getClassId(val, breaks);
      if (i == -1) {
        error('Indexing error');
      } else {
        arr[i]++;
      }
    });
    return arr;
  }

  function getAscendingNumbers(values) {
    var numbers = values.filter(utils.isFiniteNumber);
    utils.genericSort(numbers, true);
    return numbers;
  }

  function arraysAreIdentical(a, b) {
    for (var i=0; i<a.length; i++) {
      if (a[i] !== b[i]) return false;
    }
    return a.length == b.length;
  }

  function testAscendingNumbers(arr) {
    return arraysAreIdentical(arr, utils.genericSort(arr.map(parseFloat)));
  }

  function testDescendingNumbers(arr) {
    return arraysAreIdentical(arr, utils.genericSort(arr.map(parseFloat), false));
  }

  // breaks: threshold values between ranges (ascending order)
  // Returns array index of a sequential range, or -1 if @val not numeric
  function getClassId(val, breaks) {
    var i = 0;
    if (!utils.isValidNumber(val)) {
      return -1;
    }
    while (i < breaks.length && val >= breaks[i]) i++;
    return i;
  }

  function getCategoricalClassifier(classValues, nullVal, opts) {
    // categories: strings to match in the data
    var categories = opts.categories;
    var classToValue = getDiscreteValueGetter(classValues, nullVal, opts.other);
    return function(val) {
      var i = categories.indexOf(val);
      var idx = -1;
      if (i >= 0) {
        idx = i;
      } else if (val) {
        idx = -2; // field contains an 'other' value
      } else {
        idx = -1; // field is empty (null value)
      }
      return classToValue(idx);
    };
  }

  function getIndexedClassifier(values, nullVal, opts) {
    // TODO: handle continuous classification
    var numBuckets = values.length;
    var classToValue = getOutputFunction(values, nullVal, opts);

    return function(val) {
      var idx = utils.isInteger(val) && val >= 0 && val < numBuckets ? val : -1;
      return classToValue(idx);
    };
  }

  // returns the number of classes, based on the largest class index found
  function validateClassIndexField(records, name) {
    var invalid = [];
    var maxId = -1;
    records.forEach(function(d) {
      var val = (d || {})[name];
      if (!utils.isInteger(val) || val < -2) {
        invalid.push(val);
      } else {
        maxId = Math.max(maxId, val);
      }
    });
    if (invalid.length > 0) {
      stop(`Class index field contains invalid value(s): ${invalid.slice(0, 5)}`);
    }
    return maxId + 1;
  }

  // Returns a function for constructing a query function that accepts an arc id and
  // returns information about the polygon or polygons that use the given arc.
  // TODO: explain this better.
  //
  // options:
  //   filter: optional filter function; signature: function(idA, idB or -1) : boolean
  //   reusable: flag that lets an arc be queried multiple times.
  function getArcClassifier(shapes, arcs) {
    var opts = arguments[2] || {},
        useOnce = !opts.reusable,
        n = arcs.size(),
        a = new Int32Array(n),
        b = new Int32Array(n);

    utils.initializeArray(a, -1);
    utils.initializeArray(b, -1);

    traversePaths(shapes, function(o) {
      var i = absArcId(o.arcId);
      var shpId = o.shapeId;
      var aval = a[i];
      if (aval == -1) {
        a[i] = shpId;
      } else if (shpId < aval) {
        b[i] = aval;
        a[i] = shpId;
      } else {
        b[i] = shpId;
      }
    });

    function classify(arcId, getKey) {
      var i = absArcId(arcId);
      var shpA = a[i];
      var shpB = b[i];
      var key;
      if (shpA == -1) return null;
      key = getKey(shpA, shpB);
      if (key === null || key === false) return null;
      if (useOnce) {
        // arc can only be queried once
        a[i] = -1;
        b[i] = -1;
      }
      // use optional filter to exclude some arcs
      if (opts.filter && !opts.filter(shpA, shpB)) return null;
      return key;
    }

    return function(getKey) {
      return function(arcId) {
        return classify(arcId, getKey);
      };
    };
  }

  var ArcClassifier = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getArcClassifier: getArcClassifier
  });

  // Returns a function for querying the neighbors of a given shape. The function
  // can be called in either of two ways:
  //
  // 1. function(shapeId, callback)
  //    Callback signature: function(adjacentShapeId, arcId)
  //    The callback function is called once for each arc that the given feature
  //    shares with another feature.
  //
  // 2. function(shapeId)
  //    The function returns an array of unique ids of neighboring shapes, or
  //    an empty array if a shape has no neighbors.
  //
  function getNeighborLookupFunction(lyr, arcs) {
    var classifier = getArcClassifier(lyr.shapes, arcs, {reusable: true});
    var classify = classifier(onShapes);
    var currShapeId;
    var neighbors;
    var callback;

    function onShapes(a, b) {
      if (b == -1) return -1; // outer edges are b == -1
      return a == currShapeId ? b : a;
    }

    function onArc(arcId) {
      var nabeId = classify(arcId);
      if (nabeId == -1) return;
      if (callback) {
        callback(nabeId, arcId);
      } else if (neighbors.indexOf(nabeId) == -1) {
        neighbors.push(nabeId);
      }
    }

    return function(shpId, cb) {
      currShapeId = shpId;
      if (cb) {
        callback = cb;
        forEachArcId(lyr.shapes[shpId], onArc);
        callback = null;
      } else {
        neighbors = [];
        forEachArcId(lyr.shapes[shpId], onArc);
        return neighbors;
      }
    };
  }


  // Returns an array containing all pairs of adjacent shapes
  // in a collection of polygon shapes. A pair of shapes is represented as
  // an array of two shape indexes [a, b].
  function findPairsOfNeighbors(shapes, arcs) {
    var getKey = function(a, b) {
      return b > -1 && a > -1 ? [a, b] : null;
    };
    var classify = getArcClassifier(shapes, arcs)(getKey);
    var arr = [];
    var index = {};
    var onArc = function(arcId) {
      var obj = classify(arcId);
      var key;
      if (obj) {
        key = obj.join('~');
        if (key in index === false) {
          arr.push(obj);
          index[key] = true;
        }
      }
    };
    forEachArcId(shapes, onArc);
    return arr;
  }

  var PolygonNeighbors = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getNeighborLookupFunction: getNeighborLookupFunction,
    findPairsOfNeighbors: findPairsOfNeighbors
  });

  var BALANCE_COLORS = true;

  function getNonAdjacentClassifier(lyr, dataset, colors) {
    requirePolygonLayer(lyr);
    var getNeighbors = getNeighborLookupFunction(lyr, dataset.arcs);
    var errorCount = 0;
    var data = utils.range(getFeatureCount(lyr)).map(function(shpId) {
      var nabes = getNeighbors(shpId) || [];
      var d = {
        nabes: nabes,
        colorId: -1,
        nabeColors: [],
        uncolored: nabes.length, // number of uncolored neighbors
        saturation: 0, // number of unique colors of neighbors
        common: 0 // number of repeated colors in neighbors
      };
      return d;
    });
    var getSortedColorIds = getUpdateFunction(colors.length);
    var colorIds = getSortedColorIds();
    // Sort adjacency data by number of neighbors in descending order
    var iter = getNodeIterator(data);
    // Assign colors, starting with polygons with the largest number of neighbors
    iter.forEach(function(d) {
      var colorId = pickColor(d, data, colorIds);
      if (colorId == -1) {
        errorCount++;
        colorId = colorIds[0];
      }
      d.colorId = colorId;
      if (BALANCE_COLORS) {
        colorIds = getSortedColorIds(colorId);
      }
    });

    if (errorCount > 0) {
      message(`Unable to find non-adjacent colors for ${errorCount} ${errorCount == 1 ? 'polygon' : 'polygons'}`);
    }
    return function(shpId) {
      return colors[data[shpId].colorId];
    };
  }

  function getNodeIterator(data) {
    var sorted = data.concat();
    utils.sortOn(sorted, 'uncolored', true);
    function forEach(cb) {
      var item;
      while(sorted.length > 0) {
        item = sorted.pop();
        cb(item);
        updateNeighbors(item, sorted, data);
      }
    }

    return {
      forEach: forEach
    };
  }

  function updateNeighbors(item, sorted, data) {
    var nabe;
    var ids = item.nabes;
    for (var i=0; i<ids.length; i++) {
      nabe = data[ids[i]];
      if (nabe.colorId > -1) continue;
      updateNeighbor(nabe, item.colorId, sorted);
    }
  }

  function updateNeighbor(a, colorId, sorted) {
    var i = findItem(a, sorted);
    var n = sorted.length;
    var b;
    if (i == -1) {
      error('Indexing error');
    }
    a.uncolored--;
    if (!a.nabeColors.includes(colorId)) {
      a.saturation++;
      a.nabeColors.push(colorId);
    } else {
      a.common++;
    }
    // bubble sort!!!
    while (++i < n) {
      b = sorted[i];
      if (!betterThan(a, b)) break;
      sorted[i-1] = b;
      sorted[i] = a;
    }
  }

  function findItem(a, sorted) {
    // return sorted.indexOf(a); // bottleneck
    // binary search in sorted array
    var start = 0, end = sorted.length, i;
    while (end - start > 50) {
      i = Math.floor((start + end) / 2);
      if (sorted[i].saturation >= a.saturation) {
        end = i;
      } else {
        start = i;
      }
    }
    return sorted.indexOf(a, start);
  }

  function betterThan(a, b) {
    if (a.saturation > b.saturation) return true;
    if (a.saturation < b.saturation) return false;
    if (a.common > b.common) return true;
    if (a.common < b.common) return false;
    // based on 4-color tests with counties and zipcodes, this condition adds a bit of strength
    if (a.uncolored < b.uncolored) return true;
    return false;
  }

  // Pick the id of a color that is not shared with a neighboring polygon
  function pickColor(d, data, colorIds) {
    var candidateId;
    for (var i=0; i<colorIds.length; i++) {
      candidateId = colorIds[i];
      if (isAvailableColor(d, data, candidateId)) {
        return candidateId;
      }
    }
    return -1; // no colors are available
  }

  function isAvailableColor(d, data, colorId) {
    var nabes = d.nabes;
    for (var i=0; i<nabes.length; i++) {
      if (data[nabes[i]].colorId === colorId) return false;
    }
    return true;
  }

  // Update function returns an array of ids, sorted in descending order of preference
  // (less-used ids are preferred).
  // Function recieves an (optional) id that was just used.
  function getUpdateFunction(n) {
    var ids = utils.range(n);
    var counts = new Uint32Array(n);
    return function(i) {
      if (i >= 0 && i < n) {
        counts[i]++;
        utils.sortArrayIndex(ids, counts, true);
      } else if (i !== undefined) {
        error('Unexpected color index:', i);
      }
      return ids;
    };
  }

  cmd.classify = function(lyr, dataset, optsArg) {
    if (!lyr.data) {
      initDataTable(lyr);
    }
    var opts = optsArg || {};
    var records = lyr.data && lyr.data.getRecords();
    var nullValue = opts.null_value || null;
    var looksLikeColors = !!opts.colors || !!opts.color_scheme;
    var colorScheme;
    var classValues, classifyByValue, classifyById;
    var numBuckets, numValues;
    var dataField, outputField;

    // validate explicitly set classes
    if (opts.classes) {
      if (!utils.isInteger(opts.classes) || opts.classes > 1 === false) {
        stop('Invalid number of classes:', opts.classes, '(expected a value greater than 1)');
      }
      numBuckets = opts.classes;
    }

    // TODO: better validation of breaks values
    if (opts.breaks) {
      numBuckets = opts.breaks.length + 1;
    }

    if (opts.index_field) {
      dataField = opts.index_field;
      if (numBuckets > 0 === false) {
        stop('The index-field= option requires the classes= option to be set');
      }
      // You can't infer the number of classes by looking at index values;
      // this can cause unwanted interpolation if one or more values are
      // not present in the index field
      // numBuckets = validateClassIndexField(records, opts.index_field);

    } else if (opts.field) {
      dataField = opts.field;
    }

    // expand categories if value is '*'
    if (dataField && opts.categories && opts.categories.includes('*')) {
      opts.categories = getUniqFieldValues(records, dataField);
    }

    if (opts.method == 'non-adjacent') {
      if (lyr.geometry_type != 'polygon') {
        stop('The non-adjacent option requires a polygon layer');
      }
      if (dataField) {
        stop('The non-adjacent option does not accept a data field argument');
      }
    } else if (!dataField) {
      stop('Missing a data field to classify');
    } else {
      requireDataField(lyr.data, dataField);
    }

    if (numBuckets) {
      numValues = opts.continuous ? numBuckets + 1 : numBuckets;
    }

    // support both deprecated color-scheme= option and colors=<color-scheme> syntax
    if (opts.color_scheme) {
      if (!isColorSchemeName(opts.color_scheme)) {
        stop('Unknown color scheme:', opts.color_scheme);
      }
      colorScheme = opts.color_scheme;
    } else if (opts.colors && isColorSchemeName(opts.colors[0])) {
      colorScheme = opts.colors[0];
    } else if (opts.colors) {
      opts.colors.forEach(parseColor); // validate colors -- error if unparsable
    }

    if (colorScheme) {
      // using a named color scheme: generate a ramp

      if (opts.categories) {
        classValues = getCategoricalColorScheme(colorScheme, opts.categories.length);
        numBuckets = numValues = classValues.length;
      } else {
        if (!numBuckets) {
          // stop('color-scheme= option requires classes= or breaks=');
          numBuckets = 4; // use a default number of classes
          numValues = opts.continuous ? numBuckets + 1 : numBuckets;
        }
        classValues = getColorRamp(colorScheme, numValues, opts.stops);
      }

    } else if (opts.colors || opts.values) {
      classValues = opts.values ? parseValues(opts.values) : opts.colors;
      if (!numValues) {
        numValues = classValues.length;
      }
      if ((classValues.length != numValues || opts.stops) && numValues > 1) {
        // TODO: handle numValues == 1
        // TODO: check for non-interpolatable value types (e.g. boolean, text)
        classValues = interpolateValuesToClasses(classValues, numValues, opts.stops);
      }

    } else if (numValues > 1) {
      // no values were given: assign indexes for each class
      classValues = getIndexValues(numValues);
      nullValue = -1;
    }

    if (looksLikeColors) {
      nullValue = nullValue || '#eee';
    }

    if (numValues > 1 === false) {
      stop('Missing a valid number of classes');
    }

    if (opts.invert) {
      classValues = classValues.concat().reverse();
    }

    if (looksLikeColors) {
      message('Colors:', formatValuesForLogging(classValues));
    }

    // get a function to convert input data to class indexes
    //
    if (opts.method == 'non-adjacent') {
      classifyById = getNonAdjacentClassifier(lyr, dataset, classValues);
    } else if (opts.index_field) {
      // data is pre-classified... just read the index from a field
      classifyByValue = getIndexedClassifier(classValues, nullValue, opts);
    } else if (opts.categories) {
      classifyByValue = getCategoricalClassifier(classValues, nullValue, opts);
    } else {
      classifyByValue = getSequentialClassifier$1(classValues, nullValue, getFieldValues(records, dataField), opts);
    }

    if (classifyByValue) {
      classifyById = function(id) {
        var d = records[id] || {};
        return classifyByValue(d[dataField]);
      };
    }


    // get the name of the output field
    //
    if (looksLikeColors) {
      outputField = lyr.geometry_type == 'polyline' ? 'stroke' : 'fill';
    } else {
      outputField = 'class';
    }
    if (opts.save_as) {
      outputField = opts.save_as; // override the default field name
    } else {
      message(`Output was saved to "${outputField}" field (use save-as= to change)`);
      // message('Use save-as=<field> to save to a different field');
    }

    records.forEach(function(d, i) {
      d[outputField] = classifyById(i);
    });
  };


  // convert strings to numbers if they all parse as numbers
  // arr: an array of strings
  function parseValues(strings) {
    var values = strings;
    if (strings.every(utils.parseNumber)) {
      values = strings.map(function(str) {
        return +str;
      });
    }
    return values;
  }

  function formatValuesForLogging(arr) {
    if (arr.some(val => utils.isString(val) && val.indexOf('rgb(') === 0)) {
      return formatColorsAsHex(arr);
    }
    return arr;
  }

  function formatColorsAsHex(colors) {
    var d3 = require('d3-color');
    return colors.map(function(col) {
      var o = d3.color(col);
      if (!o) stop('Unable to parse color:', col);
      return o.formatHex();
    });
  }


  function getIndexValues(n) {
    var vals = [];
    for (var i=0; i<n; i++) {
      vals.push(i);
    }
    return vals;
  }

  // Remove small-area polygon rings (very simple implementation of sliver removal)
  // TODO: more sophisticated sliver detection (e.g. could consider ratio of area to perimeter)
  // TODO: consider merging slivers into adjacent polygons to prevent gaps from forming
  // TODO: consider separate gap removal function as an alternative to merging slivers
  //
  cmd.filterSlivers = function(lyr, dataset, opts) {
    if (lyr.geometry_type != 'polygon') {
      return 0;
    }
    return filterSlivers(lyr, dataset, opts);
  };

  function filterSlivers(lyr, dataset, optsArg) {
    var opts = utils.extend({sliver_control: 1}, optsArg);
    var filterData = getSliverFilter(lyr, dataset, opts);
    var ringTest = filterData.filter;
    var removed = 0;
    var pathFilter = function(path, i, paths) {
      if (ringTest(path)) {
        removed++;
        return null;
      }
    };

    editShapes(lyr.shapes, pathFilter);
    message(utils.format("Removed %'d sliver%s using %s", removed, utils.pluralSuffix(removed), filterData.label));
    return removed;
  }

  function filterClipSlivers(lyr, clipLyr, arcs) {
    var threshold = getDefaultSliverThreshold(lyr, arcs);
    // message('Using variable sliver threshold (based on ' + (threshold / 1e6) + ' sqkm)');
    var ringTest = getSliverTest(arcs, threshold, 1);
    var flags = new Uint8Array(arcs.size());
    var removed = 0;
    var pathFilter = function(path) {
      var prevArcs = 0,
          newArcs = 0;
      for (var i=0, n=path && path.length || 0; i<n; i++) {
        if (flags[absArcId(path[i])] > 0) {
          newArcs++;
        } else {
          prevArcs++;
        }
      }
      // filter paths that contain arcs from both original and clip/erase layers
      //   and are small
      if (newArcs > 0 && prevArcs > 0 && ringTest(path)) {
        removed++;
        return null;
      }
    };

    countArcsInShapes(clipLyr.shapes, flags);
    editShapes(lyr.shapes, pathFilter);
    return removed;
  }

  // Assumes: Arcs have been divided
  //
  function clipPolylines(targetShapes, clipShapes, nodes, type) {
    var index = new PathIndex(clipShapes, nodes.arcs);

    return targetShapes.map(function(shp) {
      return clipPolyline(shp);
    });

    function clipPolyline(shp) {
      var clipped = null;
      if (shp) clipped = shp.reduce(clipPath, []);
      return clipped && clipped.length > 0 ? clipped : null;
    }

    function clipPath(memo, path) {
      var clippedPath = null,
          arcId, enclosed;
      for (var i=0; i<path.length; i++) {
        arcId = path[i];
        enclosed = index.arcIsEnclosed(arcId);
        if (enclosed && type == 'clip' || !enclosed && type == 'erase') {
          if (!clippedPath) {
            memo.push(clippedPath = []);
          }
          clippedPath.push(arcId);
        } else {
          clippedPath = null;
        }
      }
      return memo;
    }
  }

  var PolylineClipping = /*#__PURE__*/Object.freeze({
    __proto__: null,
    clipPolylines: clipPolylines
  });

  // TODO: remove this obsolete dissolve code (still used by clip)

  function concatShapes(shapes) {
    return shapes.reduce(function(memo, shape) {
      extendShape(memo, shape);
      return memo;
    }, []);
  }

  function extendShape(dest, src) {
    if (src) {
      for (var i=0, n=src.length; i<n; i++) {
        dest.push(src[i]);
      }
    }
  }

  // TODO: to prevent invalid holes,
  // could erase the holes from the space-enclosing rings.
  function appendHolesToRings(cw, ccw) {
    for (var i=0, n=ccw.length; i<n; i++) {
      cw.push(ccw[i]);
    }
    return cw;
  }

  function getPolygonDissolver(nodes, spherical) {
    spherical = spherical && !nodes.arcs.isPlanar();
    var flags = new Uint8Array(nodes.arcs.size());
    var divide = getHoleDivider(nodes, spherical);
    var pathfind = getRingIntersector(nodes, flags);

    return function(shp) {
      if (!shp) return null;
      var cw = [],
          ccw = [];

      divide(shp, cw, ccw);
      cw = pathfind(cw, 'flatten');
      ccw.forEach(reversePath);
      ccw = pathfind(ccw, 'flatten');
      ccw.forEach(reversePath);
      var shp2 = appendHolesToRings(cw, ccw);
      var dissolved = pathfind(shp2, 'dissolve');

      if (dissolved.length > 1) {
        dissolved = fixNestingErrors(dissolved, nodes.arcs);
      }

      return dissolved.length > 0 ? dissolved : null;
    };
  }

  // TODO: remove dependency on old polygon dissolve function

  // assumes layers and arcs have been prepared for clipping
  function clipPolygons(targetShapes, clipShapes, nodes, type, optsArg) {
    var arcs = nodes.arcs;
    var opts = optsArg || {};
    var clipFlags = new Uint8Array(arcs.size());
    var routeFlags = new Uint8Array(arcs.size());
    var clipArcTouches = 0;
    var clipArcUses = 0;
    var usedClipArcs = [];
    var dividePath = getPathFinder(nodes, useRoute, routeIsActive);
    var dissolvePolygon = getPolygonDissolver(nodes);

    // The following cleanup step is a performance bottleneck (it often takes longer than
    // other clipping operations) and is usually not needed. Furthermore, it only
    // eliminates a few kinds of problems, like target polygons with abnormal winding
    // or overlapping rings. TODO: try to optimize or remove it for all cases

    // skipping shape cleanup when using the experimental fast bbox clipping option
    if (!opts.bbox2) {
      // clean each target polygon by dissolving its rings
      targetShapes = targetShapes.map(dissolvePolygon);
    }

    // Originally, clip shapes were dissolved here as an optimization, using
    // an unreliable dissolve function.
    // Now, clip shapes are dissolved using a more reliable (but slower)
    // function in mapshaper-clip-erase.js
    // clipShapes = [dissolvePolygon(internal.concatShapes(clipShapes))];

    // Open pathways in the clip/erase layer
    // Need to expose clip/erase routes in both directions by setting route
    // in both directions to visible -- this is how cut-out shapes are detected
    // Or-ing with 0x11 makes both directions visible (so reverse paths will block)
    openArcRoutes(clipShapes, arcs, clipFlags, type == 'clip', type == 'erase', !!"dissolve", 0x11);
    var index = new PathIndex(clipShapes, arcs);
    var clippedShapes = targetShapes.map(function(shape, i) {
      if (shape) {
        return clipPolygon(shape, type, index);
      }
      return null;
    });

    // add clip/erase polygons that are fully contained in a target polygon
    // need to index only non-intersecting clip shapes
    // (Intersecting shapes have one or more arcs that have been scanned)

    // first, find shapes that do not intersect the target layer
    // (these could be inside or outside the target polygons)
    var undividedClipShapes = findUndividedClipShapes(clipShapes);

    closeArcRoutes(clipShapes, arcs, routeFlags, true, true); // not needed?
    index = new PathIndex(undividedClipShapes, arcs);
    targetShapes.forEach(function(shape, shapeId) {
      // find clipping paths that are internal to this target polygon
      var paths = shape ? findInteriorPaths(shape, type, index) : null;
      if (paths) {
        clippedShapes[shapeId] = (clippedShapes[shapeId] || []).concat(paths);
      }
    });

    return clippedShapes;

    function clipPolygon(shape, type, index) {
      var dividedShape = [],
          clipping = type == 'clip',
          erasing = type == 'erase';

      // open pathways for entire polygon rather than one ring at a time --
      // need to create polygons that connect positive-space rings and holes
      openArcRoutes(shape, arcs, routeFlags, true, false, false);

      forEachShapePart(shape, function(ids) {
        var path;
        for (var i=0, n=ids.length; i<n; i++) {
          clipArcTouches = 0;
          clipArcUses = 0;
          path = dividePath(ids[i]);
          if (path) {
            // if ring doesn't touch/intersect a clip/erase polygon, check if it is contained
            // if (clipArcTouches === 0) {
            // if ring doesn't incorporate an arc from the clip/erase polygon,
            // check if it is contained (assumes clip shapes are dissolved)
            if (clipArcTouches === 0 || clipArcUses === 0) { //
              var contained = index.pathIsEnclosed(path);
              if (clipping && contained || erasing && !contained) {
                dividedShape.push(path);
              }
              // TODO: Consider breaking if polygon is unchanged
            } else {
              dividedShape.push(path);
            }
          }
        }
      });

      // Clear pathways of current target shape to hidden/closed
      closeArcRoutes(shape, arcs, routeFlags, true, true, true);
      // Also clear pathways of any clip arcs that were used
      if (usedClipArcs.length > 0) {
        closeArcRoutes(usedClipArcs, arcs, routeFlags, true, true, true);
        usedClipArcs = [];
      }

      return dividedShape.length === 0 ? null : dividedShape;
    }

    function routeIsActive(id) {
      var fw = id >= 0,
          abs = fw ? id : ~id,
          visibleBit = fw ? 1 : 0x10,
          targetBits = routeFlags[abs],
          clipBits = clipFlags[abs];

      if (clipBits > 0) clipArcTouches++;
      return (targetBits & visibleBit) > 0 || (clipBits & visibleBit) > 0;
    }

    function useRoute(id) {
      var fw = id >= 0,
          abs = fw ? id : ~id,
          targetBits = routeFlags[abs],
          clipBits = clipFlags[abs],
          targetRoute, clipRoute;

      if (fw) {
        targetRoute = targetBits;
        clipRoute = clipBits;
      } else {
        targetRoute = targetBits >> 4;
        clipRoute = clipBits >> 4;
      }
      targetRoute &= 3;
      clipRoute &= 3;

      var usable = false;
      // var usable = targetRoute === 3 || targetRoute === 0 && clipRoute == 3;
      if (targetRoute == 3) {
        // special cases where clip route and target route both follow this arc
        if (clipRoute == 1) {
          // 1. clip/erase polygon blocks this route, not usable
        } else if (clipRoute == 2 && type == 'erase') {
          // 2. route is on the boundary between two erase polygons, not usable
        } else {
          usable = true;
        }

      } else if (targetRoute === 0 && clipRoute == 3) {
        usedClipArcs.push(id);
        usable = true;
      }

      if (usable) {
        if (clipRoute == 3) {
          clipArcUses++;
        }
        // Need to close all arcs after visiting them -- or could cause a cycle
        //   on layers with strange topology
        if (fw) {
          targetBits = setBits(targetBits, 1, 3);
        } else {
          targetBits = setBits(targetBits, 0x10, 0x30);
        }
      }

      targetBits |= fw ? 4 : 0x40; // record as visited
      routeFlags[abs] = targetBits;
      return usable;
    }

    // Filter a collection of shapes to exclude paths that contain clip/erase arcs
    // and paths that are hidden (e.g. internal boundaries)
    function findUndividedClipShapes(clipShapes) {
      return clipShapes.map(function(shape) {
        var usableParts = [];
        forEachShapePart(shape, function(ids) {
          var pathIsClean = true,
              pathIsVisible = false;
          for (var i=0; i<ids.length; i++) {
            // check if arc was used in fw or rev direction
            if (!arcIsUnused(ids[i], routeFlags)) {
              pathIsClean = false;
              break;
            }
            // check if clip arc is visible
            if (!pathIsVisible && arcIsVisible(ids[i], clipFlags)) {
              pathIsVisible = true;
            }
          }
          if (pathIsClean && pathIsVisible) usableParts.push(ids);
        });
        return usableParts.length > 0 ? usableParts : null;
      });
    }

    // Test if arc is unused in both directions
    // (not testing open/closed or visible/hidden)
    function arcIsUnused(id, flags) {
      var abs = absArcId(id),
          flag = flags[abs];
          return (flag & 0x44) === 0;
    }

    function arcIsVisible(id, flags) {
      var flag = flags[absArcId(id)];
      return (flag & 0x11) > 0;
    }

    // search for indexed clipping paths contained in a shape
    // dissolve them if needed
    function findInteriorPaths(shape, type, index) {
      var enclosedPaths = index.findPathsInsideShape(shape),
          dissolvedPaths = [];
      if (!enclosedPaths) return null;
      // ...
      if (type == 'erase') enclosedPaths.forEach(reversePath);
      if (enclosedPaths.length <= 1) {
        dissolvedPaths = enclosedPaths; // no need to dissolve single-part paths
      } else {
        openArcRoutes(enclosedPaths, arcs, routeFlags, true, false, true);
        enclosedPaths.forEach(function(ids) {
          var path;
          for (var j=0; j<ids.length; j++) {
            path = dividePath(ids[j]);
            if (path) {
              dissolvedPaths.push(path);
            }
          }
        });
      }

      return dissolvedPaths.length > 0 ? dissolvedPaths : null;
    }
  } // end clipPolygons()

  //
  function clipPoints(points, clipShapes, arcs, type) {
    var index = new PathIndex(clipShapes, arcs);

    var points2 = points.reduce(function(memo, feat) {
      var n = feat ? feat.length : 0,
          feat2 = [],
          enclosed;

      for (var i=0; i<n; i++) {
        enclosed = index.findEnclosingShape(feat[i]) > -1;
        if (type == 'clip' && enclosed || type == 'erase' && !enclosed) {
          feat2.push(feat[i].concat());
        }
      }

      memo.push(feat2.length > 0 ? feat2 : null);
      return memo;
    }, []);

    return points2;
  }

  var ClipPoints = /*#__PURE__*/Object.freeze({
    __proto__: null,
    clipPoints: clipPoints
  });

  // Create a merged dataset by appending the overlay layer to the target dataset
  // so it is last in the layers array.
  // DOES NOT insert clipping points
  function mergeLayersForOverlay(targetLayers, targetDataset, clipSrc, opts) {
    var usingPathClip = utils.some(targetLayers, layerHasPaths);
    var bbox = opts.bbox || opts.bbox2;
    var mergedDataset, clipDataset, clipLyr;
    if (clipSrc && clipSrc.geometry_type) {
      // TODO: update tests to remove this case (clipSrc is a layer)
      clipSrc = {dataset: targetDataset, layer: clipSrc, disposable: true};
    }
    if (bbox) {
      clipDataset = convertClipBounds(bbox);
      clipLyr = clipDataset.layers[0];
    } else if (!clipSrc) {
      stop("Command requires a source file, layer id or bbox");
    } else if (clipSrc.layer && clipSrc.dataset) {
      clipLyr = clipSrc.layer;
      clipDataset = utils.defaults({layers: [clipLyr]}, clipSrc.dataset);
    } else if (clipSrc.layers && clipSrc.layers.length == 1) {
      clipLyr = clipSrc.layers[0];
      clipDataset = clipSrc;
    }
    if (targetDataset.arcs != clipDataset.arcs) {
      // using external dataset -- need to merge arcs
      if (clipSrc && !clipSrc.disposable) {
        // copy overlay layer shapes because arc ids will be reindexed during merging
        clipDataset.layers[0] = copyLayerShapes(clipDataset.layers[0]);
      }
      // merge external dataset with target dataset,
      // so arcs are shared between target layers and clipping lyr
      // Assumes that layers in clipDataset can be modified (if necessary, a copy should be passed in)
      mergedDataset = mergeDatasets([targetDataset, clipDataset]);
      buildTopology(mergedDataset); // identify any shared arcs between clipping layer and target dataset
    } else {
      // overlay layer belongs to the same dataset as target layers... move it to the end
      mergedDataset = utils.extend({}, targetDataset);
      mergedDataset.layers = targetDataset.layers.filter(function(lyr) {return lyr != clipLyr;});
      mergedDataset.layers.push(clipLyr);
    }
    return mergedDataset;
  }

  function convertClipBounds(bb) {
    var x0 = bb[0], y0 = bb[1], x1 = bb[2], y1 = bb[3],
        arc = [[x0, y0], [x0, y1], [x1, y1], [x1, y0], [x0, y0]];

    if (!(y1 > y0 && x1 > x0)) {
      stop("Invalid bbox (should be [xmin, ymin, xmax, ymax]):", bb);
    }
    return {
      arcs: new ArcCollection([arc]),
      layers: [{
        shapes: [[[0]]],
        geometry_type: 'polygon'
      }]
    };
  }

  var OverlayUtils = /*#__PURE__*/Object.freeze({
    __proto__: null,
    mergeLayersForOverlay: mergeLayersForOverlay
  });

  // Insert cutting points in arcs, where bbox intersects other shapes
  // Return a polygon layer containing the bounding box vectors, divided at cutting points.
  function divideDatasetByBBox(dataset, bbox) {
    var arcs = dataset.arcs;
    var data = findBBoxCutPoints(arcs, bbox);
    var map = insertCutPoints(data.cutPoints, arcs);
    arcs.dedupCoords();
    remapDividedArcs(dataset, map);
    // merge bbox dataset with target dataset,
    // so arcs are shared between target layers and bbox layer
    var clipDataset = bboxPointsToClipDataset(data.bboxPoints);
    var mergedDataset = mergeDatasets([dataset, clipDataset]);
    // TODO: detect if we need to rebuild topology (unlikely), like with the full clip command
    // buildTopology(mergedDataset);
    var clipLyr = mergedDataset.layers.pop();
    dataset.arcs = mergedDataset.arcs;
    dataset.layers = mergedDataset.layers;
    return clipLyr;
  }

  function bboxPointsToClipDataset(arr) {
    var arcs = [];
    var shape = [];
    var layer = {geometry_type: 'polygon', shapes: [[shape]]};
    var p1, p2;
    for (var i=0, n=arr.length - 1; i<n; i++) {
      p1 = arr[i];
      p2 = arr[i+1];
      arcs.push([[p1.x, p1.y], [p2.x, p2.y]]);
      shape.push(i);
    }
    return {
      arcs: new ArcCollection(arcs),
      layers: [layer]
    };
  }

  function findBBoxCutPoints(arcs, bbox) {
    var left = bbox[0],
        bottom = bbox[1],
        right = bbox[2],
        top = bbox[3];

    // arrays of intersection points along each bbox edge
    var tt = [],
        rr = [],
        bb = [],
        ll = [];

    arcs.forEachSegment(function(i, j, xx, yy) {
      var ax = xx[i],
          ay = yy[i],
          bx = xx[j],
          by = yy[j];
      var hit;
      if (segmentOutsideBBox(ax, ay, bx, by, left, bottom, right, top)) return;
      if (segmentInsideBBox(ax, ay, bx, by, left, bottom, right, top)) return;

      hit = geom.segmentIntersection(left, top, right, top, ax, ay, bx, by);
      if (hit) addHit(tt, hit, i, j, xx, yy);

      hit = geom.segmentIntersection(left, bottom, right, bottom, ax, ay, bx, by);
      if (hit) addHit(bb, hit, i, j, xx, yy);

      hit = geom.segmentIntersection(left, bottom, left, top, ax, ay, bx, by);
      if (hit) addHit(ll, hit, i, j, xx, yy);

      hit = geom.segmentIntersection(right, bottom, right, top, ax, ay, bx, by);
      if (hit) addHit(rr, hit, i, j, xx, yy);
    });

    return {
      cutPoints: ll.concat(bb, rr, tt),
      bboxPoints: getDividedBBoxPoints(bbox, ll, tt, rr, bb)
    };

    function addHit(arr, hit, i, j, xx, yy) {
      if (!hit) return;
      arr.push(formatHit(hit[0], hit[1], i, j, xx, yy));
      if (hit.length == 4) {
        arr.push(formatHit(hit[2], hit[3], i, j, xx, yy));
      }
    }

    function formatHit(x, y, i, j, xx, yy) {
      var ids = formatIntersectingSegment(x, y, i, j, xx, yy);
      return getCutPoint(x, y, ids[0], ids[1], xx, yy);
    }
  }

  function segmentOutsideBBox(ax, ay, bx, by, xmin, ymin, xmax, ymax) {
    return ax < xmin && bx < xmin || ax > xmax && bx > xmax ||
        ay < ymin && by < ymin || ay > ymax && by > ymax;
  }

  function segmentInsideBBox(ax, ay, bx, by, xmin, ymin, xmax, ymax) {
    return ax > xmin && bx > xmin && ax < xmax && bx < xmax &&
        ay > ymin && by > ymin && ay < ymax && by < ymax;
  }

  // Returns an array of points representing the vertices in
  // the bbox with cutting points inserted.
  function getDividedBBoxPoints(bbox, ll, tt, rr, bb) {
    var bl = {x: bbox[0], y: bbox[1]},
        tl = {x: bbox[0], y: bbox[3]},
        tr = {x: bbox[2], y: bbox[3]},
        br = {x: bbox[2], y: bbox[1]};
    ll = utils.sortOn(ll.concat([bl, tl]), 'y', true);
    tt = utils.sortOn(tt.concat([tl, tr]), 'x', true);
    rr = utils.sortOn(rr.concat([tr, br]), 'y', false);
    bb = utils.sortOn(bb.concat([br, bl]), 'x', false);
    return ll.concat(tt, rr, bb).reduce(function(memo, p2) {
      var p1 = memo.length > 0 ? memo[memo.length-1] : null;
      if (p1 === null || p1.x != p2.x || p1.y != p2.y) memo.push(p2);
      return memo;
    }, []);
  }

  var Bbox2Clipping = /*#__PURE__*/Object.freeze({
    __proto__: null,
    divideDatasetByBBox: divideDatasetByBBox,
    segmentOutsideBBox: segmentOutsideBBox,
    segmentInsideBBox: segmentInsideBBox
  });

  cmd.clipLayers = function(target, src, dataset, opts) {
    return clipLayers(target, src, dataset, "clip", opts);
  };

  cmd.eraseLayers = function(target, src, dataset, opts) {
    return clipLayers(target, src, dataset, "erase", opts);
  };

  cmd.clipLayer = function(targetLyr, src, dataset, opts) {
    return cmd.clipLayers([targetLyr], src, dataset, opts)[0];
  };

  cmd.eraseLayer = function(targetLyr, src, dataset, opts) {
    return cmd.eraseLayers([targetLyr], src, dataset, opts)[0];
  };

  cmd.sliceLayers = function(target, src, dataset, opts) {
    return clipLayers(target, src, dataset, "slice", opts);
  };

  cmd.sliceLayer = function(targetLyr, src, dataset, opts) {
    return cmd.sliceLayers([targetLyr], src, dataset, opts);
  };

  function clipLayersInPlace(layers, clipSrc, dataset, type, opts) {
    var outputLayers = clipLayers(layers, clipSrc, dataset, type, opts);
    // remove arcs from the clipping dataset, if they are not used by any layer
    layers.forEach(function(lyr, i) {
      var lyr2 = outputLayers[i];
      lyr.shapes = lyr2.shapes;
      lyr.data = lyr2.data;
    });
    dissolveArcs(dataset);
  }

  // @clipSrc: layer in @dataset or filename
  // @type: 'clip' or 'erase'
  function clipLayers(targetLayers, clipSrc, targetDataset, type, opts) {
    var usingPathClip = utils.some(targetLayers, layerHasPaths);
    var mergedDataset, clipLyr, nodes;
    opts = opts || {no_cleanup: true}; // TODO: update testing functions
    if (opts.bbox2 && usingPathClip) { // assumes target dataset has arcs
      return clipLayersByBBox(targetLayers, targetDataset, opts);
    }
    mergedDataset = mergeLayersForOverlay(targetLayers, targetDataset, clipSrc, opts);
    clipLyr = mergedDataset.layers[mergedDataset.layers.length-1];
    if (usingPathClip) {
      // add vertices at all line intersections
      // (generally slower than actual clipping)
      nodes = addIntersectionCuts(mergedDataset, opts);
      targetDataset.arcs = mergedDataset.arcs;
      // dissolve clip layer shapes (to remove overlaps and other topological issues
      // that might confuse the clipping function)
      clipLyr = dissolvePolygonLayer2(clipLyr, mergedDataset, {quiet: true, silent: true});

    } else {
      nodes = new NodeCollection(mergedDataset.arcs);
    }
    // clipLyr = mergedDataset.layers.pop();
    return clipLayersByLayer(targetLayers, clipLyr, nodes, type, opts);
  }

  function clipLayersByBBox(layers, dataset, opts) {
    var bbox = opts.bbox2;
    var clipLyr = divideDatasetByBBox(dataset, bbox);
    var nodes = new NodeCollection(dataset.arcs);
    var retn = clipLayersByLayer(layers, clipLyr, nodes, 'clip', opts);
    return retn;
  }

  function clipLayersByLayer(targetLayers, clipLyr, nodes, type, opts) {
    requirePolygonLayer(clipLyr, "Requires a polygon clipping layer");
    return targetLayers.reduce(function(memo, targetLyr) {
      if (type == 'slice') {
        memo = memo.concat(sliceLayerByLayer(targetLyr, clipLyr, nodes, opts));
      } else {
        memo.push(clipLayerByLayer(targetLyr, clipLyr, nodes, type, opts));
      }
      return memo;
    }, []);
  }

  function getSliceLayerName(clipLyr, field, i) {
    var id = field ? clipLyr.data.getRecords()[0][field] : i + 1;
    return 'slice-' + id;
  }

  function sliceLayerByLayer(targetLyr, clipLyr, nodes, opts) {
    // may not need no_replace
    var clipLayers = cmd.splitLayer(clipLyr, opts.id_field, {no_replace: true});
    return clipLayers.map(function(clipLyr, i) {
      var outputLyr = clipLayerByLayer(targetLyr, clipLyr, nodes, 'clip', opts);
      outputLyr.name = getSliceLayerName(clipLyr, opts.id_field, i);
      return outputLyr;
    });
  }

  function clipLayerByLayer(targetLyr, clipLyr, nodes, type, opts) {
    var arcs = nodes.arcs;
    var shapeCount = targetLyr.shapes ? targetLyr.shapes.length : 0;
    var nullCount = 0, sliverCount = 0;
    var clippedShapes, outputLyr;
    if (shapeCount === 0) {
      return targetLyr; // ignore empty layer
    }
    if (targetLyr === clipLyr) {
      stop('Can\'t clip a layer with itself');
    }

    // TODO: optimize some of these functions for bbox clipping
    if (targetLyr.geometry_type == 'point') {
      clippedShapes = clipPoints(targetLyr.shapes, clipLyr.shapes, arcs, type);
    } else if (targetLyr.geometry_type == 'polygon') {
      clippedShapes = clipPolygons(targetLyr.shapes, clipLyr.shapes, nodes, type, opts);
    } else if (targetLyr.geometry_type == 'polyline') {
      clippedShapes = clipPolylines(targetLyr.shapes, clipLyr.shapes, nodes, type);
    } else {
      stop('Invalid target layer:', targetLyr.name);
    }

    outputLyr = {
      name: targetLyr.name,
      geometry_type: targetLyr.geometry_type,
      shapes: clippedShapes,
      data: targetLyr.data // replaced post-filter
    };

    // Remove sliver polygons
    if (opts.remove_slivers && outputLyr.geometry_type == 'polygon') {
      sliverCount = filterClipSlivers(outputLyr, clipLyr, arcs);
    }

    // Remove null shapes (likely removed by clipping/erasing, although possibly already present)
    cmd.filterFeatures(outputLyr, arcs, {remove_empty: true, verbose: false});

    // clone data records (to avoid sharing records between layers)
    // TODO: this is not needed when replacing target with a single layer
    if (outputLyr.data) {
      outputLyr.data = outputLyr.data.clone();
    }

    // TODO: redo messages, now that many layers may be clipped
    nullCount = shapeCount - outputLyr.shapes.length;
    if (nullCount && sliverCount) {
      message(getClipMessage(nullCount, sliverCount));
    }
    return outputLyr;
  }

  function getClipMessage(nullCount, sliverCount) {
    var nullMsg = nullCount ? utils.format('%,d null feature%s', nullCount, utils.pluralSuffix(nullCount)) : '';
    var sliverMsg = sliverCount ? utils.format('%,d sliver%s', sliverCount, utils.pluralSuffix(sliverCount)) : '';
    if (nullMsg || sliverMsg) {
      return utils.format('Removed %s%s%s', nullMsg, (nullMsg && sliverMsg ? ' and ' : ''), sliverMsg);
    }
    return '';
  }

  var ClipErase = /*#__PURE__*/Object.freeze({
    __proto__: null,
    clipLayersInPlace: clipLayersInPlace,
    clipLayers: clipLayers,
    clipLayersByBBox: clipLayersByBBox,
    clipLayersByLayer: clipLayersByLayer,
    getClipMessage: getClipMessage
  });

  // Assign a cluster id to each polygon in a dataset, which can be used with
  //   one of the dissolve commands to dissolve the clusters
  // Works by iteratively grouping pairs of polygons with the smallest distance
  //   between centroids.
  // Results are not optimal -- may be useful for creating levels of detail on
  //   interactive maps, not useful for analysis.
  //
  cmd.cluster = function(lyr, arcs, opts) {
    requirePolygonLayer(lyr);
    var groups = calcPolygonClusters(lyr, arcs, opts);
    var idField = opts.id_field || "cluster";
    insertFieldValues(lyr, idField, groups);
    return lyr;
  };

  function calcPolygonClusters(lyr, arcs, opts) {
    var calcScore = getPolygonClusterCalculator(opts);
    var size = lyr.shapes.length;
    var pct = opts.pct ? utils.parsePercent(opts.pct) : 1;
    var count = Math.round(size * pct);
    var groupField = opts.group_by || null;

    // working set of polygon records
    var shapeItems = lyr.shapes.map(function(shp, i) {
      var groupId = groupField && lyr.data.getRecordAt(i)[groupField] || null;
      return {
        ids: [i],
        area: geom.getShapeArea(shp, arcs),
        bounds: arcs.getMultiShapeBounds(shp),
        centroid: geom.getShapeCentroid(shp, arcs), // centroid of largest ring
        group: groupId,
        friends: []
      };
    });

    var mergeItems = []; // list of pairs of shapes that can be merged
    var mergeIndex = {}; // keep track of merges, to prevent duplicates
    var next;

    if (groupField && !lyr.data) stop("Missing attribute data table");

    // Populate mergeItems array
    findPairsOfNeighbors(lyr.shapes, arcs).forEach(function(ab, i) {
      // ab: [a, b] indexes of two polygons
      var a = shapeItems[ab[0]],
          b = shapeItems[ab[1]],
          item, id;
      if (a.group !== b.group) return;
      item = {ids: ab};
      item.score = getScore(item);
      if (item.score < 0) return;
      id = mergeItems.length;
      a.friends.push(id);
      b.friends.push(id);
      mergeItems.push(item);
    });

    // main loop
    while (count-- > 0 && (next = nextItem())) {
      merge(next);
    }

    // Assign a sequential id to each of the remaining original shapes and the
    // new aggregated shapes
    return shapeItems.filter(Boolean).reduce(function(memo, shape, clusterId) {
      var ids = shape.ids;
      for (var i=0; i<ids.length; i++) {
        memo[ids[i]] = clusterId;
      }
      return memo;
    }, []);

    function merge(item) {
      var merged = mergeShapes(item.ids);
      var mergedId = shapeItems.length;
      shapeItems[mergedId] = merged;
      updateList(merged.friends, item.ids, mergedId);
    }

    // Find lowest-ranked merge candidate and remove it from the list
    // Scans entire list - n^2 performance - tested ~20sec for 50,000 polygons
    function nextItem() {
      var minId = -1,
          min = Infinity,
          item, i, n;
      for (i=0, n=mergeItems.length; i<n; i++) {
        item = mergeItems[i];
        if (item !== null && item.score < min) {
          min = item.score;
          minId = i;
        }
      }
      if (minId == -1) return null;
      item = mergeItems[minId];
      mergeItems[minId] = null;
      return item;
    }

    function getScore(item) {
      return calcScore(shapeItems[item.ids[0]], shapeItems[item.ids[1]]);
    }

    function mergeCentroids(dest, src) {
      var k = dest.area / (dest.area + src.area),
          a = dest.centroid,
          b = src.centroid;
      // TODO: consider using geodetic distance when appropriate
      a.x = a.x * k + b.x * (1 - k);
      a.y = a.y * k + b.y * (1 - k);
    }

    function mergeShapes(ids) {
      var dest = shapeItems[ids[0]];
      var src = shapeItems[ids[1]];
      dest.bounds.mergeBounds(src.bounds);
      dest.area += src.area;
      dest.ids = dest.ids.concat(src.ids);
      mergeCentroids(dest, src);
      shapeItems[ids[0]] = null;
      shapeItems[ids[1]] = null;
      dest.friends = filterFriends(dest.friends.concat(src.friends));
      return dest;
    }

    // remove ids of duplicate and invalid merge candidates
    function filterFriends(friends) {
      var index = {};
      var merged = [];
      var id;
      for (var i=0; i<friends.length; i++) {
        id = friends[i];
        if ((id in index === false) && mergeItems[id] !== null) {
          merged.push(id);
          index[id] = true;
        }
      }
      return merged;
    }

    // re-index merge candidates after merging two shapes into a new shape
    function updateList(friends, oldIds, newId) {
      var item, id;
      for (var i=0, n=friends.length; i<n; i++) {
        id = friends[i];
        item = mergeItems[id];
        if (contains(item.ids, oldIds)) {
          mergeItems[id] = updateItem(item, oldIds, newId);
        }
      }
    }

    // re-index a merge candidate; return null if it duplicates a previously merged
    //   pair of shapes
    function updateItem(item, oldIds, newId) {
      var a = item.ids[0];
      var b = item.ids[1];
      var key;
      if (oldIds[0] == a || oldIds[1] == a) a = newId;
      if (oldIds[0] == b || oldIds[1] == b) b = newId;
      if (a == b) return null;
      item.ids = [a, b];
      key = clusterKey(item);
      if (key in mergeIndex) return null;
      mergeIndex[key] = true;
      item.score = getScore(item);
      if (item.score < 0) return null;
      return item;
    }

    function contains(a, b) {
      return a[0] === b[0] || a[0] === b[1] || a[1] === b[0] || a[1] === b[1];
    }

    function clusterKey(friend) {
      var a = friend.ids[0],
          b = friend.ids[1];
      if (b < a) {
        a = b;
        b = friend.ids[0];
      }
      return a + ',' + b;
    }
  }

  function getPolygonClusterCalculator(opts) {
    var maxWidth = opts.max_width || Infinity;
    var maxHeight = opts.max_height || Infinity;
    var maxArea = opts.max_area || Infinity;
    return function(a, b) {
      var area = a.area + b.area,
          // TODO: use geodetic distance when appropriate
          score = geom.distance2D(a.centroid.x, a.centroid.y, b.centroid.x, b.centroid.y),
          bounds = a.bounds.clone().mergeBounds(b.bounds);
      if (area > maxArea || bounds.width() > maxWidth ||
          bounds.height() > maxHeight) {
        score = -1;
      }
      return score;
    };
  }

  cmd.colorizer = function(opts) {
    if (!opts.name) {
      stop("Missing required name= parameter");
    }
    if (isReservedName(opts.name)) {
      stop('"' + opts.name + '" is a reserved name');
    }
    getStateVar('defs')[opts.name] = getColorizerFunction(opts);
  };

  function isReservedName(name) {
    return /^(stroke|stroke-width|stroke-dasharray|stroke-opacity|fill|fill-opacity|opacity|r|class)$/.test(name);
  }

  function getColorizerFunction(opts) {
    var nodataColor = opts.nodata || 'white';
    var round = opts.precision ? getRoundingFunction(opts.precision) : null;
    var colorFunction;

    if (!opts.random && (!opts.colors || !opts.colors.length)) {
      stop("Missing colors= parameter");
    }

    if (opts.random) {
      colorFunction = getRandomColorFunction(opts.colors);
    } else if (opts.breaks) {
      if (opts.colors.length != opts.breaks.length + 1) {
        stop("Number of colors should be one more than number of class breaks");
      }
      colorFunction = getSequentialClassifier(opts.breaks, opts.colors, nodataColor, round);
    } else if (opts.categories) {
      if (opts.colors.length != opts.categories.length) {
        stop("Number of colors should be equal to the number of categories");
      }
      colorFunction = getCategoricalClassifier(opts.colors, nodataColor, opts);
    } else {
      stop("Missing categories= or breaks= parameter");
    }

    return colorFunction;
  }

  function getSequentialClassifier(breaks, colors, nullVal, round) {
    var classify = getDiscreteClassifier(breaks, round);
    var toColor = getDiscreteValueGetter(colors, nullVal);
    return function(val) {
      return toColor(classify(val));
    };
  }

  function getCategoricalColorFunction(categories, colors, otherVal, nullVal) {
    var classify = getCategoricalClassifier(categories);
    var toColor = getDiscreteValueGetter(colors, nullVal, otherVal);
    return function(val) {
      return toColor(classify(val));
    };
  }

  function fastStringHash(val) {
    // based on https://github.com/darkskyapp/string-hash (public domain)
    var str = String(val),
        hash = 5381,
        i = str.length;
    while (i > 0) {
      hash = (hash * 33) ^ str.charCodeAt(--i);
    }
    return Math.abs(hash);
  }

  function getRandomColorFunction(colors) {
    if (!colors || !colors.length) {
      colors = '#ccc,#888,#444'.split(',');
    }
    return function(val) {
      var n = colors.length;
      var i = val === undefined ?
          Math.floor(Math.random() * n) : fastStringHash(val) % n;
      return colors[i];
    };
  }

  var Colorizer = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getColorizerFunction: getColorizerFunction
  });

  function expressionUsesGeoJSON(exp) {
    return exp.includes('this.geojson');
  }

  function getFeatureEditor(lyr, dataset) {
    var changed = false;
    var api = {};
    // need to copy attribute to avoid circular references if geojson is assigned
    // to a data property.
    var copy = copyLayer(lyr);
    var features = exportLayerAsGeoJSON(copy, dataset, {}, true);

    api.get = function(i) {
      return features[i];
    };

    api.set = function(feat, i) {
      changed = true;
      if (utils.isString(feat)) {
        feat = JSON.parse(feat);
      }
      features[i] = GeoJSON.toFeature(feat); // TODO: validate
    };

    api.done = function() {
      if (!changed) return; // read-only expression
      // TODO: validate number of features, etc.
      var geojson = {
        type: 'FeatureCollection',
        features: features
      };

      // console.log(JSON.stringify(geojson, null, 2))
      return importGeoJSON(geojson);
    };
    return api;
  }

  cmd.dashlines = function(lyr, dataset, opts) {
    var crs = getDatasetCRS(dataset);
    var defs = getStateVar('defs');
    var exp = `this.geojson = splitFeature(this.geojson)`;
    requirePolylineLayer(lyr);
    defs.splitFeature = getSplitFeatureFunction(crs, opts);
    cmd.evaluateEachFeature(lyr, dataset, exp, opts);
    delete defs.splitFeature;
  };

  function getSplitFeatureFunction(crs, opts) {
    var dashLen = opts.dash_length ? convertDistanceParam(opts.dash_length, crs) : 0;
    var gapLen = opts.gap_length ? convertDistanceParam(opts.gap_length, crs) : 0;
    if (dashLen > 0 === false) {
      stop('Missing required dash-length parameter');
    }
    if (gapLen >= 0 == false) {
      stop('Invalid gap-length option');
    }
    var splitLine = getSplitLineFunction(crs, dashLen, gapLen, opts);
    return function(feat) {
      var geom = feat.geometry;
      if (!geom) return feat;
      if (geom.type == 'LineString') {
        geom.type = 'MultiLineString';
        geom.coordinates = [geom.coordinates];
      }
      if (geom.type != 'MultiLineString') {
        error('Unexpected geometry:', geom.type);
      }
      geom.coordinates = geom.coordinates.reduce(function(memo, coords) {
        try {
          var parts = splitLine(coords);
          memo = memo.concat(parts);
        } catch(e) {
          console.error(e);
          throw e;
        }
        return memo;
      }, []);

      return feat;
    };
  }

  function getSplitLineFunction(crs, dashLen, gapLen, opts) {
    var planar = !!opts.planar;
    var interpolate = getInterpolationFunction(planar ? null : crs);
    var distance =  isLatLngCRS(crs) ? greatCircleDistance : distance2D;
    var inDash, parts2, interval, scale;
    function addPart(coords) {
      if (inDash) parts2.push(coords);
      if (gapLen > 0) {
        inDash = !inDash;
        interval = scale * (inDash ? dashLen : gapLen);
      }
    }

    return function splitLineString(coords) {
      var elapsedDist = 0;
      var p = coords[0];
      var coords2 = [p];
      var segLen, pct, prev;
      if (opts.scaled) {
        scale = scaleDashes(dashLen, gapLen, getLineLength(coords, distance));
      } else {
        scale = 1;
      }
      // init this LineString
      inDash = gapLen > 0 ? false : true;
      interval = scale * (inDash ? dashLen : gapLen);
      if (!inDash) {
        // start gapped lines with a half-gap
        // (a half-gap or a half-dash is probably better for rings and intersecting lines)
        interval *= 0.5;
      }
      parts2 = [];
      for (var i=1, n=coords.length; i<n; i++) {
        prev = p;
        p = coords[i];
        segLen = distance(prev[0], prev[1], p[0], p[1]);
        if (segLen <= 0) continue;
        while (elapsedDist + segLen >= interval) {
          // this segment contains a break either within it or at the far endpoint
          pct = (interval - elapsedDist) / segLen;
          if (pct > 0.999 && i == n - 1) {
            // snap to endpoint (so fp rounding errors don't result in a tiny
            // last segment)
            pct = 1;
          }
          if (pct < 1) {
            prev = interpolate(prev[0], prev[1], p[0], p[1], pct);
          } else {
            prev = p;
          }
          coords2.push(prev);
          addPart(coords2);
          // start a new part
          coords2 = pct < 1 ? [prev] : [];
          elapsedDist = 0;
          segLen = (1 - pct) * segLen;
        }
        coords2.push(p);
        elapsedDist += segLen;
      }
      if (elapsedDist > 0 && coords2.length > 1) {
        addPart(coords2);
      }
      return parts2;
    };
  }

  function getLineLength(coords, distance) {
    var len = 0;
    for (var i=1, n=coords.length; i<n; i++) {
      len += distance(coords[i-1][0], coords[i-1][1], coords[i][0], coords[i][1]);
    }
    return len;
  }

  function scaleDashes(dash, gap, len) {
    var dash2, gap2;
    var n = len / (dash + gap); // number of dashes
    var n1 = Math.floor(n);
    var n2 = Math.ceil(n);
    var k1 = len / (n1 * (dash + gap)); // scaled-up dashes, >1
    var k2 = len / (n2 * (dash + gap)); // scaled-down dashes <1
    var k = k2;
    if (k1 < 1/k2 && n1 > 0) {
      k = k1; // pick the smaller of the two scales
    }
    return k;
  }

  // This function creates a continuous mosaic of data values in a
  // given field by assigning data from adjacent polygon features to polygons
  // that contain null values.
  // The 'contiguous' option removes data islands to create contiguous groups
  // that are likely to be the result of unreliable data (e.g. faulty geocodes).

  cmd.dataFill = function(lyr, arcs, opts) {
    var field = opts.field;
    if (!field) stop("Missing required field= parameter");
    requireDataField(lyr, field);
    if (lyr.geometry_type != 'polygon') stop("Target layer must be polygon type");
    var getNeighbors = getNeighborLookupFunction(lyr, arcs);
    var fillCount, islandCount;

    // get function to check if a shape was empty before data-fill
    var initiallyEmpty = (function() {
      var flags = lyr.data.getRecords().map(function(rec) {
        return isEmptyValue(rec[field]);
      });
      return function(i) {return flags[i];};
    }());

    // step one: fill empty units
    fillCount = dataFillEmpty(field, lyr, arcs, getNeighbors);

    // step two: smooth perimeters
    dataFillSmooth(field, lyr, arcs, getNeighbors, initiallyEmpty);

    // step three: remove non-contiguous data islands
    if (opts.contiguous) {
      islandCount = dataFillIslandGroups(field, lyr, arcs, getNeighbors, opts);
    }

    message('Filled', fillCount, 'empty polygons' + utils.pluralSuffix(fillCount));
    if (islandCount > 0) {
      message('Removed', islandCount, 'non-contiguous polygon group' + utils.pluralSuffix(islandCount));
    }
  };

  // Assign values to units without data, using the values of neighboring units.
  function dataFillEmpty(field, lyr, arcs, getNeighbors) {
    var records = lyr.data.getRecords();
    var onShape = getDataFillCalculator(field, lyr, arcs, getNeighbors);
    var isEmpty = getEmptyValueFilter(field, lyr);
    var groups = {}; // groups, indexed by key
    var assignCount = 0;

    // step one: place features in groups based on data values of non-empty neighbors.
    // (grouping is an attempt to avoid ragged edges between groups of same-value units,
    // which occured when data was assigned to units independently of adjacent units).
    lyr.shapes.forEach(function(shp, i) {
      if (!isEmpty(i)) return; // only assign shapes with missing values
      var data = onShape(i);
      if (!data.group) return; // e.g. if no neighbors have data
      addDataToGroup(data, groups);
    });

    // step two: assign the same value to all members of a group
    Object.keys(groups).forEach(function(groupId) {
      var group = groups[groupId];
      var value = getMaxWeightValue(group);
      assignValueToShapes(group.shapes, value);
    });

    function assignValueToShapes(ids, val) {
      ids.forEach(function(id) {
        assignCount++;
        records[id][field] = val;
      });
    }

    function addDataToGroup(d, groups) {
      var group = groups[d.group];
      var j;
      if (!group) {
        groups[d.group] = {
          shapes: [d.shape],
          weights: d.weights,
          values: d.values
        };
        return;
      }
      group.shapes.push(d.shape);
      for (var i=0, n=d.values.length; i<n; i++) {
        // add new weights to the group's total weights
        j = group.values.indexOf(d.values[i]);
        group.weights[j] += d.weights[i];
      }
    }

    if (assignCount > 0) {
      // recursively fill empty neighbors of the newly filled shapes
      assignCount += dataFillEmpty(field, lyr, arcs, getNeighbors);
    }
    return assignCount;
  }


  // Try to smooth out jaggedness resulting from filling empty units
  // This function assigns a different adjacent data value to formerly empty units,
  // if this would produce a shorter boundary.
  function dataFillSmooth(field, lyr, arcs, getNeighbors, wasEmpty) {
    var onShape = getDataFillCalculator(field, lyr, arcs, getNeighbors);
    var records = lyr.data.getRecords();
    var updates = 0;
    lyr.shapes.forEach(function(shp, i) {
      if (!wasEmpty(i)) return; // only edit shapes that were originally empty
      var data = onShape(i);
      if (data.values.length < 2) return; // no other values are available
      var currVal = records[i][field];
      var topVal = getMaxWeightValue(data);
      if (currVal != topVal) {
        records[i][field] = topVal;
        updates++;
      }
    });
    return updates;
  }

  // Remove less-important data islands to ensure that data groups are contiguous
  //
  function dataFillIslandGroups(field, lyr, arcs, getNeighbors, opts) {
    var records = lyr.data.getRecords();
    var groupsByValue = {}; // array of group objects, indexed by data values
    var unitIndex = new Uint8Array(lyr.shapes.length);
    var currGroup = null;
    var islandCount = 0;
    var weightField = opts.weight_field || null;

    if (weightField) {
      requireDataField(lyr, weightField);
    }

    // 1. form groups of contiguous units with the same attribute value
    lyr.shapes.forEach(function(shp, shpId) {
      onShape(shpId);
    });

    // 2. retain the most important group for each value; discard satellite groups
    Object.keys(groupsByValue).forEach(function(val) {
      var groups = groupsByValue[val];
      var maxIdx;
      if (groups.length < 2) return;
      maxIdx = indexOfMaxValue(groups, 'weight');
      if (maxIdx == -1) return; // error condition...
      groups
        .filter(function(group, i) {return i != maxIdx;})
        .forEach(clearIslandGroup);
    });

    // 3. fill gaps left by removing groups
    if (islandCount > 0) {
      dataFillEmpty(field, lyr, arcs, getNeighbors);
    }
    return islandCount;

    function clearIslandGroup(group) {
      islandCount++;
      group.shapes.forEach(function(shpId) {
        records[shpId][field] = null;
      });
    }

    function onShape(shpId) {
      if (unitIndex[shpId] == 1) return; // already added to a group
      var val = records[shpId][field];
      var firstShape = false;
      if (isEmptyValue(val)) return;
      if (!currGroup) {
        // start a new group
        firstShape = true;
        currGroup = {
          value: val,
          shapes: [],
          weight: 0
        };
        if (val in groupsByValue === false) {
          groupsByValue[val] = [];
        }
        groupsByValue[val].push(currGroup);
      } else if (val != currGroup.value) {
        return;
      }
      if (weightField) {
        currGroup.weight += records[shpId][weightField];
      } else {
        currGroup.weight += geom.getShapeArea(lyr.shapes[shpId], arcs);
      }
      currGroup.shapes.push(shpId);
      unitIndex[shpId] = 1;
      // TODO: consider switching from depth-first traversal to breadth-first
      getNeighbors(shpId).forEach(onShape);
      if (firstShape) {
        currGroup = null;
      }
    }
  }


  // Return value with the greatest weight from a datafill object
  function getMaxWeightValue(d) {
    var maxWeight = Math.max.apply(null, d.weights);
    var i = d.weights.indexOf(maxWeight);
    return d.values[i]; // return highest weighted value
  }

  // TODO: move to a more sensible file... mapshaper-calc-utils?
  function indexOfMaxValue(arr, key) {
    var maxWeight = -Infinity;
    var idx = -1;
    arr.forEach(function(o, i) {
      if (o.weight > maxWeight) {
        idx = i;
        maxWeight = o.weight;
      }
    });
    return idx;
  }

  function isEmptyValue(val) {
     return !val && val !== 0;
  }

  function getEmptyValueFilter(field, lyr) {
    var records = lyr.data.getRecords();
    return function(i) {
      var rec = records[i];
      return rec ? isEmptyValue(rec[field]) : false;
    };
  }

  // Returns a function to fetch the values of a data field from the neighbors of
  // a polygon feature. Each value is assigned a weight in proportion to the
  // length of the borders between the polygon and its neighbors.
  function getDataFillCalculator(field, lyr, arcs, getNeighbors) {
    var isPlanar = arcs.isPlanar();
    var records = lyr.data.getRecords();
    var tmp;

    function onSharedArc(nabeId, arcId) {
      var weight, i;
      var val = records[nabeId][field];
      if (isEmptyValue(val)) return;
      // weight is the length of the shared border
      // TODO: consider support for alternate weighting schemes
      weight = geom.calcPathLen([arcId], arcs, !isPlanar);
      i = tmp.values.indexOf(val);
      if (i == -1) {
        tmp.values.push(val);
        tmp.weights.push(weight);
      } else {
        tmp.weights[i] += weight;
      }
    }

    return function(shpId) {
      tmp = {
        shape: shpId,
        weights: [],
        values: [],
        group: ''
      };
      getNeighbors(shpId, onSharedArc);
      tmp.group = tmp.values.concat().sort().join('~');
      return tmp;
    };
  }

  cmd.define = function(opts) {
    if (!opts.expression) {
      stop('Missing an assignment expression');
    }
    var defs = getStateVar('defs');
    var compiled = compileFeatureExpression(opts.expression, {}, null, {no_warn: true});
    var result = compiled(null, defs);
  };

  // Removes small gaps and all overlaps
  cmd.dissolve2 = function(layers, dataset, opts) {
    layers.forEach(requirePolygonLayer);
    var nodes = addIntersectionCuts(dataset, opts);
    return layers.map(function(lyr) {
      if (!layerHasPaths(lyr)) return lyr;
      return dissolvePolygonLayer2(lyr, dataset, opts);
    });
  };

  // Returns a function for filtering multiple source-table records
  // (used by -join command)
  function getJoinFilter(data, exp) {
    var test = getJoinFilterTestFunction(exp, data);
    var calc = null;
    if (expressionHasCalcFunction(exp)) {
      calc = getJoinFilterCalcFunction(exp, data);
    }

    return function(srcIds, destRec) {
      var d = calc ? calc(srcIds) : null;
      var filtered = [],
          retn, i;
      for (i=0; i<srcIds.length; i++) {
        retn = test(srcIds[i], destRec, d);
        if (retn === true) {
          filtered.push(srcIds[i]);
        } else if (retn !== false) {
          stop('"where" expression must return true or false');
        }
      }
      return filtered;
    };
  }

  function expressionHasCalcFunction(exp) {
    return utils.some(['isMax', 'isMin', 'isMode'], function(name) {
      return exp.indexOf(name) > -1;
    });
  }


  function getJoinFilterCalcFunction(exp, data) {
    var values, counts, max, min, context, calc, n;

    context = {
      isMax: function(val) {
        if (val > max) max = val;
      },
      isMin: function(val) {
        if (val < min) min = val;
      },
      isMode: function(val) {
        if (!values) {
          values = [];
        }
        values.push(val);
      }
    };

    calc = compileFeatureExpression(exp, {data: data}, null, {context: context});

    function reset() {
      max = -Infinity;
      min = Infinity;
      values = null;
    }

    return function(ids) {
      var mode;
      reset();
      for (var i=0; i<ids.length; i++) {
        calc(ids[i]);
      }
      mode = values ? getModeData(values) : null;
      return {
        max: max,
        min: min,
        modes: mode ? mode.modes : null,
        margin: mode ? mode.margin : null
      };
    };
  }


  function getJoinFilterTestFunction(exp, data) {
    var test, calcRec, destRec;
    var context = {
      isMax: function(val) {
        return val === calcRec.max;
      },
      isMin: function(val) {
        return val === calcRec.min;
      },
      isMode: function(val) {
        return calcRec.modes.indexOf(val) > -1;
      }
    };
    // 'target' property is an accessor function,
    // so the object it references can be updated.
    Object.defineProperty(context, 'target', {
      get: function() {
        return destRec;
      },
      enumerable: true // so it can be mixed-in to the actual expression context
    });

    test = compileFeatureExpression(exp, {data: data}, null, {context: context, returns: true});

    // calcR: results from calculation phase, or null
    return function(srcId, destR, calcR) {
      calcRec = calcR;
      destRec = destR;
      return test(srcId);
    };
  }

  var JoinFilter = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getJoinFilter: getJoinFilter
  });

  // Join data from @src table to records in @dest table
  function joinTables(dest, src, join, opts) {
    return joinTableToLayer({data: dest}, src, join, opts);
  }

  // Join data from @src table to records in @destLyr layer.
  // @join function
  //    Receives index of record in the dest table
  //    Returns array of matching records in src table, or null if no matches
  //
  function joinTableToLayer(destLyr, src, join, opts) {
    var dest = destLyr.data,
        useDuplication = !!opts.duplication,
        srcRecords = src.getRecords(),
        destRecords = dest.getRecords(),
        prefix = opts.prefix || '',
        unmatchedRecords = [],
        joinFields = getFieldsToJoin(dest.getFields(), src.getFields(), opts),
        sumFields = opts.sum_fields || [],
        copyFields = utils.difference(joinFields, sumFields),
        joinCounts = new Uint32Array(srcRecords.length),
        matchCount = 0,
        collisionCount = 0,
        collisionFields = [],
        skipCount = 0,
        retn = {},
        srcRec, srcId, destRec, joins, count, filter, calc, i, j, n, m;

    // support for duplication of destination records
    var duplicateRecords, destShapes;
    if (useDuplication) {
      if (opts.calc) stop('duplication and calc options cannot be used together');
      duplicateRecords = dest.clone().getRecords();
      destShapes = destLyr.shapes || [];
    }

    if (opts.where) {
      filter = getJoinFilter(src, opts.where);
    }

    if (opts.calc) {
      calc = getJoinCalc(src, opts.calc);
    }

    // join source records to target records
    n = destRecords.length;
    for (i=0; i<n; i++) {
      destRec = destRecords[i];
      joins = join(i);
      if (joins && filter) {
        skipCount += joins.length;
        joins = filter(joins, destRec);
        skipCount -= joins.length;
      }
      for (j=0, count=0, m=joins ? joins.length : 0; j<m; j++) {
        srcId = joins[j];
        srcRec = srcRecords[srcId];
        // duplication mode: many-to-one joins add new features to the target layer.
        if (count > 0 && useDuplication) {
          destRec = copyRecord(duplicateRecords[i]);
          destRecords.push(destRec);
          destShapes.push(cloneShape(destShapes[i]));
        }
        if (count === 0 || useDuplication) {
          if (copyFields.length > 0) {
            // only copying the first match
            joinByCopy(destRec, srcRec, copyFields, prefix);
          }
        } else if (count == 1) {
          if (copyFields.length > 0 && !prefix) {
            findCollisionFields(destRec, srcRec, copyFields, collisionFields);
          }
          collisionCount++; // count target records with multiple joins
        }
        if (sumFields.length > 0) {
          joinBySum(destRec, srcRec, sumFields, prefix);
        }
        joinCounts[srcId]++;
        count++;
      }
      if (calc) {
        calc(joins, destRec);
      }
      if (count > 0) {
        matchCount++;
      } else if (destRec) {
        if (opts.unmatched) {
          // Save a copy of unmatched record, before null values from join fields
          // are added.
          unmatchedRecords.push(utils.extend({}, destRec));
        }
        updateUnmatchedRecord(destRec, copyFields, sumFields, prefix);
      }
    }

    printJoinMessage(matchCount, n,
        countJoins(joinCounts), srcRecords.length, skipCount, collisionCount, collisionFields);

    if (opts.unjoined) {
      retn.unjoined = {
        name: 'unjoined',
        data: new DataTable(srcRecords.filter(function(o, i) {
          return joinCounts[i] === 0;
        }))
      };
    }
    if (opts.unmatched) {
      retn.unmatched = {
        name: 'unmatched',
        data: new DataTable(unmatchedRecords)
      };
    }
    return retn;
  }

  function validateFieldNames(arr) {
    arr.forEach(function(name) {
      if (/:(str|num)/.test(name)) {
        stop("Unsupported use of type hints. Use string-fields= or field-types= options instead");
      }
    });
  }


  function countJoins(counts) {
    var joinCount = 0;
    for (var i=0, n=counts.length; i<n; i++) {
      if (counts[i] > 0) {
        joinCount++;
      }
    }
    return joinCount;
  }

  // Unset fields of unmatched records get null/empty values
  function updateUnmatchedRecord(rec, copyFields, sumFields, prefix) {
    joinByCopy(rec, {}, copyFields, prefix);
    joinBySum(rec, {}, sumFields, prefix);
  }

  /*
  internal.getCountFieldName = function(fields) {
    var uniq = internal.getUniqFieldNames(fields.concat("joins"));
    return uniq.pop();
  };
  */

  function joinByCopy(dest, src, fields, prefix) {
    var f, f2;
    prefix = prefix || '';
    for (var i=0, n=fields.length; i<n; i++) {
      // dest[fields[i]] = src[fields[i]];
      // Use null when the source record is missing an expected value
      // TODO: think some more about whether this is desirable
      f = fields[i];
      f2 = prefix + f;
      if (Object.prototype.hasOwnProperty.call(src, f)) {
        dest[f2] = src[f];
      } else if (!Object.prototype.hasOwnProperty.call(dest, f2)) {
        dest[f2] = null;
      }
    }
  }

  function joinBySum(dest, src, fields, prefix) {
    var f, f2;
    prefix = prefix || '';
    for (var j=0; j<fields.length; j++) {
      f = fields[j];
      f2 = prefix + f;
      dest[f2] = (dest[f2] || 0) + (src[f] || 0);
    }
  }

  function findCollisionFields(dest, src, fields, collisionFields) {
    var f;
    for (var i=0, n=fields.length; i<n; i++) {
      f = fields[i];
      if (dest[f] !== src[f] && collisionFields.indexOf(f) === -1) {
        collisionFields.push(f);
      }
    }
  }

  function printJoinMessage(matches, n, joins, m, skipped, collisions, collisionFields) {
    // TODO: add tip for troubleshooting join problems, if join is less than perfect.
    var unmatched = n - matches;
    if (matches > 0 === false) {
      message("No records could be joined");
      return;
    }
    message(utils.format("Joined data from %'d source record%s to %'d target record%s",
        joins, utils.pluralSuffix(joins), matches, utils.pluralSuffix(matches)));
    if (unmatched > 0) {
      message(utils.format('%d target record%s received no data', unmatched, utils.pluralSuffix(unmatched)));
      // message(utils.format('%d target records received no data', n-matches));
    }
    if (joins < m) {
      message(utils.format("%d/%d source records could not be joined", m-joins, m));
    }
    if (skipped > 0) {
      message(utils.format("%d/%d source records were skipped", skipped, m));
    }
    if (collisions > 0) {
      message(utils.format('%d/%d target records were matched by multiple source records (many-to-one relationship)', collisions, n));
      if (collisionFields.length > 0) {
        message(utils.format('Inconsistent values were found in field%s [%s] during many-to-one join. Values in the first joining record were used.', utils.pluralSuffix(collisionFields.length), collisionFields.join(',')));
      }
    }
  }

  function getFieldsToJoin(destFields, srcFields, opts) {
    var joinFields;
    if (opts.fields) {
      if (opts.fields.indexOf('*') > -1) {
        joinFields = srcFields;
      } else {
        joinFields = opts.fields;
        validateFieldNames(joinFields);
      }
    } else if (opts.calc) {
      // presence of calc= option suggests a many-to-one or many-to-many join;
      // it usually doesn't make sense to join all fields by default
      joinFields = [];
    } else {
      // If a list of fields to join is not given, try to join all of the
      // source fields
      joinFields = srcFields;
      // exclude source key field from key-based join (if fields are not given explicitly)
      if (opts.keys) {
        joinFields = utils.difference(joinFields, [opts.keys[1]]);
      }
    }
    if (!opts.force && !opts.prefix) {
      // overwrite existing fields if the "force" option is set.
      // prefix also overwrites... TODO: consider changing this
      joinFields = utils.difference(joinFields, destFields);
    }
    return joinFields;
  }

  var JoinTables = /*#__PURE__*/Object.freeze({
    __proto__: null,
    joinTables: joinTables,
    joinTableToLayer: joinTableToLayer,
    validateFieldNames: validateFieldNames,
    updateUnmatchedRecord: updateUnmatchedRecord,
    findCollisionFields: findCollisionFields,
    getFieldsToJoin: getFieldsToJoin
  });

  cmd.divide = function(targetLayers, targetDataset, source, opts) {
    targetLayers.forEach(requirePolylineLayer);
    var mergedDataset = mergeLayersForOverlay(targetLayers, targetDataset, source, opts);
    var nodes = addIntersectionCuts(mergedDataset, opts);
    var polygonLyr = mergedDataset.layers.pop();
    requirePolygonLayer(polygonLyr);
    // Assume that topology is now built
    targetDataset.arcs = mergedDataset.arcs;
    targetLayers.forEach(function(polylineLyr) {
      dividePolylineLayer(polylineLyr, polygonLyr, nodes, opts);
    });
  };

  function dividePolylineLayer(polylineLyr, polygonLyr, nodes, opts) {
    var index = new PathIndex(polygonLyr.shapes, nodes.arcs);
    var records = polylineLyr.data ? polylineLyr.data.getRecords() : [];
    var shapes2 = [];
    var records2 = [];
    var index2 = [];
    var outputLines;
    var outputKeys;
    var outputMatches;
    polylineLyr.shapes.forEach(function(shp, i) {
      var rec = records[i] || {};
      if (!shp) {
        // case: record with no geometry -- retain in the output layer
        shapes2.push(null);
        records2.push(rec);
        return;
      }
      outputLines = [];
      outputKeys = [];
      outputMatches = [];
      forEachShapePart(shp, onPart);
      outputLines.forEach(function(shape2, i) {
        shapes2.push(shape2);
        records2.push(i > 0 ? utils.extend({}, rec) : rec); // assume input data is being replaced
        index2.push(outputMatches[i]);
      });
    });
    polylineLyr.shapes = shapes2;
    polylineLyr.data = new DataTable(records2);
    joinTables(polylineLyr.data, polygonLyr.data, function(i) {
      return index2[i] || [];
    }, opts);

    function addDividedParts(parts, keys, matches) {
      var keyId, key;
      for (var i=0; i<parts.length; i++) {
        key = keys[i];
        keyId = outputKeys.indexOf(key);
        if (keyId == -1) {
          outputKeys.push(key);
          outputLines.push([parts[i]]);
          outputMatches.push(matches[i]);
        } else {
          outputLines[keyId].push(parts[i]);
        }
      }
    }

    function getKey(shapeIds) {
      return shapeIds.sort().join(',');
      // multiple matches: treat like no match
      // return shapeIds.length == 1 ? String(shapeIds[0]) : '-1';
    }

    // Partition each part
    function onPart(ids) {
      var parts2 = [];
      var keys2 = [];
      var matches2 = [];
      var prevKey = null;
      var containingIds, key, part2, arcId;
      // assign each arc to a divided shape
      for (var i=0, n=ids.length; i<n; i++) {
        arcId = ids[i];
        containingIds = index.findShapesEnclosingArc(absArcId(arcId));
        key = getKey(containingIds);
        if (key === prevKey) {
          // case: continuation of a part
          part2.push(arcId);
        } else {
          // case: start of a new part
          part2 = [arcId];
          parts2.push(part2);
          keys2.push(key);
          matches2.push(containingIds);
        }
        prevKey = key;
      }
      addDividedParts(parts2, keys2, matches2);
    }
  }

  function MinHeap() {
    return new Heap('min');
  }

  function MaxHeap() {
    return new Heap('max');
  }

  // A heap data structure used for computing Visvalingam simplification data.
  // type: 'max' or 'min' (min is default)
  //
  function Heap(type) {
    var heapBuf = utils.expandoBuffer(Int32Array),
        indexBuf = utils.expandoBuffer(Int32Array),
        heavierThan = type == 'max' ? lessThan : greaterThan,
        itemsInHeap = 0,
        dataArr,
        heapArr,
        indexArr;

    this.init = function(values) {
      var i;
      dataArr = values;
      itemsInHeap = values.length;
      heapArr = heapBuf(itemsInHeap);
      indexArr = indexBuf(itemsInHeap);
      for (i=0; i<itemsInHeap; i++) {
        insertValue(i, i);
      }
      // place non-leaf items
      for (i=(itemsInHeap-2) >> 1; i >= 0; i--) {
        downHeap(i);
      }
    };

    this.size = function() {
      return itemsInHeap;
    };

    // Update a single value and re-heap
    this.updateValue = function(valIdx, val) {
      var heapIdx = indexArr[valIdx];
      dataArr[valIdx] = val;
      if (!(heapIdx >= 0 && heapIdx < itemsInHeap)) {
        error("Out-of-range heap index.");
      }
      downHeap(upHeap(heapIdx));
    };

    this.popValue = function() {
      return dataArr[this.pop()];
    };

    this.getValue = function(idx) {
      return dataArr[idx];
    };

    this.peek = function() {
      return heapArr[0];
    };

    this.peekValue = function() {
      return dataArr[heapArr[0]];
    };

    // Return the idx of the lowest-value item in the heap
    this.pop = function() {
      var popIdx;
      if (itemsInHeap <= 0) {
        error("Tried to pop from an empty heap.");
      }
      popIdx = heapArr[0];
      insertValue(0, heapArr[--itemsInHeap]); // move last item in heap into root position
      downHeap(0);
      return popIdx;
    };

    function upHeap(idx) {
      var parentIdx;
      // Move item up in the heap until it's at the top or is not lighter than its parent
      while (idx > 0) {
        parentIdx = (idx - 1) >> 1;
        if (heavierThan(idx, parentIdx)) {
          break;
        }
        swapItems(idx, parentIdx);
        idx = parentIdx;
      }
      return idx;
    }

    // Swap item at @idx with any lighter children
    function downHeap(idx) {
      var minIdx = compareDown(idx);

      while (minIdx > idx) {
        swapItems(idx, minIdx);
        idx = minIdx; // descend in the heap
        minIdx = compareDown(idx);
      }
    }

    function swapItems(a, b) {
      var i = heapArr[a];
      insertValue(a, heapArr[b]);
      insertValue(b, i);
    }

    // Associate a heap idx with the index of a value in data arr
    function insertValue(heapIdx, valId) {
      indexArr[valId] = heapIdx;
      heapArr[heapIdx] = valId;
    }

    // comparator for Visvalingam min heap
    // @a, @b: Indexes in @heapArr
    function greaterThan(a, b) {
      var idx1 = heapArr[a],
          idx2 = heapArr[b],
          val1 = dataArr[idx1],
          val2 = dataArr[idx2];
      // If values are equal, compare array indexes.
      // This is not a requirement of the Visvalingam algorithm,
      // but it generates output that matches Mahes Visvalingam's
      // reference implementation.
      // See https://hydra.hull.ac.uk/assets/hull:10874/content
      return (val1 > val2 || val1 === val2 && idx1 > idx2);
    }

    // comparator for max heap
    function lessThan(a, b) {
      var idx1 = heapArr[a],
          idx2 = heapArr[b];
      return dataArr[idx1] < dataArr[idx2];
    }

    function compareDown(idx) {
      var a = 2 * idx + 1,
          b = a + 1,
          n = itemsInHeap;
      if (a < n && heavierThan(idx, a)) {
        idx = a;
      }
      if (b < n && heavierThan(idx, b)) {
        idx = b;
      }
      return idx;
    }
  }

  // TODO: optimize point-in-polygon tests for complex polygons and many points
  // import { PathIndex } from '../paths/mapshaper-path-index';

  function placeDotsInPolygon(shp, arcs, n, opts) {
    // TODO: skip tiny sliver polygons?
    if (n === 0) return [];
    if (opts.evenness === 0) return placeDotsRandomly(shp, arcs, n);
    // TODO: if n == 1, consider using the 'inner' point of a polygon
    return placeDotsEvenly(shp, arcs, n, opts);
  }

  function placeDotsRandomly(shp, arcs, n) {
    var bounds = arcs.getMultiShapeBounds(shp);
    var coords = [];
    for (var i=0; i<n; i++) {
      coords.push(placeRandomDot(shp, arcs, bounds));
    }
    return coords;
  }

  function placeRandomDot(shp, arcs, bounds) {
    var limit = 100;
    var i = 0;
    var x, y;
    while (++i < limit) {
      x = bounds.xmin + Math.random() * bounds.width();
      y = bounds.ymin + Math.random() * bounds.height();
      if (testPointInPolygon(x, y, shp, arcs)) {
        return [x, y];
      }
    }
    return null;
  }

  function placeDotsEvenly(shp, arcs, n, opts) {
    var evenness = opts.evenness >= 0 ? Math.min(opts.evenness, 1) : 1;
    var shpArea = geom.getPlanarShapeArea(shp, arcs);
    if (shpArea > 0 === false) return [];
    var bounds = arcs.getMultiShapeBounds(shp);
    var approxQueries = Math.round(n * bounds.area() / shpArea);
    if (opts.progressive) {
      // TODO: implement this properly
      approxQueries = Math.ceil(approxQueries / 6);
    }
    var grid = new DotGrid(bounds, approxQueries, evenness);
    var coords = [];
    for (var i=0; i<n; i++) {
      coords.push(placeDot(shp, arcs, grid));
    }
    grid.done();
    return coords;
  }

  function placeDot(shp, arcs, grid) {
    var i = 0;
    var limit = 100;
    var p;
    while (++i < limit) {
      p = grid.getPoint();
      if (!p) continue;
      if (testPointInPolygon(p[0], p[1], shp, arcs)) {
        return p;
      }
    }
    return null;
  }

  // A method for placing dots in a 2D rectangular space
  // evenness: varies from 0-1
  //   0 is purely random
  //   1 uses a hybrid approach, first creating a sparse structure of random
  //      dots, then progressively filling in the spaces between dots
  //   (0-1) first creates an evenish structure of dots, then places additional
  //      dots using "dart-throwing" -- picking random points until a point
  //      is found that exceeds a (variable) distance from any other point
  //
  function DotGrid(bounds, approxQueries, evenness) {
    var x0 = bounds.xmin;
    var y0 = bounds.ymin;
    var w = bounds.width();
    var h = bounds.height();
    var k =  0.5 * (evenness - 1) + 1; // k varies from 0.5 to 1
    var approxCells = approxQueries * 0.9 * k;
    var cols = Math.round(Math.sqrt(approxCells * w / h)) || 1;
    var rows = Math.ceil(cols * h / w); // overshoots bbox height
    var gridWidth = w;
    var gridHeight = w * rows / cols;
    var cells = cols * rows;
    var cellSize = gridWidth / cols;
    var cellId = -1;
    var shuffledIds;
    var grid = initGrid(cells);
    // data used by optimal method
    var bestPoints;
    var bestHeap;

    // Set the initial distance threshold between dots (based on a square grid)
    // When evenness < 1 (dart-throwing mode) the distance threshold is reduced in
    //   proportion to the value of evenness.
    // From trial and error, a 0.7 constant seems to give good results.
    var initialDotSpacing = gridWidth / cols * 0.7 * evenness;
    var dotSpacing = initialDotSpacing;

    // metrics
    var queries = 0;
    var bestCount = 0;

    this.done = done;
    this.getPoint = getPoint;

    function done() {
      // console.log( 'queries:', queries,'bestPct:', pct(bestCount, queries), "dotSpacing:", Math.round(dotSpacing));
      function pct(a, b) {
        return Math.round(a / b * 100) + '%';
      }
    }

    function getPoint() {
      queries++;
      if (evenness === 1) return getOptimalPoint();
      if (evenness === 0) return getRandomPoint();
      return getSpacedPoint();
    }

    function initGrid(n) {
      var arr = [];
      for (var i=0; i<n; i++) arr.push([]);
      return arr;
    }

    function getOptimalPoint() {
      var p = getFirstFillPoint();
      if (p) return usePoint(p);

      // fill in the gaps of the initial placement, starting with the largest gap
      if (!bestPoints) {
        initBestPoints();
      }
      return useBestPoint();
    }

    // try to place a random but spaced point in each grid cell
    // (to create an initial sparse structure that gets filled in later)
    function getFirstFillPoint() {
      var p;
      if (!shuffledIds) {
        shuffledIds = utils.range(cells);
        utils.shuffle(shuffledIds);
      }
      while (++cellId < cells) {
        p = getRandomPointInCell(shuffledIds[cellId]);
        if (pointIsUsable(p)) {
          return p;
        }
      }
    }

    function getSpacedPoint() {
      // use dart-throwing, reject points that are within the minimum distance
      var probesBeforeRelaxation = Math.ceil(Math.pow(cells, 0.8));
      var maxProbes = cells * 10;
      var probes = 0;
      var p = getFirstFillPoint();
      if (p) return usePoint(p);

      while (probes++ < maxProbes) {
        p = getRandomPoint();
        if (pointIsUsable(p)) {
          return usePoint(p);
        }
        if (probes % probesBeforeRelaxation === 0) {
          // relax min dist after a number of failed probes
          dotSpacing *= 0.9;
        }
      }
      return null;
    }

    // Add point to grid of used points
    function usePoint(p) {
      var i = pointToIdx(p);
      grid[i].push(p);
      return p;
    }

    function useBestPoint() {
      var bestId = bestHeap.peek();
      var p = bestPoints[bestId];
      usePoint(p); // add to grid of used points
      updateNeighbors(p, bestId); // update best point of this cell and neighbors
      dotSpacing = bestHeap.peekValue();
      bestCount++;
      return p;
    }

    function initBestPoints() {
      var values = [];
      bestPoints = [];
      for (var i=0; i<cells; i++) {
        values.push(findBestPointInCell(i));
      }
      bestHeap = new MaxHeap();
      bestHeap.init(values);
    }

    function updateNeighbors(p, i) {
      var r = idxToRow(i);
      var c = idxToCol(i);
      updateBestPointInCell(i);
      updateNeighbor(p, c+1, r);
      updateNeighbor(p, c, r+1);
      updateNeighbor(p, c-1, r);
      updateNeighbor(p, c, r-1);
      updateNeighbor(p, c+1, r+1);
      updateNeighbor(p, c-1, r+1);
      updateNeighbor(p, c-1, r-1);
      updateNeighbor(p, c+1, r-1);
    }

    function updateNeighbor(addedPt, c, r) {
      var i = colRowToIdx(c, r);
      if (i == -1) return;
      var bestPt = bestPoints[i];
      var dist = bestHeap.getValue(i);
      // don't need to update best point if the newly added point is too far away
      // to have an effect.
      // (about 80% of updates are skipped, typically)
      if (distSq(addedPt, bestPt) < dist * dist) {
        updateBestPointInCell(i);
      }
    }

    function updateBestPointInCell(i) {
      var dist = findBestPointInCell(i);
      bestHeap.updateValue(i, dist);
    }

    // simpler, less performant -- for debugging
    function findBestPointInCell2(idx) {
      var r = idxToRow(idx);
      var c = idxToCol(idx);
      var perSide = 4;
      var maxDist = 0;
      var dist, p, bestPoint;
      for (var i=0; i<perSide; i++) {
        for (var j=0; j<perSide; j++) {
          p = getGridPointInCell(c, r, i, j, perSide);
          dist = findDistanceFromNearbyFeatures(maxDist, p, c, r);
          if (dist > maxDist) {
            maxDist = dist;
            bestPoint = p;
          }
        }
      }
      bestPoints[idx] = bestPoint;
      return maxDist;
    }

    function findBestPointInCell(idx) {
      // Find a point by finding the best-placed center point in a grid of sub-cells,
      // then recursively dividing the winning sub-cell
      var r = idxToRow(idx);
      var c = idxToCol(idx);
      var p = findBestPointInSubCell(c, r, 0, 0, 1);
      bestPoints[idx] = p;
      return p.pop();
    }

    // c, r: location of parent cell in the grid
    // c1, r1: index of sub-cell at the given z-value
    // z: depth of recursive subdivision
    function findBestPointInSubCell(c, r, c1, r1, z) {
      // using a 3x3 grid instead of 2x2 ... testing showed that 2x2 was more
      // likely to misidentify the sub-cell with the optimal point
      var q = 3;
      var perSide = Math.pow(q, z); // number of cell divisions per axis at this z
      var maxDist = 0;
      var c2, r2, p, best, dist;
      for (var i=0; i<q; i++) {
        for (var j=0; j<q; j++) {
          p = getGridPointInCell(c, r, c1 + i, r1 + j, perSide);
          dist = findDistanceFromNearbyFeatures(maxDist, p, c, r);
          if (dist > maxDist) {
            maxDist = dist;
            best = p;
            c2 = i;
            r2 = j;
          }
        }
      }
      if (z == 2) { // stop subdividing the cell at this level
        best.push(maxDist); // return distance as third element
        return best;
      } else {
        return findBestPointInSubCell(c, r, (c1 + c2)*q, (r1 + r2)*q, z + 1);
      }
    }

    function getGridPointInCell(c, r, c2, r2, n) {
      var dx = (c2 + 0.5) / n;
      var dy = (r2 + 0.5) / n;
      var x = (dx + c) / cols * w + x0;
      var y = (dy + r) / rows * h + y0;
      return [x, y];
    }

    // col, row offsets of a cell and its 8 neighbors
    // (ordered to reject unsuitable points faster)
    var nabes = [
      [0, 0], [0, -1], [-1, 0], [1, 0], [0, 1],
      [-1, 1], [1, -1], [-1, -1], [1, 1]
    ];

    function findDistanceFromNearbyFeatures(memo, xy, c, r) {
      var minDistSq = Infinity;
      var offs, c2, r2, distSq, dist;
      for (var i=0; i<9; i++) {
        offs = nabes[i];
        c2 = offs[0];
        r2 = offs[1];
        distSq = distSqFromPointsInCell(xy, c + c2, r + r2);
        if (distSq < memo * memo) {
          // short-circuit rejection of this point (optimization)
          // -- it is closer than a previously tested point
          return 0;
        }
        if (distSq < minDistSq) {
          minDistSq = distSq;
        }
      }
      dist = Math.sqrt(minDistSq);
      // maintain distance from grid edge
      // (this prevents two sets of dots from appearing right along the edges of
      // rectangular polygons).
      dist = Math.min(dist, spaceFromEdge(xy, c, r));
      return dist;
    }

    function spaceFromEdge(xy, c, r) {
      // ignore edges if cell is internal to the grid
      if (c > 0 && r > 0 && c < cols-1 && r < rows-1) return Infinity;
      var x = xy[0], y = xy[1];
      // exaggerating the true distance to prevent a visible gutter from appearing
      // along the borders of shapes with rectangular edges.
      return Math.min(x - x0, x0 + w - x, y - y0, y0 + h - y) * 3;
    }

    function distSqFromPointsInCell(xy, c, r) {
      var minDist = Infinity, dist;
      var idx = colRowToIdx(c, r);
      var points = idx > -1 ? grid[idx] : []; // off the edge
      for (var i=0; i<points.length; i++) {
        dist = distSq(xy, points[i]);
        if (dist < minDist) minDist = dist;
      }
      return minDist;
    }

    function distSq(a, b) {
      var dx = a[0] - b[0];
      var dy = a[1] - b[1];
      return dx * dx + dy * dy;
    }

    function getRandomPointInCell(i) {
      var r = idxToRow(i);
      var c = idxToCol(i);
      var x = (Math.random() + c) / cols * w + x0;
      var y = (Math.random() + r) / rows * h + y0;
      var p = [x, y];
      return p;
    }

    function getRandomPoint() {
      return getRandomPointInCell(getRandomCell());
    }

    function getRandomCell() {
      return Math.floor(Math.random() * cells);
    }

    function pointIsUsable(xy) {
      var c = pointToCol(xy),
          r = pointToRow(xy);
      var collision = testCollision(xy, c, r) ||
        testEdgeCollision(xy, c, r) ||
        testCollision(xy, c+1, r) ||
        testCollision(xy, c, r+1) ||
        testCollision(xy, c-1, r) ||
        testCollision(xy, c, r-1) ||
        testCollision(xy, c+1, r+1) ||
        testCollision(xy, c-1, r+1) ||
        testCollision(xy, c-1, r-1) ||
        testCollision(xy, c+1, r-1);
      return !collision;
    }

    function testEdgeCollision(xy, c, r) {
      return spaceFromEdge(xy, c, r) < dotSpacing;
    }

    function testCollision(xy, c, r) {
      var i = colRowToIdx(c, r);
      if (i == -1) return false;
      var points = grid[i];
      return testPointCollision(xy, points, dotSpacing);
    }

    function testPointCollision(xy, points, dist) {
      var d2 = dist * dist;
      for (var i=0; i<points.length; i++) {
        if (distSq(xy, points[i]) < d2) {
          return true;
        }
      }
      return false;
    }

    function pointToCol(xy) {
      var dx = xy[0] - x0;
      var c = Math.floor(dx / w * cols);
      if (c < 0) c = 0;
      if (c >= cols) c = cols-1;
      return c;
    }

    function pointToRow(xy) {
      var dy = xy[1] - y0;
      var r = Math.floor(dy / h * rows);
      if (r < 0) r = 0;
      if (r >= rows) r = rows-1;
      return r;
    }

    function colRowToIdx(c, r) {
      if (c < 0 || r < 0 || c >= cols || r >= rows) return -1;
      return r * cols + c;
    }

    function pointToIdx(xy) {
      var c = pointToCol(xy);
      var r = pointToRow(xy);
      var idx = r * cols + c;
      return idx;
    }

    function idxToCol(i) {
      return i % cols;
    }

    function idxToRow(i) {
      return Math.floor(i / cols);
    }
  }

  cmd.dots = function(lyr, arcs, opts) {
    requirePolygonLayer(lyr);
    if (!Array.isArray(opts.fields)) {
      stop("Missing required fields parameter");
    }
    if (layerHasNonNullData(lyr)) {
      opts.fields.forEach(function(f, i) {
        requireDataField(lyr, f);
      });
      (opts.copy_fields || []).forEach(function(f) {
        requireDataField(lyr, f);
      });
    }
    // if (!Array.isArray(opts.colors)) {
    //   stop("Missing required colors parameter");
    // }
    if (Array.isArray(opts.colors)) {
      opts.colors.forEach(parseColor); // validate colors
    }

    var records = lyr.data ? lyr.data.getRecords() : [];
    var shapes2 = [];
    var records2 = [];
    lyr.shapes.forEach(function(shp, i) {
      var d = records[i];
      if (!d) return;
      var data =  makeDotsForShape(shp, arcs, d, opts);
      for (var j=0, n=data.shapes.length; j<n; j++) {
        shapes2.push(data.shapes[j]);
        records2.push(data.attributes[j]);
      }
    });

    var lyr2 = {
      geometry_type: 'point',
      shapes: shapes2,
      data: new DataTable(records2)
    };
    setOutputLayerName(lyr2, lyr, null, opts);
    return [lyr2];
  };

  function makeDotsForShape(shp, arcs, rec, opts) {
    var retn = {
      shapes: [],
      attributes:[]
    };
    if (!shp) return retn;
    var counts = opts.fields.map(function(f) {
      var val = rec[f] || 0;
      if (opts.per_dot > 0) {
        val = Math.round(val / opts.per_dot);
      }
      return val;
    });
    var indexes = expandCounts(counts);
    var dots = placeDots(shp, arcs, indexes.length, opts);

    // randomize dot sequence so dots of the same color do not always overlap dots of
    // other colors in dense areas.
    // TODO: instead of random shuffling, interleave dot classes more regularly?
    utils.shuffle(indexes);
    var idx, prevIdx = -1;
    var multipart = !!opts.multipart;
    var coords, p, d;
    for (var i=0; i<dots.length; i++) {
      p = dots[i];
      if (!p) continue;
      idx = indexes[i];
      if (p.length === 3 && opts.debug) {
        idx = p.pop(); // way to debug dot placement visually
      }
      if (!multipart || idx != prevIdx) {
        prevIdx = idx;
        retn.shapes.push(coords = []);
        d = getDataRecord(idx, rec, opts);
        retn.attributes.push(d);
      }
      coords.push(p);
    }
    return retn;
  }

  function placeDots(shp, arcs, n, opts) {
    // split apart multipart polygons for more efficient dot placement
    var polys = shp.length > 1 ? explodePolygon(shp, arcs) : [shp];
    var counts = apportionDotsByArea(polys, arcs, n);
    var dots = [];
    for (var i=0; i<polys.length; i++) {
      dots = dots.concat(placeDotsInPolygon(polys[i], arcs, counts[i], opts));
    }
    return dots;
  }

  function apportionDotsByArea(polys, arcs, n) {
    if (polys.length === 1) return [n];
    var areas = polys.map(function(shp) {
      return geom.getPlanarShapeArea(shp, arcs);
    });
    var remainingArea = utils.sum(areas);
    var remainingDots = n;
    return areas.map(function(area, i) {
      var pct = area / remainingArea;
      var count = Math.round(remainingDots * pct);
      remainingDots -= count;
      remainingArea -= area;
      return count;
    });
  }

  function expandCounts(counts) {
    var arr = [];
    counts.forEach(function(n, i) {
      while (n-- > 0) arr.push(i);
    });
    return arr;
  }

  // i: dot class index
  // d: properties of original polygon
  // opts: dots command options
  function getDataRecord(i, d, opts) {
    var o = {};
    var key = opts.save_as || 'fill';
    var values = opts.colors || opts.values;
    if (values) {
      o[key] = values[i];
      o.r = opts.r || 1.3;
    } else if (opts.r) {
      o.r = opts.r;
    }
    if (opts.copy_fields) {
      for (var j=0; j<opts.copy_fields.length; j++) {
        o[opts.copy_fields[j]] = d[opts.copy_fields[j]];
      }
    }
    return o;
  }

  cmd.drop2 = function(catalog, targets, opts) {
    targets.forEach(function(target) {
      cmd.drop(catalog, target.layers, target.dataset, opts);
    });
  };

  cmd.drop = function(catalog, layers, dataset, opts) {
    var updateArcs = false;

    layers.forEach(function(lyr) {
      var fields = lyr.data && opts.fields;
      var allFields = fields && fieldListContainsAll(fields, lyr.data.getFields());
      var deletion = !fields && !opts.geometry && !opts.holes || allFields && opts.geometry;
      if (opts.geometry) {
        updateArcs |= layerHasPaths(lyr);
        delete lyr.shapes;
        delete lyr.geometry_type;
      }
      if (opts.holes && lyr.geometry_type == 'polygon') {
        deleteHoles(lyr, dataset.arcs);
      }
      if (deletion) {
        catalog.deleteLayer(lyr, dataset);
      } else if (allFields) {
        delete lyr.data;
      } else if (fields) {
        opts.fields.forEach(lyr.data.deleteField, lyr.data);
      }
    });

    if (updateArcs) {
      pruneArcs(dataset);
    }
  };

  cmd.evaluateEachFeature = function(lyr, dataset, exp, opts) {
    var n = getFeatureCount(lyr),
        arcs = dataset.arcs,
        compiled, filter;

    var exprOpts = {
      geojson_editor: expressionUsesGeoJSON(exp) ? getFeatureEditor(lyr, dataset) : null
    };

    // TODO: consider not creating a data table -- not needed if expression only references geometry
    if (n > 0 && !lyr.data) {
      lyr.data = new DataTable(n);
    }
    if (opts && opts.where) {
      filter = compileValueExpression(opts.where, lyr, arcs);
    }
    // 'defs' are now added to the context of all expressions
    // compiled = compileFeatureExpression(exp, lyr, arcs, {context: getStateVar('defs')});
    compiled = compileFeatureExpression(exp, lyr, arcs, exprOpts);
    // call compiled expression with id of each record
    for (var i=0; i<n; i++) {
      if (!filter || filter(i)) {
        compiled(i);
      }
    }

    var replacement = exprOpts.geojson_editor ? exprOpts.geojson_editor.done() : null;
    if (replacement) {
      replaceLayerContents(lyr, dataset, replacement);
    }
  };

  var externalCommands = {};

  cmd.external = function(opts) {
    // TODO: remove duplication with -require command
    var _module, moduleFile, moduleName;
    if (!opts.module) {
      stop('Missing required "module" parameter');
    }
    if (cli.isFile(opts.module)) {
      moduleFile = opts.module;
    } else if (cli.isFile(opts.module + '.js')) {
      moduleFile = opts.module + '.js';
    } else {
      moduleName = opts.module;
    }
    if (moduleFile) {
      moduleFile = require('path').join(process.cwd(), moduleFile);
    }
    try {
      _module = require(moduleFile || moduleName);
      _module(coreAPI);
    } catch(e) {
      // stop(e);
      stop('Unable to load external module:', e.message);
    }
  };

  cmd.registerCommand = function(name, params) {
    var defn = {name: name, options: params.options || []};
    // Add definitions of options common to all commands (TODO: remove duplication)
    defn.options.push({name: 'target'});
    utils.defaults(defn, params);
    validateExternalCommand(defn);
    externalCommands[name] = defn;
  };

  function validateExternalCommand(defn) {
    var targetTypes = ['layer', 'layers'];
    if (typeof defn.command != 'function') {
      stop('Expected "command" parameter function');
    }
    if (!defn.target) {
      stop('Missing required "target" parameter');
    }
  }

  cmd.runExternalCommand = function(cmdOpts, catalog) {
    var name = cmdOpts.name;
    var cmdDefn = externalCommands[name];
    if (!cmdDefn) {
      stop('Unsupported command');
    }
    var targetType = cmdDefn.target;
    var opts = parseExternalCommand(name, cmdDefn, cmdOpts._);
    var targets = catalog.findCommandTargets(opts.target || '*');
    var target = targets[0];
    if (!target) {
      stop('Missing a target');
    }
    if (targetType == 'layer' && (target.layers.length != 1 || targets.length > 1)) {
      stop('This command only supports targeting a single layer');
    }
    if (targets.length > 1) {
      stop("Targetting layers from multiple datasets is not supported");
    }
    if (targetType == 'layer') {
      cmdDefn.command(target.layers[0], target.dataset, opts.options);
    } else if (targetType == 'layers') {
      cmdDefn.command(target.layers, target.dataset, opts.options);
    }
  };

  function parseExternalCommand(name, cmdDefn, tokens) {
    var parser = new CommandParser();
    var cmd = parser.command(name);
    (cmdDefn.options || []).forEach(function(o) {
      cmd.option(o.name, o);
    });
    var parsed = parser.parseArgv(['-' + name].concat(tokens));
    return parsed[0];
  }

  cmd.filterGeom = function(lyr, arcs, opts) {
    if (!layerHasGeometry(lyr)) {
      stop("Layer is missing geometry");
    }
    if (opts.bbox) {
      filterByBoundsIntersection(lyr, arcs, opts);
    }
    cmd.filterFeatures(lyr, arcs, {remove_empty: true, verbose: false});
  };

  function filterByBoundsIntersection(lyr, arcs, opts) {
    var filter = getBoundsIntersectionFilter(opts.bbox, lyr, arcs);
    editShapes(lyr.shapes, filter);
  }

  function getBoundsIntersectionFilter(bbox, lyr, arcs) {
    var bounds = new Bounds(bbox);
    var filter = lyr.geometry_type == 'point' ?
          getPointInBoundsTest(bounds) :
          getPathBoundsIntersectionTest(bounds, arcs);
    return filter;
  }

  function getPointInBoundsTest(bounds) {
    return function(xy) {
      var contains =  bounds.containsPoint(xy[0], xy[1]);
      return contains ? xy : null;
    };
  }

  // V1 too-simple test: bounding-box intersection
  // internal.getPathBoundsIntersectionTest = function(bounds, arcs) {
  //   return function(path) {
  //     return bounds.intersects(arcs.getSimpleShapeBounds(path)) ? path : null;
  //   };
  // };

  function getPathBoundsIntersectionTest(bounds, arcs) {
    var bbox = bounds.toArray(),
      left = bbox[0],
      bottom = bbox[1],
      right = bbox[2],
      top = bbox[3];

    return function(path) {
      // case: bounding boxes don't intersect -> the path doesn't intersect the box
      if (!bounds.intersects(arcs.getSimpleShapeBounds(path))) {
        return null;
      }
      var intersects = false;
      var ax, ay, bx, by;
      var iter = arcs.getShapeIter(path);

      if (iter.hasNext()) {
        ax = iter.x;
        ay = iter.y;
      }
      while (iter.hasNext()) {
        bx = ax;
        by = ay;
        ax = iter.x;
        ay = iter.y;
        if (segmentOutsideBBox(ax, ay, bx, by, left, bottom, right, top)) continue;
        if (segmentInsideBBox(ax, ay, bx, by, left, bottom, right, top)) {
          intersects = true;
          break;
        }
        if (geom.segmentIntersection(left, top, right, top, ax, ay, bx, by) ||
            geom.segmentIntersection(left, bottom, right, bottom, ax, ay, bx, by) ||
            geom.segmentIntersection(left, bottom, left, top, ax, ay, bx, by) ||
            geom.segmentIntersection(right, bottom, right, top, ax, ay, bx, by)) {
          intersects = true;
          break;
        }
      }

      // case: bbox is entirely inside this ring
      if (!intersects && geom.testPointInRing(left, bottom, path, arcs)) {
        intersects = true;
      }
      return intersects ? path : null;
    };
  }

  // Return a function for testing if a shape (path or point) intersects a bounding box
  // TODO: move this function to a different file
  function getBBoxIntersectionTest(bbox, lyr, arcs) {
    var filter = getBoundsIntersectionFilter(bbox, lyr, arcs);
    return function(shapeId) {
      var shp = lyr.shapes[shapeId];
      if (!shp) return false;
      for (var i=0; i<shp.length; i++) {
        if (filter(shp[i])) return true;
      }
      return false;
    };
  }

  // return array of shape ids
  function findShapesIntersectingBBox(bbox, lyr, arcs) {
    var test = getBBoxIntersectionTest(bbox, lyr, arcs);
    var ids = [];
    for (var i=0; i<lyr.shapes.length; i++) {
      if (test(i)) ids.push(i);
    }
    return ids;
  }

  var FilterGeom = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getBBoxIntersectionTest: getBBoxIntersectionTest,
    findShapesIntersectingBBox: findShapesIntersectingBBox
  });

  cmd.filterFeatures = function(lyr, arcs, opts) {
    var records = lyr.data ? lyr.data.getRecords() : null,
        shapes = lyr.shapes || null,
        n = getFeatureCount(lyr),
        filteredShapes = shapes ? [] : null,
        filteredRecords = records ? [] : null,
        filteredLyr = getOutputLayer(lyr, opts),
        invert = !!opts.invert,
        filter;

    if (opts.expression) {
      filter = compileValueExpression(opts.expression, lyr, arcs);
    }

    if (opts.ids) {
      filter = combineFilters(filter, getIdFilter(opts.ids));
    }

    if (opts.remove_empty) {
      filter = combineFilters(filter, getNullGeometryFilter(lyr, arcs));
    }

    if (opts.bbox) {
      filter = combineFilters(filter, getBBoxIntersectionTest(opts.bbox, lyr, arcs));
    }

    if (!filter) {
      stop("Missing a filter criterion");
    }

    utils.repeat(n, function(shapeId) {
      var result = filter(shapeId);
      if (invert) result = !result;
      if (result === true) {
        if (shapes) filteredShapes.push(shapes[shapeId] || null);
        if (records) filteredRecords.push(records[shapeId] || null);
      } else if (result !== false) {
        stop("Expression must return true or false");
      }
    });

    filteredLyr.shapes = filteredShapes;
    filteredLyr.data = filteredRecords ? new DataTable(filteredRecords) : null;
    if (opts.no_replace) {
      // if adding a layer, don't share objects between source and filtered layer
      filteredLyr = copyLayer(filteredLyr);
    }

    if (opts.verbose !== false) {
      message(utils.format('Retained %,d of %,d features', getFeatureCount(filteredLyr), n));
    }

    return filteredLyr;
  };

  // TODO: update filter command to use this function
  function filterLayerInPlace(lyr, filter, invert) {
    var records = lyr.data ? lyr.data.getRecords() : null,
        shapes = lyr.shapes || null,
        n = getFeatureCount(lyr),
        filteredShapes = shapes ? [] : null,
        filteredRecords = records ? [] : null;
    utils.repeat(n, function(shapeId) {
      var result = filter(shapeId);
      if (invert) result = !result;
      if (result === true) {
        if (shapes) filteredShapes.push(shapes[shapeId] || null);
        if (records) filteredRecords.push(records[shapeId] || null);
      } else if (result !== false) {
        stop("Expression must return true or false");
      }
    });
    lyr.shapes = filteredShapes;
    lyr.data = filteredRecords ? new DataTable(filteredRecords) : null;
  }

  function getIdFilter(ids) {
    var set = new Set(ids);
    return function(i) {
      return set.has(i);
    };
  }

  function getNullGeometryFilter(lyr, arcs) {
    var shapes = lyr.shapes;
    if (lyr.geometry_type == 'polygon') {
      return getEmptyPolygonFilter(shapes, arcs);
    }
    return function(i) {return !!shapes[i];};
  }

  function getEmptyPolygonFilter(shapes, arcs) {
    return function(i) {
      var shp = shapes[i];
      return !!shp && geom.getPlanarShapeArea(shapes[i], arcs) > 0;
    };
  }

  function combineFilters(a, b) {
    return (a && b && function(id) {
        return a(id) && b(id);
      }) || a || b;
  }

  cmd.filterIslands = function(lyr, dataset, optsArg) {
    var opts = utils.extend({sliver_control: 0}, optsArg); // no sliver control
    var arcs = dataset.arcs;
    var removed = 0;
    var filter;
    if (lyr.geometry_type != 'polygon') {
      return;
    }
    if (!opts.min_area && !opts.min_vertices) {
      message("Missing a criterion for filtering islands; use min-area or min-vertices");
      return;
    }

    if (opts.min_area) {
      filter = getSliverFilter(lyr, dataset, opts).filter;
    } else {
      filter = getVertexCountTest(opts.min_vertices, arcs);
    }
    removed += filterIslands(lyr, arcs, filter);
    if (opts.remove_empty) {
      cmd.filterFeatures(lyr, arcs, {remove_empty: true, verbose: false});
    }
    message(utils.format("Removed %'d island%s", removed, utils.pluralSuffix(removed)));
  };

  function getVertexCountTest(minVertices, arcs) {
    return function(path) {
      // first and last vertex in ring count as one
      return geom.countVerticesInPath(path, arcs) <= minVertices;
    };
  }

  function filterIslands(lyr, arcs, ringTest) {
    var removed = 0;
    var counts = new Uint8Array(arcs.size());
    countArcsInShapes(lyr.shapes, counts);

    var pathFilter = function(path, i, paths) {
      if (path.length == 1) { // got an island ring
        if (counts[absArcId(path[0])] === 1) { // and not part of a donut hole
          if (!ringTest || ringTest(path)) { // and it meets any filtering criteria
            // and it does not contain any holes itself
            // O(n^2), so testing this last
            if (!ringHasHoles(path, paths, arcs)) {
              removed++;
              return null;
            }
          }
        }
      }
    };
    editShapes(lyr.shapes, pathFilter);
    return removed;
  }

  function ringIntersectsBBox(ring, bbox, arcs) {
    for (var i=0, n=ring.length; i<n; i++) {
      if (arcs.arcIntersectsBBox(absArcId(ring[i]), bbox)) {
        return true;
      }
    }
    return false;
  }

  // Assumes that ring boundaries to not cross
  function ringHasHoles(ring, rings, arcs) {
    var bbox = arcs.getSimpleShapeBounds2(ring);
    var sibling, p;
    for (var i=0, n=rings.length; i<n; i++) {
      sibling = rings[i];
      // try to avoid expensive point-in-ring test
      if (sibling && sibling != ring && ringIntersectsBBox(sibling, bbox, arcs)) {
        p = arcs.getVertex(sibling[0], 0);
        if (geom.testPointInRing(p.x, p.y, ring, arcs)) {
          return true;
        }
      }
    }
    return false;
  }

  cmd.filterIslands2 = function(lyr, dataset, optsArg) {
    var opts = utils.extend({sliver_control: 0}, optsArg); // no sliver control
    var arcs = dataset.arcs;
    var removed = 0;
    var filter;
    if (lyr.geometry_type != 'polygon') {
      return;
    }
    if (!opts.min_area && !opts.min_vertices) {
      message("Missing a criterion for filtering islands; use min-area or min-vertices");
      return;
    }

    if (opts.min_area) {
      filter = getSliverFilter(lyr, dataset, opts).filter;
    } else {
      filter = getVertexCountTest(opts.min_vertices, arcs);
    }
    removed += filterIslands2(lyr, arcs, filter);
    if (opts.remove_empty) {
      cmd.filterFeatures(lyr, arcs, {remove_empty: true, verbose: false});
    }
    message(utils.format("Removed %'d island%s", removed, utils.pluralSuffix(removed)));
  };

  function buildIslandIndex(lyr, arcs, ringTest) {
    // index of all islands
    // (all rings are considered to belong to an island)
    var islandIndex = [];
    // this index maps id of first arc in each ring to
    // an island in islandIndex
    var firstArcIndex = new ArcToIdIndex(arcs);
    var shpId;
    var parts;

    lyr.shapes.forEach(function(shp, i) {
      if (!shp) return;
      shpId = i;
      forEachShapePart(parts, eachRing);

    });

    function eachRing(ring, ringId, shp) {
      var area = geom.getPathArea(ring, arcs);
      var firstArcId = ring[0];
      if (area <= 0) return; // skip holes (really?)
      var islandId = firstArcIndex.getId(firstArcId);
      var islandData;
      if (islandId == -1) {
        islandData = {
          area: 0
        };
        islandId = islandIndex.length;
        islandIndex.push(islandData);
      } else {
        islandData = islandIndex[islandId];
      }
      islandData.area += area;

    }

  }


  function filterIslands2(lyr, arcs, ringTest) {
    var removed = 0;
    var counts = new Uint8Array(arcs.size());
    countArcsInShapes(lyr.shapes, counts);

    var pathFilter = function(path, i, paths) {
      if (path.length == 1) { // got an island ring
        if (counts[absArcId(path[0])] === 1) { // and not part of a donut hole
          if (!ringTest || ringTest(path)) { // and it meets any filtering criteria
            // and it does not contain any holes itself
            // O(n^2), so testing this last
            if (!ringHasHoles(path, paths, arcs)) {
              removed++;
              return null;
            }
          }
        }
      }
    };
    editShapes(lyr.shapes, pathFilter);
    return removed;
  }

  function ArcToIdIndex(arcs) {
    var n = arcs.size();
    var fwdArcIndex = new Int32Array(n);
    var revArcIndex = new Int32Array(n);
    utils.initializeArray(fwdArcIndex, -1);
    utils.initializeArray(revArcIndex, -1);
    this.setId = function(arcId, id) {
      if (arcId >= 0) {
        fwdArcIndex[arcId] = id;
      } else {
        revArcIndex[~arcId] = id;
      }
    };

    this.getId = function(arcId) {
      var i = absArcId(arcId);
      if (i < n === false) return -1;
      return (arcId < 0 ? revArcIndex : fwdArcIndex)[i];
    };
  }

  cmd.filterFields = function(lyr, names) {
    var table = lyr.data;
    names = names || [];
    requireDataFields(table, names);
    if (!table) return;
    // old method: does not set field order e.g. in CSV output files
    // utils.difference(table.getFields(), names).forEach(table.deleteField, table);
    // the below method sets field order of CSV output, and is generally faster
    var map = mapFieldNames(names);
    lyr.data.update(getRecordMapper(map));
  };

  cmd.renameFields = function(lyr, names) {
    var map = mapFieldNames(names);
    requireDataFields(lyr.data, Object.keys(map));
    utils.defaults(map, mapFieldNames(lyr.data.getFields()));
    lyr.data.update(getRecordMapper(map));
  };

  function mapFieldNames(names) {
    return (names || []).reduce(function(memo, str) {
      var parts = str.split('='),
          dest = utils.trimQuotes(parts[0]),
          src = parts.length > 1 ? utils.trimQuotes(parts[1]) : dest;
      if (!src || !dest) stop("Invalid name assignment:", str);
      memo[src] = dest;
      return memo;
    }, {});
  }

  function getRecordMapper(map) {
    var fields = Object.keys(map);
    return function(src) {
      var dest = {}, key;
      for (var i=0, n=fields.length; i<n; i++) {
        key = fields[i];
        dest[map[key]] = src[key];
      }
      return dest;
    };
  }

  // internal.getRecordMapper = function(map) {
  //   var fields = Object.keys(map);
  //   return new Function("rec", "return {" + fields.map(function(name, i) {
  //     var key = JSON.stringify(name);
  //     return key + ": rec[" + key + "]";
  //   }).join(",") + "}");
  // };

  cmd.filterPoints = function(lyr, dataset, opts) {
    requireSinglePointLayer(lyr);
    if (opts.group_interval > 0 === false) {
      stop('Expected a positive group_interval parameter');
    }

    // TODO: remove duplication with mapshaper-alpha-shapes.js
    var alphaFilter = getAlphaDistanceFilter(dataset, opts.group_interval);
    var points = getPointsInLayer(lyr);
    var del = Delaunator.from(points);
    var triangles = del.triangles;
    var index = new Uint8Array(points.length);
    var a, b, c, ai, bi, ci;
    for (var i=0, n=triangles.length; i<n; i+=3) {
      // a, b, c: triangle verticies in CCW order
      ai = triangles[i];
      bi = triangles[i+1];
      ci = triangles[i+2];
      a = points[ai];
      b = points[bi];
      c = points[ci];
      if (alphaFilter(a, b) && alphaFilter(b, c) && alphaFilter(a, c)) {
        index[ai] = 1;
        index[bi] = 1;
        index[ci] = 1;
      }
    }
    filterLayerInPlace(lyr, function(shpId) {
      return index[shpId] == 1;
    });
  };

  function joinPointsToPolygons(targetLyr, arcs, pointLyr, opts) {
    // TODO: option to copy points that can't be joined to a new layer
    var joinFunction = getPolygonToPointsFunction(targetLyr, arcs, pointLyr, opts);
    prepJoinLayers(targetLyr, pointLyr);
    return joinTableToLayer(targetLyr, pointLyr.data, joinFunction, opts);
  }

  function joinPolygonsToPoints(targetLyr, polygonLyr, arcs, opts) {
    var joinFunction = getPointToPolygonsFunction(targetLyr, polygonLyr, arcs, opts);
    prepJoinLayers(targetLyr, polygonLyr);
    return joinTableToLayer(targetLyr, polygonLyr.data, joinFunction, opts);
  }

  function prepJoinLayers(targetLyr, srcLyr) {
    if (!targetLyr.data) {
      // create an empty data table if target layer is missing attributes
      targetLyr.data = new DataTable(targetLyr.shapes.length);
    }
    if (!srcLyr.data) {
      stop("Can't join a layer that is missing attribute data");
    }
  }

  function getPolygonToPointsFunction(polygonLyr, arcs, pointLyr, opts) {
    // Build a reverse lookup table for mapping polygon ids to point ids.
    var joinFunction = getPointToPolygonsFunction(pointLyr, polygonLyr, arcs, opts);
    var index = [];
    var firstMatch = !!opts.first_match; // a point is assigned to the first matching polygon
    var hits, polygonId;
    pointLyr.shapes.forEach(function(shp, pointId) {
      var polygonIds = joinFunction(pointId);
      var n = polygonIds ? polygonIds.length : 0;
      var polygonId;
      for (var i=0; i<n; i++) {
        polygonId = polygonIds[i];
        if (polygonId in index) {
          index[polygonId].push(pointId);
        } else {
          index[polygonId] = [pointId];
        }
        if (firstMatch) break;
      }
    });

    return function(polygonId) {
      return index[polygonId] || null;
    };
  }


  // Returned function gets ids of all polygons that intersect a point (or the first
  //   point of multipoint features). TODO: handle multipoint features properly.
  function getPointToPolygonsFunction(pointLyr, polygonLyr, arcs, opts) {
    var index = new PathIndex(polygonLyr.shapes, arcs),
        points = pointLyr.shapes;

    return function(pointId) {
      var shp = points[pointId],
          polygonIds = shp ? index.findEnclosingShapes(shp[0]) : [];
      return polygonIds.length > 0 ? polygonIds : null;
    };
  }


  // TODO: remove (replaced by getPointToPolygonsFunction())
  function getPointToPolygonFunction(pointLyr, polygonLyr, arcs, opts) {
    var index = new PathIndex(polygonLyr.shapes, arcs),
        points = pointLyr.shapes;

    // @i id of a point feature
    return function(i) {
      var shp = points[i],
          shpId = -1;
      if (shp) {
        // TODO: handle multiple hits
        shpId = index.findEnclosingShape(shp[0]);
      }
      return shpId == -1 ? null : [shpId];
    };
  }

  var PointPolygonJoin = /*#__PURE__*/Object.freeze({
    __proto__: null,
    joinPointsToPolygons: joinPointsToPolygons,
    joinPolygonsToPoints: joinPolygonsToPoints,
    prepJoinLayers: prepJoinLayers,
    getPolygonToPointsFunction: getPolygonToPointsFunction
  });

  // This is a special-purpose function designed to copy a data field from a points
  // layer to a target polygon layer using a spatial join. It tries to create a continuous
  // mosaic of data values, even if some of the polygons are not intersected by points.
  // It is "fuzzy" because it treats locations in the points file as potentially unreliable.
  //
  // A typical use case is joining geocoded address data containing a neighborhood
  // or precinct field to a Census Block file, in preparation to dissolving the
  // blocks into larger polygons.
  //
  cmd.fuzzyJoin = function(polygonLyr, arcs, src, opts) {
    var pointLyr = src ? src.layer : null;
    if (!pointLyr || !layerHasPoints(pointLyr)) {
      stop('Missing a point layer to join from');
    }
    requireDataField(pointLyr, opts.field);
    requirePolygonLayer(polygonLyr);
    if (opts.dedup_points) {
      cmd.uniq(pointLyr, null, {expression: 'this.x + "~" + this.y + "~" + this.properties[' + JSON.stringify(opts.field) + ']', verbose: false});
    }
    fuzzyJoin(polygonLyr, arcs, pointLyr, opts);
  };

  function fuzzyJoin(polygonLyr, arcs, pointLyr, opts) {
    var field = opts.field;
    // using first_match param: don't let a point be assigned to multiple polygons
    var getPointIds = getPolygonToPointsFunction(polygonLyr, arcs, pointLyr, {first_match: true});
    var getFieldValues = getFieldValuesFunction(pointLyr, field);
    var assignedValues = [];
    var countData = [];
    var modeCounts = [];

    // Step one: assign join values to mode value; resolve ties
    polygonLyr.shapes.forEach(function(shp, i) {
      var pointIds = getPointIds(i) || [];
      var values = getFieldValues(pointIds);
      var modeData = getModeData(values, true);
      var modeValue = modeData.margin > 0 ? modeData.modes[0] : null;
      var isTie = modeValue === null && modeData.modes.length > 1;
      if (isTie) {
        // resolve ties by picking between the candidate data values
        // todo: consider using this method to evaluate near-ties as well
        modeValue = resolveFuzzyJoinTie(modeData.modes, pointLyr, pointIds, field, shp, arcs);
      }
      modeCounts[i] = modeData.count || 0;
      // retain count/mode data, to use later for restoring dropouts
      if (opts.no_dropouts) {
        countData.push(modeData);
      }
      assignedValues.push(modeValue);
    });

    insertFieldValues(polygonLyr, 'join-count', modeCounts);
    insertFieldValues(polygonLyr, field, assignedValues);

    // fill in missing values, etc. using the data-fill function
    cmd.dataFill(polygonLyr, arcs,
      {field: field, weight_field: 'join-count', contiguous: opts.contiguous});

    // restore dropouts
    if (opts.no_dropouts) {
      var missingValues = findDropoutValues(polygonLyr, pointLyr, field);
      if (missingValues.length > 0) {
        restoreDropoutValues(polygonLyr, field, missingValues, countData);
      }
    }

  }

  // Returns a function for converting an array of feature ids to an array of values from a given data field.
  function getFieldValuesFunction(lyr, field) {
    var records = lyr.data.getRecords();
    return function getFieldValues(ids) {
      var values = [], rec;
      for (var i=0; i<ids.length; i++) {
        rec = records[ids[i]];
        values.push(rec[field]);
      }
      return values;
    };
  }

  function findDropoutValues(targetLyr, sourceLyr, field) {
    var sourceValues = getUniqFieldValues(sourceLyr.data.getRecords(), field);
    var targetValues = getUniqFieldValues(targetLyr.data.getRecords(), field);
    var missing = utils.difference(sourceValues, targetValues);
    return missing;
  }

  function restoreDropoutValues(lyr, field, missingValues, countData) {
    var records = lyr.data.getRecords();
    var failures = [];
    var restoredIds = [];

    var targetIds = missingValues.map(function(missingValue) {
      var shpId = findDropoutInsertionShape(missingValue, countData);
      if (shpId > -1 && restoredIds.indexOf(shpId) === -1) {
        records[shpId][field] = missingValue;
        restoredIds.push(shpId);
      } else {
        failures.push(missingValue);
      }
    });

    message('Restored', restoredIds.length, 'dropout value' + utils.pluralSuffix(restoredIds.length));

    // TODO: handle different kinds of failure differently:
    // a. values that point-to-polygon failed to match to a polygon
    // b. multiple dropout values are assigned to the same target polygon
    // c. restoring a dropout results in replacing the only instance of another value
    if (failures.length > 0) {
      message('Failed to restore dropout value(s):', failures.join(', '));
    }
  }

  function findDropoutInsertionShape(value, countData) {
    var id = -1;
    var count = 0;
    countData.forEach(function(d, shpId) {
      var i = d.values.indexOf(value);
      var n = i > -1 ? d.counts[i] : 0;
      if (n > count) {
        id = shpId;
        count = n;
      }
    });
    return id;
  }

  // TODO: move to more appropriate file
  function getPointsToPolygonDistance(points, poly, arcs) {
    // todo: handle multipoint geometry (this function will return an invalid distance
    // if the first point in a multipoint feature falls outside the target polygon
    var p = points[0];
    // unsigned distance to nearest polygon boundary
    return geom.getPointToShapeDistance(p[0], p[1], poly, arcs);
  }

  function resolveFuzzyJoinTie(modeValues, pointLyr, pointIds, field, shp, arcs) {
    var weights = modeValues.map(function() {return 0;}); // initialize to 0
    pointIds.forEach(function(pointId) {
      var coords = pointLyr.shapes[pointId];
      var val = pointLyr.data.getRecordAt(pointId)[field];
      var i = modeValues.indexOf(val);
      if (i === -1) return;
      var dist = getPointsToPolygonDistance(coords, shp, arcs);
      weights[i] += dist;
    });
    // use value with the highest weight
    var maxWeight = Math.max.apply(null, weights);
    var maxValue = modeValues[weights.indexOf(maxWeight)];
    return maxValue;
  }

  // Returns number of arcs that were removed
  function editArcs(arcs, onPoint) {
    var nn2 = [],
        xx2 = [],
        yy2 = [],
        errors = 0,
        n;

    arcs.forEach(function(arc, i) {
      editArc(arc, onPoint);
    });
    arcs.updateVertexData(nn2, xx2, yy2);
    return errors;

    function append(p) {
      if (p) {
        xx2.push(p[0]);
        yy2.push(p[1]);
        n++;
      }
    }

    function editArc(arc, cb) {
      var x, y, xp, yp, retn;
      var valid = true;
      var i = 0;
      n = 0;
      while (arc.hasNext()) {
        x = arc.x;
        y = arc.y;
        retn = cb(append, x, y, xp, yp, i++);
        if (retn === false) {
          valid = false;
          // assumes that it's ok for the arc iterator to be interrupted.
          break;
        }
        xp = x;
        yp = y;
      }
      if (valid && n == 1) {
        // only one valid point was added to this arc (invalid)
        // e.g. this could happen during reprojection.
        // making this arc empty
        // error("An invalid arc was created");
        message("An invalid arc was created");
        valid = false;
      }
      if (valid) {
        nn2.push(n);
      } else {
        // remove any points that were added for an invalid arc
        while (n-- > 0) {
          xx2.pop();
          yy2.pop();
        }
        nn2.push(0); // add empty arc (to preserve mapping from paths to arcs)
        errors++;
      }
    }
  }

  function DatasetEditor(dataset) {
    var layers = [];
    var arcs = [];

    this.done = function() {
      dataset.layers = layers;
      if (arcs.length) {
        dataset.arcs = new ArcCollection(arcs);
        buildTopology(dataset);
      }
    };

    this.editLayer = function(lyr, cb) {
      var type = lyr.geometry_type;
      if (dataset.layers.indexOf(lyr) != layers.length) {
        error('Layer was edited out-of-order');
      }
      if (!type) {
        layers.push(lyr);
        return;
      }
      var shapes = lyr.shapes.map(function(shape, shpId) {
        var shape2 = [], retn, input;
        for (var i=0, n=shape ? shape.length : 0; i<n; i++) {
          input = type == 'point' ? shape[i] : idsToCoords(shape[i]);
          retn = cb(input, i, shape);
          if (!Array.isArray(retn)) continue;
          if (type == 'point') {
            shape2.push(retn);
          } else if (type == 'polygon' || type == 'polyline') {
            extendPathShape(shape2, retn || []);
          }
        }
        return shape2.length > 0 ? shape2 : null;
      });
      layers.push(Object.assign(lyr, {shapes: shapes}));
    };

    function extendPathShape(shape, parts) {
      for (var i=0; i<parts.length; i++) {
        shape.push([arcs.length]);
        arcs.push(parts[i]);
      }
    }

    function idsToCoords(ids) {
      var coords = [];
      var iter = dataset.arcs.getShapeIter(ids);
      while (iter.hasNext()) {
        coords.push([iter.x, iter.y]);
      }
      return coords;
    }
  }

  function densifyDataset(dataset, opts) {
    var interval = opts.interval;
    if (interval > 0 === false) {
      error('Expected a valid interval parameter');
    }
    var editor = new DatasetEditor(dataset);
    dataset.layers.forEach(function(lyr) {
      var type = lyr.geometry_type;
      editor.editLayer(lyr, function(coords, i, shape) {
        if (type == 'point') return coords;
        return [densifyPathByInterval(coords, interval)];
      });
    });
    editor.done();
  }


  // Planar densification by an interval
  function densifyPathByInterval(coords, interval, interpolate) {
    if (findMaxPathInterval(coords) < interval) return coords;
    if (!interpolate) {
      interpolate = getIntervalInterpolator(interval);
    }
    var coords2 = [coords[0]], a, b;
    for (var i=1, n=coords.length; i<n; i++) {
      a = coords[i-1];
      b = coords[i];
      if (geom.distance2D(a[0], a[1], b[0], b[1]) > interval + 1e-4) {
        appendArr(coords2, interpolate(a, b));
      }
      coords2.push(b);
    }
    return coords2;
  }

  function getIntervalInterpolator(interval) {
    return function(a, b) {
      var points = [];
      // var rev = a[0] == b[0] ? a[1] > b[1] : a[0] > b[0];
      var dist = geom.distance2D(a[0], a[1], b[0], b[1]);
      var n = Math.round(dist / interval) - 1;
      var dx = (b[0] - a[0]) / (n + 1),
          dy = (b[1] - a[1]) / (n + 1);
      for (var i=1; i<=n; i++) {
        points.push([a[0] + dx * i, a[1] + dy * i]);
      }
      return points;
    };
  }


  // Interpolate the same points regardless of segment direction
  function densifyAntimeridianSegment(a, b, interval) {
    var y1, y2;
    var coords = [];
    var ascending = a[1] < b[1];
    if (a[0] != b[0]) error('Expected an edge segment');
    if (interval > 0 === false) error('Expected a positive interval');
    if (ascending) {
      y1 = a[1];
      y2 = b[1];
    } else {
      y1 = b[1];
      y2 = a[1];
    }
    var y = Math.floor(y1 / interval) * interval + interval;
    while (y < y2) {
      coords.push([a[0], y]);
      y += interval;
    }
    if (!ascending) coords.reverse();
    return coords;
  }


  function appendArr(dest, src) {
    for (var i=0; i<src.length; i++) dest.push(src[i]);
  }

  function findMaxPathInterval(coords) {
    var maxSq = 0, intSq, a, b;
    for (var i=1, n=coords.length; i<n; i++) {
      a = coords[i-1];
      b = coords[i];
      intSq = geom.distanceSq(a[0], a[1], b[0], b[1]);
      if (intSq > maxSq) maxSq = intSq;
    }
    return Math.sqrt(maxSq);
  }

  function densifyUnprojectedPathByDistance(coords, meters) {
    // stub
  }

  function projectAndDensifyArcs(arcs, proj) {
    var interval = getDefaultDensifyInterval(arcs, proj);
    var minIntervalSq = interval * interval * 25;
    var p;
    return editArcs(arcs, onPoint);

    function onPoint(append, lng, lat, prevLng, prevLat, i) {
      var pp = p;
      p = proj(lng, lat);
      if (!p) return false; // signal that current arc contains an error

      // Don't try to densify shorter segments (optimization)
      if (i > 0 && geom.distanceSq(p[0], p[1], pp[0], pp[1]) > minIntervalSq) {
        densifySegment(prevLng, prevLat,  pp[0],  pp[1], lng, lat, p[0], p[1], proj, interval)
          .forEach(append);
      }
      append(p);
    }
  }

  function getDefaultDensifyInterval(arcs, proj) {
    var xy = getAvgSegment2(arcs),
        bb = arcs.getBounds(),
        a = proj(bb.centerX(), bb.centerY()),
        b = proj(bb.centerX() + xy[0], bb.centerY() + xy[1]),
        c = proj(bb.centerX(), bb.ymin), // right center
        d = proj(bb.xmax, bb.centerY()); // bottom center
    // interval A: based on average segment length
    var intervalA = a && b ? geom.distance2D(a[0], a[1], b[0], b[1]) : Infinity;
    // interval B: a fraction of avg bbox side length
    // (added this for bbox densification)
    var intervalB = c && d ? (geom.distance2D(a[0], a[1], c[0], c[1]) +
          geom.distance2D(a[0], a[1], d[0], d[1])) / 5000 : Infinity;
    var interval = Math.min(intervalA, intervalB);
    if (interval == Infinity) {
      error('Densification error');
    }
    return interval;
  }

  // Interpolate points into a projected line segment if needed to prevent large
  //   deviations from path of original unprojected segment.
  // @points (optional) array of accumulated points
  function densifySegment(lng0, lat0, x0, y0, lng2, lat2, x2, y2, proj, interval, points) {
    // Find midpoint between two endpoints and project it (assumes longitude does
    // not wrap). TODO Consider bisecting along great circle path -- although this
    // would not be good for boundaries that follow line of constant latitude.
    var lng1 = (lng0 + lng2) / 2,
        lat1 = (lat0 + lat2) / 2,
        p = proj(lng1, lat1),
        distSq;
    if (!p) return; // TODO: consider if this is adequate for handling proj. errors
    distSq = geom.pointSegDistSq2(p[0], p[1], x0, y0, x2, y2); // sq displacement
    points = points || [];
    // Bisect current segment if the projected midpoint deviates from original
    //   segment by more than the @interval parameter.
    //   ... but don't bisect very small segments to prevent infinite recursion
    //   (e.g. if projection function is discontinuous)
    if (distSq > interval * interval * 0.25 && geom.distance2D(lng0, lat0, lng2, lat2) > 0.01) {
      densifySegment(lng0, lat0, x0, y0, lng1, lat1, p[0], p[1], proj, interval, points);
      points.push(p);
      densifySegment(lng1, lat1, p[0], p[1], lng2, lat2, x2, y2, proj, interval, points);
    }
    return points;
  }

  // Create rectangles around each feature in a layer
  cmd.rectangles = function(targetLyr, targetDataset, opts) {
    if (!layerHasGeometry(targetLyr)) {
      stop("Layer is missing geometric shapes");
    }
    var crs = getDatasetCRS(targetDataset);
    var records = targetLyr.data ? targetLyr.data.getRecords() : null;
    var geometries = targetLyr.shapes.map(function(shp) {
      var bounds = targetLyr.geometry_type == 'point' ?
        getPointFeatureBounds(shp) : targetDataset.arcs.getMultiShapeBounds(shp);
      bounds = applyRectangleOptions(bounds, crs, opts);
      if (!bounds) return null;
      return convertBboxToGeoJSON(bounds.toArray(), opts);
    });
    var geojson = {
      type: 'FeatureCollection',
      features: geometries.map(function(geom, i) {
        var rec = records && records[i] || null;
        if (rec && opts.no_replace) {
          rec = utils.extend({}, rec); // make a copy
        }
        return {
          type: 'Feature',
          properties: rec,
          geometry: geom
        };
      })
    };
    var dataset = importGeoJSON(geojson, {});
    var outputLayers = mergeDatasetsIntoDataset(targetDataset, [dataset]);
    setOutputLayerName(outputLayers[0], targetLyr, null, opts);
    return outputLayers;
  };

  // Create rectangles around one or more target layers
  //
  cmd.rectangle2 = function(target, opts) {
    var datasets = target.layers.map(function(lyr) {
      var dataset = cmd.rectangle({layer: lyr, dataset: target.dataset}, opts);
      setOutputLayerName(dataset.layers[0], lyr, null, opts);
      if (!opts.no_replace) {
        dataset.layers[0].name = lyr.name || dataset.layers[0].name;
      }
      return dataset;
    });
    return mergeDatasetsIntoDataset(target.dataset, datasets);
  };

  cmd.rectangle = function(source, opts) {
    var offsets, bounds, crs, coords, sourceInfo;
    if (source) {
      bounds = getLayerBounds(source.layer, source.dataset.arcs);
      sourceInfo = source.dataset.info;
      crs = getDatasetCRS(source.dataset);
    } else if (opts.bbox) {
      bounds = new Bounds(opts.bbox);
      crs = getCRS('wgs84');
    }
    bounds = bounds && applyRectangleOptions(bounds, crs, opts);
    if (!bounds || !bounds.hasBounds()) {
      stop('Missing rectangle extent');
    }
    var geojson = convertBboxToGeoJSON(bounds.toArray(), opts);
    var dataset = importGeoJSON(geojson, {});
    dataset.layers[0].name = opts.name || 'rectangle';
    if (sourceInfo) {
      setDatasetCRS(dataset, sourceInfo);
    }
    return dataset;
  };

  function applyRectangleOptions(bounds, crs, opts) {
    var isGeoBox = probablyDecimalDegreeBounds(bounds);
    if (opts.offset) {
      bounds = applyBoundsOffset(opts.offset, bounds, crs);
    }
    if (bounds.area() > 0 === false) return null;
    if (opts.aspect_ratio) {
      bounds = applyAspectRatio(opts.aspect_ratio, bounds);
    }
    if (isGeoBox) {
      bounds = clampToWorldBounds(bounds);
    }
    return bounds;
  }

  // opt: aspect ratio as a single number or a range (e.g. "1,2");
  function applyAspectRatio(opt, bounds) {
    var range = String(opt).split(',').map(parseFloat),
      aspectRatio = bounds.width() / bounds.height(),
      min, max; // min is height limit, max is width limit
    if (range.length == 1) {
      range.push(range[0]);
    } else if (range[0] > range[1]) {
      range.reverse();
    }
    min = range[0];
    max = range[1];
    if (!min && !max) return bounds;
    if (!min) min = -Infinity;
    if (!max) max = Infinity;
    if (aspectRatio < min) {
      bounds.fillOut(min);
    } else if (aspectRatio > max) {
      bounds.fillOut(max);
    }
    return bounds;
  }

  function applyBoundsOffset(offsetOpt, bounds, crs) {
    var offsets = convertFourSides(offsetOpt, crs, bounds);
    bounds.padBounds(offsets[0], offsets[1], offsets[2], offsets[3]);
    return bounds;
  }

  function convertBboxToGeoJSON(bbox, optsArg) {
    var opts = optsArg || {};
    var coords = [[bbox[0], bbox[1]], [bbox[0], bbox[3]], [bbox[2], bbox[3]],
        [bbox[2], bbox[1]], [bbox[0], bbox[1]]];
    if (opts.interval > 0) {
      coords = densifyPathByInterval(coords, opts.interval);
    }
    return opts.geometry_type == 'polyline' ? {
      type: 'LineString',
      coordinates: coords
    } : {
      type: 'Polygon',
      coordinates: [coords]
    };
  }

  var Rectangle = /*#__PURE__*/Object.freeze({
    __proto__: null,
    applyAspectRatio: applyAspectRatio,
    convertBboxToGeoJSON: convertBboxToGeoJSON
  });

  function getSemiMinorAxis(P) {
    return P.a * Math.sqrt(1 - (P.es || 0));
  }

  function getCircleRadiusFromAngle(P, angle) {
    // Using semi-minor axis radius, to prevent overflowing projection bounds
    // when clipping up to the edge of the projectable area
    // TODO: improve (this just gives a safe minimum distance, not the best distance)
    // TODO: modify point buffer function to use angle + ellipsoidal geometry
    return angle * Math.PI / 180 * getSemiMinorAxis(P);
  }

  function getCrsSlug(P) {
    return P.params.proj.param; // kludge
  }

  // 'normal' = the projection is aligned to the Earth's axis
  // (i.e. it has a normal aspect)
  function isRotatedNormalProjection(P) {
    return isAxisAligned(P) && P.lam0 !== 0;
  }

  // Projection is vertically aligned to earth's axis
  function isAxisAligned(P) {
    // TODO: consider projections that may or may not be aligned,
    // depending on parameters
    if (inList(P, 'cassini,gnom,bertin1953,chamb,ob_tran,tpeqd,healpix,rhealpix,' +
      'ocea,omerc,tmerc,etmerc')) {
      return false;
    }
    if (isAzimuthal(P)) {
      return false;
    }
    return true;
  }

  function getBoundingMeridian(P) {
    if (P.lam0 === 0) return 180;
    return getAntimeridian(P.lam0 * 180 / Math.PI);
  }

  // Are the projection's bounds meridians?
  function isMeridianBounded(P) {
    // TODO: add azimuthal projection with lat0 == 0
    // if (inList(P, 'ortho') && P.lam0 === 0) return true;
    return isAxisAligned(P); // TODO: look for exceptions to this
  }

  // Is the projection bounded by parallels or polar lines?
  function isParallelBounded(P) {
    // TODO: add polar azimuthal projections
    // TODO: reject world projections that do not have polar lines
    return isAxisAligned(P);
  }


  function isConic(P) {
    return inList(P, 'aea,bonne,eqdc,lcc,poly,euler,murd1,murd2,murd3,pconic,tissot,vitk1');
  }

  function isAzimuthal(P) {
    return inList(P,
      'aeqd,gnom,laea,mil_os,lee_os,gs48,alsk,gs50,nsper,tpers,ortho,qsc,stere,ups,sterea');
  }

  function inList(P, str) {
    return str.split(',').includes(getCrsSlug(P));
  }

  // based on d3 implementation of Euler-angle rotation
  // https://github.com/d3/d3-geo/blob/master/src/rotation.js
  // license: https://github.com/d3/d3-geo/blob/master/LICENSE

  function rotateDatasetCoords(dataset, rotation, inv) {
    var proj = getRotationFunction(rotation, inv);
    dataset.layers.filter(layerHasPoints).forEach(function(lyr) {
      projectPointLayer(lyr, proj);
    });
    if (dataset.arcs) {
      projectArcs(dataset.arcs, proj);
    }
  }

  function getRotationFunction(rotation, inv) {
    var f = getRotationFunction2(rotation, inv);
    return function(lng, lat) {
      return f([lng, lat]);
    };
  }

  function getRotationFunction2(rotation, inv) {
    var a = (rotation[0] || 0) * D2R,
        b = (rotation[1] || 0) * D2R,
        c = (rotation[2] || 0) * D2R;
    return function(p) {
      p[0] *= D2R;
      p[1] *= D2R;
      var rotate = inv ? rotatePointInv : rotatePoint;
      rotate(p, a, b, c);
      p[0] *= R2D;
      p[1] *= R2D;
      return p;
    };
  }

  function rotatePoint(p, deltaLam, deltaPhi, deltaGam) {
    if (deltaLam != 0) rotateLambda(p, deltaLam);
    if (deltaPhi !== 0 || deltaGam !== 0) {
      rotatePhiGamma(p, deltaPhi, deltaGam, false);
    }
    return p;
  }

  function rotatePointInv(p, deltaLam, deltaPhi, deltaGam) {
    if (deltaPhi !== 0 || deltaGam !== 0) {
      rotatePhiGamma(p, deltaPhi, deltaGam, true);
    }
    if (deltaLam != 0) rotateLambda(p, -deltaLam);
    return p;
  }

  function rotateLambda(p, deltaLam) {
    var lam = p[0] + deltaLam;
    if (lam > Math.PI) lam -= 2 * Math.PI;
    else if (lam < -Math.PI) lam += 2 * Math.PI;
    p[0] = lam;
  }

  function rotatePhiGamma(p, deltaPhi, deltaGam, inv) {
    var cosDeltaPhi = Math.cos(deltaPhi),
        sinDeltaPhi = Math.sin(deltaPhi),
        cosDeltaGam = Math.cos(deltaGam),
        sinDeltaGam = Math.sin(deltaGam),
        cosPhi = Math.cos(p[1]),
        x = Math.cos(p[0]) * cosPhi,
        y = Math.sin(p[0]) * cosPhi,
        z = Math.sin(p[1]),
        k;
    if (inv) {
      k = z * cosDeltaGam - y * sinDeltaGam;
      p[0] = Math.atan2(y * cosDeltaGam + z * sinDeltaGam, x * cosDeltaPhi + k * sinDeltaPhi);
      p[1] = Math.asin(k * cosDeltaPhi - x * sinDeltaPhi);
    } else {
      k = z * cosDeltaPhi + x * sinDeltaPhi;
      p[0] = Math.atan2(y * cosDeltaGam - k * sinDeltaGam, x * cosDeltaPhi - z * sinDeltaPhi);
      p[1] = Math.asin(k * cosDeltaGam + y * sinDeltaGam);
    }
  }

  cmd.rotate = rotateDataset;

  function rotateDataset(dataset, opts) {
    if (!isLatLngCRS(getDatasetCRS(dataset))) {
      stop('Command requires a lat-long dataset.');
    }
    if (!Array.isArray(opts.rotation) || !opts.rotation.length) {
      stop('Invalid rotation parameter');
    }
    var rotatePoint = getRotationFunction2(opts.rotation, opts.invert);
    var editor = new DatasetEditor(dataset);
    if (dataset.arcs) {
      dataset.arcs.flatten();
    }

    dataset.layers.forEach(function(lyr) {
      var type = lyr.geometry_type;
      editor.editLayer(lyr, getGeometryRotator(type, rotatePoint, opts));
    });
    editor.done();
    if (!opts.debug) {
      buildTopology(dataset);
      cleanProjectedLayers(dataset);
    }
  }

  function getGeometryRotator(layerType, rotatePoint, opts) {
    var rings;
    if (layerType == 'point') {
      return function(coords) {
        coords.forEach(rotatePoint);
        return coords;
      };
    }
    if (layerType == 'polyline') {
      return function(coords) {
        coords = densifyPathByInterval(coords, 0.5);
        coords.forEach(rotatePoint);
        return removePolylineCrosses(coords);
      };
    }
    if (layerType == 'polygon') {
      return function(coords, i, shape) {
        if (isWholeWorld(coords)) {
          coords = densifyPathByInterval(coords, 0.5);
        } else {
          coords.forEach(snapToEdge);
          coords = removeCutSegments(coords);
          coords = densifyPathByInterval(coords, 0.5, getInterpolator(0.5));
          coords.forEach(rotatePoint);
          // coords.forEach(snapToEdge);
        }
        if (i === 0) { // first part
          rings = [];
        }
        if (coords.length < 4) {
          debug('Short ring', coords);
          return;
        }
        if (!samePoint(coords[0], lastEl(coords))) {
          error('Open polygon ring');
        }
        rings.push(coords); // accumulate rings
        if (i == shape.length - 1) { // last part
          return opts.debug ? rings : removePolygonCrosses(rings);
        }
      };
    }
    return null; // assume layer has no geometry -- callback should not be called
  }

  function getInterpolator(interval) {
    var interpolate = getIntervalInterpolator(interval);
    return function(a, b) {
      var points;
      if (onPole(a) || onPole(b)) {
        points = [];
      } else if (isEdgeSegment(a, b)) {
        points = densifyAntimeridianSegment(a, b, interval);
      } else if (segmentCrossesAntimeridian(a, b)) {
        // TODO: interpolate up to antimeridian?
        points = [];
      } else {
        points = interpolate(a, b);
      }
      return points;
    };
  }

  cmd.lines = function(lyr, dataset, opts) {
    opts = opts || {};
    if (opts.callouts) {
      requirePointLayer(lyr);
      return pointsToCallouts(lyr, dataset, opts);
    } else if (lyr.geometry_type == 'point') {
      return pointsToLines(lyr, dataset, opts);
    } else if (opts.segments) {
      return [convertShapesToSegments(lyr, dataset)];
    } else if (opts.arcs) {
      return [convertShapesToArcs(lyr, dataset)];
    } else if (lyr.geometry_type == 'polygon') {
      return polygonsToLines(lyr, dataset.arcs, opts);
    } else {
      requirePolygonLayer(lyr, "Command requires a polygon or point layer");
    }
  };

  function convertShapesToArcs(lyr, dataset) {
    var arcs = dataset.arcs;
    var test = getArcPresenceTest(lyr.shapes, arcs);
    var records = [];
    var shapes = [];
    for (var i=0, n=arcs.size(); i<n; i++) {
      if (!test(i)) continue;
      records.push({arcid: i});
      shapes.push([[i]]);
    }
    return {
      geometry_type: 'polyline',
      data: new DataTable(records),
      shapes: shapes
    };
  }

  function convertShapesToSegments(lyr, dataset) {
    var arcs = dataset.arcs;
    var features = [];
    var geojson = {type: 'FeatureCollection', features: []};
    var test = getArcPresenceTest(lyr.shapes, arcs);
    var arcId;
    for (var i=0, n=arcs.size(); i<n; i++) {
      arcId = i;
      if (!test(arcId)) continue;
      arcs.forEachArcSegment(arcId, onSeg);
    }
    function onSeg(i1, i2, xx, yy) {
      var a = xx[i1],
          b = yy[i1],
          c = xx[i2],
          d = yy[i2];
      geojson.features.push({
        type: 'Feature',
        properties: {arc: arcId, i1: i1, i2: i2, x1: a, y1: b, x2: c, y2: d},
        geometry: {type: 'LineString', coordinates: [[a, b], [c, d]]}
      });
    }
    var merged = mergeDatasets([dataset, importGeoJSON(geojson, {})]);
    dataset.arcs = merged.arcs;
    // buildTopology(dataset);
    return merged.layers.pop();
  }

  function pointsToLines(lyr, dataset, opts) {
    var geojson = opts.groupby ?
      groupedPointsToLineGeoJSON(lyr, opts.groupby, opts) :
      pointShapesToLineGeometry(lyr.shapes); // no grouping: return single line with no attributes
    var dataset2 = importGeoJSON(geojson);
    var outputLayers = mergeDatasetsIntoDataset(dataset, [dataset2]);
    // if (!opts.no_replace) {
    //   outputLayers[0].name = lyr.name || outputLayers[0].name;
    // }
    setOutputLayerName(outputLayers[0], lyr, null, opts);
    return outputLayers;
  }

  function pointsToCallouts(lyr, dataset, opts) {
    var records = lyr.data ? lyr.data.getRecords() : null;
    var calloutLen = getLayerBounds(lyr).width() / 50;
    var pointToSegment = function(p) {
      return [p, [p[0] + calloutLen, p[1]]];
    };
    var geojson = {
      type: 'FeatureCollection',
      features: lyr.shapes.map(function(shp, i) {
        return {
          type: 'Feature',
          properties: records ? records[i] : null,
          geometry: {
            type: 'MultiLineString',
            coordinates: shp.map(pointToSegment)
          }
        };
      })
    };
    var dataset2 = importGeoJSON(geojson);
    var outputLayers = mergeDatasetsIntoDataset(dataset, [dataset2]);
    setOutputLayerName(outputLayers[0], lyr.name, null, opts);
    return outputLayers;
  }

  function groupedPointsToLineGeoJSON(lyr, field, opts) {
    var groups = [];
    var getGroupId = getCategoryClassifier([field], lyr.data);
    var dataOpts = utils.defaults({fields: [field]}, opts);
    var records = aggregateDataRecords(lyr.data.getRecords(), getGroupId, dataOpts);
    var features;
    lyr.shapes.forEach(function(shape, i) {
      var groupId = getGroupId(i);
      if (groupId in groups === false) {
        groups[groupId] = [];
      }
      groups[groupId].push(shape);
    });
    features = groups.map(function(shapes, i) {
      return {
        type: 'Feature',
        properties: records[i],
        geometry: shapes.length > 1 ? pointShapesToLineGeometry(shapes) : null
      };
    });
    return {
      type: 'FeatureCollection',
      features: features
    };
  }

  // TOOD: automatically convert rings into separate shape parts
  function pointShapesToLineGeometry(shapes) {
    var coords = [];
    forEachPoint(shapes, function(p) {
      coords.push(p.concat());
    });
    return {type: 'LineString', coordinates: coords};
  }

  function polygonsToLines(lyr, arcs, opts) {
    opts = opts || {};
    var filter = opts.where ? compileFeaturePairFilterExpression(opts.where, lyr, arcs) : null,
        decorateRecord = opts.each ? getLineRecordDecorator(opts.each, lyr, arcs) : null,
        classifier = getArcClassifier(lyr.shapes, arcs, {filter: filter}),
        fields = utils.isArray(opts.fields) ? opts.fields : [],
        rankId = 0,
        shapes = [],
        records = [],
        outputLyr;

    if (fields.length > 0 && !lyr.data) {
      stop("Missing a data table");
    }

    addLines(extractOuterLines(lyr.shapes, classifier), 'outer');

    fields.forEach(function(field) {
      var data = lyr.data.getRecords();
      var key = function(a, b) {
        var arec = data[a];
        var brec = data[b];
        var aval, bval;
        if (!arec || !brec || arec[field] === brec[field]) {
          return null;
        }
        return a + '-' + b;
      };
      requireDataField(lyr, field);
      addLines(extractLines(lyr.shapes, classifier(key)), field);
    });

    addLines(extractInnerLines(lyr.shapes, classifier), 'inner');
    outputLyr = createLineLayer(shapes, records);
    setOutputLayerName(outputLyr, lyr, null, opts);
    return outputLyr;

    function addLines(lines, typeName) {
      var attr = lines.map(function(shp, i) {
        var rec = {RANK: rankId, TYPE: typeName};
        if (decorateRecord) decorateRecord(rec, shp);
        return rec;
      });
      shapes = utils.merge(lines, shapes);
      records = utils.merge(attr, records);
      rankId++;
    }
  }


  // kludgy way to implement each= option of -lines command
  function getLineRecordDecorator(exp, lyr, arcs) {
    // repurpose arc classifier function to convert arc ids to shape ids of original polygons
    var procArcId = getArcClassifier(lyr.shapes, arcs)(procShapeIds);
    var compiled = compileFeaturePairExpression(exp, lyr, arcs);
    var tmp;

    function procShapeIds(shpA, shpB) {
      compiled(shpA, shpB, tmp);
    }

    return function(rec, shp) {
      tmp = rec;
      procArcId(shp[0][0]);
      return rec;
    };
  }


  function createLineLayer(lines, records) {
    return {
      geometry_type: 'polyline',
      shapes: lines,
      data: records ? new DataTable(records) : null
    };
  }

  function extractOuterLines(shapes, classifier) {
    var key = function(a, b) {return b == -1 ? String(a) : null;};
    return extractLines(shapes, classifier(key));
  }

  function extractInnerLines(shapes, classifier) {
    var key = function(a, b) {return b > -1 ? a + '-' + b : null;};
    return extractLines(shapes, classifier(key));
  }

  function extractLines(shapes, classify) {
    var lines = [],
        index = {},
        prev = null,
        prevKey = null,
        part;

    traversePaths(shapes, onArc, onPart);

    function onArc(o) {
      var arcId = o.arcId,
          key = classify(arcId),
          isContinuation, line;
      if (!!key) {
        line = key in index ? index[key] : null;
        isContinuation = key == prevKey && o.shapeId == prev.shapeId && o.partId == prev.partId;
        if (!line) {
          line = [[arcId]]; // new shape
          index[key] = line;
          lines.push(line);
        } else if (isContinuation) {
          line[line.length-1].push(arcId); // extending prev part
        } else {
          line.push([arcId]); // new part
        }

        // if extracted line is split across endpoint of original polygon ring, then merge
        if (o.i == part.arcs.length - 1 &&  // this is last arc in ring
            line.length > 1 &&              // extracted line has more than one part
            line[0][0] == part.arcs[0]) {   // first arc of first extracted part is first arc in ring
          line[0] = line.pop().concat(line[0]);
        }
      }
      prev = o;
      prevKey = key;
    }

    function onPart(o) {
      part = o;
    }

    return lines;
  }

  var Lines = /*#__PURE__*/Object.freeze({
    __proto__: null,
    polygonsToLines: polygonsToLines,
    createLineLayer: createLineLayer,
    extractInnerLines: extractInnerLines
  });

  function getClippingDataset(src, dest, opts) {
    return getUnprojectedBoundingPolygon(src, dest, opts);
  }

  function getUnprojectedBoundingPolygon(src, dest, opts) {
    var dataset;
    if (isCircleClippedProjection(dest) || opts.clip_angle || dest.clip_angle) {
      dataset = getBoundingCircle(src, dest, opts);
    } else if (isRectangleClippedProjection(dest) || opts.clip_bbox) {
      dataset = getBoundingRectangle(dest, opts);
    }
    return dataset || null;
  }

  // If possible, return a lat-long bbox that can be used to
  // test whether data exceeds the projection bounds ands needs to be clipped
  // export function getInnerBoundingBBox(P, opts) {
  //   var bbox = null;
  //   if (opts.clip_bbox) {
  //     bbox = opts.clip_bbox;
  //   } else if (isRectangleClippedProjection(dest)) {
  //     bbox
  //   }
  //   return bbox;
  // }

  // Return projected polygon extent of both clipped and unclipped projections
  function getPolygonDataset$1(src, dest, opts) {
    // use clipping area if projection is clipped
    var dataset = getUnprojectedBoundingPolygon(src, dest, opts);
    if (!dataset) {
      // use entire world if projection is not clipped
      dataset = getBoundingRectangle(dest, {clip_bbox: [-180,-90,180,90]});
    }
    projectDataset(dataset, src, dest, {no_clip: false, quiet: true});
    return dataset;
  }

  // Return projected outline of clipped projections
  function getOutlineDataset(src, dest, opts) {
    var dataset = getUnprojectedBoundingPolygon(src, dest, opts);
    if (dataset) {
      // project, with cutting & cleanup
      projectDataset(dataset, src, dest, {no_clip: false, quiet: true});
      dataset.layers[0].geometry_type = 'polyline';
    }
    return dataset || null;
  }

  function getBoundingRectangle(dest, opts) {
    var bbox = opts.clip_bbox || getDefaultClipBBox(dest);
    var rotation = getRotationParams(dest);
    if (!bbox) error('Missing expected clip bbox.');
    opts = Object.assign({interval: 0.5}, opts); // make sure edges can curve
    var geojson = convertBboxToGeoJSON(bbox, opts);
    var dataset = importGeoJSON(geojson);
    if (rotation) {
      rotateDataset(dataset, {rotation: rotation, invert: true});
    }
    return dataset;
  }

  function getBoundingCircle(src, dest, opts) {
    var angle = opts.clip_angle || dest.clip_angle || getDefaultClipAngle(dest);
    if (!angle) return null;
    verbose(`Using clip angle of ${ +angle.toFixed(2) } degrees`);
    var dist = getClippingRadius(src, angle);
    var cp = getProjCenter(dest);
    // kludge: attach the clipping angle to the CRS, so subsequent commands
    // (e.g. -graticule) can create an outline
    dest.clip_angle = angle;
    var geojson = getCircleGeoJSON(cp, dist, null, opts);
    return importGeoJSON(geojson);
  }

  function isRectangleClippedProjection(P) {
    // TODO: add tmerc, etmerc, ...
    // return inList(P, 'tmerc,utm,etmerc,merc,bertin1953');
    return inList(P, 'merc,bertin1953');
  }

  function getDefaultClipBBox(P) {
    var e = 1e-3;
    var slug = getCrsSlug(P);
    var tmerc = [-179,-90,179,90];
    var bbox = {
      // longlat: [-180, -90, 180, 90],
      tmerc: tmerc,
      utm: tmerc,
      etmerc: tmerc,
      merc: [-180, -89, 180, 89],
      lcc: [-180, -89, 180, 89],
      bertin1953: [-180 + e, -90 + e, 180 - e, 90 - e]
    }[slug];
    return bbox;
  }

  function getClampBBox(P) {
    var bbox;
    if (inList(P, 'merc,lcc')) {
      bbox = getDefaultClipBBox(P);
    }
    return bbox;
  }

  function isCircleClippedProjection(P) {
    return inList(P, 'stere,sterea,ups,ortho,gnom,laea,nsper,tpers');
  }

  function getPerspectiveClipAngle(P) {
    var h = parseFloat(P.params.h.param);
    if (!h || h < 0) {
      return 0;
    }
    var theta = Math.acos(P.a / (P.a + h)) * 180 / Math.PI;
    theta *= 0.995; // reducing a bit to avoid out-of-range errors
    return theta;
  }

  function getDefaultClipAngle(P) {
    var slug = getCrsSlug(P);
    if (slug == 'nsper') return getPerspectiveClipAngle(P);
    if (slug == 'tpers') {
      message('Automatic clipping is not supported for the Tilted Perspective projection');
      return 0;
    }
    return {
      gnom: 60,
      laea: 179,
      ortho: 89.9, // TODO: investigate projection errors closer to 90
      stere: 142,
      sterea: 142,
      ups: 10.5 // TODO: should be 6.5 deg at north pole
    }[slug] || 0;
  }

  function getRotationParams(P) {
    var slug = getCrsSlug(P);
    if (slug == 'bertin1953') return [-16.5,-42];
    if (slug == 'tmerc' || slug == 'utm' || slug == 'etmerc') {
      if (P.lam0 !== 0) return [P.lam0 * 180 / Math.PI];
    }
    return null;
  }


  function getProjCenter(P) {
    var rtod = 180 / Math.PI;
    return [P.lam0 * rtod, P.phi0 * rtod];
  }

  // Convert a clip angle to a distance in meters
  function getClippingRadius(P, angle) {
    return getCircleRadiusFromAngle(P, angle);
  }

  function preProjectionClip(dataset, src, dest, opts) {
    if (!isLatLngCRS(src) || opts.no_clip) return false;
    // rotated normal-aspect projections can generally have a thin slice removed
    // from the rotated antimeridian, instead of clipping them
    var cut = insertPreProjectionCuts(dataset, src, dest);
    var clipped = false;
    var clipData;
    // experimental -- we can probably get away with just clamping some CRSs that
    // have a slightly restricted coord range (e.g. Mercator), instead of doing
    // a clip (more expensive)
    var clampBox = getClampBBox(dest);
    if (clampBox) {
      clampDataset(dataset, clampBox);
    } else {
      clipData = getClippingDataset(src, dest, opts);
    }
    if (clipData) {
      // TODO: don't bother to clip content that is fully within
      // the clipping shape. But how to tell?
      clipLayersInPlace(dataset.layers, clipData, dataset, 'clip');
      clipped = true;
    }
    return cut || clipped;
  }


  function insertPreProjectionCuts(dataset, src, dest) {
    var antimeridian = getAntimeridian(dest.lam0 * 180 / Math.PI);
    // currently only supports adding a single vertical cut to earth axis-aligned
    // map projections centered on a non-zero longitude.
    // TODO: need a more sophisticated kind of cutting to handle other cases
    if (dataset.arcs && isRotatedNormalProjection(dest) && datasetCrossesLon(dataset, antimeridian)) {
      insertVerticalCut(dataset, antimeridian);
      dissolveArcs(dataset);
      return true;
    }
    return false;
  }

  function clampDataset(dataset, bbox) {
    transformPoints(dataset, function(x, y) {
      return [utils.clamp(x, bbox[0], bbox[2]), utils.clamp(y, bbox[1], bbox[3])];
    });
  }

  function datasetCrossesLon(dataset, lon) {
    var crosses = 0;
    dataset.arcs.forEachSegment(function(i, j, xx, yy) {
      var ax = xx[i],
          bx = xx[j];
      if (ax <= lon && bx >= lon || ax >= lon && bx <= lon) crosses++;
    });
    return crosses > 0;
  }

  function insertVerticalCut(dataset, lon) {
    var pathLayers = dataset.layers.filter(layerHasPaths);
    if (pathLayers.length === 0) return;
    var e = 1e-8;
    var bbox = [lon-e, -91, lon+e, 91];
    // densify (so cut line can curve, e.g. Cupola projection)
    var geojson = convertBboxToGeoJSON(bbox, {interval: 0.5});
    var clip = importGeoJSON(geojson);
    clipLayersInPlace(pathLayers, clip, dataset, 'erase');
  }

  // Converts a Proj.4 projection name (e.g. lcc, tmerc) to a Proj.4 string
  // by picking parameters that are appropriate to the extent of the dataset
  // being projected (e.g. standard parallels, longitude of origin)
  // Works for lcc, aea, tmerc, etc.
  // TODO: add more projections
  //
  function expandProjDefn(str, dataset) {
    var mproj = require('mproj');
    var proj4, params, bbox, isConic2SP, isCentered, decimals;
    if (str in mproj.internal.pj_list === false) {
      // not a bare projection code -- assume valid projection string in other format
      return str;
    }
    isConic2SP = ['lcc', 'aea'].includes(str);
    isCentered = ['tmerc', 'etmerc'].includes(str);
    proj4 = '+proj=' + str;
    if (isConic2SP || isCentered) {
      bbox = getBBox(dataset);
      decimals = getBoundsPrecisionForDisplay(bbox);
      params = isCentered ? getCenterParams(bbox, decimals) : getConicParams(bbox, decimals);
      proj4 += ' ' + params;
      message(`Converted "${str}" to "${proj4}"`);
    }
    return proj4;
  }

  function getBBox(dataset) {
    if (!isLatLngCRS(getDatasetCRS(dataset))) {
      stop('Expected unprojected data');
    }
    return getDatasetBounds(dataset).toArray();
  }

  // See: Savric & Jenny, "Automating the selection of standard parallels for conic map projections"
  // Using one-sixth rule, not the more complicated formula proposed by the authors
  function getConicParams(bbox, decimals) {
    var cx = (bbox[0] + bbox[2]) / 2;
    var h = bbox[3] - bbox[1];
    var sp1 = bbox[1] + 1/6 * h;
    var sp2 = bbox[1] + 5/6 * h;
    return `+lon_0=${ cx.toFixed(decimals) } +lat_1=${ sp1.toFixed(decimals) } +lat_2=${ sp2.toFixed(decimals) }`;
  }

  function getCenterParams(bbox, decimals) {
    var cx = (bbox[0] + bbox[2]) / 2;
    var cy = (bbox[1] + bbox[3]) / 2;
    return `+lon_0=${ cx.toFixed(decimals) } +lat_0=${ cy.toFixed(decimals) }`;
  }

  cmd.proj = function(dataset, catalog, opts) {
    var srcInfo, destInfo, destStr;
    if (opts.init) {
      srcInfo = getCrsInfo(opts.init, catalog);
      if (!srcInfo.crs) stop("Unknown projection source:", opts.init);
      setDatasetCRS(dataset, srcInfo);
    }
    if (opts.match) {
      destInfo = getCrsInfo(opts.match, catalog);
    } else if (opts.crs) {
      destStr = expandProjDefn(opts.crs, dataset);
      destInfo = getCrsInfo(destStr);
    }
    if (destInfo) {
      projCmd(dataset, destInfo, opts);
    }
  };

  function projCmd(dataset, destInfo, opts) {
    // modify copy of coordinate data when running in web UI, so original shapes
    // are preserved if an error occurs
    var modifyCopy = runningInBrowser(),
        originals = [],
        target = {info: dataset.info || {}},
        src, dest;

    dest = destInfo.crs;
    if (!dest) {
      stop("Missing projection data");
    }

    if (!datasetHasGeometry(dataset)) {
      // still set the crs of datasets that are missing geometry
      dataset.info.crs = dest;
      dataset.info.prj = destInfo.prj; // may be undefined
      return;
    }

    src = getDatasetCRS(dataset);
    if (!src) {
      stop("Unable to project -- source coordinate system is unknown");
    }

    if (crsAreEqual(src, dest)) {
      message("Source and destination CRS are the same");
      return;
    }

    if (dataset.arcs) {
      dataset.arcs.flatten(); // bake in any pending simplification
      target.arcs = modifyCopy ? dataset.arcs.getCopy() : dataset.arcs;
    }

    target.layers = dataset.layers.map(function(lyr) {
      if (modifyCopy) {
        originals.push(lyr);
        lyr = copyLayerShapes(lyr);
      }
      return lyr;
    });

    projectDataset(target, src, dest, opts || {});

    dataset.info.prj = destInfo.prj; // may be undefined
    dataset.arcs = target.arcs;
    originals.forEach(function(lyr, i) {
      // replace original layers with modified layers
      utils.extend(lyr, target.layers[i]);
    });
  }


  // name: a layer identifier, .prj file or projection defn
  // Converts layer ids and .prj files to CRS defn
  // Returns projection defn
  function getCrsInfo(name, catalog) {
    var dataset, source, info = {};
    if (/\.prj$/i.test(name)) {
      dataset = importFile(name, {});
      if (dataset) {
        info.prj = dataset.info.prj;
        info.crs = parsePrj(info.prj);
      }
      return info;
    }
    if (catalog && (source = catalog.findSingleLayer(name))) {
      dataset = source.dataset;
      info.crs = getDatasetCRS(dataset);
      info.prj = dataset.info.prj; // may be undefined
      // defn = internal.crsToProj4(P);
      return info;
    }
    // assume name is a projection defn
    info.crs = getCRS(name);
    return info;
  }

  function projectDataset(dataset, src, dest, opts) {
    var proj = getProjTransform2(src, dest); // v2 returns null points instead of throwing an error
    var badArcs = 0;
    var badPoints = 0;
    var clipped = preProjectionClip(dataset, src, dest, opts);

    dataset.layers.forEach(function(lyr) {
      if (layerHasPoints(lyr)) {
        badPoints += projectPointLayer(lyr, proj); // v2 compatible (invalid points are removed)
      }
    });
    if (dataset.arcs) {
      if (opts.densify) {
        badArcs = projectAndDensifyArcs(dataset.arcs, proj);
      } else {
        badArcs = projectArcs2(dataset.arcs, proj);
      }
    }

    if (clipped) {
      // TODO: could more selective in cleaning clipped layers
      // (probably only needed when clipped area crosses the antimeridian or includes a pole)
      cleanProjectedLayers(dataset);
    }

    if (badArcs > 0 && !opts.quiet) {
      message(`Removed ${badArcs} ${badArcs == 1 ? 'path' : 'paths'} containing unprojectable vertices.`);
    }
    if (badPoints > 0 && !opts.quiet) {
      message(`Removed ${badPoints} unprojectable ${badPoints == 1 ? 'point' : 'points'}.`);
    }
    dataset.info.crs = dest;
  }

  // * Heals cuts in previously split-apart polygons
  // * Removes line intersections
  // * TODO: what if a layer contains polygons with desired overlaps? should
  //   we ignore overlaps between different features?
  function cleanProjectedLayers(dataset) {
    // TODO: only clean affected polygons (cleaning all polygons can be slow)
    var polygonLayers = dataset.layers.filter(lyr => lyr.geometry_type == 'polygon');
    // clean options: force a topology update (by default, this only happens when
    // vertices change during cleaning, but reprojection can require a topology update
    // even if clean does not change vertices)
    var cleanOpts = {
      allow_overlaps: true,
      rebuild_topology: true,
      no_arc_dissolve: true,
      quiet: true,
      verbose: false};
    cleanLayers(polygonLayers, dataset, cleanOpts);
   // remove unused arcs from polygon and polyline layers
    // TODO: fix bug that leaves uncut arcs in the arc table
    //   (e.g. when projecting a graticule)
    dissolveArcs(dataset);
  }

  // proj: function to project [x, y] point; should return null if projection fails
  // TODO: fatal error if no points project?
  function projectPointLayer(lyr, proj) {
    var errors = 0;
    editShapes(lyr.shapes, function(p) {
      var p2 = proj(p[0], p[1]);
      if (!p2) errors++;
      return p2; // removes points that fail to project
    });
    return errors;
  }

  function projectArcs(arcs, proj) {
    var data = arcs.getVertexData(),
        xx = data.xx,
        yy = data.yy,
        // old simplification data  will not be optimal after reprojection;
        // re-using for now to avoid error in web ui
        zz = data.zz,
        p;

    for (var i=0, n=xx.length; i<n; i++) {
      p = proj(xx[i], yy[i]);
      xx[i] = p[0];
      yy[i] = p[1];
    }
    arcs.updateVertexData(data.nn, xx, yy, zz);
  }

  function projectArcs2(arcs, proj) {
    return editArcs(arcs, onPoint);
    function onPoint(append, x, y, prevX, prevY, i) {
      var p = proj(x, y);
      // TODO: prevent arcs with just one point
      if (p) {
        append(p);
      } else {
        return false; // signal that the arc is invalid (no more points will be projected in this arc)
      }
    }
  }

  var Proj = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getCrsInfo: getCrsInfo,
    projectDataset: projectDataset,
    cleanProjectedLayers: cleanProjectedLayers,
    projectPointLayer: projectPointLayer,
    projectArcs: projectArcs,
    projectArcs2: projectArcs2
  });

  cmd.graticule = function(dataset, opts) {
    var name = opts.polygon ? 'polygon' : 'graticule';
    var graticule, dest;
    if (dataset && !isLatLngDataset(dataset)) {
      // project graticule to match dataset
      dest = getDatasetCRS(dataset);
      if (!dest) stop("Coordinate system is unknown, unable to create a graticule");
      graticule = opts.polygon ?
        createProjectedPolygon(dest, opts) :
        createProjectedGraticule(dest, opts);
    } else {
      graticule = opts.polygon ?
        createUnprojectedPolygon(opts) :
        createUnprojectedGraticule(opts);
    }
    graticule.layers[0].name = name;
    return graticule;
  };

  function createUnprojectedPolygon(opts) {
    var crs = getCRS('wgs84');
    return getPolygonDataset$1(crs, crs, opts);
  }

  function createProjectedPolygon(dest, opts) {
    var src = getCRS('wgs84');
    return getPolygonDataset$1(src, dest, opts);
  }

  function createUnprojectedGraticule(opts) {
    var src = getCRS('wgs84');
    var graticule = importGeoJSON(createGraticule(src, false, opts));
    return graticule;
  }

  function createProjectedGraticule(dest, opts) {
    var src = getCRS('wgs84');
    // var outline = getOutlineDataset(src, dest, {inset: 0, geometry_type: 'polyline'});
    var outline = getOutlineDataset(src, dest, {});
    var graticule = importGeoJSON(createGraticule(dest, !!outline, opts));
    projectDataset(graticule, src, dest, {no_clip: false}); // TODO: densify?
    if (outline) {
      graticule = addOutlineToGraticule(graticule, outline);
    }
    buildTopology(graticule); // needed for cleaning to work
    cleanLayers(graticule.layers, graticule, {verbose: false});
    return graticule;
  }

  function addOutlineToGraticule(graticule, outline) {
    var merged = mergeDatasets([graticule, outline]);
    var src = merged.layers.pop();
    var dest = merged.layers[0];
    var records = dest.data.getRecords();
    src.shapes.forEach(function(shp) {
      dest.shapes.push(shp);
      records.push({type: 'outline', value: null});
    });
    return merged;
  }

  // Create graticule as a polyline dataset
  //
  function createGraticule(P, outlined, opts) {
    var interval = opts.interval || 10;
    if (![5,10,15,30,45].includes(interval)) stop('Invalid interval:', interval);
    var lon0 = P.lam0 * 180 / Math.PI;
    var precision = interval > 10 ? 1 : 0.5; // degrees between each vertex
    var xstep = interval;
    var ystep = interval;
    var xstepMajor = 90;
    var xn = Math.round(360 / xstep);
    var yn = Math.round(180 / ystep) + 1;
    var xx = utils.range(xn, -180 + xstep, xstep);
    var yy = utils.range(yn, -90, ystep);
    var meridians = [];
    var parallels = [];
    var edgeMeridians = isMeridianBounded(P) ? getEdgeMeridians(P) : null;
    xx.forEach(function(x) {
      if (edgeMeridians && (tooClose(x, edgeMeridians[0]) || tooClose(x, edgeMeridians[1]))) {
        return;
      }
      createMeridian(x, x % xstepMajor === 0);
    });

    if (edgeMeridians && !outlined) {
      // add meridian lines that will appear on the left and right sides of the
      // projected graticule
      createMeridian(edgeMeridians[0], true);
      createMeridian(edgeMeridians[1], true);
    }

    yy.forEach(function(y) {
      createParallel(y);
    });

    var geojson = {
      type: 'FeatureCollection',
      features: meridians.concat(parallels)
    };
    return geojson;

    function tooClose(a, b) {
      return Math.abs(a - b) < interval / 5;
    }

    function createMeridian(x, extended) {
      var y0 = ystep <= 15 ? ystep : 0;
      createMeridianPart(x, -90 + y0, 90 - y0);
      if (extended && y0 > 0) {
        // adding extensions as separate parts, so if the polar coordinates
        // fail to project, at least the rest of the meridian line will remain
        createMeridianPart(x, -90, -90 + y0);
        createMeridianPart(x, 90 - y0, 90);
      }
    }

    function createMeridianPart(x, ymin, ymax) {
      var coords = densifyPathByInterval([[x, ymin], [x, ymax]], precision);
      meridians.push(graticuleFeature(coords, {type: 'meridian', value: roundCoord$1(x)}));
    }

    function createParallel(y) {
      var coords = densifyPathByInterval([[-180, y], [180, y]], precision);
      parallels.push(graticuleFeature(coords, {type: 'parallel', value: y}));
    }
  }

  // remove tiny offsets
  function roundCoord$1(x) {
    return +x.toFixed(3) || 0;
  }

  function getEdgeMeridians(P) {
    var lon = getBoundingMeridian(P);
    // offs must be larger than gutter width in mapshaper-spherical-cutting.js
    var offs = 2e-8;
    return lon == 180 ? [-180, 180] : [lon - offs, lon + offs];
  }

  function graticuleFeature(coords, o) {
    return {
      type: 'Feature',
      properties: o,
      geometry: {
        type: 'LineString',
        coordinates: coords
      }
    };
  }

  cmd.ignore = function(targetLayer, dataset, opts) {
    if (opts.empty && layerIsEmpty(targetLayer)) {
      interrupt('Layer is empty, stopping processing');
    }
  };

  cmd.include = function(opts) {
    var content, obj, context;
    // TODO: handle web context
    if (!opts.file) {
      stop("Missing name of a JS file to load");
    }
    // opts.input is an optional file cache (used by applyCommands())
    cli.checkFileExists(opts.file, opts.input);
    content = cli.readFile(opts.file, 'utf8', opts.input);
    if (typeof content == 'string') {
      if (!/^\s*\{[\s\S]*\}\s*$/.test(content)) {
        stop("Expected a JavaScript object containing key:value pairs");
      }
      try {
        // Try to isolate the imported JS code from the program scope and global environment
        // TODO: consider whether this is desirable... it may be pointless anyway
        //   as long as we're passing through the 'require()' function
        context = getBaseContext();
        context.require = require;
        obj = Function('ctx', 'with(ctx) {return (' + content + ');}').call({}, context);
        // obj = eval('(' + content + ')');
      } catch(e) {
        stop(e.name, 'in JS source:', e.message);
      }
    } else if (typeof content == 'object') {
      // content could be an object if an object is passed to applyCommands()
      obj = content;
    }

    utils.extend(getStateVar('defs'), obj);
  };

  var MAX_RULE_LEN = 50;

  cmd.printInfo = function(layers) {
    var str = '';
    layers.forEach(function(o, i) {
      var title =  'Layer:    ' + (o.layer.name || '[unnamed layer]');
      var tableStr = getAttributeTableInfo(o.layer);
      var tableWidth = measureLongestLine(tableStr);
      var ruleLen = Math.min(Math.max(title.length, tableWidth), MAX_RULE_LEN);
      str += '\n';
      str += utils.lpad('', ruleLen, '=') + '\n';
      str += title + '\n';
      str += utils.lpad('', ruleLen, '-') + '\n';
      str += getLayerInfo(o.layer, o.dataset);
      str += tableStr;
    });
    message(str);
  };

  function measureLongestLine(str) {
    return Math.max.apply(null, str.split('\n').map(function(line) {return stringDisplayWidth(line);}));
  }

  function stringDisplayWidth(str) {
    var w = 0;
    for (var i = 0, n=str.length; i < n; i++) {
      w += charDisplayWidth(str.charCodeAt(i));
    }
    return w;
  }

  // see https://www.cl.cam.ac.uk/~mgk25/ucs/wcwidth.c
  // this is a simplified version, focusing on double-width CJK chars and ignoring nonprinting etc chars
  function charDisplayWidth(c) {
    if (c >= 0x1100 &&
      (c <= 0x115f || c == 0x2329 || c == 0x232a ||
      (c >= 0x2e80 && c <= 0xa4cf && c != 0x303f) || /* CJK ... Yi */
      (c >= 0xac00 && c <= 0xd7a3) || /* Hangul Syllables */
      (c >= 0xf900 && c <= 0xfaff) || /* CJK Compatibility Ideographs */
      (c >= 0xfe10 && c <= 0xfe19) || /* Vertical forms */
      (c >= 0xfe30 && c <= 0xfe6f) || /* CJK Compatibility Forms */
      (c >= 0xff00 && c <= 0xff60) || /* Fullwidth Forms */
      (c >= 0xffe0 && c <= 0xffe6) ||
      (c >= 0x20000 && c <= 0x2fffd) ||
      (c >= 0x30000 && c <= 0x3fffd))) return 2;
    return 1;
  }

  function getLayerData(lyr, dataset) {
    var n = getFeatureCount(lyr);
    var o = {
      geometry_type: lyr.geometry_type,
      feature_count: n,
      null_shape_count: 0,
      null_data_count: lyr.data ? countNullRecords(lyr.data.getRecords()) : n
    };
    if (lyr.shapes) {
      o.null_shape_count = countNullShapes(lyr.shapes);
      o.bbox =getLayerBounds(lyr, dataset.arcs).toArray();
      o.proj4 = getProjInfo(dataset);
    }
    return o;
  }

  // TODO: consider polygons with zero area or other invalid geometries
  function countNullShapes(shapes) {
    var count = 0;
    for (var i=0; i<shapes.length; i++) {
      if (!shapes[i] || shapes[i].length === 0) count++;
    }
    return count;
  }

  function countNullRecords(records) {
    var count = 0;
    for (var i=0; i<records.length; i++) {
      if (!records[i]) count++;
    }
    return count;
  }

  function countRings(shapes, arcs) {
    var holes = 0, rings = 0;
    editShapes(shapes, function(ids) {
      var area = geom.getPlanarPathArea(ids, arcs);
      if (area > 0) rings++;
      if (area < 0) holes++;
    });
    return {rings: rings, holes: holes};
  }

  function getLayerInfo(lyr, dataset) {
    var data = getLayerData(lyr, dataset);
    var str = '';
    str += "Type:     " + (data.geometry_type || "tabular data") + "\n";
    str += utils.format("Records:  %,d\n",data.feature_count);
    if (data.null_shape_count > 0) {
      str += utils.format("Nulls:     %'d", data.null_shape_count) + "\n";
    }
    if (data.geometry_type && data.feature_count > data.null_shape_count) {
      str += "Bounds:   " + data.bbox.join(',') + "\n";
      str += "CRS:      " + data.proj4 + "\n";
    }
    str += "Source:   " + (getLayerSourceFile(lyr, dataset) || 'n/a') + "\n";
    return str;
  }

  function getAttributeTableInfo(lyr, i) {
    if (!lyr.data || lyr.data.size() === 0 || lyr.data.getFields().length === 0) {
      return "Attribute data: [none]\n";
    }
    return "\nAttribute data\n" + formatAttributeTable(lyr.data, i);
  }

  function formatAttributeTable(data, i) {
    var fields = applyFieldOrder(data.getFields(), 'ascending');
    var vals = fields.map(function(fname) {
      return data.getReadOnlyRecordAt(i || 0)[fname];
    });
    var maxIntegralChars = vals.reduce(function(max, val) {
      if (utils.isNumber(val)) {
        max = Math.max(max, countIntegralChars(val));
      }
      return max;
    }, 0);
    var col1Arr = ['Field'].concat(fields);
    var col2Arr = vals.reduce(function(memo, val) {
      memo.push(formatTableValue(val, maxIntegralChars));
      return memo;
    }, [i >= 0 ? 'Value' : 'First value']);
    var col1Chars = maxChars(col1Arr);
    var col2Chars = maxChars(col2Arr);
    var sepStr = (utils.rpad('', col1Chars + 2, '-') + '+' +
        utils.rpad('', col2Chars + 2, '-')).substr(0, MAX_RULE_LEN);
    var sepLine = sepStr + '\n';
    var table = sepLine;
    col1Arr.forEach(function(col1, i) {
      var w = stringDisplayWidth(col1);
      table += ' ' + col1 + utils.rpad('', col1Chars - w, ' ') + ' | ' +
        col2Arr[i] + '\n';
      if (i === 0) table += sepLine; // separator after first line
    });
    return table + sepLine;
  }



  function maxChars(arr) {
    return arr.reduce(function(memo, str) {
      var w = stringDisplayWidth(str);
      return w > memo ? w : memo;
    }, 0);
  }

  function formatString(str) {
    var replacements = {
      '\n': '\\n',
      '\r': '\\r',
      '\t': '\\t'
    };
    var cleanChar = function(c) {
      // convert newlines and carriage returns
      // TODO: better handling of non-printing chars
      return c in replacements ? replacements[c] : '';
    };
    str = str.replace(/[\r\t\n]/g, cleanChar);
    return "'" + str + "'";
  }

  function countIntegralChars(val) {
    return utils.isNumber(val) ? (utils.formatNumber(val) + '.').indexOf('.') : 0;
  }

  function formatTableValue(val, integralChars) {
    var str;
    if (utils.isNumber(val)) {
      str = utils.lpad("", integralChars - countIntegralChars(val), ' ') +
        utils.formatNumber(val);
    } else if (utils.isString(val)) {
      str = formatString(val);
    } else if (utils.isDate(val)) {
      str = utils.formatDateISO(val) + ' (Date)';
    } else if (utils.isObject(val)) { // if {} or [], display JSON
      str = JSON.stringify(val);
    } else {
      str = String(val);
    }
    return str;
  }

  function getSimplificationInfo(arcs) {
    var nodeCount = new NodeCollection(arcs).size();
    // get count of non-node vertices
    var internalVertexCount = countInteriorVertices(arcs);
  }

  function countInteriorVertices(arcs) {
    var count = 0;
    arcs.forEach2(function(i, n) {
      if (n > 2) {
        count += n - 2;
      }
    });
    return count;
  }

  var Info = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getLayerData: getLayerData,
    getAttributeTableInfo: getAttributeTableInfo,
    formatTableValue: formatTableValue
  });

  // TODO: make sure that the inlay shapes and data are not shared
  cmd.inlay = function(targetLayers, src, targetDataset, opts) {
    var mergedDataset = mergeLayersForOverlay(targetLayers, targetDataset, src, opts);
    var inlayLyr = mergedDataset.layers[mergedDataset.layers.length - 1];
    requirePolygonLayer(inlayLyr);
    targetLayers.forEach(requirePolygonLayer);
    var eraseSrc = {layer: copyLayer(inlayLyr), dataset: mergedDataset};
    var erasedLayers = cmd.eraseLayers(targetLayers, eraseSrc, mergedDataset, opts);
    var outputLayers = erasedLayers.map(function(lyr0) {
      // similar to applyCommandToLayerSelection() (mapshaper-command-utils.js)
      var lyr1 = copyLayer(inlayLyr);
      var lyr2 = cmd.mergeLayers([lyr0, lyr1], {force: true})[0];
      lyr2.name = lyr0.name;
      return lyr2;
    });
    targetDataset.arcs = mergedDataset.arcs;
    return outputLayers;
  };

  cmd.innerlines = function(lyr, arcs, opts) {
    opts = opts || {};
    requirePolygonLayer(lyr);
    var filter = opts.where ? compileFeaturePairFilterExpression(opts.where, lyr, arcs) : null;
    var classifier = getArcClassifier(lyr.shapes, arcs, {filter: filter});
    var lines = extractInnerLines(lyr.shapes, classifier);
    var outputLyr = createLineLayer(lines, null);

    if (lines.length === 0) {
      message("No shared boundaries were found");
    }
    setOutputLayerName(outputLyr, lyr, null, opts);
    return outputLyr;
  };

  cmd.inspect = function(lyr, arcs, opts) {
    var ids = selectFeatures(lyr, arcs, opts);
    var msg;
    if (ids.length == 1) {
      msg = getFeatureInfo(ids[0], lyr, arcs);
    } else {
      msg = utils.format("Expression matched %d feature%s. Select one feature for details", ids.length, utils.pluralSuffix(ids.length));
    }
    message(msg);
  };

  function getFeatureInfo(id, lyr, arcs) {
      var msg = "Feature " + id + '\n';
      msg += getShapeInfo(id, lyr, arcs);
      msg += getAttributeTableInfo(lyr, id);
      return msg;
  }

  function getShapeInfo(id, lyr, arcs) {
    var shp = lyr.shapes ? lyr.shapes[id] : null;
    var type = lyr.geometry_type;
    var info, msg;
    if (!shp || !type) {
      return 'Geometry: [null]\n';
    }
    msg = 'Geometry\n  Type: ' + type + '\n';
    if (type == 'point') {
      msg += '  Points: ' + shp.length + '\n';
    } else if (type == 'polyline') {
      msg += '  Parts: ' + shp.length + '\n';
    } else if (type == 'polygon') {
      info = getPolygonInfo(shp, arcs);
      msg += utils.format('  Rings: %d cw, %d ccw\n', info.cw, info.ccw);
      msg += '  Planar area: ' + info.area + '\n';
      if (info.sph_area) {
        msg += '  Spherical area: ' + info.sph_area + ' sq. meters\n';
      }
    }
    return msg;
  }

  function getPolygonInfo(shp, arcs) {
    var o = {rings: shp.length, cw: 0, ccw: 0, area: 0};
    var area;
    for (var i=0; i<shp.length; i++) {
      area = geom.getPlanarPathArea(shp[i], arcs);
      if (area > 0) {
        o.cw++;
      } else if (area < 0) {
        o.ccw++;
      }
      o.area += area;
    }
    if (!arcs.isPlanar()) {
      o.sph_area = geom.getSphericalShapeArea(shp, arcs);
    }
    return o;
  }

  function selectFeatures(lyr, arcs, opts) {
    var n = getFeatureCount(lyr),
        ids = [],
        filter;
    if (!opts.expression) {
      stop("Missing a JS expression for selecting a feature");
    }
    filter = compileValueExpression(opts.expression, lyr, arcs);
    utils.repeat(n, function(id) {
      var result = filter(id);
      if (result === true) {
        ids.push(id);
      } else if (result !== false) {
        stop("Expression must return true or false");
      }
    });
    return ids;
  }

  function joinPolygonsViaMosaic(targetLyr, targetDataset, source, opts) {
    var mergedDataset = mergeLayersForOverlay([targetLyr], targetDataset, source, opts);
    var nodes = addIntersectionCuts(mergedDataset, opts);
    var sourceLyr = mergedDataset.layers.pop();
    targetDataset.arcs = mergedDataset.arcs;
    prepJoinLayers(targetLyr, sourceLyr);
    var mergedLyr = {
      geometry_type: 'polygon',
      shapes: targetLyr.shapes.concat(sourceLyr.shapes)
    };
    var mosaicIndex = new MosaicIndex(mergedLyr, nodes, {flat: false});

    var joinOpts = utils.extend({}, opts);
    var joinFunction = getPolygonToPolygonFunction(targetLyr, sourceLyr, mosaicIndex, opts);
    var retn = joinTableToLayer(targetLyr, sourceLyr.data, joinFunction, joinOpts);

    if (opts.interpolate) {
      if (opts.duplication) stop('duplication and interpolate options cannot be used together');
      interpolateFieldsByArea(targetLyr, sourceLyr, mosaicIndex, opts);
    }
    return retn;
  }


  function interpolateFieldsByArea(destLyr, sourceLyr, mosaicIndex, opts) {
    var mosaicRecords = getOverlapDataByTile(destLyr, sourceLyr, mosaicIndex, opts);
    var sourceFields = opts.interpolate;
    var sourceRecords = sourceLyr.data.getRecords();

    // for each destination polygon, calculate interpolated values,
    // using the data calculated in previous steps
    destLyr.data.getRecords().forEach(function(destRec, destId) {
      var tileIds = mosaicIndex.getTileIdsByShapeId(destId);
      var tileRecords = [], i, field;
      for (i=0; i<tileIds.length; i++) {
        tileRecords.push(mosaicRecords[tileIds[i]]);
      }
      for (i=0; i<sourceFields.length; i++) {
        field = sourceFields[i];
        destRec[field] = getInterpolatedValue(field, tileRecords, sourceRecords);
      }
    });
  }

  function getOverlapDataByTile(destLyr, sourceLyr, mosaicIndex, opts) {
    var getShapeArea = opts.planar ? geom.getPlanarShapeArea : geom.getShapeArea;
    var destLen = destLyr.shapes.length;
    var mosaicShapes = mosaicIndex.mosaic;
    var arcs = mosaicIndex.nodes.arcs;
    // initialize data objects for each mosaic tile
    var mosaicRecords = mosaicShapes.map(function(tile, i) {
      var rec = {
        area: getShapeArea(tile, arcs),
        weight: 0,
        sourceId: -1
      };
      return rec;
    });

    // identify the source polygon that overlaps each tile,
    // and calculate the percentage of the source shape represented by each tile
    sourceLyr.shapes.forEach(function(sourceShp, sourceId) {
      var tileIds = mosaicIndex.getTileIdsByShapeId(sourceId + destLen);
      var shapeArea = getShapeArea(sourceShp, arcs);
      var tileRec;
      for (var i=0; i<tileIds.length; i++) {
        tileRec = mosaicRecords[tileIds[i]];
        if (tileRec.sourceId > -1) {
          // overlap in source layer
          continue;
        }
        tileRec.weight = tileRec.area / shapeArea;
        tileRec.sourceId = sourceId;
      }
    });
    return mosaicRecords;
  }


  function getInterpolatedValue(field, tileRecords, sourceRecords) {
    var value = 0, tileRec, sourceRec;
    for (var i=0; i<tileRecords.length; i++) {
      tileRec = tileRecords[i];
      if (tileRec.sourceId == -1) continue;
      sourceRec = sourceRecords[tileRec.sourceId];
      value += tileRec.weight * sourceRec[field];
    }
    return value;
  }

  function getIdConversionFunction(offset, length) {
    return function (mergedIds) {
      var ids = [], id;
      for (var i=0; i<mergedIds.length; i++) {
        id = mergedIds[i] - offset;
        if (id >= 0 && id < length) ids.push(id);
      }
      return ids;
    };
  }

  function getMaxOverlapFunction(destLyr, srcLyr, mosaicIndex) {
    var arcs = mosaicIndex.nodes.arcs;
    var destLen = destLyr.shapes.length;

    function getTotalArea(tileIds) {
      var area = 0;
      for (var i=0; i<tileIds.length; i++) {
        area += geom.getShapeArea(mosaicIndex.mosaic[tileIds[i]], arcs);
      }
      return area;
    }

    return function(destId, srcIds) {
      var destTileIds = mosaicIndex.getTileIdsByShapeId(destId);
      var maxArea = 0;
      var maxId = -1;
      srcIds.forEach(function(srcId, i) {
        var srcTileIds = mosaicIndex.getTileIdsByShapeId(srcId + destLen);
        var sharedIds = utils.intersection(destTileIds, srcTileIds);
        var area = getTotalArea(sharedIds);
        if (area >= maxArea) {
          maxId = srcId;
          maxArea = area;
        }
      });
      if (maxId == -1) error('Geometry error');
      return [maxId];
    };
  }


  // Returned function converts a target layer feature id to multiple source feature ids
  // TODO: option to join the source polygon with the greatest overlapping area
  // TODO: option to ignore source polygon with small overlaps
  //       (as a percentage of the area of one or the other polygon?)
  function getPolygonToPolygonFunction(targetLyr, srcLyr, mosaicIndex, opts) {
    var mergedToSourceIds = getIdConversionFunction(targetLyr.shapes.length, srcLyr.shapes.length);
    var selectMaxOverlap;
    if (opts.largest_overlap) {
      selectMaxOverlap = getMaxOverlapFunction(targetLyr, srcLyr, mosaicIndex);
    }

    return function(targId) {
      var tileIds = mosaicIndex.getTileIdsByShapeId(targId);
      var sourceIds = [], overlappingTiles = [], tmp;
      for (var i=0; i<tileIds.length; i++) {
        tmp = mosaicIndex.getSourceIdsByTileId(tileIds[i]);
        tmp = mergedToSourceIds(tmp);
        sourceIds = sourceIds.length > 0 ? sourceIds.concat(tmp) : tmp;
      }
      sourceIds = utils.uniq(sourceIds);
      if (sourceIds.length > 1 && opts.largest_overlap) {
        sourceIds = selectMaxOverlap(targId, sourceIds);
      }
      return sourceIds;
    };
  }

  // Parse a formatted value in DMS DM or D to a numeric value. Returns NaN if unparsable.
  // Delimiters: degrees: D|d|; minutes: '; seconds: "
  function parseDMS(str) {
    var rxp = /^([nsew+-]?)([0-9.]+)[d]? ?([0-9.]*)[']? ?([0-9.]*)["]? ?([nsew]?)$/i;
    var match = rxp.exec(str.trim());
    var d = NaN;
    var deg, min, sec, inv;
    if (match) {
      deg = match[2] || '0';
      min = match[3] || '0';
      sec = match[4] || '0';
      d = (+deg) + (+min) / 60 + (+sec) / 3600;
      if (/[sw-]/i.test(match[1]) || /[sw]/i.test(match[5])) {
        d = -d;
      }
    }
    return d;
  }

  function findNearestVertices(p, shp, arcs) {
    var p2 = findNearestVertex(p[0], p[1], shp, arcs);
    return findVertexIds(p2.x, p2.y, arcs);
  }

  // p: point to snap
  // ids: ids of nearby vertices, possibly including an arc endpoint
  function snapPointToArcEndpoint(p, ids, arcs) {
    var p2, p3, dx, dy;
    ids.forEach(function(idx) {
      if (vertexIsArcStart(idx, arcs)) {
        p2 = getVertexCoords(idx + 1, arcs);
      } else if (vertexIsArcEnd(idx, arcs)) {
        p2 = getVertexCoords(idx - 1, arcs);
      }
    });
    if (!p2) return;
    dx = p2[0] - p[0];
    dy = p2[1] - p[1];
    if (Math.abs(dx) > Math.abs(dy)) {
      p[1] = p2[1]; // snap y coord
    } else {
      p[0] = p2[0];
    }
  }

  // Find ids of vertices with identical coordinates to x,y in an ArcCollection
  // Caveat: does not exclude vertices that are not visible at the
  //   current level of simplification.
  function findVertexIds(x, y, arcs) {
    var data = arcs.getVertexData(),
        xx = data.xx,
        yy = data.yy,
        ids = [];
    for (var i=0, n=xx.length; i<n; i++) {
      if (xx[i] == x && yy[i] == y) ids.push(i);
    }
    return ids;
  }

  function getVertexCoords(i, arcs) {
    var data = arcs.getVertexData();
    return [data.xx[i], data.yy[i]];
  }

  function vertexIsArcEnd(idx, arcs) {
    // Test whether the vertex at index @idx is the endpoint of an arc
    var data = arcs.getVertexData(),
        ii = data.ii,
        nn = data.nn;
    for (var j=0, n=ii.length; j<n; j++) {
      if (idx === ii[j] + nn[j] - 1) return true;
    }
    return false;
  }

  function vertexIsArcStart(idx, arcs) {
    var ii = arcs.getVertexData().ii;
    for (var j=0, n=ii.length; j<n; j++) {
      if (idx === ii[j]) return true;
    }
    return false;
  }

  function setVertexCoords(x, y, i, arcs) {
    var data = arcs.getVertexData();
    data.xx[i] = x;
    data.yy[i] = y;
  }

  function findNearestVertex(x, y, shp, arcs, spherical) {
    var calcLen = spherical ? geom.greatCircleDistance : geom.distance2D,
        minLen = Infinity,
        minX, minY, dist, iter;
    for (var i=0; i<shp.length; i++) {
      iter = arcs.getShapeIter(shp[i]);
      while (iter.hasNext()) {
        dist = calcLen(x, y, iter.x, iter.y);
        if (dist < minLen) {
          minLen = dist;
          minX = iter.x;
          minY = iter.y;
        }
      }
    }
    return minLen < Infinity ? {x: minX, y: minY} : null;
  }

  var VertexUtils = /*#__PURE__*/Object.freeze({
    __proto__: null,
    findNearestVertices: findNearestVertices,
    snapPointToArcEndpoint: snapPointToArcEndpoint,
    findVertexIds: findVertexIds,
    getVertexCoords: getVertexCoords,
    vertexIsArcEnd: vertexIsArcEnd,
    vertexIsArcStart: vertexIsArcStart,
    setVertexCoords: setVertexCoords,
    findNearestVertex: findNearestVertex
  });

  // Returns x,y coordinates of the point that is at the midpoint of each polyline feature
  // Uses 2d cartesian geometry
  // TODO: optionally use spherical geometry
  function polylineToMidpoints(shp, arcs, opts) {
    if (!shp) return null;
    var points = shp.map(function(path) {
      return findPathMidpoint(path, arcs);
    });
    return points;
  }

  function findPathMidpoint(path, arcs) {
    var halfLen = calcPathLen(path, arcs, false) / 2;
    var partialLen = 0;
    var done = false;
    var p;
    forEachSegmentInPath(path, arcs, function(i, j, xx, yy) {
      var a = xx[i],
          b = yy[i],
          c = xx[j],
          d = yy[j];
      if (p) return;
      if (halfLen > 0 === false) {
        return [a, b];
      }
      var segLen = distance2D(a, b, c, d);
      var k;
      if (partialLen + segLen >= halfLen) {
        k = (halfLen - partialLen) / segLen;
        p = [a + k * (c - a), b + k * (d - b)];
      }
      partialLen += segLen;
    });
    if (!p) {
      error('Geometry error');
    }
    return p;
  }

  // Returns x,y coordinates of the vertex that is closest to the bbox center point
  //   (uses part with the largest-area bbox in )
  // TODO: explore other methods for replacing a polyline with a point.
  function polylineToPoint(shp, arcs, opts) {
    var spherical = !arcs.isPlanar();
    var part = !shp ? null : (shp.length == 1 ? shp[0] : findLongestPolylinePart(shp, arcs, spherical));
    if (!part) return null;
    var bbox = arcs.getSimpleShapeBounds(part);
    var p = findNearestVertex(bbox.centerX(), bbox.centerY(), [part], arcs, spherical);
    return p;
  }

  function findLongestPolylinePart(shp, arcs, spherical) {
    var maxLen = 0;
    var maxPart = null;
    shp.forEach(function(path) {
      var len = geom.calcPathLen(path, arcs, spherical);
      if (len > maxLen) {
        maxLen = len;
        maxPart = path;
      }
    });
    return maxPart;
  }

  cmd.createPointLayer = function(srcLyr, dataset, opts) {
    var destLyr = getOutputLayer(srcLyr, opts);
    var arcs = dataset.arcs;
    if (opts.intersections) {
      testIntersections(arcs);
      destLyr = srcLyr;
    } else if (opts.interpolated) {
      // TODO: consider making attributed points, including distance from origin
      destLyr.shapes = interpolatedPointsFromVertices(srcLyr, dataset, opts);
    } else if (opts.vertices) {
      destLyr.shapes = pointsFromVertices(srcLyr, arcs, opts);
    } else if (opts.vertices2) {
      destLyr.shapes = pointsFromVertices2(srcLyr, arcs, opts);
    } else if (opts.endpoints) {
      destLyr.shapes = pointsFromEndpoints(srcLyr, arcs, opts);
    } else if (opts.x || opts.y) {
      destLyr.shapes = pointsFromDataTable(srcLyr.data, opts);
    } else if (srcLyr.geometry_type == 'polygon') {
      destLyr.shapes = pointsFromPolygons(srcLyr, arcs, opts);
    } else if (opts.midpoints) {
      requirePolylineLayer(srcLyr);
      destLyr.shapes = midpointsFromPolylines(srcLyr, arcs, opts);
    } else if (srcLyr.geometry_type == 'polyline') {
      destLyr.shapes = pointsFromPolylines(srcLyr, arcs, opts);
    } else if (!srcLyr.geometry_type) {
      destLyr.shapes = pointsFromDataTableAuto(srcLyr.data);
    } else {
      stop("Expected a polygon or polyline layer");
    }
    destLyr.geometry_type = 'point';

    var nulls = destLyr.shapes.reduce(function(sum, shp) {
      if (!shp) sum++;
      return sum;
    }, 0);

    if (nulls > 0) {
      message(utils.format('%,d of %,d points are null', nulls, destLyr.shapes.length));
    }
    if (srcLyr.data) {
      destLyr.data = opts.no_replace ? srcLyr.data.clone() : srcLyr.data;
    }
    return destLyr;
  };

  // TODO: finish testing stripe count functions and remove
  function testIntersections(arcs) {
    var pointCount =  arcs.getFilteredPointCount(),
        arcCount = arcs.size(),
        segCount = pointCount - arcCount,
        stripes = calcSegmentIntersectionStripeCount2(arcs),
        stripes2 = Math.ceil(stripes / 10),
        stripes3 = stripes * 10,
        stripes4 = calcSegmentIntersectionStripeCount(arcs);

    console.log("points:", pointCount, "arcs:", arcCount, "segs:", segCount);
    [stripes2, stripes, stripes3, stripes4].forEach(function(n) {
      console.time(n + ' stripes');
      findSegmentIntersections(arcs, {stripes: n});
      console.timeEnd(n + ' stripes');
    });
  }

  function interpolatePointsAlongArc(ids, arcs, interval) {
    var iter = arcs.getShapeIter(ids);
    var distance = arcs.isPlanar() ? geom.distance2D : geom.greatCircleDistance;
    var coords = [];
    var elapsedDist = 0;
    var prevX, prevY;
    var segLen, k, p;
    if (iter.hasNext()) {
      coords.push([iter.x, iter.y]);
      prevX = iter.x;
      prevY = iter.y;
    }
    while (iter.hasNext()) {
      segLen = distance(prevX, prevY, iter.x, iter.y);
      while (elapsedDist + segLen >= interval) {
        k = (interval - elapsedDist) / segLen;
        // TODO: consider using great-arc distance for lat-long points
        p = interpolatePoint2D(prevX, prevY, iter.x, iter.y, k);
        elapsedDist = 0;
        coords.push(p);
        prevX = p[0];
        prevY = p[1];
        segLen = distance(prevX, prevY, iter.x, iter.y);
      }
      elapsedDist += segLen;
      prevX = iter.x;
      prevY = iter.y;
    }
    if (elapsedDist > 0) {
      coords.push([prevX, prevY]);
    }
    return coords;
  }

  function interpolatedPointsFromVertices(lyr, dataset, opts) {
    var interval = convertIntervalParam(opts.interval, getDatasetCRS(dataset));
    var coords;
    if (interval > 0 === false) stop("Invalid interpolation interval:", opts.interval);
    if (lyr.geometry_type != 'polyline') stop("Expected a polyline layer");
    return lyr.shapes.map(function(shp, shpId) {
      coords = [];
      if (shp) shp.forEach(nextPart);
      return coords.length > 0 ? coords : null;
    });
    function nextPart(ids) {
      var points = interpolatePointsAlongArc(ids, dataset.arcs, interval);
      coords = coords.concat(points);
    }
  }

  // Unique vertices within each feature
  function pointsFromVertices(lyr, arcs, opts) {
    var coords, index;
    if (lyr.geometry_type != "polygon" && lyr.geometry_type != 'polyline') {
      stop("Expected a polygon or polyline layer");
    }
    return lyr.shapes.map(function(shp, shpId) {
      coords = [];
      index = {}; // TODO: use more efficient index
      (shp || []).forEach(nextPart);
      return coords.length > 0 ? coords : null;
    });

    function addPoint(p) {
      var key = p.x + '~' + p.y;
      if (key in index === false) {
        index[key] = true;
        coords.push([p.x, p.y]);
      }
    }

    function nextPart(ids) {
      var iter = arcs.getShapeIter(ids);
      while (iter.hasNext()) {
        addPoint(iter);
      }
    }
  }

  // Simple conversion of path vertices to points (duplicate locations not removed)
  // TODO: Provide some way to rebuild paths from points (e.g. multipart features)
  function pointsFromVertices2(lyr, arcs, opts) {
    var coords;
    if (lyr.geometry_type != "polygon" && lyr.geometry_type != 'polyline') {
      stop("Expected a polygon or polyline layer");
    }
    return lyr.shapes.map(function(shp, shpId) {
      coords = [];
      (shp || []).forEach(nextPart);
      return coords.length > 0 ? coords : null;
    });

    function nextPart(ids) {
      var iter = arcs.getShapeIter(ids);
      while (iter.hasNext()) {
        coords.push([iter.x, iter.y]);
      }
    }
  }

  function pointsFromEndpoints(lyr, arcs) {
    var coords, index;
    if (lyr.geometry_type != "polygon" && lyr.geometry_type != 'polyline') {
      stop("Expected a polygon or polyline layer");
    }
    return lyr.shapes.map(function(shp, shpId) {
      coords = [];
      index = {}; // TODO: use more efficient index
      (shp || []).forEach(nextPart);
      return coords.length > 0 ? coords : null;
    });

    function addPoint(p) {
      var key = p.x + '~' + p.y;
      if (key in index === false) {
        index[key] = true;
        coords.push([p.x, p.y]);
      }
    }

    function nextPart(ids) {
      for (var i=0; i<ids.length; i++) {
        addPoint(arcs.getVertex(ids[i], 0));
        addPoint(arcs.getVertex(ids[i], -1));
      }
    }
  }

  function midpointsFromPolylines(lyr, arcs, opts) {
    return lyr.shapes.map(function(shp) {
      return polylineToMidpoints(shp, arcs, opts);
    });
  }

  function pointsFromPolylines(lyr, arcs, opts) {
    return lyr.shapes.map(function(shp) {
      var p = polylineToPoint(shp, arcs, opts);
      return p ? [[p.x, p.y]] : null;
    });
  }

  function pointsFromPolygons(lyr, arcs, opts) {
    var func = opts.inner ? findAnchorPoint : geom.getShapeCentroid;
    return lyr.shapes.map(function(shp) {
      var p = func(shp, arcs);
      return p ? [[p.x, p.y]] : null;
    });
  }

  function coordinateFromValue(val) {
    var tmp;
    if (utils.isFiniteNumber(val)) {
      return val;
    }
    // exclude empty string (not a valid coordinate, but would get coerced to 0)
    if (utils.isString(val) && val !== '') {
      tmp = +val;
      if (utils.isFiniteNumber(tmp)) {
        return tmp;
      }
      tmp = parseDMS(val); // try to parse as DMS
      if (utils.isFiniteNumber(tmp)) {
        return tmp;
      }
    }
    return NaN;
  }

  function findXField(fields) {
    var rxp = /^(lng|long?|longitude|x)$/i;
    return utils.find(fields, function(name) {
      return rxp.test(name);
    });
  }

  function findYField(fields) {
    var rxp = /^(lat|latitude|y)$/i;
    return utils.find(fields, function(name) {
      return rxp.test(name);
    });
  }

  function pointsFromDataTableAuto(data) {
    var fields = data ? data.getFields() : [];
    var opts = {
      x: findXField(fields),
      y: findYField(fields)
    };
    return pointsFromDataTable(data, opts);
  }

  function pointsFromDataTable(data, opts) {
    if (!data) stop("Layer is missing a data table");
    if (!opts.x || !opts.y || !data.fieldExists(opts.x) || !data.fieldExists(opts.y)) {
      stop("Missing x,y data fields");
    }

    return data.getRecords().map(function(rec) {
      var x = coordinateFromValue(rec[opts.x]),
          y = coordinateFromValue(rec[opts.y]);
      if (isNaN(x) || isNaN(y)) {
        return null;
      }
      return [[x, y]];
    });
  }

  var Points = /*#__PURE__*/Object.freeze({
    __proto__: null,
    pointsFromPolygons: pointsFromPolygons,
    coordinateFromValue: coordinateFromValue,
    findXField: findXField,
    findYField: findYField
  });

  function joinPolygonsViaPoints(targetLyr, targetDataset, source, opts) {

    var sourceLyr = source.layer,
        sourceDataset = source.dataset,
        pointLyr, retn;

    if (targetLyr.shapes.length > sourceLyr.shapes.length) {
      // convert target polygons to points, then join source data to points
      pointLyr = pointsFromPolygonsForJoin(targetLyr, targetDataset);
      retn = joinPolygonsToPoints(pointLyr, sourceLyr, sourceDataset.arcs, opts);
      targetLyr.data = pointLyr.data;
    } else {
      // convert source polygons to points, then join points to target polygons
      pointLyr = pointsFromPolygonsForJoin(sourceLyr, sourceDataset);
      retn = joinPointsToPolygons(targetLyr, targetDataset.arcs, pointLyr, opts);
    }
    return retn;
  }

  function pointsFromPolygonsForJoin(lyr, dataset) {
    // TODO use faster method to get inner points
    return {
      geometry_type: 'point',
      shapes: pointsFromPolygons(lyr, dataset.arcs, {inner: true}),
      data: lyr.data // TODO copy if needed
    };
  }

  function joinPolygonsToPolygons(targetLyr, targetDataset, source, opts) {
    if (opts.point_method) {
      return joinPolygonsViaPoints(targetLyr, targetDataset, source, opts);
    } else {
      return joinPolygonsViaMosaic(targetLyr, targetDataset, source, opts);
    }
  }

  function pointsFromPolylinesForJoin(lyr, dataset) {
    var shapes = lyr.shapes.map(function(shp) {
      return polylineToMidpoints(shp, dataset.arcs);
    });
    return {
      geometry_type: 'point',
      shapes: shapes,
      data: lyr.data // TODO copy if needed
    };
  }

  function validateOpts(opts) {
    if (!opts.point_method) {
      stop('The "point-method" flag is required for polyline-polygon joins');
    }
  }

  function joinPolylinesToPolygons(targetLyr, targetDataset, source, opts) {
    validateOpts(opts);
    var pointLyr = pointsFromPolylinesForJoin(source.layer, source.dataset);
    var retn = joinPointsToPolygons(targetLyr, targetDataset.arcs, pointLyr, opts);
    return retn;
  }

  function joinPolygonsToPolylines(targetLyr, targetDataset, source, opts) {
    validateOpts(opts);
    var pointLyr = pointsFromPolylinesForJoin(targetLyr, targetDataset);
    var retn = joinPolygonsToPoints(pointLyr, source.layer, source.dataset.arcs, opts);
    targetLyr.data = pointLyr.data;
    return retn;
  }

  class TinyQueue {
      constructor(data = [], compare = defaultCompare) {
          this.data = data;
          this.length = this.data.length;
          this.compare = compare;

          if (this.length > 0) {
              for (let i = (this.length >> 1) - 1; i >= 0; i--) this._down(i);
          }
      }

      push(item) {
          this.data.push(item);
          this.length++;
          this._up(this.length - 1);
      }

      pop() {
          if (this.length === 0) return undefined;

          const top = this.data[0];
          const bottom = this.data.pop();
          this.length--;

          if (this.length > 0) {
              this.data[0] = bottom;
              this._down(0);
          }

          return top;
      }

      peek() {
          return this.data[0];
      }

      _up(pos) {
          const {data, compare} = this;
          const item = data[pos];

          while (pos > 0) {
              const parent = (pos - 1) >> 1;
              const current = data[parent];
              if (compare(item, current) >= 0) break;
              data[pos] = current;
              pos = parent;
          }

          data[pos] = item;
      }

      _down(pos) {
          const {data, compare} = this;
          const halfLength = this.length >> 1;
          const item = data[pos];

          while (pos < halfLength) {
              let left = (pos << 1) + 1;
              let best = data[left];
              const right = left + 1;

              if (right < this.length && compare(data[right], best) < 0) {
                  left = right;
                  best = data[right];
              }
              if (compare(best, item) >= 0) break;

              data[pos] = best;
              pos = left;
          }

          data[pos] = item;
      }
  }

  function defaultCompare(a, b) {
      return a < b ? -1 : a > b ? 1 : 0;
  }

  /*
  ISC License

  Copyright (c) 2017, Vladimir Agafonkin

  Permission to use, copy, modify, and/or distribute this software for any purpose
  with or without fee is hereby granted, provided that the above copyright notice
  and this permission notice appear in all copies.

  THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH
  REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND
  FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT,
  INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS
  OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER
  TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF
  THIS SOFTWARE.
  */

  var earthRadius = 6371;
  var rad = Math.PI / 180;

  function around(index, lng, lat, maxResults, maxDistance, predicate) {
      var maxHaverSinDist = 1, result = [];

      if (maxResults === undefined) maxResults = Infinity;
      if (maxDistance !== undefined) maxHaverSinDist = haverSin(maxDistance / earthRadius);

      // a distance-sorted priority queue that will contain both points and kd-tree nodes
      var q = new TinyQueue([], compareDist);

      // an object that represents the top kd-tree node (the whole Earth)
      var node = {
          left: 0, // left index in the kd-tree array
          right: index.ids.length - 1, // right index
          axis: 0, // 0 for longitude axis and 1 for latitude axis
          dist: 0, // will hold the lower bound of children's distances to the query point
          minLng: -180, // bounding box of the node
          minLat: -90,
          maxLng: 180,
          maxLat: 90
      };

      var cosLat = Math.cos(lat * rad);
      var right, left, item;

      while (node) {
          right = node.right;
          left = node.left;

          if (right - left <= index.nodeSize) { // leaf node

              // add all points of the leaf node to the queue
              for (var i = left; i <= right; i++) {
                  item = index.points[index.ids[i]];
                  if (!predicate || predicate(item)) {
                      q.push({
                          i: index.ids[i],
                          item: item,
                          dist: haverSinDist(lng, lat, index.coords[2 * i], index.coords[2 * i + 1], cosLat)
                      });
                  }
              }

          } else { // not a leaf node (has child nodes)

              var m = (left + right) >> 1; // middle index
              var midLng = index.coords[2 * m];
              var midLat = index.coords[2 * m + 1];

              // add middle point to the queue
              item = index.points[index.ids[m]];
              if (!predicate || predicate(item)) {
                  q.push({
                      i: index.ids[m],
                      item: item,
                      dist: haverSinDist(lng, lat, midLng, midLat, cosLat)
                  });
              }

              var nextAxis = (node.axis + 1) % 2;

              // first half of the node
              var leftNode = {
                  left: left,
                  right: m - 1,
                  axis: nextAxis,
                  minLng: node.minLng,
                  minLat: node.minLat,
                  maxLng: node.axis === 0 ? midLng : node.maxLng,
                  maxLat: node.axis === 1 ? midLat : node.maxLat,
                  dist: 0
              };
              // second half of the node
              var rightNode = {
                  left: m + 1,
                  right: right,
                  axis: nextAxis,
                  minLng: node.axis === 0 ? midLng : node.minLng,
                  minLat: node.axis === 1 ? midLat : node.minLat,
                  maxLng: node.maxLng,
                  maxLat: node.maxLat,
                  dist: 0
              };

              leftNode.dist = boxDist(lng, lat, cosLat, leftNode);
              rightNode.dist = boxDist(lng, lat, cosLat, rightNode);

              // add child nodes to the queue
              q.push(leftNode);
              q.push(rightNode);
          }

          // fetch closest points from the queue; they're guaranteed to be closer
          // than all remaining points (both individual and those in kd-tree nodes),
          // since each node's distance is a lower bound of distances to its children
          while (q.length && q.peek().item) {
              var candidate = q.pop();
              if (candidate.dist > maxHaverSinDist) return result;
              // result.push(candidate.item);
              result.push(candidate.i);
              if (result.length === maxResults) return result;
          }

          // the next closest kd-tree node
          node = q.pop();
      }

      return result;
  }

  // lower bound for distance from a location to points inside a bounding box
  function boxDist(lng, lat, cosLat, node) {
      var minLng = node.minLng;
      var maxLng = node.maxLng;
      var minLat = node.minLat;
      var maxLat = node.maxLat;

      // query point is between minimum and maximum longitudes
      if (lng >= minLng && lng <= maxLng) {
          if (lat < minLat) return haverSin((lat - minLat) * rad);
          if (lat > maxLat) return haverSin((lat - maxLat) * rad);
          return 0;
      }

      // query point is west or east of the bounding box;
      // calculate the extremum for great circle distance from query point to the closest longitude;
      var haverSinDLng = Math.min(haverSin((lng - minLng) * rad), haverSin((lng - maxLng) * rad));
      var extremumLat = vertexLat(lat, haverSinDLng);

      // if extremum is inside the box, return the distance to it
      if (extremumLat > minLat && extremumLat < maxLat) {
          return haverSinDistPartial(haverSinDLng, cosLat, lat, extremumLat);
      }
      // otherwise return the distan e to one of the bbox corners (whichever is closest)
      return Math.min(
          haverSinDistPartial(haverSinDLng, cosLat, lat, minLat),
          haverSinDistPartial(haverSinDLng, cosLat, lat, maxLat)
      );
  }

  function compareDist(a, b) {
      return a.dist - b.dist;
  }

  function haverSin(theta) {
      var s = Math.sin(theta / 2);
      return s * s;
  }

  function haverSinDistPartial(haverSinDLng, cosLat1, lat1, lat2) {
      return cosLat1 * Math.cos(lat2 * rad) * haverSinDLng + haverSin((lat1 - lat2) * rad);
  }

  function haverSinDist(lng1, lat1, lng2, lat2, cosLat1) {
      var haverSinDLng = haverSin((lng1 - lng2) * rad);
      return haverSinDistPartial(haverSinDLng, cosLat1, lat1, lat2);
  }

  function distance(lng1, lat1, lng2, lat2) {
      var h = haverSinDist(lng1, lat1, lng2, lat2, Math.cos(lat1 * rad));
      return 2 * earthRadius * Math.asin(Math.sqrt(h));
  }

  function vertexLat(lat, haverSinDLng) {
      var cosDLng = 1 - 2 * haverSinDLng;
      if (cosDLng <= 0) return lat > 0 ? 90 : -90;
      return Math.atan(Math.tan(lat * rad) / cosDLng) / rad;
  }

  function PointIndex(srcLyr, crs, opts) {
    requireSinglePointLayer(srcLyr);
    var points = getPointsInLayer(srcLyr);
    var maxDist = opts.max_distance ? convertDistanceParam(opts.max_distance, crs) : 1e-3;
    var kdbush = require('kdbush');
    var index = new kdbush(points);
    var lookup = getLookupFunction(index, crs, maxDist);
    var uniqIndex = new IdTestIndex(points.length);

    this.lookupByMultiPoint = function(shape) {
      var hits = [], p, i, j, n;
      for (i=0, n=shape ? shape.length : 0; i<n; i++) {
        p = shape[i];
        hits = lookup(p);
        for (j=0; j<hits.length; j++) {
          uniqIndex.setId(hits[j]);
        }
      }
      hits = uniqIndex.getIds();
      uniqIndex.clear();
      return hits;
    };
  }

  function getLookupFunction(index, crs, meterDist) {
    var geodetic = crs ? isLatLngCRS(crs) : false;
    var toMeter = crs && crs.to_meter || 1;
    if (geodetic) {
      return function(p) {
        // kdbush uses km
        return around(index, p[0], p[1], Infinity, meterDist / 1000);
      };
    }
    return function(p) {
      return index.within(p[0], p[1], meterDist / toMeter);
    };
  }

  function joinPointsToPoints(targetLyr, srcLyr, crs, opts) {
    var joinFunction = getPointToPointFunction(targetLyr, srcLyr, crs, opts);
    prepJoinLayers(targetLyr, srcLyr);
    return joinTableToLayer(targetLyr, srcLyr.data, joinFunction, opts);
  }

  function getPointToPointFunction(targetLyr, srcLyr, crs, opts) {
    var shapes = targetLyr.shapes;
    var index = new PointIndex(srcLyr, crs, opts);
    return function(targId) {
      var matches = index.lookupByMultiPoint(shapes[targId]);
      return matches.length > 0 ? matches : null;
    };
  }

  cmd.join = function(targetLyr, targetDataset, src, opts) {
    var srcType, targetType, retn;
    if (!src || !src.dataset) {
      stop("Missing a joinable data source");
    }
    if (opts.keys) {
      // join using data in attribute fields
      if (opts.keys.length != 2) {
        stop("Expected two key fields: a target field and a source field");
      }
      if (!src.layer.data) {
        stop("Source layer is missing attribute data");
      }
      retn = joinAttributesToFeatures(targetLyr, src.layer.data, opts);
    } else {
      // spatial join
      if (!src.layer.data) {
        // KLUDGE -- users might want to join a layer without attributes
        // to test for intersection... the simplest way to support this is
        // to add an empty data table to the source layer
        initDataTable(src.layer);
      }
      requireDatasetsHaveCompatibleCRS([targetDataset, src.dataset]);
      srcType = src.layer.geometry_type;
      targetType = targetLyr.geometry_type;
      if (srcType == 'point' && targetType == 'polygon') {
        retn = joinPointsToPolygons(targetLyr, targetDataset.arcs, src.layer, opts);
      } else if (srcType == 'polygon' && targetType == 'point') {
        retn = joinPolygonsToPoints(targetLyr, src.layer, src.dataset.arcs, opts);
      } else if (srcType == 'point' && targetType == 'point') {
        retn = joinPointsToPoints(targetLyr, src.layer, getDatasetCRS(targetDataset), opts);
      } else if (srcType == 'polygon' && targetType == 'polygon') {
        retn = joinPolygonsToPolygons(targetLyr, targetDataset, src, opts);
      } else if (srcType == 'polyline' && targetType == 'polygon') {
        retn = joinPolylinesToPolygons(targetLyr, targetDataset, src, opts);
      } else if (srcType == 'polygon' && targetType == 'polyline') {
        retn = joinPolygonsToPolylines(targetLyr, targetDataset, src, opts);
      } else {
        stop(utils.format("Unable to join %s geometry to %s geometry",
            srcType || 'null', targetType || 'null'));
      }
    }

    if (retn.unmatched) {
      targetDataset.layers.push(retn.unmatched);
    }
    if (retn.unjoined) {
      targetDataset.layers.push(retn.unjoined);
    }
  };

  function joinAttributesToFeatures(destLyr, srcTable, opts) {
    var keys = opts.keys,
        destKey = keys[0],
        srcKey = keys[1],
        destTable = destLyr.data,
        joinFunction = getJoinByKey(destTable, destKey, srcTable, srcKey);
    validateFieldNames(keys);
    return joinTableToLayer(destLyr, srcTable, joinFunction, opts);
  }

  // Return a function for translating a target id to an array of source ids based on values
  // of two key fields.
  function getJoinByKey(dest, destKey, src, srcKey) {
    if (!dest) {
      stop('Target layer is missing an attribute table');
    }
    if (!src) {
      stop('Source layer is missing an attribute table');
    }
    var destRecords = dest.getRecords();
    var srcRecords = src.getRecords();
    var index = createTableIndex(srcRecords, srcKey);
    var srcType, destType;
    if (srcRecords.length == 0) {
      // allow empty external tables
      return function(i) {return [];};
    }
    requireDataField(src, srcKey, 'External table is missing a field named:');
    requireDataField(dest, destKey, 'Target layer is missing key field:');
    srcType = getColumnType(srcKey, src.getRecords());
    destType = getColumnType(destKey, destRecords);
    validateJoinFieldType(srcKey, srcType);
    validateJoinFieldType(destKey, destType);
    if (srcType != destType) {
      stop("Join keys have mismatched data types:", destType, "and", srcType);
    }
    return function(i) {
      var destRec = destRecords[i],
          val = destRec ? destRec[destKey] : null,
          retn = null;
      if (destRec && val in index) {
        retn = index[val];
        if (!Array.isArray(retn)) retn = [retn];
      }
      return retn;
    };
  }

  function validateJoinFieldType(field, type) {
    if (!type || type == 'object') {
      stop('[' + field + '] field has an unsupported data type. Expected string or number.');
    }
  }

  function createTableIndex(records, f) {
    var index = {}, rec, key;
    for (var i=0, n=records.length; i<n; i++) {
      rec = records[i];
      key = rec[f];
      if (key in index === false) {
        index[key] = i;
      } else if (Array.isArray(index[key])) {
        index[key].push(i);
      } else {
        index[key] = [index[key], i];
      }
    }
    return index;
  }

  var Join = /*#__PURE__*/Object.freeze({
    __proto__: null,
    joinAttributesToFeatures: joinAttributesToFeatures
  });

  cmd.mosaic = function(layers, dataset, opts) {
    var lyr = layers[0];
    if (!lyr || layers.length > 1) {
      stop('Command takes a single target layer');
    }
    requirePolygonLayer(lyr);
    var nodes = addIntersectionCuts(dataset, opts);
    var mosaicIndex = new MosaicIndex(lyr, nodes, {flat: false});
    var mosaicShapes = mosaicIndex.mosaic;
    var records2;

    var lyr2 = {
      name: 'name' in lyr ? lyr.name : undefined,
      shapes: mosaicShapes,
      geometry_type: 'polygon',
    };

    if (opts.calc) {
      records2 = recombineDataRecords(lyr.data.getRecords(), mosaicIndex.getSourceIdsByTileId, mosaicShapes.length, opts);
      lyr2.data = new DataTable(records2);
    }

    return [lyr2];
  };

  cmd.polygonGrid = function(targetLayers, targetDataset, opts) {
    requireProjectedDataset(targetDataset);
    var params = getGridParams(targetLayers, targetDataset, opts);
    var gridDataset = makeGridDataset(params, opts);

    gridDataset.info = targetDataset.info; // copy CRS to grid dataset // TODO: improve
    setOutputLayerName(gridDataset.layers[0], null, 'grid', opts);
    if (opts.debug) gridDataset.layers.push(cmd.pointGrid2(targetLayers, targetDataset, opts));
    return gridDataset;
  };

  // TODO: Update -point-grid command to use this function
  cmd.pointGrid2 = function(targetLayers, targetDataset, opts) {
    var params = getGridParams(targetLayers, targetDataset, opts);
    var geojson;
    if (params.type == 'square') {
      geojson = getPointGridGeoJSON(getSquareGridCoordinates(params));
    } else if (params.type == 'hex') {
      geojson = getPointGridGeoJSON(getHexGridCoordinates(params));
    } else {
      stop('Unsupported grid type');
    }
    alignGridToBounds(geojson, params.bbox);
    var gridDataset = importGeoJSON(geojson, {});
    if (opts.name) gridDataset.layers[0].name = opts.name;
    return gridDataset.layers[0];
  };

  function makeGridDataset(params, opts) {
    var geojson, dataset;
    if (params.type == 'square') {
      geojson = getSquareGridGeoJSON(getSquareGridCoordinates(params));
    } else if (params.type == 'hex') {
      geojson = getHexGridGeoJSON(getHexGridCoordinates(params));
    } else if (params.type == 'hex2') {
      // use rotated grid
      geojson = getHexGridGeoJSON(getHexGridCoordinates(swapGridParams(params)));
      swapPolygonCoords(geojson);
    } else {
      stop('Unsupported grid type');
    }
    alignGridToBounds(geojson, params.bbox);
    dataset = importGeoJSON(geojson, {});
    buildTopology(dataset);
    return dataset;
  }

  function swapGridParams(params) {
    var bbox = params.bbox;
    return utils.defaults({
      width: params.height,
      height: params.width,
      bbox: [bbox[1], bbox[0], bbox[3], bbox[2]]
    }, params);
  }

  function swapPolygonCoords(json) {
    json.geometries.forEach(function(geom) {
      geom.coordinates[0] = geom.coordinates[0].map(function(p) {
        return [p[1], p[0]];
      });
    });
  }

  function getGridParams(layers, dataset, opts) {
    var params = {};
    var crs = dataset ? getDatasetCRS(dataset) : null;
    if (opts.interval) {
      params.interval = convertIntervalParam(opts.interval, crs);
    } else {
      stop('Missing required interval option');
    }
    if (opts.bbox) {
      params.bbox = opts.bbox;
    } else if (dataset) {
      dataset = utils.defaults({layers: layers}, dataset);
      params.bbox = getDatasetBounds(dataset).toArray();
    } else {
      stop('Missing grid bbox');
    }
    params.width = params.bbox[2] - params.bbox[0];
    params.height = params.bbox[3] - params.bbox[1];
    params.type = opts.type || 'square';
    return params;
  }

  function getPointGridGeoJSON(arr) {
    var geometries = [];
    arr.forEach(function(row) {
      row.forEach(function(xy) {
        geometries.push({
          type: 'Point',
          coordinates: xy
        });
      });
    });
    return {type: 'GeometryCollection', geometries: geometries};
  }

  function getHexGridGeoJSON(arr) {
    var geometries = [], a, b, c, d, e, f;
    var rows = arr.length - 2;
    var row, col, midOffset, evenRow;
    for (row = 0; row < rows; row++) {
      evenRow = row % 2 === 0;
      col = evenRow ? 0 : 2;
      midOffset = evenRow ? 0 : -1;
      for (; true; col += 3) {
        a = arr[row][col];
        b = arr[row + 1][col + midOffset]; // middle-left
        c = arr[row + 2][col];
        d = arr[row + 2][col + 1];
        e = arr[row + 1][col + 2 + midOffset]; // middle-right
        f = arr[row][col + 1];
        if (!d || !e) break; // end of row
        geometries.push({
          type: 'Polygon',
          coordinates: [[a, b, c, d, e, f, a]]
        });
      }
    }
    return {type: 'GeometryCollection', geometries: geometries};
  }

  function getSquareGridGeoJSON(arr) {
    var geometries = [], a, b, c, d;
    for (var row = 0, rows = arr.length - 1; row < rows; row++) {
      for (var col = 0, cols = arr[row].length - 1; col < cols; col++) {
        a = arr[row][col];
        b = arr[row + 1][col];
        c = arr[row + 1][col + 1];
        d = arr[row][col + 1];
        geometries.push({
          type: 'Polygon',
          coordinates: [[a, b, c, d, a]]
        });
      }
    }
    return {type: 'GeometryCollection', geometries: geometries};
  }

  function getHexGridCoordinates(params) {
    var xInterval = params.interval;
    var yInterval = Math.sqrt(3) * xInterval / 2;
    var xOddRowShift = xInterval / 2;
    var xmax = params.width + xInterval * 2; // width of hexagon is 2 * xInterval
    var ymax = params.height + yInterval * 2; // height of hexagon is 2 * yInterval
    var y = -yInterval;
    var rows = [];
    var x, row;
    while (y < ymax) {
      x = rows.length % 2 === 0 ? 0 : -xOddRowShift;
      row = [];
      rows.push(row);
      while (x < xmax) {
        row.push([x, y]);
        x += xInterval;
      }
      y += yInterval;
    }
    return rows;
  }

  function getSquareGridCoordinates(params) {
    var y = 0, rows = [],
        interval = params.interval,
        xmax = params.width + interval,
        ymax = params.height + interval,
        x, row;
    while (y < ymax) {
      x = 0;
      row = [];
      rows.push(row);
      while (x < xmax) {
        row.push([x, y]);
        x += interval;
      }
      y += interval;
    }
    return rows;
  }

  function alignGridToBounds(geojson, bbox) {
    var geojsonBbox = findPolygonGridBounds(geojson);
    var dx = (bbox[2] + bbox[0]) / 2 - (geojsonBbox[2] + geojsonBbox[0]) / 2;
    var dy = (bbox[3] + bbox[1]) / 2 - (geojsonBbox[3] + geojsonBbox[1]) / 2;
    shiftPolygonGrid(geojson, dx, dy);
  }

  function shiftPolygonGrid(geojson, dx, dy) {
    geojson.geometries.forEach(function(geom) {
      if (geom.type == 'Point') {
        geom.coordinates = [geom.coordinates[0] + dx, geom.coordinates[1] + dy];
      }
      if (geom.type == 'Polygon') {
        geom.coordinates[0] = geom.coordinates[0].map(function(xy) {
          return [xy[0] + dx, xy[1] + dy];
        });
      }
    });
  }

  function findPolygonGridBounds(geojson) {
    var boundsFunctions = {
      Point: pointBounds,
      Polygon: polygonBounds
    };
    return geojson.geometries.reduce(function(memo, geom) {
      var getBounds = boundsFunctions[geom.type];
      var bbox = getBounds(geom);
      if (!memo) return bbox;
      updateBounds(memo, bbox[0], bbox[1]);
      updateBounds(memo, bbox[2], bbox[3]);
      return memo;
    }, null);

    function polygonBounds(geom) {
      return geom.coordinates[0].reduce(function(bbox, p) {
        if (!bbox) return [p[0], p[1], p[0], p[1]];
        updateBounds(bbox, p[0], p[1]);
        return bbox;
      }, null);
    }

    function pointBounds(geom) {
      var p = geom.coordinates;
      return [p[0], p[1], p[0], p[1]];
    }

    function updateBounds(bbox, x, y) {
      if (x < bbox[0]) bbox[0] = x;
      if (y < bbox[1]) bbox[1] = y;
      if (x > bbox[2]) bbox[2] = x;
      if (y > bbox[3]) bbox[3] = y;
    }
  }

  cmd.pointGrid = function(dataset, opts) {
    var gridOpts = getPointGridParams(dataset, opts);
    var lyr = createPointGridLayer(createPointGrid(gridOpts), opts);
    setOutputLayerName(lyr, null, 'grid', opts);
    return lyr;
  };

  function getPointGridParams(dataset, opts) {
    var params = {};
    var crs = dataset ? getDatasetCRS(dataset) : null;
    if (opts.interval) {
      params.interval = convertIntervalParam(opts.interval, crs);
    } else if (opts.rows > 0 && opts.cols > 0) {
      params.rows = opts.rows;
      params.cols = opts.cols;
    } else {
      // error, handled later
    }
    if (opts.bbox) {
      params.bbox = opts.bbox;
    } else if (dataset) {
      params.bbox = getDatasetBounds(dataset).toArray();
    } else {
      params.bbox = [-180, -90, 180, 90];
    }
    return params;
  }

  function createPointGridLayer(rows, opts) {
    var points = [], lyr;
    rows.forEach(function(row, rowId) {
      for (var i=0; i<row.length; i++) {
        points.push([row[i]]);
      }
    });
    return {
      geometry_type: 'point',
      shapes: points
    };
  }


  // Returns a grid of [x,y] points so that point(c,r) == arr[r][c]
  function createPointGrid(opts) {
    var bbox = opts.bbox,
        w = bbox[2] - bbox[0],
        h = bbox[3] - bbox[1],
        rowsArr = [], rowArr,
        cols, rows, dx, dy, x0, y0, x, y;

    if (opts.interval > 0) {
      dx = opts.interval;
      dy = opts.interval;
      cols = Math.round(w / dx) - 1;
      rows = Math.round(h / dy) - 1;
      x0 = bbox[0] + (w - cols * dx) / 2;
      y0 = bbox[1] + (h - rows * dy) / 2;
    } else if (opts.rows > 0 && opts.cols > 0) {
      cols = opts.cols;
      rows = opts.rows;
      dx = (w / cols);
      dy = (h / rows);
      x0 = bbox[0] + dx / 2;
      y0 = bbox[1] + dy / 2;
    }

    if (dx > 0 === false || dy > 0 === false) {
      stop('Invalid grid parameters');
    }

    y = y0;
    while (y <= bbox[3]) {
      x = x0;
      rowsArr.push(rowArr = []);
      while (x <= bbox[2]) {
        rowArr.push([x, y]);
        x += dx;
      }
      y += dy;
    }
    return rowsArr;
  }

  cmd.pointToGrid = function(targetLayers, targetDataset, opts) {
    targetLayers.forEach(requirePointLayer);
    if (opts.interval > 0 === false) {
      stop('Expected a non-negative interval parameter');
    }
    if (opts.radius > 0 === false) {
      stop('Expected a non-negative radius parameter');
    }
    // var bbox = getLayerBounds(pointLyr).toArray();
    // Use target dataset, so grids are aligned between layers
    // TODO: align grids between datasets
    var bbox = getDatasetBounds(targetDataset).toArray();

    var datasets = [targetDataset];
    var outputLayers = targetLayers.map(function(pointLyr) {
      if (countMultiPartFeatures(pointLyr) > 0) {
        stop('This command requires single points');
      }
      var dataset = getPolygonDataset(pointLyr, bbox, opts);
      var gridLyr = dataset.layers[0];
      datasets.push(dataset);
      setOutputLayerName(gridLyr, pointLyr, 'grid', opts);
      return gridLyr;
    });

    var merged = mergeDatasets(datasets);
    // build topology for the entire dataset, in case the command is used on
    // multiple target layers.
    buildTopology(merged);
    targetDataset.arcs = merged.arcs;
    return outputLayers;
  };

  function getPolygonDataset(pointLyr, gridBBox, opts) {
    var interval = opts.interval;
    var points = getPointsInLayer(pointLyr);
    var grid = getGridData(gridBBox, interval);
    var lookup = getPointIndex(points, grid, opts.radius);
    var n = grid.cells();
    var geojson = {
      type: 'FeatureCollection',
      features: []
    };
    var calc = null;
    var cands, center, weight, d;
    if (opts.calc) {
      calc = getJoinCalc(pointLyr.data, opts.calc);
    }

    for (var i=0; i<n; i++) {
      cands = lookup(i);
      if (!cands.length) continue;
      center = grid.idxToPoint(i);
      d = calcCellProperties(center, cands, points, calc, opts);
      // weight = calcCellWeight(center, cands, points, opts);
      if (d.weight > 0.05 === false) continue;
      d.id = i;
      geojson.features.push({
        type: 'Feature',
        properties: d,
        geometry: makeCellPolygon(i, grid, opts)
      });
    }
    var dataset = importGeoJSON(geojson, {});
    return dataset;
  }

  function calcCellProperties(center, cands, points, calc, opts) {
    // radius of circle with same area as the cell
    var interval = opts.interval;
    var radius = interval * Math.sqrt(1 / Math.PI);
    var circleArea = Math.PI * opts.radius * opts.radius;
    var cellArea = interval * interval;
    var ids = [];
    var totArea = 0;
    var intersection;
    for (var i=0; i<cands.length; i++) {
      intersection = twoCircleIntersection(center, radius, points[cands[i]], opts.radius);
      if (intersection > 0 === false) continue;
      totArea += intersection;
      ids.push(cands[i]);
    }
    var d = {weight: totArea / cellArea};
    if (calc) {
      calc(ids, d);
    }
    return d;
  }

  // function calcCellWeight(center, ids, points, opts) {
  //   // radius of circle with same area as the cell
  //   var interval = opts.interval;
  //   var radius = interval * Math.sqrt(1 / Math.PI);
  //   var circleArea = Math.PI * opts.radius * opts.radius;
  //   var cellArea = interval * interval;
  //   var totArea = 0;
  //   for (var i=0; i<ids.length; i++) {
  //     totArea += twoCircleIntersection(center, radius, points[ids[i]], opts.radius);
  //   }
  //   return totArea / cellArea;
  // }

  // Source: https://diego.assencio.com/?index=8d6ca3d82151bad815f78addf9b5c1c6
  function twoCircleIntersection(c1, r1, c2, r2) {
    var d = distance2D(c1[0], c1[1], c2[0], c2[1]);
    if (d >= r1 + r2) return 0;
    var r1sq = r1 * r1,
        r2sq = r2 * r2,
        d1 = (r1sq - r2sq + d * d) / (2 * d),
        d2 = d - d1;
    if (d <= Math.abs(r1 - r2)) {
      return Math.PI * Math.min(r1sq, r2sq);
    }
    return r1sq * Math.acos(d1/r1) - d1 * Math.sqrt(r1sq - d1 * d1) +
      r2sq * Math.acos(d2/r2) - d2 * Math.sqrt(r2sq - d2 * d2);
  }

  function makeCellPolygon(idx, grid, opts) {
    var coords = opts.circles ?
      makeCircleCoords(grid.idxToPoint(idx), opts) :
      makeCellCoords(grid.idxToBBox(idx), opts);
    return {
      type: 'Polygon',
      coordinates: [coords]
    };
  }

  function makeCellCoords(bbox, opts) {
    var margin = opts.interval * (opts.cell_margin || 0);
    var a = bbox[0] + margin,
        b = bbox[1] + margin,
        c = bbox[2] - margin,
        d = bbox[3] - margin;
    return [[a, b],[a, d],[c, d],[c, b],[a, b]];
  }

  function makeCircleCoords(center, opts) {
    var margin = opts.cell_margin > 0 ? opts.cell_margin : 1e-6;
    var radius = opts.interval / 2 * (1 - margin);
    return getPointBufferCoordinates(center, radius, 20, getPlanarSegmentEndpoint);
  }

  function getPointIndex(points, grid, radius) {
    var Flatbush = require('flatbush');
    var gridIndex = new IdTestIndex(grid.cells());
    var bboxIndex = new Flatbush(points.length);
    var empty = [];
    points.forEach(function(p) {
      addPointToGridIndex(p, gridIndex, grid);
      bboxIndex.add.apply(bboxIndex, getPointBounds(p, radius));
    });
    bboxIndex.finish();
    return function(i) {
      if (!gridIndex.hasId(i)) return empty;
      var bbox = grid.idxToBBox(i);
      return bboxIndex.search.apply(bboxIndex, bbox);
    };
  }

  function addPointToGridIndex(p, index, grid) {
    var i = grid.pointToIdx(p);
    var c = grid.idxToCol(i);
    var r = grid.idxToRow(i);
    addCellToGridIndex(c+1, r+1, grid, index);
    addCellToGridIndex(c+1, r, grid, index);
    addCellToGridIndex(c+1, r-1, grid, index);
    addCellToGridIndex(c, r+1, grid, index);
    addCellToGridIndex(c, r, grid, index);
    addCellToGridIndex(c, r-1, grid, index);
    addCellToGridIndex(c-1, r+1, grid, index);
    addCellToGridIndex(c-1, r, grid, index);
    addCellToGridIndex(c-1, r-1, grid, index);
  }

  function addCellToGridIndex(c, r, grid, index) {
    var i = grid.colRowToIdx(c, r);
    if (i > -1) index.setId(i);
  }

  // TODO: support spherical coords
  function getPointBounds(p, radius) {
    return [p[0] - radius, p[1] - radius, p[0] + radius, p[1] + radius];
  }

  function getGridInterpolator(bbox, interval) {
    var sparseArr = [];
    var grid = getGridData(bbox, interval);

  }

  // TODO: put this in a separate file, use it for other grid-based commands
  // like -dots
  function getGridData(bbox, interval) {
    var xmin = bbox[0] - interval;
    var ymin = bbox[1] - interval;
    var xmax = bbox[2] + interval;
    var ymax = bbox[3] + interval;
    var w = xmax - xmin;
    var h = ymax - ymin;
    var cols = Math.ceil(w / interval);
    var rows = Math.ceil(h / interval);
    function size() {
      return [cols, rows];
    }
    function cells() {
      return cols * rows;
    }
    function pointToCol(xy) {
      var dx = xy[0] - xmin;
      return Math.floor(dx / w * cols);
    }
    function pointToRow(xy) {
      var dy = xy[1] - ymin;
      return Math.floor(dy / h * rows);
    }
    function colRowToIdx(c, r) {
      if (c < 0 || r < 0 || c >= cols || r >= rows) return -1;
      return r * cols + c;
    }
    function pointToIdx(xy) {
      var c = pointToCol(xy);
      var r = pointToRow(xy);
      return colRowToIdx(c, r);
    }
    function idxToCol(i) {
      return i % cols;
    }
    function idxToRow(i) {
      return Math.floor(i / cols);
    }
    function idxToPoint(idx) {
      var x = xmin + (idxToCol(idx) + 0.5) * interval;
      var y = ymin + (idxToRow(idx) + 0.5) * interval;
      return [x, y];
    }
    function idxToBBox(idx) {
      var c = idxToCol(idx);
      var r = idxToRow(idx);
      return [
        xmin + c * interval, ymin + r * interval,
        xmin + (c + 1) * interval, ymin + (r + 1) * interval
      ];
    }
    return {
      size, cells, pointToCol, pointToRow, colRowToIdx, pointToIdx,
      idxToCol, idxToRow, idxToBBox, idxToPoint
    };
  }

  function closeUndershoots(lyr, dataset, opts) {
    var maxGapLen = opts.gap_tolerance ? convertIntervalParam(opts.gap_tolerance, getDatasetCRS(dataset)) : 0;
    var arcs = dataset.arcs;
    var arcFilter = getArcPresenceTest(lyr.shapes, arcs);
    var nodes = new NodeCollection(dataset.arcs, arcFilter);
    var dangles = findPotentialUndershoots(nodes, maxGapLen);
    if (dangles.length === 0) return nodes;
    var arcShapes = arcsToShapes(arcs, arcFilter);
    var index = new PathIndex(arcShapes, arcs);
    var extensions = dangles.reduce(function(memo, dangle) {
      var candidates = index.findPointEnclosureCandidates(dangle.point, maxGapLen);
      var nearestHit = findUndershootTarget(dangle, candidates, arcs, maxGapLen);
      if (nearestHit) {
        memo.push(getArcExtension(nearestHit, dangle.arc, arcs));
      }
      return memo;
    }, []);

    // TODO: consider alternative: append small patch arcs to paths instead of shifting endpoints
    dataset.arcs = insertArcExtensions(arcs, extensions);
    return addIntersectionCuts(dataset, {});
  }

  // Return information about an arc that @endpoint can connect with to close a gap
  // @candidates: array of ids of possible target arcs
  function findUndershootTarget(endpoint, candidates, arcs, maxGapLen) {
    var absId = absArcId(endpoint.arc);
    var target = null;
    candidates.forEach(function(candId) {
      var hit;
      if (candId == absId) return; // ignore self-intersections
      hit = geom.getPointToPathInfo(endpoint.point[0], endpoint.point[1], [candId], arcs);
      if (hit && hit.distance <= maxGapLen && (!target || hit.distance < target.distance)) {
        target = hit;
      }
    });
    return target;
  }


  // Create a polyline shape for each arc in an ArcCollection
  function arcsToShapes(arcs, filter) {
    var shapes = [];
    for (var i=0, n=arcs.size(); i<n; i++) {
      shapes.push(filter(i) ? [[i]] : null);
    }
    return shapes;
  }

  // Find unconnected (dangling) arcs that don't look like overshoots
  function findPotentialUndershoots(nodes, maxLen) {
    return nodes.findDanglingEndpoints().filter(function(o) {
      return geom.calcPathLen([o.arc], nodes.arcs) > maxLen;
    });
  }

  function insertArcExtensions(arcs, extensions) {
    var data = arcs.getVertexData();
    extensions.forEach(function(obj) {
      var i = arcs.indexOfVertex(obj.arc, -1);
      data.xx[i] = obj.point[0];
      data.yy[i] = obj.point[1];
    });

    // re-index arc bounds
    arcs.updateVertexData(data.nn, data.xx, data.yy, data.zz);
    return arcs;
  }

  function chooseCloserPoint(p, a, b) {
    return geom.distance2D(p[0], p[1], a[0], a[1]) < geom.distance2D(p[0], p[1], b[0], b[1]) ? a : b;
  }

  function pointIsEndpoint(p, a, b) {
    return p[0] == a[0] && p[1] == a[1] || p[0] == b[0] && p[1] == b[1];
  }

  // move point <b> a bit farther away from <a>
  function addTinyOvershoot(a, b) {
    var dist = geom.distance2D(a[0], a[1], b[0], b[1]);
    var k = (dist + 1e-6) / dist;
    return [a[0] + k * (b[0] - a[0]), a[1] + k * (b[1] - a[1])];
  }

  function getArcExtension(hit, arcId, arcs) {
    var v0 = arcs.getVertex(arcId, -1),
        endPtOld = [v0.x, v0.y],
        v1 = arcs.getVertex(arcId, -2),
        p1 = [v1.x, v1.y],
        s1 = hit.segment[0],
        s2 = hit.segment[1],
        endPtNew = geom.findClosestPointOnSeg(endPtOld[0], endPtOld[1], s1[0], s1[1], s2[0], s2[1]);
    if (!pointIsEndpoint(endPtNew, s1, s2)) {
      // add small overshoot if new endpoint is not a vertex, to make sure intersection
      // is correctly detected later
      endPtNew = addTinyOvershoot(p1, endPtNew);
      // handle floating point rounding errors by snapping to a segment endpoint
      if (!geom.segmentIntersection(p1[0], p1[1], endPtNew[0], endPtNew[1], s1[0], s1[1], s2[0], s2[1])) {
        endPtNew = chooseCloserPoint(p1, s1, s2);
      }
      // TODO: test edge cases; moving the endpoint of a dangling arc could create
      //   invalid geometry, e.g. duplicate points
    }
    return {
      arc: arcId,
      point: endPtNew
    };
  }

  cmd.polygons = function(layers, dataset, opts) {
    layers.forEach(requirePolylineLayer);
    // use larger-than-default snapping in addIntersectionCuts()
    // (kludge, snaps together some almost-identical pairs of lines in ne_10m_land_ocean_seams.shp)
    // if (opts.gap_tolerance) {
      //opts = utils.defaults({snap_interval: opts.gap_tolerance * 0.1}, opts);
    // }
    addIntersectionCuts(dataset, opts);
    return layers.map(function(lyr) {
      if (lyr.geometry_type != 'polyline') stop("Expected a polyline layer");
      if (opts.from_rings) {
        return createPolygonLayerFromRings(lyr, dataset);
      }
      return createPolygonLayer(lyr, dataset, opts);
    });
  };

  // Convert a polyline layer of rings to a polygon layer
  function createPolygonLayerFromRings(lyr, dataset) {
    var arcs = dataset.arcs;
    var openCount = 0;
    editShapes(lyr.shapes, function(part) {
      if (geom.pathIsClosed(part, arcs)) {
        return part;
      }
      openCount++;
      return null;
    });
    if (openCount > 0) {
      message('Removed', openCount, 'open ' + (openCount == 1 ? 'ring' : 'rings'));
    }
    lyr.geometry_type = 'polygon';
    rewindPolygons(lyr, arcs);
    return lyr;
  }

  function createPolygonLayer(lyr, dataset, opts) {
    var nodes = closeUndershoots(lyr, dataset, opts);
    var data = buildPolygonMosaic(nodes);
    return {
      geometry_type: 'polygon',
      name: lyr.name,
      shapes: data.mosaic
    };
  }

  cmd.renameLayers = function(layers, names, catalog) {
    if (names && names.join('').indexOf('=') > -1) {
      renameByAssignment(names, catalog);
    } else {
      renameTargetLayers(names, layers);
    }
  };

  function renameByAssignment(names, catalog) {
    var index = mapLayerNames(names);
    catalog.forEachLayer(function(lyr) {
      if (index[lyr.name]) {
        lyr.name = index[lyr.name];
      }
    });
  }

  function renameTargetLayers(names, layers) {
    var nameCount = names && names.length || 0;
    var name = '';
    var suffix = '';
    layers.forEach(function(lyr, i) {
      if (i < nameCount) {
        name = names[i];
      }
      if (name && nameCount < layers.length && (i >= nameCount - 1)) {
        suffix = (suffix || 0) + 1;
      }
      lyr.name = name + suffix;
    });
  }

  // TODO: remove duplication with mapFieldNames()
  function mapLayerNames(names) {
    return (names || []).reduce(function(memo, str) {
      var parts = str.split('='),
          dest = utils.trimQuotes(parts[0]),
          src = utils.trimQuotes(parts[1] || '');
      if (!src) stop("Invalid name assignment:", str);
      memo[src] = dest;
      return memo;
    }, {});
  }

  // Parse an array or a string of command line tokens into an array of
  // command objects.
  function parseCommands(tokens) {
    if (Array.isArray(tokens) && utils.isObject(tokens[0])) {
      // argv seems to contain parsed commands already... make a copy
      return tokens.map(function(cmd) {
        return {name: cmd.name, options: Object.assign({}, cmd.options)};
      });
    }
    if (utils.isString(tokens)) {
      tokens = splitShellTokens(tokens);
    }
    return getOptionParser().parseArgv(tokens);
  }

  function standardizeConsoleCommands(raw) {
    var str = raw.replace(/^mapshaper\b/, '').trim();
    var parser = getOptionParser();
    // support multiline string of commands pasted into console
    str = str.split(/\n+/g).map(function(str) {
      var match = /^[a-z][\w-]*/.exec(str = str.trim());
      if (match && parser.isCommandName(match[0])) {
        str = '-' + str; // add hyphen prefix to bare command
      }
      return str;
    }).join(' ');
    return str;
  }

  // Parse a command line string for the browser console
  function parseConsoleCommands(raw) {
    var blocked = ['i', 'include', 'require', 'external'];
    var str = standardizeConsoleCommands(raw);
    var parsed;
    parsed = parseCommands(str);
    parsed.forEach(function(cmd) {
      var i = blocked.indexOf(cmd.name);
      if (i > -1) {
        stop("The -" + blocked[i] + " command cannot be run in the browser");
      }
    });
    return parsed;
  }

  var ParseCommands = /*#__PURE__*/Object.freeze({
    __proto__: null,
    parseCommands: parseCommands,
    standardizeConsoleCommands: standardizeConsoleCommands,
    parseConsoleCommands: parseConsoleCommands
  });

  cmd.run = function(targets, catalog, opts, cb) {
    var commandStr, commands;
    if (opts.include) {
      cmd.include({file: opts.include});
    }
    if (!opts.commands) {
      stop("Missing commands parameter");
    }
    commandStr = runGlobalExpression(opts.commands, targets);
    if (commandStr) {
      commands = parseCommands(commandStr);
      runParsedCommands(commands, catalog, cb);
    } else {
      cb(null);
    }
  };

  function runGlobalExpression(expression, targets) {
    var ctx = getBaseContext();
    var output, targetData;
    // TODO: throw an informative error if target is used when there are multiple targets
    if (targets.length == 1) {
      targetData = getRunCommandData(targets[0]);
      Object.defineProperty(ctx, 'target', {value: targetData});
    }
    utils.extend(ctx, getStateVar('defs'));
    try {
      output = Function('ctx', 'with(ctx) {return (' + expression + ');}').call({}, ctx);
    } catch(e) {
      stop(e.name, 'in JS source:', e.message);
    }
    return output;
  }


  function getRunCommandData(target) {
    var lyr = target.layers[0];
    var data = getLayerData(lyr, target.dataset);
    data.layer = lyr;
    data.dataset = target.dataset;
    return data;
  }

  cmd.require = function(targets, opts) {
    var defs = getStateVar('defs');
    var moduleFile, moduleName, mod;
    if (!opts.module) {
      stop("Missing module name or path to module");
    }
    if (cli.isFile(opts.module)) {
      moduleFile = opts.module;
    } else if (cli.isFile(opts.module + '.js')) {
      moduleFile = opts.module + '.js';
    } else {
      moduleName = opts.module;
    }
    if (moduleFile) {
      moduleFile = require('path').join(process.cwd(), moduleFile);
    }
    try {
      mod = require(moduleFile || moduleName);
    } catch(e) {
      stop(e);
    }
    if (moduleName || opts.alias) {
      defs[opts.alias || moduleName] = mod;
    } else {
      Object.assign(defs, mod);
    }
    if (opts.init) {
      runGlobalExpression(opts.init, targets);
    }
  };

  symbolRenderers.circle = function(d, x, y) {
    var o = importPoint([x, y], d, {});
    applyStyleAttributes(o, 'Point', d);
    return [o];
  };

  symbolRenderers.label = function(d, x, y) {
    var o = importStyledLabel(d, [x, y]);
    return [o];
  };

  symbolRenderers.image = function(d, x, y) {
    var w = d.width || 20,
        h = d.height || 20;
    var o = {
      tag: 'image',
      properties: {
        width: w,
        height: h,
        x: x - w / 2,
        y: y - h / 2,
        href: d.href || ''
      }
    };
    return [o];
  };

  symbolRenderers.square = function(d, x, y) {
    var o = importPoint([x, y], d, {point_symbol: 'square'});
    applyStyleAttributes(o, 'Point', d);
    return [o];
  };

  symbolRenderers.line = function(d, x, y) {
    var coords, o;
    coords = [[x, y], [x + (d.dx || 0), y + (d.dy || 0)]];
    o = importLineString(coords);
    applyStyleAttributes(o, 'LineString', d);
    return [o];
  };

  symbolRenderers.polyline = function(d, x, y) {
    var coords = d.coordinates || [];
    var o = importMultiLineString(coords);
    applyStyleAttributes(o, 'LineString', d);
    return [o];
  };

  symbolRenderers.polygon = function(d, x, y) {
    var coords = d.coordinates || [];
    var o = importPolygon(coords);
    applyStyleAttributes(o, 'Polygon', d);
    return [o];
  };

  symbolRenderers.group = function(d, x, y) {
    return (d.parts || []).reduce(function(memo, o) {
      var sym = renderSymbol(o, x, y);
      if (d.chained) {
        x += (o.dx || 0);
        y += (o.dy || 0);
      }
      return memo.concat(sym);
    }, []);
  };

  cmd.scalebar = function(catalog, opts) {
    var frame = findFrameDataset(catalog);
    var obj, lyr;
    if (!frame) {
      stop('Missing a map frame');
    }
    obj = utils.defaults({type: 'scalebar'}, opts);
    lyr = {
      name: opts.name || 'scalebar',
      data: new DataTable([obj])
    };
    frame.layers.push(lyr);
  };

  // TODO: generalize to other kinds of furniture as they are developed
  function getScalebarPosition(d) {
    var opts = { // defaults
      valign: 'top',
      halign: 'left',
      voffs: 10,
      hoffs: 10
    };
    if (+d.left > 0) {
      opts.hoffs = +d.left;
    }
    if (+d.top > 0) {
      opts.voffs = +d.top;
    }
    if (+d.right > 0) {
      opts.hoffs = +d.right;
      opts.halign = 'right';
    }
    if (+d.bottom > 0) {
      opts.voffs = +d.bottom;
      opts.valign = 'bottom';
    }
    return opts;
  }

  furnitureRenderers.scalebar = function(d, frame) {
    var pos = getScalebarPosition(d);
    var metersPerPx = getMapFrameMetersPerPixel(frame);
    var label = d.label_text || getAutoScalebarLabel(frame.width, metersPerPx);
    var scalebarKm = parseScalebarLabelToKm(label);
    var barHeight = 3;
    var labelOffs = 4;
    var fontSize = +d.font_size || 13;
    var width = Math.round(scalebarKm / metersPerPx * 1000);
    var height = Math.round(barHeight + labelOffs + fontSize * 0.8);
    var labelPos = d.label_position == 'top' ? 'top' : 'bottom';
    var anchorX = pos.halign == 'left' ? 0 : width;
    var anchorY = barHeight + labelOffs;
    var dx = pos.halign == 'right' ? frame.width - width - pos.hoffs : pos.hoffs;
    var dy = pos.valign == 'bottom' ? frame.height - height - pos.voffs : pos.voffs;

    if (labelPos == 'top') {
      anchorY = -labelOffs;
      dy += Math.round(labelOffs + fontSize * 0.8);
    }

    if (width > 0 === false) {
      stop("Null scalebar length");
    }
    var barObj = {
      tag: 'rect',
      properties: {
        fill: 'black',
        x: 0,
        y: 0,
        width: width,
        height: barHeight
      }
    };
    var labelOpts = {
        'label-text': label,
        'font-size': fontSize,
        'text-anchor': pos.halign == 'left' ? 'start': 'end',
        'dominant-baseline': labelPos == 'top' ? 'auto' : 'hanging'
        //// 'dominant-baseline': labelPos == 'top' ? 'text-after-edge' : 'text-before-edge'
        // 'text-after-edge' is buggy in Safari and unsupported by Illustrator,
        // so I'm using 'hanging' and 'auto', which seem to be well supported.
        // downside: requires a kludgy multiplier to calculate scalebar height (see above)
      };
    var labelObj = symbolRenderers.label(labelOpts, anchorX, anchorY)[0];
    var g = {
      tag: 'g',
      children: [barObj, labelObj],
      properties: {
        transform: 'translate(' + dx + ' ' + dy + ')'
      }
    };
    return [g];
  };

  function getAutoScalebarLabel(mapWidth, metersPerPx) {
    var minWidth = 100; // TODO: vary min size based on map width
    var minKm = metersPerPx * minWidth / 1000;
    var options = ('1/8 1/5 1/4 1/2 1 1.5 2 3 4 5 8 10 12 15 20 25 30 40 50 75 ' +
      '100 150 200 250 300 350 400 500 750 1,000 1,200 1,500 2,000 ' +
      '2,500 3,000 4,000 5,000').split(' ');
    return options.reduce(function(memo, str) {
      if (memo) return memo;
      var label = formatDistanceLabelAsMiles(str);
      if (parseScalebarLabelToKm(label) > minKm) {
         return label;
      }
    }, null) || '';
  }

  function formatDistanceLabelAsMiles(str) {
    var num = parseScalebarNumber(str);
    return str + (num > 1 ? ' MILES' : ' MILE');
  }

  // See test/mapshaper-scalebar.js for examples of supported formats
  function parseScalebarLabelToKm(str) {
    var units = parseScalebarUnits(str);
    var value = parseScalebarNumber(str);
    if (!units || !value) return NaN;
    return units == 'mile' ? value * 1.60934 : value;
  }

  function parseScalebarUnits(str) {
    var isMiles = /miles?$/.test(str.toLowerCase());
    var isKm = /(km|kilometers?|kilometres?)$/.test(str.toLowerCase());
    return isMiles && 'mile' || isKm && 'km' || '';
  }

  function parseScalebarNumber(str) {
    var fractionRxp = /^([0-9]+) ?\/ ?([0-9]+)/;
    var match, value;
    str = str.replace(/[\s]/g, '').replace(/,/g, '');
    if (fractionRxp.test(str)) {
      match = fractionRxp.exec(str);
      value = +match[1] / +match[2];
    } else {
      value = parseFloat(str);
    }
    return value > 0 && value < Infinity ? value : NaN;
  }

  var Scalebar = /*#__PURE__*/Object.freeze({
    __proto__: null,
    formatDistanceLabelAsMiles: formatDistanceLabelAsMiles,
    parseScalebarLabelToKm: parseScalebarLabelToKm
  });

  cmd.shape = function(targetDataset, opts) {
    var geojson, dataset;
    if (opts.coordinates) {
      geojson = makeShapeFromCoords(opts);
    } else if (opts.type == 'circle') {
      geojson = makeCircle(opts);
    } else if (opts.type == 'rectangle' && opts.bbox) {
      geojson = getRectangleGeoJSON(opts);
    } else {
      stop('Missing coordinates parameter');
    }
    // TODO: project shape if targetDataset is projected
    dataset = importGeoJSON(geojson, {});
    if (opts.rotation) {
      rotateDatasetCoords(dataset, opts.rotation);
    }
    dataset.layers[0].name = opts.name || opts.type || 'shape';
    return dataset;
  };

  function getRectangleGeoJSON(opts) {
    var bbox = opts.bbox,
        xmin = bbox[0],
        ymin = bbox[1],
        xmax = bbox[2],
        ymax = bbox[3],
        interval = 0.5,
        coords = [],
        type = opts.geometry == 'polyline' ? 'LineString' : 'Polygon';
    addSide(xmin, ymin, xmin, ymax);
    addSide(xmin, ymax, xmax, ymax);
    addSide(xmax, ymax, xmax, ymin);
    addSide(xmax, ymin, xmin, ymin);
    coords.push([xmin, ymin]);
    return {
      type: type,
      coordinates: type == 'Polygon' ? [coords] : coords
    };

    function addSide(x1, y1, x2, y2) {
      var dx = x2 - x1,
          dy = y2 - y1,
          n = Math.ceil(Math.max(Math.abs(dx) / interval, Math.abs(dy) / interval)),
          xint = dx / n,
          yint = dy / n;
      for (var i=0; i<n; i++) {
        coords.push([x1 + i * xint, y1 + i * yint]);
      }
    }
  }

  function makeCircle(opts) {
    if (opts.radius > 0 === false && opts.radius_angle > 0 === false) {
      stop('Missing required radius parameter.');
    }
    var cp = opts.center || [0, 0];
    var radius = opts.radius || getCircleRadiusFromAngle(getCRS('wgs84'), opts.radius_angle);
    return getCircleGeoJSON(cp, radius, null, {geometry_type : opts.geometry || 'polygon'});
  }

  function makeShapeFromCoords(opts) {
    var coordinates = [];
    var offsets = opts.offsets || [];
    var coords = opts.coordinates;
    var type, i, x, y;
    if (coords.length >= 2 === false) {
      stop('Invalid coordinates parameter.');
    }
    for (i=0; i<coords.length; i+= 2) {
      x = coords[i];
      y = coords[i + 1];
      coordinates.push([x, y]);
    }
    for (i=0; i<offsets.length; i+=2) {
      x += offsets[i];
      y += offsets[i + 1];
      coordinates.push([x, y]);
    }
    if (GeoJSON.pathIsRing(coordinates)) {
      type = 'Polygon';
    } else if (opts.closed && coordinates.length >= 3) {
      type = 'Polygon';
      coordinates.push(coordinates[0]);
    } else {
      type = 'LineString';
    }
    return {
      type: type,
      coordinates: type == 'Polygon' ? [coordinates] : coordinates
    };

  }

  function calcSimplifyStats(arcs, use3D) {
    var distSq = use3D ? pointSegGeoDistSq : geom.pointSegDistSq,
        calcAngle = use3D ? geom.signedAngleSph : geom.signedAngle,
        removed = 0,
        retained = 0,
        collapsedRings = 0,
        max = 0,
        sum = 0,
        sumSq = 0,
        iprev = -1,
        jprev = -1,
        measures = [],
        angles = [],
        zz = arcs.getVertexData().zz,
        count, stats;

    arcs.forEachSegment(function(i, j, xx, yy) {
      var ax, ay, bx, by, d2, d, skipped, angle, tmp;
      ax = xx[i];
      ay = yy[i];
      bx = xx[j];
      by = yy[j];

      if (i == jprev) {
        angle = calcAngle(xx[iprev], yy[iprev], ax, ay, bx, by);
        if (angle > Math.PI) angle = 2 * Math.PI - angle;
        if (!isNaN(angle)) {
          angles.push(angle * 180 / Math.PI);
        }
      }
      iprev = i;
      jprev = j;

      if (zz[i] < Infinity) {
        retained++;
      }
      skipped = j - i - 1;
      if (skipped < 1) return;
      removed += skipped;

      if (ax == bx && ay == by) {
        collapsedRings++;
      } else {
        d2 = 0;
        while (++i < j) {
          tmp = distSq(xx[i], yy[i], ax, ay, bx, by);
          d2 = Math.max(d2, tmp);
        }
        sumSq += d2;
        d = Math.sqrt(d2);
        sum += d;
        measures.push(d);
        max = Math.max(max, d);
      }
    });

    function pointSegGeoDistSq(alng, alat, blng, blat, clng, clat) {
      var xx = [], yy = [], zz = [];
      geom.convLngLatToSph([alng, blng, clng], [alat, blat, clat], xx, yy, zz);
      return geom.pointSegDistSq3D(xx[0], yy[0], zz[0], xx[1], yy[1], zz[1],
            xx[2], yy[2], zz[2]);
    }

    stats = {
      angleMean: 0,
      displacementMean: 0,
      displacementMax: max,
      collapsedRings: collapsedRings,
      removed: removed,
      retained: retained,
      uniqueCount: countUniqueVertices(arcs),
      removableCount: removed + retained
    };

    if (angles.length > 0) {
      // stats.medianAngle = utils.findMedian(angles);
      stats.angleMean = utils.sum(angles) / angles.length;
      // stats.lt30 = utils.findRankByValue(angles, 30) / angles.length * 100;
      // stats.lt45 = utils.findRankByValue(angles, 45) / angles.length * 100;
      // stats.lt60 = utils.findRankByValue(angles, 60) / angles.length * 100;
      // stats.lt90 = utils.findRankByValue(angles, 90) / angles.length * 100;
      // stats.lt120 = utils.findRankByValue(angles, 120) / angles.length * 100;
      // stats.lt135 = utils.findRankByValue(angles, 135) / angles.length * 100;
      stats.angleQuartiles = [
        utils.findValueByPct(angles, 0.75),
        utils.findValueByPct(angles, 0.5),
        utils.findValueByPct(angles, 0.25)
      ];
    }

    if (measures.length > 0) {
      stats.displacementMean = sum / measures.length;
      // stats.median = utils.findMedian(measures);
      // stats.stdDev = Math.sqrt(sumSq / measures.length);
      stats.displacementQuartiles = [
        utils.findValueByPct(measures, 0.75),
        utils.findValueByPct(measures, 0.5),
        utils.findValueByPct(measures, 0.25)
      ];
    }
    return stats;
  }

  function countUniqueVertices(arcs) {
    // TODO: exclude any zero-length arcs
    var endpoints = arcs.size() * 2;
    var nodes = new NodeCollection(arcs).size();
    return arcs.getPointCount() - endpoints + nodes;
  }

  var Visvalingam = {};

  Visvalingam.getArcCalculator = function(metric, is3D) {
    var heap = new Heap(),
        prevBuf = utils.expandoBuffer(Int32Array),
        nextBuf = utils.expandoBuffer(Int32Array),
        calc = is3D ?
          function(b, c, d, xx, yy, zz) {
            return metric(xx[b], yy[b], zz[b], xx[c], yy[c], zz[c], xx[d], yy[d], zz[d]);
          } :
          function(b, c, d, xx, yy) {
            return metric(xx[b], yy[b], xx[c], yy[c], xx[d], yy[d]);
          };

    // Calculate Visvalingam simplification data for an arc
    // @kk (Float64Array|Array) Receives calculated simplification thresholds
    // @xx, @yy, (@zz) Buffers containing vertex coordinates
    return function calcVisvalingam(kk, xx, yy, zz) {
      var arcLen = kk.length,
          prevArr = prevBuf(arcLen),
          nextArr = nextBuf(arcLen),
          val, maxVal = -Infinity,
          b, c, d; // indexes of points along arc

      if (zz && !is3D) {
        error("[visvalingam] Received z-axis data for 2D simplification");
      } else if (!zz && is3D) {
        error("[visvalingam] Missing z-axis data for 3D simplification");
      } else if (kk.length > xx.length) {
        error("[visvalingam] Incompatible data arrays:", kk.length, xx.length);
      }

      // Initialize Visvalingam "effective area" values and references to
      //   prev/next points for each point in arc.
      for (c=0; c<arcLen; c++) {
        b = c-1;
        d = c+1;
        if (b < 0 || d >= arcLen) {
          val = Infinity; // endpoint maxVals
        } else {
          val = calc(b, c, d, xx, yy, zz);
        }
        kk[c] = val;
        nextArr[c] = d;
        prevArr[c] = b;
      }
      heap.init(kk);

      // Calculate removal thresholds for each internal point in the arc
      //
      while (heap.size() > 0) {
        c = heap.pop(); // Remove the point with the least effective area.
        val = kk[c];
        if (val === Infinity) {
          break;
        }
        if (val < maxVal) {
          // don't assign current point a lesser value than the last removed vertex
          kk[c] = maxVal;
        } else {
          maxVal = val;
        }

        // Recompute effective area of neighbors of the removed point.
        b = prevArr[c];
        d = nextArr[c];
        if (b > 0) {
          val = calc(prevArr[b], b, d, xx, yy, zz);
          heap.updateValue(b, val);
        }
        if (d < arcLen-1) {
          val = calc(b, d, nextArr[d], xx, yy, zz);
          heap.updateValue(d, val);
        }
        nextArr[b] = d;
        prevArr[d] = b;
      }
    };
  };

  Visvalingam.standardMetric = geom.triangleArea;
  Visvalingam.standardMetric3D = geom.triangleArea3D;

  Visvalingam.getWeightedMetric = function(opts) {
    var weight = Visvalingam.getWeightFunction(opts);
    return function(ax, ay, bx, by, cx, cy) {
      var area = geom.triangleArea(ax, ay, bx, by, cx, cy),
          cos = geom.cosine(ax, ay, bx, by, cx, cy);
      return weight(cos) * area;
    };
  };

  Visvalingam.getWeightedMetric3D = function(opts) {
    var weight = Visvalingam.getWeightFunction(opts);
    return function(ax, ay, az, bx, by, bz, cx, cy, cz) {
      var area = geom.triangleArea3D(ax, ay, az, bx, by, bz, cx, cy, cz),
          cos = geom.cosine3D(ax, ay, az, bx, by, bz, cx, cy, cz);
      return weight(cos) * area;
    };
  };

  Visvalingam.getWeightCoefficient = function(opts) {
    return opts && utils.isNumber(opts && opts.weighting) ? opts.weighting : 0.7;
  };

  // Get a parameterized version of Visvalingam.weight()
  Visvalingam.getWeightFunction = function(opts) {
    var k = Visvalingam.getWeightCoefficient(opts);
    return function(cos) {
      return -cos * k + 1;
    };
  };

  // Weight triangle area by inverse cosine
  // Standard weighting favors 90-deg angles; this curve peaks at 120 deg.
  Visvalingam.weight = function(cos) {
    var k = 0.7;
    return -cos * k + 1;
  };

  Visvalingam.getEffectiveAreaSimplifier = function(use3D) {
    var metric = use3D ? Visvalingam.standardMetric3D : Visvalingam.standardMetric;
    return Visvalingam.getPathSimplifier(metric, use3D);
  };

  Visvalingam.getWeightedSimplifier = function(opts, use3D) {
    var metric = use3D ? Visvalingam.getWeightedMetric3D(opts) : Visvalingam.getWeightedMetric(opts);
    return Visvalingam.getPathSimplifier(metric, use3D);
  };

  Visvalingam.getPathSimplifier = function(metric, use3D) {
    return Visvalingam.scaledSimplify(Visvalingam.getArcCalculator(metric, use3D));
  };


  Visvalingam.scaledSimplify = function(f) {
    return function(kk, xx, yy, zz) {
      f(kk, xx, yy, zz);
      for (var i=1, n=kk.length - 1; i<n; i++) {
        // convert area metric to a linear equivalent
        kk[i] = Math.sqrt(kk[i]) * 0.65;
      }
    };
  };

  function getSimplifyMethodLabel(slug) {
    return {
      dp: "Ramer-Douglas-Peucker",
      visvalingam: "Visvalingam",
      weighted_visvalingam: "Weighted Visvalingam"
    }[slug] || "Unknown";
  }

  function printSimplifyInfo(arcs, opts) {
    var method = getSimplifyMethod(opts);
    var name = getSimplifyMethodLabel(method);
    var spherical = useSphericalSimplify(arcs, opts);
    var stats = calcSimplifyStats(arcs, spherical);
    var pct1 = (stats.removed + stats.collapsedRings) / stats.uniqueCount || 0;
    var pct2 = stats.removed / stats.removableCount || 0;
    var aq = stats.angleQuartiles;
    var dq = stats.displacementQuartiles;
    var lines = ["Simplification statistics"];
    lines.push(utils.format("Method: %s (%s) %s", name, spherical ? 'spherical' : 'planar',
        method == 'weighted_visvalingam' ? '(weighting=' + Visvalingam.getWeightCoefficient(opts) + ')' : ''));
    lines.push(utils.format("Removed vertices: %,d", stats.removed + stats.collapsedRings));
    lines.push(utils.format("   %.1f% of %,d unique coordinate locations", pct1 * 100, stats.uniqueCount));
    lines.push(utils.format("   %.1f% of %,d filterable coordinate locations", pct2 * 100, stats.removableCount));
    lines.push(utils.format("Simplification threshold: %.4f %s", arcs.getRetainedInterval(),
        spherical ? 'meters' : ''));
    lines.push(utils.format("Collapsed rings: %,d", stats.collapsedRings));
    lines.push("Displacement statistics");
    lines.push(utils.format("   Mean displacement: %.4f", stats.displacementMean));
    lines.push(utils.format("   Max displacement: %.4f", stats.displacementMax));
    if (dq) {
      lines.push(utils.format("   Quartiles: %.2f, %.2f, %.2f", dq[0], dq[1], dq[2]));
    }
    lines.push("Vertex angle statistics");
    lines.push(utils.format("   Mean angle: %.2f degrees", stats.angleMean));
    // lines.push(utils.format("   Angles < 45: %.2f%", stats.lt45));
    if (aq) {
      lines.push(utils.format("   Quartiles: %.2f, %.2f, %.2f", aq[0], aq[1], aq[2]));
    }

    message(lines.join('\n   '));
  }

  // Remove line-segment intersections introduced by simplification by rolling
  // back simplification along intersecting segments.
  //
  // Limitation of this method: it can't remove intersections that are present
  // in the original dataset.
  // TODO: don't roll back simplification for unrepairable intersections.
  //
  function postSimplifyRepair(arcs) {
    var intersections = findSegmentIntersections(arcs),
        unfixable = repairIntersections(arcs, intersections),
        countPre = intersections.length,
        countPost = unfixable.length,
        countFixed = countPre > countPost ? countPre - countPost : 0,
        msg;
    if (countPre > 0) {
      msg = utils.format("Repaired %'i intersection%s", countFixed,
          utils.pluralSuffix(countFixed));
      if (countPost > 0) {
        msg += utils.format("; %'i intersection%s could not be repaired", countPost,
            utils.pluralSuffix(countPost));
      }
      message(msg);
    }
  }

  // @intersections (Array) Output from findSegmentIntersections()
  // Returns array of unresolved intersections, or empty array if none.
  // (export for GUI)
  function repairIntersections(arcs, intersections) {
    while (unwindIntersections(arcs, intersections) > 0) {
      intersections = findSegmentIntersections(arcs);
    }
    return intersections;
  }

  function unwindIntersections(arcs, intersections) {
    var data = arcs.getVertexData(),
        zlim = arcs.getRetainedInterval(),
        changes = 0,
        loops = 0,
        replacements, queue, target, i;

    // create a queue of unwind targets
    queue = getUnwindTargets(intersections, zlim, data.zz);
    utils.sortOn(queue, 'z', !!"ascending");

    while (queue.length > 0) {
      target = queue.pop();
      // redetect unwind target, in case a previous unwind operation has changed things
      // TODO: don't redetect if target couldn't have been affected
      replacements = redetectIntersectionTarget(target, zlim, data.xx, data.yy, data.zz);
      if (replacements.length == 1) {
        replacements = unwindIntersection(replacements[0], zlim, data.zz);
        changes++;
      } else  {
        // either 0 or multiple intersections detected
      }

      for (i=0; i<replacements.length; i++) {
        insertUnwindTarget(queue, replacements[i]);
      }
    }
    if (++loops > 500000) {
      verbose("Caught an infinite loop at intersection:", target);
      return 0;
    }
    return changes;
  }

  function getUnwindTargets(intersections, zlim, zz) {
    return intersections.reduce(function(memo, o) {
      var target = getUnwindTarget(o, zlim, zz);
      if (target !== null) {
        memo.push(target);
      }
      return memo;
    }, []);
  }

  // @o an intersection object
  // returns null if no vertices can be added along both segments
  // else returns an object with properties:
  //   a: intersecting segment to be partitioned
  //   b: intersecting segment to be retained
  //   z: threshold value of one or more points along [a] to be re-added
  function getUnwindTarget(o, zlim, zz) {
    var ai = findNextRemovableVertex(zz, zlim, o.a[0], o.a[1]),
        bi = findNextRemovableVertex(zz, zlim, o.b[0], o.b[1]),
        targ;
    if (ai == -1 && bi == -1) {
      targ = null;
    } else if (bi == -1 || ai != -1 && zz[ai] > zz[bi]) {
      targ = {
        a: o.a,
        b: o.b,
        z: zz[ai]
      };
    } else {
      targ = {
        a: o.b,
        b: o.a,
        z: zz[bi]
      };
    }
    return targ;
  }

  // Insert an intersection into sorted position
  function insertUnwindTarget(arr, obj) {
    var ins = arr.length;
    while (ins > 0) {
      if (arr[ins-1].z <= obj.z) {
        break;
      }
      arr[ins] = arr[ins-1];
      ins--;
    }
    arr[ins] = obj;
  }

  // Partition one of two intersecting segments by setting the removal threshold
  // of vertices indicated by @target equal to @zlim (the current simplification
  // level of the ArcCollection)
  function unwindIntersection(target, zlim, zz) {
    var replacements = [];
    var start = target.a[0],
        end = target.a[1],
        z = target.z;
    for (var i = start + 1; i <= end; i++) {
      if (zz[i] == z || i == end) {
        replacements.push({
          a: [start, i],
          b: target.b,
          z: z
        });
        if (i != end) zz[i] = zlim;
        start = i;
      }
    }
    if (replacements.length < 2) error("Error in unwindIntersection()");
    return replacements;
  }

  function redetectIntersectionTarget(targ, zlim, xx, yy, zz) {
    var segIds = getIntersectionCandidates(targ, zlim, xx, yy, zz);
    var intersections = intersectSegments(segIds, xx, yy);
    return getUnwindTargets(intersections, zlim, zz);
  }

  function getIntersectionCandidates(o, zlim, xx, yy, zz) {
    var segIds = getSegmentVertices(o.a, zlim, xx, yy, zz);
    segIds = segIds.concat(getSegmentVertices(o.b, zlim, xx, yy, zz));
    return segIds;
  }

  // Get all segments defined by two endpoints and the vertices between
  // them that are at or above the current simplification threshold.
  // TODO: test intersections with identical start + end ids
  function getSegmentVertices(seg, zlim, xx, yy, zz) {
    var start, end, prev, ids = [];
    if (seg[0] <= seg[1]) {
      start = seg[0];
      end = seg[1];
    } else {
      start = seg[1];
      end = seg[0];
    }
    prev = start;
    for (var i=start+1; i<=end; i++) {
      if (zz[i] >= zlim) {
        if (xx[prev] < xx[i]) {
          ids.push(prev, i);
        } else {
          ids.push(i, prev);
        }
        prev = i;
      }
    }
    return ids;
  }

  var PostSimplifyRepair = /*#__PURE__*/Object.freeze({
    __proto__: null,
    postSimplifyRepair: postSimplifyRepair,
    repairIntersections: repairIntersections
  });

  var DouglasPeucker = {};

  DouglasPeucker.metricSq3D = geom.pointSegDistSq3D;
  DouglasPeucker.metricSq = geom.pointSegDistSq;

  // @dest array to contain point removal thresholds
  // @xx, @yy arrays of x, y coords of a path
  // @zz (optional) array of z coords for spherical simplification
  //
  DouglasPeucker.calcArcData = function(dest, xx, yy, zz) {
    var len = dest.length,
        useZ = !!zz;

    dest[0] = dest[len-1] = Infinity;
    if (len > 2) {
      procSegment(0, len-1, 1, Number.MAX_VALUE);
    }

    function procSegment(startIdx, endIdx, depth, distSqPrev) {
      // get endpoint coords
      var ax = xx[startIdx],
          ay = yy[startIdx],
          cx = xx[endIdx],
          cy = yy[endIdx],
          az, cz;
      if (useZ) {
        az = zz[startIdx];
        cz = zz[endIdx];
      }

      var maxDistSq = 0,
          maxIdx = 0,
          distSqLeft = 0,
          distSqRight = 0,
          distSq;

      for (var i=startIdx+1; i<endIdx; i++) {
        if (useZ) {
          distSq = DouglasPeucker.metricSq3D(xx[i], yy[i], zz[i], ax, ay, az, cx, cy, cz);
        } else {
          distSq = DouglasPeucker.metricSq(xx[i], yy[i], ax, ay, cx, cy);
        }

        if (distSq >= maxDistSq) {
          maxDistSq = distSq;
          maxIdx = i;
        }
      }

      // Case -- threshold of parent segment is less than threshold of curr segment
      // Curr max point is assigned parent's threshold, so parent is not removed
      // before child as simplification is increased.
      //
      if (distSqPrev < maxDistSq) {
        maxDistSq = distSqPrev;
      }

      if (maxIdx - startIdx > 1) {
        distSqLeft = procSegment(startIdx, maxIdx, depth+1, maxDistSq);
      }
      if (endIdx - maxIdx > 1) {
        distSqRight = procSegment(maxIdx, endIdx, depth+1, maxDistSq);
      }

      // Case -- max point of curr segment is highest-threshold point of an island polygon
      // Give point the same threshold as the next-highest point, to prevent
      // a 3-vertex degenerate ring.
      if (depth == 1 && ax == cx && ay == cy) {
        maxDistSq = Math.max(distSqLeft, distSqRight);
      }

      dest[maxIdx] =  Math.sqrt(maxDistSq);
      return maxDistSq;
    }
  };

  function keepEveryPolygon(arcData, layers) {
    layers.forEach(function(lyr) {
      if (lyr.geometry_type == 'polygon') {
        protectLayerShapes(arcData, lyr.shapes);
      }
    });
  }

  function protectLayerShapes(arcData, shapes) {
    shapes.forEach(function(shape) {
      protectShape(arcData, shape);
    });
  }

  // Protect a single shape from complete removal by simplification
  // @arcData an ArcCollection
  // @shape an array containing one or more arrays of arc ids, or null if null shape
  //
  function protectShape(arcData, shape) {
    var maxArea = 0,
        arcCount = shape ? shape.length : 0,
        maxRing, area;
    // Find ring with largest bounding box
    for (var i=0; i<arcCount; i++) {
      area = arcData.getSimpleShapeBounds(shape[i]).area();
      if (area > maxArea) {
        maxRing = shape[i];
        maxArea = area;
      }
    }

    if (!maxRing || maxRing.length === 0) {
      // invald shape
      verbose("[protectShape()] Invalid shape:", shape);
    } else {
      protectPolygonRing(arcData, maxRing);
    }
  }

  // Re-inflate a polygon ring that has collapsed due to simplification by
  //   adding points in reverse order of removal until polygon is inflated.
  function protectPolygonRing(arcData, ring) {
    var zlim = arcData.getRetainedInterval(),
        // use epsilon as min area instead of 0, in case f.p. rounding produces
        // a positive area for a collapsed polygon.
        minArea = 1e-10,
        area, added;
    arcData.setRetainedInterval(Infinity);
    area = geom.getPlanarPathArea(ring, arcData);
    while (area <= minArea) {
      added = lockMaxThreshold(arcData, ring);
      if (added === 0) {
        verbose("[protectMultiRing()] Failed on ring:", ring);
        break;
      }
      area = geom.getPlanarPathArea(ring, arcData);
    }
    arcData.setRetainedInterval(zlim);
  }

  // Protect the vertex or vertices with the largest non-infinite
  // removal threshold in a ring.
  //
  function lockMaxThreshold(arcData, ring) {
    var targZ = 0,
        targArcId,
        raw = arcData.getVertexData(),
        arcId, id, z,
        start, end;

    for (var i=0; i<ring.length; i++) {
      arcId = ring[i];
      if (arcId < 0) arcId = ~arcId;
      start = raw.ii[arcId];
      end = start + raw.nn[arcId] - 1;
      id = findNextRemovableVertex(raw.zz, Infinity, start, end);
      if (id == -1) continue;
      z = raw.zz[id];
      if (z > targZ) {
        targZ = z;
        targArcId = arcId;
      }
    }
    if (targZ > 0) {
      // There may be more than one vertex with the target Z value; lock them all.
      start = raw.ii[targArcId];
      end = start + raw.nn[targArcId] - 1;
      return replaceInArray(raw.zz, targZ, Infinity, start, end);
    }
    return 0;
  }

  function replaceInArray(zz, value, replacement, start, end) {
    var count = 0;
    for (var i=start; i<=end; i++) {
      if (zz[i] === value) {
        zz[i] = replacement;
        count++;
      }
    }
    return count;
  }

  var KeepShapes = /*#__PURE__*/Object.freeze({
    __proto__: null,
    keepEveryPolygon: keepEveryPolygon,
    protectShape: protectShape,
    replaceInArray: replaceInArray
  });

  cmd.simplify = function(dataset, opts) {
    var arcs = dataset.arcs;
    if (!arcs || arcs.size() === 0) return; // removed in v0.4.125: stop("Missing path data");
    opts = getStandardSimplifyOpts(dataset, opts); // standardize options
    simplifyPaths(arcs, opts);

    // calculate and apply simplification interval
    if (opts.percentage || opts.percentage === 0) {
      arcs.setRetainedPct(utils.parsePercent(opts.percentage));
    } else if (opts.interval || opts.interval === 0) {
      arcs.setRetainedInterval(convertSimplifyInterval(opts.interval, dataset, opts));
    } else if (opts.resolution) {
      arcs.setRetainedInterval(convertSimplifyResolution(opts.resolution, arcs, opts));
    } else if (opts.presimplify) {
      return;
    } else {
      stop("Missing a simplification amount");
    }

    finalizeSimplification(dataset, opts);
  };

  function finalizeSimplification(dataset, opts) {
    var arcs = dataset.arcs;
    if (opts.keep_shapes) {
      keepEveryPolygon(arcs, dataset.layers);
    }

    if (!opts.no_repair && arcs.getRetainedInterval() > 0) {
      postSimplifyRepair(arcs);
    }

    if (opts.stats) {
      printSimplifyInfo(arcs, opts);
    }

    // stash simplification options (used by gui settings dialog)
    dataset.info = utils.defaults({simplify: opts}, dataset.info);
  }

  function getStandardSimplifyOpts(dataset, opts) {
    opts = opts || {};
    return utils.defaults({
      method: getSimplifyMethod(opts),
      spherical: useSphericalSimplify(dataset.arcs, opts)
    }, opts);
  }

  function useSphericalSimplify(arcs, opts) {
    return !opts.planar && !arcs.isPlanar();
  }

  // Calculate simplification thresholds for each vertex of an arc collection
  // (modifies @arcs ArcCollection in-place)
  function simplifyPaths(arcs, opts) {
    var simplifyPath = getSimplifyFunction(opts);
    arcs.setThresholds(new Float64Array(arcs.getPointCount())); // Create array to hold simplification data
    if (opts.spherical) {
      simplifyPaths3D(arcs, simplifyPath);
      protectWorldEdges(arcs);
    } else {
      simplifyPaths2D(arcs, simplifyPath);
    }
    if (opts.lock_box) {
      protectContentEdges(arcs);
    }
  }

  function simplifyPaths2D(arcs, simplify) {
    arcs.forEach3(function(xx, yy, kk, i) {
      simplify(kk, xx, yy);
    });
  }

  function simplifyPaths3D(arcs, simplify) {
    var xbuf = utils.expandoBuffer(Float64Array),
        ybuf = utils.expandoBuffer(Float64Array),
        zbuf = utils.expandoBuffer(Float64Array);
    arcs.forEach3(function(xx, yy, kk, i) {
      var n = xx.length,
          xx2 = xbuf(n),
          yy2 = ybuf(n),
          zz2 = zbuf(n);
      geom.convLngLatToSph(xx, yy, xx2, yy2, zz2);
      simplify(kk, xx2, yy2, zz2);
    });
  }

  function getSimplifyMethod(opts) {
    var m = opts.method;
    if (!m || m == 'weighted' || m == 'visvalingam' && opts.weighting) {
      m =  'weighted_visvalingam';
    }
    return m;
  }

  function getSimplifyFunction(opts) {
    var f;
    if (opts.method == 'dp') {
      f = DouglasPeucker.calcArcData;
    } else if (opts.method == 'visvalingam') {
      f = Visvalingam.getEffectiveAreaSimplifier(opts.spherical);
    } else if (opts.method == 'weighted_visvalingam') {
      f = Visvalingam.getWeightedSimplifier(opts, opts.spherical);
    } else {
      stop('Unsupported simplify method:', opts.method);
    }
    return f;
  }

  function protectContentEdges(arcs) {
    var e = 1e-14;
    var bb = arcs.getBounds();
    bb.padBounds(-e, -e, -e, -e);
    limitSimplificationExtent(arcs, bb.toArray(), true);
  }

  // @hardLimit
  //    true: never remove edge vertices
  //    false: never remove before other vertices
  function limitSimplificationExtent(arcs, bb, hardLimit) {
    var arcBounds = arcs.getBounds().toArray();
    // return if content doesn't reach edges
    if (geom.containsBounds(bb, arcBounds) === true) return;
    arcs.forEach3(function(xx, yy, zz) {
      var lockZ = hardLimit ? Infinity : 0,
      x, y;
      for (var i=0, n=zz.length; i<n; i++) {
        x = xx[i];
        y = yy[i];
        if (x >= bb[2] || x <= bb[0] || y <= bb[1] || y >= bb[3]) {
          if (lockZ === 0) {
            lockZ = findMaxThreshold(zz);
          }
          if (zz[i] !== Infinity) { // don't override lock value
            zz[i] = lockZ;
          }
        }
      }
    });
  }

  // Protect polar coordinates and coordinates at the prime meridian from
  // being removed before other points in a path.
  // Assume: coordinates are in decimal degrees
  //
  function protectWorldEdges(arcs) {
    // Need to handle coords with rounding errors:
    // -179.99999999999994 in test/data/ne/ne_110m_admin_0_scale_rank.shp
    // 180.00000000000003 in ne/ne_50m_admin_0_countries.shp
    limitSimplificationExtent(arcs, getWorldBounds(1e-12), false);
  }

  // Return largest value in an array, ignoring Infinity (lock value)
  //
  function findMaxThreshold(zz) {
    var z, maxZ = 0;
    for (var i=0, n=zz.length; i<n; i++) {
      z = zz[i];
      if (z > maxZ && z < Infinity) {
        maxZ = z;
      }
    }
    return maxZ;
  }

  function parseSimplifyResolution(raw) {
    var parts, w, h;
    if (utils.isNumber(raw)) {
      w = raw;
      h = raw;
    }
    else if (utils.isString(raw)) {
      parts = raw.split(/[x ,]/);
      w = Number(parts[0]) || 0;
      h = parts.length == 2 ? Number(parts[1]) || 0 : w;
    }
    if (!(w >= 0 && h >= 0 && w + h > 0)) {
      stop("Invalid simplify resolution:", raw);
    }
    return [w, h]; // TODO: validate;
  }

  function calcPlanarInterval(xres, yres, width, height) {
    var fitWidth = xres !== 0 && width / height > xres / yres || yres === 0;
    return fitWidth ? width / xres : height / yres;
  }

  // Calculate a simplification interval for unprojected data, given an output resolution
  // (This is approximate, since we don't know how the data will be projected for display)
  function calcSphericalInterval(xres, yres, bounds) {
    // Using length of arc along parallel through center of bbox as content width
    // TODO: consider using great circle instead of parallel arc to calculate width
    //    (doesn't work if width of bbox is greater than 180deg)
    var width = geom.degreesToMeters(bounds.width()) * Math.cos(bounds.centerY() * geom.D2R);
    var height = geom.degreesToMeters(bounds.height());
    return calcPlanarInterval(xres, yres, width, height);
  }

  function convertSimplifyInterval(param, dataset, opts) {
    var crs = getDatasetCRS(dataset);
    var interval;
    if (useSphericalSimplify(dataset.arcs, opts)) {
      interval = convertDistanceParam(param, crs);
    } else {
      interval = convertIntervalParam(param, crs);
    }
    return interval;
  }

  // convert resolution to an interval
  function convertSimplifyResolution(param, arcs, opts) {
    var res = parseSimplifyResolution(param);
    var bounds = arcs.getBounds();
    var interval;
    if (useSphericalSimplify(arcs, opts)) {
      interval = calcSphericalInterval(res[0], res[1], bounds);
    } else {
      interval = calcPlanarInterval(res[0], res[1], bounds.width(), bounds.height());
    }
    // scale interval to double the resolution (single-pixel resolution creates
    //  visible artifacts)
    interval *= 0.5;
    return interval;
  }

  var Simplify = /*#__PURE__*/Object.freeze({
    __proto__: null,
    finalizeSimplification: finalizeSimplification,
    getStandardSimplifyOpts: getStandardSimplifyOpts,
    useSphericalSimplify: useSphericalSimplify,
    simplifyPaths: simplifyPaths,
    getSimplifyMethod: getSimplifyMethod,
    protectWorldEdges: protectWorldEdges,
    parseSimplifyResolution: parseSimplifyResolution,
    calcPlanarInterval: calcPlanarInterval,
    calcSphericalInterval: calcSphericalInterval,
    convertSimplifyInterval: convertSimplifyInterval,
    convertSimplifyResolution: convertSimplifyResolution
  });

  cmd.sortFeatures = function(lyr, arcs, opts) {
    var n = getFeatureCount(lyr),
        ascending = !opts.descending,
        compiled = compileValueExpression(opts.expression, lyr, arcs),
        values = [];

    utils.repeat(n, function(i) {
      values.push(compiled(i));
    });

    var ids = utils.getSortedIds(values, ascending);
    if (lyr.shapes) {
      utils.reorderArray(lyr.shapes, ids);
    }
    if (lyr.data) {
      utils.reorderArray(lyr.data.getRecords(), ids);
    }
  };

  cmd.snap = function(dataset, opts) {
    var interval = 0;
    var snapCount = 0;
    var arcs = dataset.arcs;
    var arcBounds = arcs && arcs.getBounds();
    if (!arcBounds || !arcBounds.hasBounds()) {
      stop('Dataset is missing path data');
    }
    if (opts.precision) {
      setCoordinatePrecision(dataset, opts.precision);
    } else if (opts.interval) {
      interval = convertIntervalParam(opts.interval, getDatasetCRS(dataset));
    } else {
      interval = getHighPrecisionSnapInterval(arcBounds.toArray());
    }
    arcs.flatten(); // bake in any simplification
    if (interval > 0) {
      snapCount = snapCoordsByInterval(arcs, interval);
      message(utils.format("Snapped %s point%s", snapCount, utils.pluralSuffix(snapCount)));
    }
    if (snapCount > 0 || opts.precision) {
      arcs.dedupCoords();
      buildTopology(dataset);
    }
  };

  // @expression: optional field name or expression
  //
  cmd.splitLayer = function(src, expression, optsArg) {
    var opts = optsArg || {},
        lyr0 = opts.no_replace ? copyLayer(src) : src,
        properties = lyr0.data ? lyr0.data.getRecords() : null,
        shapes = lyr0.shapes,
        index = {},
        splitLayers = [],
        namer;

    if (opts.ids) {
      namer = getIdSplitFunction(opts.ids);
    } else {
      namer = getSplitNameFunction(lyr0, expression);
    }

    // if (splitField) {
    //   internal.requireDataField(lyr0, splitField);
    // }

    utils.repeat(getFeatureCount(lyr0), function(i) {
      var name = namer(i),
          lyr;

      if (name in index === false) {
        index[name] = splitLayers.length;
        lyr = {
          geometry_type: lyr0.geometry_type,
          name: name,
          data: properties ? new DataTable() : null,
          shapes: shapes ? [] : null
        };
        splitLayers.push(lyr);
      } else {
        lyr = splitLayers[index[name]];
      }
      if (shapes) {
        lyr.shapes.push(shapes[i]);
      }
      if (properties) {
        lyr.data.getRecords().push(properties[i]);
      }
    });
    return splitLayers;
  };

  function getIdSplitFunction(ids) {
    var set = new Set(ids);
    return function(i) {
      return set.has(i) ? '1' : '2';
    };
  }

  function getDefaultSplitFunction(lyr) {
    // if not splitting on an expression and layer is unnamed, name split-apart layers
    // like: split-1, split-2, ...
    return function(i) {
      return (lyr && lyr.name || 'split') + '-' + (i + 1);
    };
  }

  function getSplitNameFunction(lyr, exp) {
    var compiled;
    if (!exp) return getDefaultSplitFunction(lyr);
    lyr = {name: lyr.name, data: lyr.data}; // remove shape info
    compiled = compileValueExpression(exp, lyr, null);
    return function(i) {
      var val = compiled(i);
      return String(val);
      // return val || val === 0 ? String(val) : '';
    };
  }


  // internal.getSplitKey = function(i, field, properties) {
  //   var rec = field && properties ? properties[i] : null;
  //   return String(rec ? rec[field] : i + 1);
  // };

  // internal.getSplitLayerName = function(base, key) {
  //   return (base ? base + '-' : '') + key;
  // };

  // internal.getStringInterpolator = function(str) {
  //   var body = 'with($$ctx) { return `' + str + '`; }';
  //   var f = new Function("$$ctx", body);
  //   return function(o) {
  //     var s = '';
  //     try {
  //       s = f(ctx);
  //     } catch(e) {
  //       stop("Unable to interpolate [" + str + "]");
  //     }
  //     return s;
  //   }
  // };

  var Split = /*#__PURE__*/Object.freeze({
    __proto__: null,
    getSplitNameFunction: getSplitNameFunction
  });

  cmd.svgStyle = function(lyr, dataset, opts) {
    var filter;
    if (!lyr.data) {
      initDataTable(lyr);
    }
    if (opts.where) {
      filter = compileValueExpression(opts.where, lyr, dataset.arcs);
    }
    Object.keys(opts).forEach(function(optName) {
      var svgName = optName.replace('_', '-'); // undo cli parser name conversion
      if (!isSupportedSvgStyleProperty(svgName)) {
        return;
      }
      var strVal = opts[optName].trim();
      var accessor = getSymbolPropertyAccessor(strVal, svgName, lyr);
      getLayerDataTable(lyr).getRecords().forEach(function(rec, i) {
        if (filter && !filter(i)) {
          // make sure field exists if record is excluded by filter
          if (svgName in rec === false) {
            rec[svgName] = undefined;
          }
        } else {
          rec[svgName] = accessor(i);
        }
      });
    });
  };

  var roundCoord = getRoundingFunction(0.01);

  function forEachSymbolCoord(coords, cb) {
    var isPoint = coords && utils.isNumber(coords[0]);
    var isNested = !isPoint && coords && Array.isArray(coords[0]);
    if (isPoint) return cb(coords);
    for (var i=0; i<coords.length; i++) {
      if (isNested) forEachSymbolCoord(coords[i], cb);
    }
  }

  function flipY(coords) {
    forEachSymbolCoord(coords, function(p) {
      p[1] = -p[1];
    });
  }

  function scaleAndShiftCoords(coords, scale, shift) {
    forEachSymbolCoord(coords, function(xy) {
      xy[0] = xy[0] * scale + shift[0];
      xy[1] = xy[1] * scale + shift[1];
    });
  }

  function roundCoordsForSVG(coords) {
    forEachSymbolCoord(coords, function(p) {
      p[0] = roundCoord(p[0]);
      p[1] = roundCoord(p[1]);
    });
  }

  function rotateCoords(coords, rotation) {
    if (!rotation) return;
    var f = getAffineTransform(rotation, 1, [0, 0], [0, 0]);
    forEachSymbolCoord(coords, function(p) {
      var p2 = f(p[0], p[1]);
      p[0] = p2[0];
      p[1] = p2[1];
    });
  }

  function findArcCenter(p1, p2, degrees) {
    var p3 = [(p1[0] + p2[0]) / 2, (p1[1] + p2[1]) / 2], // midpoint betw. p1, p2
        tan = 1 / Math.tan(degrees / 180 * Math.PI / 2),
        cp = getAffineTransform(90, tan, [0, 0], p3)(p2[0], p2[1]);
    return cp;
  }

  // export function addBezierArcControlPoints(p1, p2, degrees) {
  function addBezierArcControlPoints(points, degrees) {
    // source: https://stackoverflow.com/questions/734076/how-to-best-approximate-a-geometrical-arc-with-a-bezier-curve
    var p2 = points.pop(),
        p1 = points.pop(),
        cp = findArcCenter(p1, p2, degrees),
        xc = cp[0],
        yc = cp[1],
        ax = p1[0] - xc,
        ay = p1[1] - yc,
        bx = p2[0] - xc,
        by = p2[1] - yc,
        q1 = ax * ax + ay * ay,
        q2 = q1 + ax * bx + ay * by,
        k2 = 4/3 * (Math.sqrt(2 * q1 * q2) - q2) / (ax * by - ay * bx);

    points.push(p1);
    points.push([xc + ax - k2 * ay, yc + ay + k2 * ax, 'C']);
    points.push([xc + bx + k2 * by, yc + by - k2 * bx, 'C']);
    points.push(p2);
  }

  // export function getStickArrowCoords(d, totalLen) {
  //   var minStemRatio = getMinStemRatio(d);
  //   var headAngle = d['arrow-head-angle'] || 90;
  //   var curve = d['arrow-stem-curve'] || 0;
  //   var unscaledHeadWidth = d['arrow-head-width'] || 9;
  //   var unscaledHeadLen = getHeadLength(unscaledHeadWidth, headAngle);
  //   var scale = getScale(totalLen, unscaledHeadLen, minStemRatio);
  //   var headWidth = unscaledHeadWidth * scale;
  //   var headLen = unscaledHeadLen * scale;
  //   var tip = getStickArrowTip(totalLen, curve);
  //   var stem = [[0, 0], tip.concat()];
  //   if (curve) {
  //     addBezierArcControlPoints(stem, curve);
  //   }
  //   if (!headLen) return [stem];
  //   var head = [addPoints([-headWidth / 2, -headLen], tip), tip.concat(), addPoints([headWidth / 2, -headLen], tip)];

  //   rotateCoords(stem, d.rotation);
  //   rotateCoords(head, d.rotation);
  //   return [stem, head];
  // }


  function getFilledArrowCoords(d) {
    var direction = d.rotation || d.direction || 0,
        stemTaper = d['stem-taper'] || 0,
        stemCurve = d['stem-curve'] || 0,
        size = calcArrowSize(d);

    if (!size) return null;

    var headDx = size.headWidth / 2,
        stemDx = size.stemWidth / 2,
        baseDx = stemDx * (1 - stemTaper),
        coords;

    if (!stemCurve || Math.abs(stemCurve) > 90) {
      coords = calcStraightArrowCoords(size.stemLen, size.headLen, stemDx, headDx, baseDx);
    } else {
      if (direction > 0) stemCurve = -stemCurve;
      coords = getCurvedArrowCoords(size.stemLen, size.headLen, size.stemCurve, stemDx, headDx, baseDx);
    }

    rotateCoords(coords, direction);
    if (d.flipped) {
      flipY(coords);
    }
    return [coords];
  }

  function calcStraightArrowCoords(stemLen, headLen, stemDx, headDx, baseDx) {
    return [[baseDx, 0], [stemDx, stemLen], [headDx, stemLen], [0, stemLen + headLen],
          [-headDx, stemLen], [-stemDx, stemLen], [-baseDx, 0], [baseDx, 0]];
  }

  function calcArrowSize(d) {
    var totalLen = d.radius || d.length || d.r || 0,
        unscaledStemWidth = d['stem-width'] || 2,
        unscaledHeadWidth = d['head-width'] || unscaledStemWidth * 3,
        unscaledHeadLen = d['head-length'] || calcHeadLength(unscaledHeadWidth, d),
        scale = 1,
        o = {};

    if (totalLen > 0) {
      scale = calcScale(totalLen, unscaledHeadLen, d);
      o.headWidth = unscaledHeadWidth * scale;
      o.headLen = unscaledHeadLen * scale;
      o.stemWidth = unscaledStemWidth * scale;
      o.stemLen = totalLen - o.headLen;

    } else {
      o.headWidth = unscaledHeadWidth;
      o.headLen = unscaledHeadLen;
      o.stemWidth = unscaledStemWidth;
      o.stemLen = d['stem-length'] || 0;
    }

    if (unscaledHeadWidth < unscaledStemWidth) {
      stop('Arrow head must be at least as wide as the stem.');
    }
    return o;
  }

  function calcScale(totalLen, headLen, d) {
    var minStemRatio = d['min-stem'] >= 0 ? d['min-stem'] : 0;
    var stemLen = d['stem-length'] || 0;
    var maxHeadPct = 1 - minStemRatio;
    var headPct = headLen / totalLen;
    var scale = 1;

    if (headPct > maxHeadPct) {
      scale = maxHeadPct / headPct;
    } else if (stemLen + headLen > totalLen) {
      scale = totalLen / (stemLen + headLen);
    }
    return scale;
  }

  // function getStickArrowTip(totalLen, curve) {
  //   // curve/2 intersects the arrowhead at 90deg (trigonometry)
  //   var theta = Math.abs(curve/2) / 180 * Math.PI;
  //   var dx = totalLen * Math.sin(theta) * (curve > 0 ? -1 : 1);
  //   var dy = totalLen * Math.cos(theta);
  //   return [dx, dy];
  // }

  function addPoints(a, b) {
    return [a[0] + b[0], a[1] + b[1]];
  }


  function calcHeadLength(headWidth, d) {
    var headAngle = d['head-angle'] || 40;
    var headRatio = 1 / Math.tan(Math.PI * headAngle / 180 / 2) / 2; // length-to-width head ratio
    return headWidth * headRatio;
  }

  function getCurvedArrowCoords(stemLen, headLen, curvature, stemDx, headDx, baseDx) {
    // coordinates go counter clockwise, starting from the leftmost head coordinate
    var theta = Math.abs(curvature) / 180 * Math.PI;
    var sign = curvature > 0 ? 1 : -1;
    var dx = stemLen * Math.sin(theta / 2) * sign;
    var dy = stemLen * Math.cos(theta / 2);
    var head = [[stemDx + dx, dy], [headDx + dx, dy],
      [dx, headLen + dy], [-headDx + dx, dy], [-stemDx + dx, dy]];
    var ax = baseDx * Math.cos(theta); // rotate arrow base
    var ay = baseDx * Math.sin(theta) * -sign;
    var leftStem = getCurvedStemCoords(-ax, -ay, -stemDx + dx, dy, theta);
    var rightStem = getCurvedStemCoords(ax, ay, stemDx + dx, dy, theta);
    var stem = leftStem.concat(rightStem.reverse());
    // stem.pop();
    return stem.concat(head);
  }

  // ax, ay: point on the base
  // bx, by: point on the stem
  function getCurvedStemCoords(ax, ay, bx, by, theta0) {
    // case: curved side intrudes into head (because stem is too short)
    if (ay > by) {
      return [[ax * by / ay, by]];
    }
    var dx = bx - ax,
        dy = by - ay,
        dy1 = (dy * dy - dx * dx) / (2 * dy),
        dy2 = dy - dy1,
        dx2 = Math.sqrt(dx * dx + dy * dy) / 2,
        theta = Math.PI - Math.asin(dx2 / dy2) * 2,
        degrees = theta * 180 / Math.PI,
        radius = dy2 / Math.tan(theta / 2),
        leftBend = bx > ax,
        sign = leftBend ? 1 : -1,
        points = Math.round(degrees / 5) + 2,
        increment = theta / (points + 1),
        coords = [[bx, by]];

    for (var i=1; i<= points; i++) {
      var phi = i * increment / 2;
      var sinPhi = Math.sin(phi);
      var cosPhi = Math.cos(phi);
      var c = sinPhi * radius * 2;
      var a = sinPhi * c;
      var b = cosPhi * c;
      coords.push([bx - a * sign, by - b]);
    }
    coords.push([ax, ay]);
    return coords;
  }

  // sides: e.g. 5-pointed star has 10 sides
  // radius: distance from center to point
  //
  function getPolygonCoords(d) {
    var radius = d.radius || d.length || d.r;
    if (radius > 0 === false) return null;
    var type = d.type;
    var sides = +d.sides || getDefaultSides(type);
    var isStar = type == 'star';
    if (isStar && (sides < 6 || sides % 2 !== 0)) {
      stop(`Invalid number of sides for a star (${sides})`);
    } else if (sides >= 3 === false) {
      stop(`Invalid number of sides (${sides})`);
    }
    var coords = [],
        angle = 360 / sides,
        b = isStar ? 1 : 0.5,
        theta, even, len;
    if (d.orientation == 'b' || d.flipped || d.rotated) {
      b = 0;
    }
    for (var i=0; i<sides; i++) {
      even = i % 2 == 0;
      len = radius;
      if (isStar && even) {
        len *= (d.star_ratio || 0.5);
      }
      theta = (i + b) * angle % 360;
      coords.push(getPlanarSegmentEndpoint(0, 0, theta, len));
    }
    coords.push(coords[0].concat());
    return [coords];
  }

  function getDefaultSides(type) {
    return {
      star: 10,
      circle: 72,
      triangle: 3,
      square: 4,
      pentagon: 5,
      hexagon: 6,
      heptagon: 7,
      octagon: 8,
      nonagon: 9,
      decagon: 10
    }[type] || 4;
  }

  // Returns GeoJSON MultiPolygon coords
  function getRingCoords(d) {
    var radii = parseRings(d.radii || '2');
    var coords = [];
    var solidCenter = utils.isOdd(radii.length);
    var ring, hole;
    for (var i=0; i<radii.length; i++) {
      ring = getPolygonCoords({
        type: 'circle',
        radius: radii[i]
      });
      if (!solidCenter || i > 0) {
        i++;
        hole = ring;
        ring = getPolygonCoords({
          type: 'circle',
          radius: radii[i]
        });
        ring.push(hole[0]);
      }
      coords.push(ring);
    }
    return coords;
  }

  function parseRings(arg) {
    var arr = Array.isArray(arg) ? arg : parseNumberList(arg);
    utils.genericSort(arr, true);
    return utils.uniq(arr);
  }

  // TODO: refactor to remove duplication in mapshaper-svg-style.js
  cmd.symbols = function(inputLyr, dataset, opts) {
    requireSinglePointLayer(inputLyr);
    var lyr = opts.no_replace ? copyLayer(inputLyr) : inputLyr;
    var polygonMode = !!opts.polygons;
    var metersPerPx;
    if (polygonMode) {
      requireProjectedDataset(dataset);
      metersPerPx = opts.pixel_scale || getMetersPerPixel(lyr, dataset);
    }
    var records = getLayerDataTable(lyr).getRecords();
    var getSymbolData = getSymbolDataAccessor(lyr, opts);
    var geometries = lyr.shapes.map(function(shp, i) {
      if (!shp) return null;
      var d = getSymbolData(i);
      var rec = records[i] || {};
      var geojsonType = 'Polygon';
      var coords;
      if (d.type == 'arrow') {
        coords = getFilledArrowCoords(d);
      } else if (d.type == 'ring') {
        coords = getRingCoords(d);
        geojsonType = 'MultiPolygon';
      } else {
        coords = getPolygonCoords(d);
      }
      if (!coords) return null;
      rotateCoords(coords, +d.rotation || 0);
      if (!polygonMode) {
        flipY(coords);
      }
      if (+opts.scale) {
        scaleAndShiftCoords(coords, +opts.scale, [0, 0]);
      }
      if (polygonMode) {
        scaleAndShiftCoords(coords, metersPerPx, shp[0]);
        if (d.tfill) rec.fill = d.fill;
        return createGeometry(coords, geojsonType);
      } else {
        rec['svg-symbol'] = makeSvgPolygonSymbol(coords, d, geojsonType);
      }
    });

    var outputLyr, dataset2;
    if (polygonMode) {
      dataset2 = importGeometries(geometries, records);
      outputLyr = mergeOutputLayerIntoDataset(inputLyr, dataset, dataset2, opts);
      outputLyr.data = lyr.data;
    } else {
      outputLyr = lyr;
    }
    return [outputLyr];
  };

  function importGeometries(geometries, records) {
    var features = geometries.map(function(geom, i) {
      var d = records[i];
      return {
        type: 'Feature',
        properties: records[i] || null,
        geometry: geom
      };
    });
    var geojson = {
      type: 'FeatureCollection',
      features: features
    };
    return importGeoJSON(geojson);
  }

  function createGeometry(coords, type) {
    return {
      type: type,
      coordinates: coords
    };
  }

  function getMetersPerPixel(lyr, dataset) {

    // TODO: handle single point, no extent
    var bounds = getLayerBounds(lyr);
    return bounds.width() / 800;
  }

  // Returns an svg-symbol data object for one symbol
  function makeSvgPolygonSymbol(coords, properties, geojsonType) {
    if (geojsonType == 'MultiPolygon') {
      coords = convertMultiPolygonCoords(coords);
    } else if (geojsonType != 'Polygon') {
      error('Unsupported type:', geojsonType);
    }
    roundCoordsForSVG(coords);
    return {
      type: 'polygon',
      coordinates: coords,
      fill: properties.fill || 'magenta'
    };
  }

  function convertMultiPolygonCoords(coords) {
    return coords.reduce(function(memo, poly) {
      return memo.concat(poly);
    }, []);
  }

  var Symbols = /*#__PURE__*/Object.freeze({
    __proto__: null
  });

  cmd.target = function(catalog, opts) {
    var type = (opts.type || '').toLowerCase().replace('linestring', 'polyline');
    var pattern = opts.target || '*';
    var targets = catalog.findCommandTargets(pattern, type);
    if (type && 'polygon,polyline,point'.split(',').indexOf(type) == -1) {
      stop("Invalid layer type:", opts.type);
    }
    if (targets.length === 0) {
      stop("No layers were matched (pattern: " + pattern + (type ? ' type: ' + type : '') + ")");
    }
    if (opts.name || opts.name === '') {
      // TODO: improve this
      targets[0].layers[0].name = opts.name;
    }
    catalog.setDefaultTargets(targets);
  };

  cmd.union = function(targetLayers, targetDataset, opts) {
    if (targetLayers.length < 2) {
      stop('Command requires at least two target layers');
    }
    targetLayers.forEach(requirePolygonLayer);

    // Need to add cuts before creating merged layer (arc ids may change)
    var nodes = addIntersectionCuts(targetDataset, opts);
    var allFields = [];
    var allShapes = [];
    var layerData = [];
    targetLayers.forEach(function(lyr, i) {
      var fields = lyr.data ? lyr.data.getFields() : [];
      if (opts.fields) {
        fields = opts.fields.indexOf('*') > 1 ? fields :
          fields.filter(function(name) {return opts.fields.indexOf(name) > -1;});
      }
      layerData.push({
        layer: lyr,
        fields: fields,
        records: lyr.data ? lyr.data.getRecords() : null,
        offset: allShapes.length,
        size: lyr.shapes.length
      });
      allFields = allFields.concat(fields);
      allShapes = allShapes.concat(lyr.shapes);
    });
    var unionFields = utils.uniqifyNames(allFields, function(name, n) {
      return name + '_' + n;
    });
    var mergedLyr = {
      geometry_type: 'polygon',
      shapes: allShapes
    };
    var mosaicIndex = new MosaicIndex(mergedLyr, nodes, {flat: false});
    var mosaicShapes = mosaicIndex.mosaic;
    var mosaicRecords = mosaicShapes.map(function(shp, i) {
      var mergedIds = mosaicIndex.getSourceIdsByTileId(i);
      var values = [];
      var lyrInfo, srcId, rec;
      for (var lyrId=0, n=layerData.length; lyrId < n; lyrId++) {
        lyrInfo = layerData[lyrId];
        srcId = unionFindOriginId(mergedIds, lyrInfo.offset, lyrInfo.size);
        rec = srcId == -1 || lyrInfo.records === null ? null : lyrInfo.records[srcId];
        unionAddDataValues(values, lyrInfo.fields, rec);
      }
      return unionMakeDataRecord(unionFields, values);
    });

    var unionLyr = {
      name: 'union',
      geometry_type: 'polygon',
      shapes: mosaicShapes,
      data: new DataTable(mosaicRecords)
    };
    return [unionLyr];
  };

  function unionFindOriginId(mergedIds, offset, length) {
    var mergedId;
    for (var i=0; i<mergedIds.length; i++) {
      mergedId = mergedIds[i];
      if (mergedId >= offset && mergedId < offset + length) {
        return mergedId - offset;
      }
    }
    return -1;
  }

  function unionAddDataValues(arr, fields, rec) {
    for (var i=0; i<fields.length; i++) {
      arr.push(rec ? rec[fields[i]] : null);
    }
  }

  function unionMakeDataRecord(fields, values) {
    var rec = {};
    for (var i=0; i<fields.length; i++) {
      rec[fields[i]] = values[i];
    }
    return rec;
  }

  cmd.uniq = function(lyr, arcs, opts) {
    var n = getFeatureCount(lyr),
        compiled = compileValueExpression(opts.expression, lyr, arcs),
        maxCount = opts.max_count || 1,
        counts = {},
        keepFlags = [],
        verbose = !!opts.verbose,
        invert = !!opts.invert,
        index = !!opts.index,
        records = lyr.data ? lyr.data.getRecords() : null,
        filter = function(d, i) {return keepFlags[i];};


    utils.repeat(n, function(i) {
      var val = compiled(i);
      var count = val in counts ? counts[val] + 1 : 1;
      var keep = count <= maxCount;
      var rec;
      if (index) {
        keep = true;
        rec = records && records[i];
        if (rec) rec.index = count;
      } else if (invert) {
        keep = !keep;
      }
      keepFlags[i] = keep;
      counts[val] = count;
      if (verbose && !keep) {
        message(utils.format('Removing feature %i key: [%s]', i, val));
      }
    });

    if (lyr.shapes) {
      lyr.shapes = lyr.shapes.filter(filter);
    }
    if (records) {
      lyr.data = new DataTable(records.filter(filter));
    }
    if (opts.verbose !== false) {
      message(utils.format('Retained %,d of %,d features', getFeatureCount(lyr), n));
    }
  };

  cmd.variableSimplify = function(layers, dataset, opts) {
    var lyr = layers[0];
    var arcs = dataset.arcs;
    var getShapeThreshold;
    var arcThresholds;
    if (layers.length != 1) {
      stop('Variable simplification requires a single target layer');
    }
    if (!layerHasPaths(lyr)) {
      stop('Target layer is missing path data');
    }

    opts = getStandardSimplifyOpts(dataset, opts);
    simplifyPaths(arcs, opts);

    if (opts.interval) {
      getShapeThreshold = getVariableIntervalFunction(opts.interval, lyr, dataset, opts);
    } else if (opts.percentage) {
      getShapeThreshold = getVariablePercentageFunction(opts.percentage, lyr, dataset, opts);
    } else if (opts.resolution) {
      getShapeThreshold = getVariableResolutionFunction(opts.resolution, lyr, dataset, opts);
    } else {
      stop("Missing a simplification expression");
    }

    arcThresholds = calculateVariableThresholds(lyr, arcs, getShapeThreshold);
    applyArcThresholds(arcs, arcThresholds);
    arcs.setRetainedInterval(1e20); // set to a huge value
    finalizeSimplification(dataset, opts);
    arcs.flatten(); // bake in simplification (different from standard -simplify)
  };

  function getVariableIntervalFunction(exp, lyr, dataset, opts) {
    var compiled = compileSimplifyExpression(exp, lyr, dataset.arcs);
    return function(shpId) {
      var val = compiled(shpId);
      return convertSimplifyInterval(val, dataset, opts);
    };
  }

  function getVariableResolutionFunction(exp, lyr, dataset, opts) {
    var compiled = compileSimplifyExpression(exp, lyr, dataset.arcs);
    return function(shpId) {
      var val = compiled(shpId);
      return convertSimplifyResolution(val, dataset.arcs, opts);
    };
  }

  function getVariablePercentageFunction(exp, lyr, dataset, opts) {
    var compiled = compileSimplifyExpression(exp, lyr, dataset.arcs);
    var pctToInterval = getThresholdFunction(dataset.arcs);
    return function(shpId) {
      var val = compiled(shpId);
      var pct = utils.parsePercent(val);
      return pctToInterval(pct);
    };
  }

  // TODO: memoize?
  function compileSimplifyExpression(exp, lyr, arcs) {
    return compileValueExpression(exp, lyr, arcs);
  }

  // Filter arcs based on an array of thresholds
  function applyArcThresholds(arcs, thresholds) {
    var zz = arcs.getVertexData().zz;
    arcs.forEach2(function(start, n, xx, yy, zz, arcId) {
      var arcZ = thresholds[arcId];
      var z;
      for (var i=1; i<n-1; i++) {
        z = zz[start + i];
        // if (z >= arcZ || arcZ === Infinity) { // Infinity test is a bug
        if (z >= arcZ) {
          // protect vertices with thresholds that are >= than the computed threshold
          // for this arc
          zz[start + i] = Infinity;
        }
      }
    });
  }

  function calculateVariableThresholds(lyr, arcs, getShapeThreshold) {
    var thresholds = new Float64Array(arcs.size()); // init to 0s
    var UNUSED = -1;
    var currThresh;
    utils.initializeArray(thresholds, UNUSED);
    lyr.shapes.forEach(function(shp, shpId) {
      currThresh = getShapeThreshold(shpId);
      forEachArcId(shp || [], procArc);
    });
    // set unset arcs to 0 so they are not simplified
    for (var i=0, n=thresholds.length; i<n; i++) {
      if (thresholds[i] == UNUSED) {
        thresholds[i] = 0;
      }
    }
    return thresholds;

    function procArc(arcId) {
      var i = arcId < 0 ? ~arcId : arcId;
      var savedThresh = thresholds[i];
      if (savedThresh > currThresh || savedThresh == UNUSED) {
        thresholds[i] = currThresh;
      }
    }
  }

  // Split the shapes in a layer according to a grid
  // Return array of layers. Use -o bbox-index option to create index
  //
  cmd.splitLayerOnGrid = function(lyr, arcs, opts) {
    var shapes = lyr.shapes,
        type = lyr.geometry_type,
        setId = !!opts.id_field, // assign id but, don't split to layers
        fieldName = opts.id_field || "__split__",
        classify = getShapeClassifier(getLayerBounds(lyr, arcs), opts.cols, opts.rows),
        properties, layers;

    if (!type) {
      stop("Layer has no geometry");
    }

    if (!lyr.data) {
      lyr.data = new DataTable(shapes.length);
    }
    properties = lyr.data.getRecords();

    lyr.shapes.forEach(function(shp, i) {
      var bounds = type == 'point' ? getPointBounds$1([shp]) : arcs.getMultiShapeBounds(shp);
      var name = bounds.hasBounds() ? classify(bounds) : '';
      var rec = properties[i] = properties[i] || {};
      rec[fieldName] = name;
    });

    if (setId) return lyr; // don't split layer (instead assign cell ids)

    return cmd.splitLayer(lyr, fieldName).filter(function(lyr) {
      var name = lyr.data.getRecordAt(0)[fieldName];
      lyr.name = name;
      lyr.data.deleteField(fieldName);
      return !!name;
    });

    function getShapeClassifier(bounds, cols, rows) {
      var xmin = bounds.xmin,
          ymin = bounds.ymin,
          w = bounds.width(),
          h = bounds.height();

      if (rows > 0 === false || cols > 0 === false) {
        stop('Invalid grid parameters');
      }

      if (w > 0 === false || h > 0 === false) {
        cols = 1;
        rows = 1;
      }

      return function(bounds) {
        var c = Math.floor((bounds.centerX() - xmin) / w * cols),
            r = Math.floor((bounds.centerY() - ymin) / h * rows);
        c = utils.clamp(c, 0, cols-1) || 0;
        r = utils.clamp(r, 0, rows-1) || 0;
        return "r" + r + "c" + c;
      };
    }
  };

  // Recursively divide a layer into two layers until a (compiled) expression
  // no longer returns true. The original layer is split along the long side of
  // its bounding box, so that each split-off layer contains half of the original
  // shapes (+/- 1).
  //
  cmd.subdivideLayer = function(lyr, arcs, exp) {
    return subdivide(lyr, arcs, exp);
  };

  function subdivide(lyr, arcs, exp) {
    var divide = evalCalcExpression(lyr, arcs, exp),
        subdividedLayers = [],
        tmp, bounds, lyr1, lyr2, layerName;

    if (!utils.isBoolean(divide)) {
      stop("Expression must evaluate to true or false");
    }
    if (divide) {
      bounds = getLayerBounds(lyr, arcs);
      tmp = divideLayer(lyr, arcs, bounds);
      lyr1 = tmp[0];
      if (lyr1.shapes.length > 1 && lyr1.shapes.length < lyr.shapes.length) {
        utils.merge(subdividedLayers, subdivide(lyr1, arcs, exp));
      } else {
        subdividedLayers.push(lyr1);
      }

      lyr2 = tmp[1];
      if (lyr2.shapes.length > 1 && lyr2.shapes.length < lyr.shapes.length) {
        utils.merge(subdividedLayers, subdivide(lyr2, arcs, exp));
      } else {
        subdividedLayers.push(lyr2);
      }
    } else {
      subdividedLayers.push(lyr);
    }
    layerName = getSplitNameFunction(lyr);
    subdividedLayers.forEach(function(lyr2, i) {
      lyr2.name = layerName(i);
      utils.defaults(lyr2, lyr);
    });
    return subdividedLayers;
  }

  // split one layer into two layers containing the same number of shapes (+-1),
  // either horizontally or vertically
  //
  function divideLayer(lyr, arcs, bounds) {
    var properties = lyr.data ? lyr.data.getRecords() : null,
        shapes = lyr.shapes,
        lyr1, lyr2;
    lyr1 = {
      geometry_type: lyr.geometry_type,
      shapes: [],
      data: properties ? [] : null
    };
    lyr2 = {
      geometry_type: lyr.geometry_type,
      shapes: [],
      data: properties ? [] : null
    };

    var useX = bounds && bounds.width() > bounds.height();
    // TODO: think about case where there are null shapes with NaN centers
    var centers = shapes.map(function(shp) {
      var bounds = arcs.getMultiShapeBounds(shp);
      return useX ? bounds.centerX() : bounds.centerY();
    });
    var ids = utils.range(centers.length);
    ids.sort(function(a, b) {
      return centers[a] - centers[b];
    });
    ids.forEach(function(shapeId, i) {
      var dest = i < shapes.length / 2 ? lyr1 : lyr2;
      dest.shapes.push(shapes[shapeId]);
      if (properties) {
        dest.data.push(properties[shapeId]);
      }
    });

    if (properties) {
      lyr1.data = new DataTable(lyr1.data);
      lyr2.data = new DataTable(lyr2.data);
    }
    return [lyr1, lyr2];
  }

  function runCommand(command, catalog, cb) {
    var name = command.name,
        opts = command.options,
        source,
        outputDataset,
        outputLayers,
        outputFiles,
        targets,
        targetDataset,
        targetLayers,
        arcs;

    try { // catch errors from synchronous functions

      T$1.start();
      if (!catalog) catalog = new Catalog();

      if (name == 'rename-layers') {
        // default target is all layers
        targets = catalog.findCommandTargets(opts.target || '*');
        targetLayers = targets.reduce(function(memo, obj) {
          return memo.concat(obj.layers);
        }, []);

      } else if (name == 'o') {
        // when combining GeoJSON layers, default is all layers
        // TODO: check that combine_layers is only used w/ GeoJSON output
        targets = catalog.findCommandTargets(opts.target || opts.combine_layers && '*');

      } else if (name == 'rotate' || name == 'info' || name == 'proj' || name == 'drop' || name == 'target') {
        // these commands accept multiple target datasets
        targets = catalog.findCommandTargets(opts.target);

      } else {
        targets = catalog.findCommandTargets(opts.target);

        // special case to allow -merge-layers and -union to combine layers from multiple datasets
        // TODO: support multi-dataset targets for other commands
        if (targets.length > 1 && (name == 'merge-layers' || name == 'union')) {
          targets = mergeCommandTargets(targets, catalog);
        }

        if (targets.length == 1) {
          targetDataset = targets[0].dataset;
          arcs = targetDataset.arcs;
          targetLayers = targets[0].layers;
          // target= option sets default target
          catalog.setDefaultTarget(targetLayers, targetDataset);

        } else if (targets.length > 1) {
          stop("This command does not support targetting layers from different datasets");
        }
      }

      if (targets.length === 0) {
        if (opts.target) {
          stop(utils.format('Missing target: %s\nAvailable layers: %s',
              opts.target, getFormattedLayerList(catalog)));
        }
        if (!(name == 'graticule' || name == 'i' || name == 'help' ||
            name == 'point-grid' || name == 'shape' || name == 'rectangle' ||
            name == 'include')) {
          throw new UserError("No data is available");
        }
      }

      if (opts.source) {
        source = findCommandSource(convertSourceName(opts.source, targets), catalog, opts);
      }

      if (name == 'affine') {
        cmd.affine(targetLayers, targetDataset, opts);

      } else if (name == 'alpha-shapes') {
        outputLayers = applyCommandToEachLayer(cmd.alphaShapes, targetLayers, targetDataset, opts);
        // outputLayers = null;

      } else if (name == 'buffer') {
         outputLayers = applyCommandToEachLayer(cmd.buffer, targetLayers, targetDataset, opts);
        // outputLayers = cmd.buffer(targetLayers, targetDataset, opts);

      } else if (name == 'data-fill') {
        applyCommandToEachLayer(cmd.dataFill, targetLayers, arcs, opts);

      } else if (name == 'cluster') {
        applyCommandToEachLayer(cmd.cluster, targetLayers, arcs, opts);

      } else if (name == 'calc') {
        applyCommandToEachLayer(cmd.calc, targetLayers, arcs, opts);

      } else if (name == 'classify') {
        applyCommandToEachLayer(cmd.classify, targetLayers, targetDataset, opts);

      } else if (name == 'clean') {
        cmd.cleanLayers(targetLayers, targetDataset, opts);

      } else if (name == 'clip') {
        outputLayers = cmd.clipLayers(targetLayers, source, targetDataset, opts);

      } else if (name == 'colorizer') {
        outputLayers = cmd.colorizer(opts);

      } else if (name == 'dashlines') {
        applyCommandToEachLayer(cmd.dashlines, targetLayers, targetDataset, opts);

      } else if (name == 'define') {
        cmd.define(opts);

      } else if (name == 'dissolve') {
        outputLayers = applyCommandToEachLayer(cmd.dissolve, targetLayers, arcs, opts);

      } else if (name == 'dissolve2') {
        outputLayers = cmd.dissolve2(targetLayers, targetDataset, opts);

      } else if (name == 'divide') {
        cmd.divide(targetLayers, targetDataset, source, opts);

      } else if (name == 'dots') {
        outputLayers = applyCommandToEachLayer(cmd.dots, targetLayers, arcs, opts);

      } else if (name == 'drop') {
        cmd.drop2(catalog, targets, opts);
        // cmd.drop(catalog, targetLayers, targetDataset, opts);

      } else if (name == 'each') {
        applyCommandToEachLayer(cmd.evaluateEachFeature, targetLayers, targetDataset, opts.expression, opts);

      } else if (name == 'erase') {
        outputLayers = cmd.eraseLayers(targetLayers, source, targetDataset, opts);

      } else if (name == 'explode') {
        outputLayers = applyCommandToEachLayer(cmd.explodeFeatures, targetLayers, arcs, opts);

      } else if (name == 'external') {
        cmd.external(opts);

      } else if (name == 'filter') {
        outputLayers = applyCommandToEachLayer(cmd.filterFeatures, targetLayers, arcs, opts);

      } else if (name == 'filter-fields') {
        applyCommandToEachLayer(cmd.filterFields, targetLayers, opts.fields);

      } else if (name == 'filter-geom') {
        applyCommandToEachLayer(cmd.filterGeom, targetLayers, arcs, opts);

      } else if (name == 'filter-islands') {
        applyCommandToEachLayer(cmd.filterIslands, targetLayers, targetDataset, opts);

      } else if (name == 'filter-islands2') {
        applyCommandToEachLayer(cmd.filterIslands2, targetLayers, targetDataset, opts);

      } else if (name == 'filter-points') {
        applyCommandToEachLayer(cmd.filterPoints, targetLayers, targetDataset, opts);

      } else if (name == 'filter-slivers') {
        applyCommandToEachLayer(cmd.filterSlivers, targetLayers, targetDataset, opts);

      } else if (name == 'frame') {
        cmd.frame(catalog, source, opts);

      } else if (name == 'fuzzy-join') {
        applyCommandToEachLayer(cmd.fuzzyJoin, targetLayers, arcs, source, opts);

      } else if (name == 'graticule') {
        catalog.addDataset(cmd.graticule(targetDataset, opts));

      } else if (name == 'help') {
        // placing this here to handle errors from invalid command names
        getOptionParser().printHelp(command.options.command);

      } else if (name == 'i') {
        if (opts.replace) catalog = new Catalog();
        targetDataset = cmd.importFiles(command.options);
        if (targetDataset) {
          catalog.addDataset(targetDataset);
          outputLayers = targetDataset.layers; // kludge to allow layer naming below
        }

      } else if (name == 'ignore') {
        applyCommandToEachLayer(cmd.ignore, targetLayers, targetDataset, opts);

      } else if (name == 'include') {
        cmd.include(opts);

      } else if (name == 'info') {
        cmd.printInfo(expandCommandTargets(targets));

      } else if (name == 'inlay') {
        outputLayers = cmd.inlay(targetLayers, source, targetDataset, opts);

      } else if (name == 'inspect') {
        applyCommandToEachLayer(cmd.inspect, targetLayers, arcs, opts);

      } else if (name == 'innerlines') {
        outputLayers = applyCommandToEachLayer(cmd.innerlines, targetLayers, arcs, opts);

      } else if (name == 'join') {
        applyCommandToEachLayer(cmd.join, targetLayers, targetDataset, source, opts);

      } else if (name == 'lines') {
        outputLayers = applyCommandToEachLayer(cmd.lines, targetLayers, targetDataset, opts);

      } else if (name == 'merge-layers') {
        // returned layers are modified input layers
        // (assumes that targetLayers are replaced by outputLayers below)
        outputLayers = cmd.mergeAndFlattenLayers(targetLayers, targetDataset, opts);
        // outputLayers = cmd.mergeLayers(targetLayers, opts);

      } else if (name == 'mosaic') {
        // opts.no_replace = true; // add mosaic as a new layer
        outputLayers = cmd.mosaic(targetLayers, targetDataset, opts);

      } else if (name == 'o') {
        outputFiles = exportTargetLayers(targets, opts);
        if (opts.final) {
          // don't propagate data if output is final
          catalog = null;
        }
        return writeFiles(outputFiles, opts, done);

      } else if (name == 'point-grid') {
        outputLayers = [cmd.pointGrid(targetDataset, opts)];
        if (!targetDataset) {
          catalog.addDataset({layers: outputLayers});
        }

      } else if (name == 'point-to-grid') {
        outputLayers = cmd.pointToGrid(targetLayers, targetDataset, opts);

      } else if (name == 'grid') {
        outputDataset = cmd.polygonGrid(targetLayers, targetDataset, opts);

      } else if (name == 'points') {
        outputLayers = applyCommandToEachLayer(cmd.createPointLayer, targetLayers, targetDataset, opts);

      } else if (name == 'polygons') {
        outputLayers = cmd.polygons(targetLayers, targetDataset, opts);

      } else if (name == 'proj') {
        initProjLibrary(opts, function() {
          var err = null;
          try {
            targets.forEach(function(targ) {
              cmd.proj(targ.dataset, catalog, opts);
            });
          } catch(e) {
            err = e;
          }
          done(err);
        });
        return; // async command

      } else if (name == 'rectangle') {
        if (source || opts.bbox || targets.length === 0) {
          catalog.addDataset(cmd.rectangle(source, opts));
        } else {
          outputLayers = cmd.rectangle2(targets[0], opts);
        }

      } else if (name == 'rectangles') {
        outputLayers = applyCommandToEachLayer(cmd.rectangles, targetLayers, targetDataset, opts);

      } else if (name == 'rename-fields') {
        applyCommandToEachLayer(cmd.renameFields, targetLayers, opts.fields);

      } else if (name == 'rename-layers') {
        cmd.renameLayers(targetLayers, opts.names, catalog);

      } else if (name == 'require') {
        cmd.require(targets, opts);

      } else if (name == 'rotate') {
        targets.forEach(function(targ) {
          cmd.rotate(targ.dataset, opts);
        });

      } else if (name == 'run') {
        cmd.run(targets, catalog, opts, done);
        return;

      } else if (name == 'scalebar') {
        cmd.scalebar(catalog, opts);

      } else if (name == 'shape') {
        catalog.addDataset(cmd.shape(targetDataset, opts));

      } else if (name == 'shapes') {
        outputLayers = applyCommandToEachLayer(cmd.shapes, targetLayers, targetDataset, opts);

      } else if (name == 'simplify') {
        if (opts.variable) {
          cmd.variableSimplify(targetLayers, targetDataset, opts);
        } else {
          cmd.simplify(targetDataset, opts);
        }

      } else if (name == 'slice') {
        outputLayers = cmd.sliceLayers(targetLayers, source, targetDataset, opts);

      } else if (name == 'snap') {
        cmd.snap(targetDataset, opts);

      } else if (name == 'sort') {
        applyCommandToEachLayer(cmd.sortFeatures, targetLayers, arcs, opts);

      } else if (name == 'split') {
        outputLayers = applyCommandToEachLayer(cmd.splitLayer, targetLayers, opts.expression, opts);

      } else if (name == 'split-on-grid') {
        outputLayers = applyCommandToEachLayer(cmd.splitLayerOnGrid, targetLayers, arcs, opts);

      } else if (name == 'stitch') {
        cmd.stitch(targetDataset);

      } else if (name == 'style') {
        applyCommandToEachLayer(cmd.svgStyle, targetLayers, targetDataset, opts);

      } else if (name == 'symbols') {
        outputLayers = applyCommandToEachLayer(cmd.symbols, targetLayers, targetDataset, opts);

      } else if (name == 'subdivide') {
        outputLayers = applyCommandToEachLayer(cmd.subdivideLayer, targetLayers, arcs, opts.expression);

      } else if (name == 'target') {
        cmd.target(catalog, opts);

      } else if (name == 'union') {
        outputLayers = cmd.union(targetLayers, targetDataset, opts);

      } else if (name == 'uniq') {
        applyCommandToEachLayer(cmd.uniq, targetLayers, arcs, opts);

      } else {
        // throws error if command is not registered
        cmd.runExternalCommand(command, catalog);
      }

      // apply name parameter
      if (('name' in opts) && outputLayers) {
        // TODO: consider uniqifying multiple layers here
        outputLayers.forEach(function(lyr) {
          lyr.name = opts.name;
        });
      }

      if (outputDataset) {
        catalog.addDataset(outputDataset); // also sets default target
        outputLayers = outputDataset.layers;
        if (targetLayers && !opts.no_replace) {
          // remove target layers from target dataset
          targetLayers.forEach(function(lyr) {
            catalog.deleteLayer(lyr, targetDataset);
          });
        }
      } else if (outputLayers && targetDataset && outputLayers != targetDataset.layers) {
        // integrate output layers into the target dataset
        if (opts.no_replace) {
          // make sure commands do not return input layers with 'no_replace' option
          if (!outputLayersAreDifferent(outputLayers, targetLayers || [])) {
            error('Command returned invalid output');
          }

          targetDataset.layers = targetDataset.layers.concat(outputLayers);
        } else {
          // TODO: consider replacing old layers as they are generated, for gc
          replaceLayers(targetDataset, targetLayers, outputLayers);
          // some operations leave unreferenced arcs that should be cleaned up
          if ((name == 'clip' || name == 'erase' || name == 'rectangle' ||
              name == 'rectangles' || name == 'filter' && opts.cleanup) && !opts.no_cleanup) {
            dissolveArcs(targetDataset);
          }
        }

        if (opts.apart) {
          catalog.setDefaultTargets(splitApartLayers( targetDataset, outputLayers).map(function(dataset) {
            return {
              dataset: dataset,
              layers: dataset.layers.concat()
            };
          }));
        } else {
          // use command output as new default target
          catalog.setDefaultTarget(outputLayers, targetDataset);
        }

      }

      // delete arcs if no longer needed (e.g. after -points command)
      // (after output layers have been integrated)
      if (targetDataset) {
        cleanupArcs(targetDataset);
      }
    } catch(e) {
      return done(e);
    }

    done(null);

    function done(err) {
      verbose('-', T$1.stop());
      cb(err, err ? null : catalog);
    }
  }

  function outputLayersAreDifferent(output, input) {
    return !utils.some(input, function(lyr) {
      return output.indexOf(lyr) > -1;
    });
  }

  // Apply a command to an array of target layers
  function applyCommandToEachLayer(func, targetLayers) {
    var args = utils.toArray(arguments).slice(2);
    return targetLayers.reduce(function(memo, lyr) {
      var result = func.apply(null, [lyr].concat(args));
      if (utils.isArray(result)) { // some commands return an array of layers
        memo = memo.concat(result);
      } else if (result) { // assuming result is a layer
        memo.push(result);
      }
      return memo;
    }, []);
  }

  // Parse command line args into commands and run them
  // Function takes an optional Node-style callback. A Promise is returned if no callback is given.
  //   function(argv[, input], callback)
  //   function(argv[, input]) (returns Promise)
  // argv: String or array containing command line args.
  // input: (optional) Object containing file contents indexed by filename
  //
  function runCommands(argv) {
    var opts = importRunArgs.apply(null, arguments);
    _runCommands(argv, opts, function(err) {
      opts.callback(err);
    });
    if (opts.promise) return opts.promise;
  }

  // Similar to runCommands(), but returns output files to the callback or Promise
  //   instead of using file I/O.
  // Callback signature: function(<error>, <data>) -- data is an object
  //   containing output from any -o commands, indexed by filename.
  //
  function applyCommands(argv) {
    var opts = importRunArgs.apply(null, arguments);
    var callback = opts.callback;
    var outputArr = opts.output = []; // output gets added to this array
    _runCommands(argv, opts, function(err) {
      if (err) {
        return callback(err);
      }
      if (opts.legacy) return callback(null, toLegacyOutputFormat(outputArr));
      return callback(null, toOutputFormat(outputArr));
    });
    if (opts.promise) return opts.promise;
  }

  // Run commands with extra heap memory
  //   function(argv[, options], callback)
  //   function(argv[, options]) (returns Promise)
  // options: (optional) object with "xl" property, e.g. {xl: "16gb"}
  //
  function runCommandsXL(argv) {
    var opts = importRunArgs.apply(null, arguments);
    var mapshaperScript = require('path').join(__dirname, 'bin/mapshaper');
    var gb = parseFloat(opts.options.xl) || 8;
    var err;
    if (gb < 1 || gb > 64) {
      err = new Error('Unsupported heap size:' + gb + 'GB');
      printError(err);
      opts.callback(err);
      return opts.promise; // may be undefined
    }
    if (!loggingEnabled()) argv += ' -quiet'; // kludge to pass logging setting to subprocess
    var mb = Math.round(gb * 1000);
    var command = [process.execPath, '--max-old-space-size=' + mb, mapshaperScript, argv].join(' ');
    var child = require('child_process').exec(command, {}, function(err, stdout, stderr) {
      opts.callback(err);
    });
    child.stdout.pipe(process.stdout);
    child.stderr.pipe(process.stderr);
    if (opts.promise) return opts.promise;
  }

  // Parse the arguments from runCommands() or applyCommands()
  function importRunArgs(arg0, arg1, arg2) {
    var opts = {options: {}};
    if (utils.isFunction(arg1)) {
      opts.callback = arg1;
    } else if (utils.isFunction(arg2)) {
      opts.callback = arg2;
      // identify legacy input format (used by some tests)
      opts.legacy = arg1 && guessInputContentType(arg1) != null;
      opts.input = arg1;
    } else {
      // if no callback, create a promise and a callback for resolving the promise
      opts.promise = new Promise(function(resolve, reject) {
        opts.callback = function(err, data) {
          if (err) reject(err);
          else resolve(data);
        };
      });
    }
    if (!opts.legacy && utils.isObject(arg1)) {
      if (arg1.xl) {
        // options for runCommandsXL()
        opts.options = arg1;
      } else {
        // input data for runCommands() and applyCommands()
        opts.input = arg1;
      }
    }
    return opts;
  }

  // Return an object containing content of zero or more output files, indexed by filename.
  function toOutputFormat(arr) {
    return arr.reduce(function(memo, o) {
      memo[o.filename] = o.content;
      return memo;
    }, {});
  }

  // Unified function for processing calls to runCommands() and applyCommands()
  function _runCommands(argv, opts, callback) {
    var outputArr = opts.output || null,
        inputObj = opts.input,
        commands;
    try {
      commands = parseCommands(argv);
    } catch(e) {
      printError(e);
      return callback(e);
    }

    if (opts.legacy) {
      message("Warning: deprecated input format");
      commands = convertLegacyCommands(commands, inputObj);
      inputObj = null;
    }

    // add options to -i -o -join -clip -erase commands to bypass file i/o
    // TODO: find a less kludgy solution, e.g. storing input data using setStateVar()
    commands.forEach(function(cmd) {
      if (commandTakesFileInput(cmd.name) && inputObj) {
        cmd.options.input = inputObj;
      }
      if (cmd.name == 'o' && outputArr) {
        cmd.options.output = outputArr;
      }
    });

    runParsedCommands(commands, null, callback);
  }

  function commandTakesFileInput(name) {
    return (name == 'i' || name == 'join' || name == 'erase' || name == 'clip' || name == 'include');
  }

  function toLegacyOutputFormat(arr) {
    if (arr.length > 1) {
      // Return an array if multiple files are output
      return utils.pluck(arr, 'content');
    }
    if (arr.length == 1) {
      // Return content if a single file is output
      return arr[0].content;
    }
    return null;
  }

  function convertLegacyCommands(arr, inputObj) {
    var i = utils.find(arr, function(cmd) {return cmd.name == 'i';});
    var o = utils.find(arr, function(cmd) {return cmd.name == 'o';});
    if (!i) {
      i = {name: 'i', options: {}};
      arr.unshift(i);
    }
    i.options.files = ['__input__'];
    i.options.input = {__input__: inputObj};
    if (!o) {
      arr.push({name: 'o', options: {}});
    }
    return arr;
  }

  // TODO: rewrite tests and remove this function
  function testCommands(argv, done) {
    _runCommands(argv, {}, function(err, catalog) {
      var targets = catalog ? catalog.getDefaultTargets() : [];
      var output;
      if (!err && targets.length > 0) {
        // returns dataset for compatibility with some older tests
        output = targets[0].dataset;
      }
      done(err, output);
    });
  }

  // Execute a sequence of parsed commands
  // @commands Array of parsed commands
  // @catalog: Optional Catalog object containing previously imported data
  // @cb: function(<error>, <catalog>)
  //
  function runParsedCommands(commands, catalog, cb) {
    if (!catalog) {
      cb = createAsyncContext(cb); // use new context when creating new catalog
      catalog = new Catalog();
    } else if (catalog instanceof Catalog === false) {
      error("Changed in v0.4: runParsedCommands() takes a Catalog object");
    }

    if (!utils.isArray(commands)) {
      error("Expected an array of parsed commands");
    }

    if (commands.length === 0) {
      return done(new UserError("No commands to run"));
    }
    commands = readAndRemoveSettings(commands);
    if (!runningInBrowser()) {
      printStartupMessages();
    }
    commands = runAndRemoveInfoCommands(commands);
    if (commands.length === 0) {
      return done(null);
    }
    if (!runningInBrowser() && commands[commands.length-1].name == 'o') {
      // in CLI, set 'final' flag on final -o command, so the export function knows
      // that it can modify the output dataset in-place instead of making a copy.
      commands[commands.length-1].options.final = true;
    }

    var groups = divideImportCommand(commands);
    if (groups.length == 1) {
      // run a simple sequence of commands (input files are not batched)
      return runParsedCommands2(commands, catalog, done);
    }

    // run duplicated commands (i.e. batch mode)
    utils.reduceAsync(groups, catalog, nextGroup, done);

    function nextGroup(catalog, commands, next) {
      runParsedCommands2(commands, catalog, function(err, catalog) {
        err = filterError(err);
        next(err, catalog);
      });
    }

    function done(err, catalog) {
      err = filterError(err);
      cb(err, catalog);
      setStateVar('current_command', null);
      setStateVar('verbose', false);
      setStateVar('debug', false);
    }
  }

  function filterError(err) {
    if (err) printError(err);
    if (err && err.name == 'NonFatalError') {
      return null;
    }
    return err;
  }

  function runParsedCommands2(commands, catalog, cb) {
    utils.reduceAsync(commands, catalog, nextCommand, cb);

    function nextCommand(catalog, cmd, next) {
      setStateVar('current_command', cmd.name); // for log msgs
      setStateVar('verbose', !!cmd.options.verbose);
      setStateVar('debug', !!cmd.options.debug);
      runCommand(cmd, catalog, next);
    }
  }


  // If an initial import command indicates that several input files should be
  //   processed separately, then duplicate the sequence of commands to run
  //   once for each input file
  // @commands Array of parsed commands
  // Returns: Array of one or more sequences of parsed commands
  //
  function divideImportCommand(commands) {
    var firstCmd = commands[0],
        opts = firstCmd.options;

    if (firstCmd.name != 'i' || opts.stdin || opts.merge_files ||
      opts.combine_files || !opts.files || opts.files.length < 2) {
      return [commands];
    }

    return opts.files.map(function(file) {
      var group = [{
        name: 'i',
        options: utils.defaults({
          files:[file],
          replace: true  // kludge to replace data catalog
        }, opts)
      }];
      group.push.apply(group, commands.slice(1));
      return group;
    });
  }


  function printStartupMessages() {
    // print heap memory message if running with a custom amount
    var rxp = /^--max-old-space-size=([0-9]+)$/;
    var arg = process.execArgv.find(function(s) {
      return rxp.test(s);
    });
    if (arg) {
      message('Allocating', rxp.exec(arg)[1] / 1000, 'GB of heap memory');
    }
  }

  // Some settings use command syntax and are parsed as commands.
  function readAndRemoveSettings(commands) {
    return commands.filter(function(cmd) {
      if (cmd.name == 'verbose') {
        setStateVar('VERBOSE', true);
      } else if (cmd.name == 'quiet') {
        setStateVar('QUIET', true);
      } else if (cmd.name == 'debug') {
        setStateVar('DEBUG', true);
      } else {
        return true;
      }
      return false;
    });
  }

  // Run informational commands and remove them from the array of parsed commands
  function runAndRemoveInfoCommands(commands) {
    return commands.filter(function(cmd) {
      if (cmd.name == 'version') {
        print(typeof VERSION == 'undefined' ? '' : VERSION);
      } else if (cmd.name == 'encodings') {
        printEncodings();
      } else if (cmd.name == 'colors') {
        printColorSchemeNames();
      } else if (cmd.name == 'projections') {
        printProjections();
      } else {
        return true;
      }
      return false;
    });
  }

  var RunCommands = /*#__PURE__*/Object.freeze({
    __proto__: null,
    runCommands: runCommands,
    applyCommands: applyCommands,
    runCommandsXL: runCommandsXL,
    testCommands: testCommands,
    runParsedCommands: runParsedCommands,
    runAndRemoveInfoCommands: runAndRemoveInfoCommands
  });

  // the mapshaper public api only has 4 functions
  var coreAPI = {
    runCommands,
    applyCommands,
    runCommandsXL,
    enableLogging
  };

  // Return an array containing points from a path iterator, clipped to a bounding box
  // Currently using this function for clipping styled polygons in the GUI to speed up layer rendering.
  // Artifacts along the edges make this unsuitable for clipping datasets
  // TODO: support clipping a single-part shape to multiple parts
  // TODO: prevent artifacts along edges
  function clipIterByBounds(iter, bounds) {
    var points = [];
    var bbox = getClippingBBox(bounds);
    var xy, xyp, first, isRing;
    while (iter.hasNext()) {
      xy = [iter.x, iter.y];
      addClippedPoint(points, xyp, xy, bbox);
      xyp = xy;
      if (!first) first = xy;
    }
    // detect closed rings
    isRing = pointsAreEqual(first, xy);
    if (isRing && points.length > 0 && !pointsAreEqual(points[0], points[points.length - 1])) {
      // some rings need to be closed
      points.push(points[0].concat());
    }
    if (isRing && points.length < 4 || points.length < 2) {
      // catch defective rings and polylines
      points = [];
    }
    return points;
  }

  function pointsAreEqual(a, b) {
    return a && b && a[0] === b[0] && a[1] === b[1];
  }

  //  2 3 4
  //  1 8 5
  //  0 7 6
  function getPointSector(x, y, bbox) {
    var bl = bbox[0];
    var tr = bbox[2];
    var i;
    if (x > tr[0]) {
      i = y > tr[1] && 4 || y >= bl[1] && 5 || 6; // right col
    } else if (x >= bl[0]) {
      i = y > tr[1] && 3 || y >= bl[1] && 8 || 7; // middle col
    } else {
      i = y > tr[1] && 2 || y >= bl[1] && 1 || 0; // left col
    }
    return i;
  }

  function isCornerSector(q) {
    return q == 0 || q == 2 || q == 4 || q == 6;
  }

  function isEdgeSector(q) {
    return q == 1 || q == 3 || q == 5 || q == 7;
  }

  // Number of CCW turns to normalize
  function getSectorRotation(q) {
    return q > 1 && q < 8 ? Math.floor(q / 2) : 0;
  }

  // i: rotation number
  // b: bbox object
  function rotateClippingBox(i, bbox) {
    var a = bbox[0],
        b = bbox[1],
        c = bbox[2],
        d = bbox[3];
    if (i === 0) {
      bbox = [a, b, c, d];
    } else if (i == 1) {
      bbox = [b, c, d, a];
    } else if (i == 2) {
      bbox = [c, d, a, b];
    } else if (i == 3) {
      bbox = [d, a, b, c];
    } else error('Invalid rotation number');
    return bbox;
  }

  // Convert a Bounds object to an array of 4 points designed to be rotated
  function getClippingBBox(bounds) {
    return [[bounds.xmin, bounds.ymin],
            [bounds.xmin, bounds.ymax],
            [bounds.xmax, bounds.ymax],
            [bounds.xmax, bounds.ymin]];
  }

  // i: ccw turns (0-3)
  function rotateSector(i, q) {
    return q < 8 && q >= 0 ? (q + 8 - i * 2) % 8 : q;
  }

  function getCornerBySector(q, bbox) {
    if (isCornerSector(q)) {
      return bbox[q / 2].concat();
    }
    error('Invalid corner sector:', q);
  }

  function addCornerPoint(points, q, bbox) {
    points.push(getCornerBySector(q, bbox));
  }

  function projectPointToEdge(p, s1, s2) {
    return s1[0] == s2[0] ? [s1[0], p[1]] : [p[0], s1[1]];
  }

  function addClippedPoint(points, p1, p2, bbox) {
    var q1 = p1 ? getPointSector(p1[0], p1[1], bbox) : -1;
    var q2 = getPointSector(p2[0], p2[1], bbox);
    var rot;
    // even polylines need to be connected along bbox edges to prevent artifact
    //   segments cutting through the bbox
    // TODO: convert disconnected parts to individual polylines or rings
    var closed = true;

    if (q1 == 8 && q2 == 8) {
      // segment is fully within box
      points.push(p2);

    } else if (q1 == q2) {
      // segment is fully within one outer sector (ignore it)

    } else if (q1 == -1) {
      // p2 is first point in the path
      if (q2 == 8) {
        points.push(p2);
      } else if (closed && isCornerSector(q2)) {
        addCornerPoint(points, q2, bbox);
      }

    } else if (q1 == 8) {
      // segment leaves box
      addSegmentBoundsIntersection(points, p1, p2, bbox);
      if (closed && isCornerSector(q2)) {
        addCornerPoint(points, q2, bbox);
      }

    } else if (q2 == 8) {
      // segment enters box
      addSegmentBoundsIntersection(points, p1, p2, bbox);
      points.push(p2);

    } else {
      // segment travels from one outer sector to another outer sector
      // normalise segment by rotating bbox so that p1 is
      // in the 0 or 1 sector relative to the bbox coordinates, if p1 is in an
      // outer segment
      rot = getSectorRotation(q1);
      bbox = rotateClippingBox(rot, bbox);
      q1 = rotateSector(rot, q1);
      q2 = rotateSector(rot, q2);
      if (q1 == 0) {
        // first point is in a corner sector
        if (q2 === 0 || q2 === 1 || q2 === 7) {
          // move to adjacent side -- no point

        } else if (q2 == 2 || q2 == 6) {
          // move to adjacent corner
          if (closed) addCornerPoint(points, q2, bbox);

        } else if (q2 == 3) {
          // far left edge (intersection or left corner)
          if (!addSegmentBoundsIntersection(points, p1, p2, bbox) && closed) addCornerPoint(points, 2, bbox);

        } else if (q2 == 4) {
          // opposite corner
          if (!addSegmentBoundsIntersection(points, p1, p2, bbox)) {
            // determine if bbox is to the left or right of segment
            if (geom.orient2D(p1[0], p1[1], p2[0], p2[1], bbox[0][0], bbox[0][1]) > 1) {
              // bbox is on the left (seg -> nearest corner is CCW)
              addCornerPoint(points, 6, bbox);
            } else {
              // bbox is on the right
              addCornerPoint(points, 2, bbox);
            }
          }
          if (closed) addCornerPoint(points, q2, bbox);

        } else if (q2 == 5) {
          // far right edge (intersection or right corner)
          if (!addSegmentBoundsIntersection(points, p1, p2, bbox) && closed) addCornerPoint(points, 6, bbox);
        }

      } else if (q1 == 1) {
        // first point is in a side sector
        if (q2 == 2 || q2 === 0) {
          // near left corner, near right corner
          addCornerPoint(points, q2, bbox);

        } else if (q2 == 3) {
          // to left side
          if (!addSegmentBoundsIntersection(points, p1, p2, bbox) && closed) addCornerPoint(points, 2, bbox);

        } else if (q2 == 4) {
          // to far left corner
          if (!addSegmentBoundsIntersection(points, p1, p2, bbox) && closed) addCornerPoint(points, 2, bbox);
          if (closed) addCornerPoint(points, 4, bbox);

        } else if (q2 == 5) {
          // to opposite side
          addSegmentBoundsIntersection(points, p1, p2, bbox);

        } else if (q2 == 6) {
          // to far right corner
          if (!addSegmentBoundsIntersection(points, p1, p2, bbox) && closed) addCornerPoint(points, 0, bbox);
          if (closed) addCornerPoint(points, 6, bbox);

        } else if (q2 == 7) {
          // to right side
          if (!addSegmentBoundsIntersection(points, p1, p2, bbox) && closed) addCornerPoint(points, 0, bbox);
        }

      } else {
        error("Sector error");
      }
    }
  }

  function addSegmentSegmentIntersection(points, a, b, c, d) {
    var p = geom.segmentIntersection(a[0], a[1], b[0], b[1], c[0], c[1],
          d[0], d[1]);
    if (p) points.push(p);
  }

  function addSegmentBoundsIntersection(points, a, b, bounds) {
    var hits = [];
    addSegmentSegmentIntersection(hits, a, b, bounds[0], bounds[1]); // first edge
    addSegmentSegmentIntersection(hits, a, b, bounds[0], bounds[3]); // last edge
    addSegmentSegmentIntersection(hits, a, b, bounds[1], bounds[2]);
    addSegmentSegmentIntersection(hits, a, b, bounds[2], bounds[3]);
    if (hits.length > 0 ) {
      points.push.apply(points, hits);
      return true;
    }
    return false;
  }

  // TODO: Need to rethink polygon repair: these function can cause problems
  // when part of a self-intersecting polygon is removed
  //
  function repairPolygonGeometry(layers, dataset, opts) {
    var nodes = addIntersectionCuts(dataset);
    layers.forEach(function(lyr) {
      repairSelfIntersections(lyr, nodes);
    });
    return layers;
  }

  // Remove any small shapes formed by twists in each ring
  // // OOPS, NO // Retain only the part with largest area
  // // this causes problems when a cut-off hole has a matching ring in another polygon
  // TODO: consider cases where cut-off parts should be retained
  //
  function repairSelfIntersections(lyr, nodes) {
    var splitter = getSelfIntersectionSplitter(nodes);

    lyr.shapes = lyr.shapes.map(function(shp, i) {
      return cleanPolygon(shp);
    });

    function cleanPolygon(shp) {
      var cleanedPolygon = [];
      forEachShapePart(shp, function(ids) {
        // TODO: consider returning null if path can't be split
        var splitIds = splitter(ids);
        if (splitIds.length === 0) {
          error("[cleanPolygon()] Defective path:", ids);
        } else if (splitIds.length == 1) {
          cleanedPolygon.push(splitIds[0]);
        } else {
          var shapeArea = geom.getPlanarPathArea(ids, nodes.arcs),
              sign = shapeArea > 0 ? 1 : -1,
              mainRing;

          var maxArea = splitIds.reduce(function(max, ringIds, i) {
            var pathArea = geom.getPlanarPathArea(ringIds, nodes.arcs) * sign;
            if (pathArea > max) {
              mainRing = ringIds;
              max = pathArea;
            }
            return max;
          }, 0);

          if (mainRing) {
            cleanedPolygon.push(mainRing);
          }
        }
      });
      return cleanedPolygon.length > 0 ? cleanedPolygon : null;
    }
  }

  var PolygonRepair = /*#__PURE__*/Object.freeze({
    __proto__: null,
    repairPolygonGeometry: repairPolygonGeometry,
    repairSelfIntersections: repairSelfIntersections
  });

  // Attach functions exported by modules to the "internal" object,
  // so they can be run by tests and by the GUI.
  // TODO: rewrite tests to import functions directly from modules,
  //       export only functions called by the GUI.

  var internal = {};
  internal.svg = Object.assign({}, SvgCommon, SvgStringify, SvgPathUtils, GeojsonToSvg);

  // Assign functions and objects exported from modules to the 'internal' namespace
  // to maintain compatibility with tests and to expose (some of) them to the GUI.

  Object.assign(internal, {
    Dbf,
    DbfReader,
    DouglasPeucker,
    geojson: GeoJSON,
    json: { parse: parse },
    ShpType,
    topojson: TopoJSON,
    Visvalingam,
    ArcCollection,
    Bounds,
    clipIterByBounds,
    CommandParser,
    DataTable,
    editArcs,
    GeoJSONReader,
    Heap,
    NodeCollection,
    parseDMS,
    PathIndex,
    PolygonIndex,
    ShpReader,
    Transform
  });

  Object.assign(internal,
    AnchorPoints,
    ArcClassifier,
    ArcDissolve,
    Bbox2Clipping,
    BinArray$1,
    BufferCommon,
    Calc,
    CalcUtils,
    Catalog$1,
    ClipErase,
    ClipPoints,
    Colorizer,
    CustomProjections,
    DataAggregation,
    DatasetUtils,
    DataUtils,
    DbfImport,
    DelimExport,
    DelimImport,
    DelimReader,
    Encodings,
    Explode,
    Export,
    Expressions,
    FileExport,
    FileImport,
    FilenameUtils,
    FileReader$1,
    FileTypes,
    FilterGeom,
    Frame,
    Furniture,
    Geodesic,
    GeojsonExport,
    GeojsonImport,
    Import,
    Info,
    IntersectionCuts,
    Join,
    JoinCalc,
    JoinFilter,
    JoinTables,
    JsonImport,
    JsonTable,
    KeepShapes,
    LatLon,
    LayerUtils,
    Lines,
    Logging,
    MergeFiles,
    Merging,
    MosaicIndex$1,
    OptionParsingUtils,
    OutputFormat,
    OverlayUtils,
    ParseCommands,
    PathBuffer,
    PathEndpoints,
    PathExport,
    Pathfinder,
    PathfinderUtils,
    PathImport,
    PathRepair,
    PathUtils,
    PixelTransform,
    PointPolygonJoin,
    Points,
    PointUtils,
    PolygonDissolve,
    PolygonDissolve2,
    PolygonHoles,
    PolygonMosaic,
    PolygonNeighbors,
    PolygonRepair,
    PolygonTiler$1,
    PolylineClipping,
    PostSimplifyRepair,
    Proj,
    Projections,
    Rectangle,
    Rounding,
    RunCommands,
    Scalebar,
    SegmentIntersection,
    ShapeIter$1,
    ShapeUtils,
    ShpCommon,
    ShpExport,
    ShpImport,
    Simplify,
    SimplifyFast,
    SimplifyPct,
    Slivers,
    Snapping,
    SourceUtils,
    Split,
    State,
    Stringify,
    Svg,
    SvgProperties,
    Symbols,
    TargetUtils,
    TopojsonExport,
    TopojsonImport,
    Topology,
    Units,
    SvgHatch,
    VertexUtils
  );

  // The entry point for the core mapshaper module
  var moduleAPI = Object.assign({
    cli, geom, utils, internal,
    importFile // Adding importFile() for compatibility with old tests; todo: rewrite tests
  }, cmd, coreAPI);  // Adding command functions to the top-level module API, for test compatibility

  if (typeof module === "object" && module.exports) {
    module.exports = moduleAPI;
  } else if (typeof window === "object" && window) {
    window.mapshaper = moduleAPI;
  }

})();

}).call(this)}).call(this,require('_process'),require("timers").setImmediate,"/node_modules/mapshaper/www")
},{"_process":7,"buffer":4,"child_process":1,"d3-color":11,"d3-interpolate":12,"d3-scale-chromatic":13,"flatbush":14,"fs":1,"iconv-lite":34,"kdbush":35,"mproj":37,"path":6,"rw":43,"sync-request":52,"timers":10}],37:[function(require,module,exports){
(function (__filename){(function (){
(function(){

// add math.h functions to library scope
// (to make porting projection functions simpler)
var fabs = Math.abs,
    floor = Math.floor,
    sin = Math.sin,
    cos = Math.cos,
    tan = Math.tan,
    asin = Math.asin,
    acos = Math.acos,
    atan = Math.atan,
    atan2 = Math.atan2,
    sqrt = Math.sqrt,
    pow = Math.pow,
    exp = Math.exp,
    log = Math.log,
    hypot = Math.hypot,
    sinh = Math.sinh,
    cosh = Math.cosh,
    MIN = Math.min,
    MAX = Math.max;

// constants from math.h
var HUGE_VAL = Infinity,
    M_PI = Math.PI;

// from proj_api.h
var RAD_TO_DEG = 57.295779513082321,
    DEG_TO_RAD = 0.017453292519943296;

// from pj_transform.c
var SRS_WGS84_SEMIMAJOR = 6378137;
var SRS_WGS84_ESQUARED = 0.0066943799901413165;

// math constants from project.h
var M_FORTPI = M_PI / 4,
    M_HALFPI = M_PI / 2,
    M_PI_HALFPI = 1.5 * M_PI,
    M_TWOPI = 2 * M_PI,
    M_TWO_D_PI = 2 / M_PI,
    M_TWOPI_HALFPI = 2.5 * M_PI;

// datum types
var PJD_UNKNOWN = 0,
    PJD_3PARAM = 1,
    PJD_7PARAM = 2,
    PJD_GRIDSHIFT = 3,
    PJD_WGS84 = 4;

// named errors
var PJD_ERR_GEOCENTRIC = -45,
    PJD_ERR_AXIS = -47,
    PJD_ERR_GRID_AREA = -48,
    PJD_ERR_CATALOG = -49;

// common
var EPS10 = 1e-10;


var PJ_LOG_NONE = 0,
    PJ_LOG_ERROR = 1,
    PJ_LOG_DEBUG_MAJOR = 2,
    PJ_LOG_DEBUG_MINOR = 3;

// context of currently running projection function
// (Unlike Proj.4, we use a single ctx object)
var ctx = {
  last_errno: 0,
  debug_level:  PJ_LOG_NONE,
  logger: null // TODO: implement
};



var pj_err_list = [
  "no arguments in initialization list",  /*  -1 */
  "no options found in 'init' file",    /*  -2 */
  "invalid init= string",   /*  -3 */ // Proj.4 text: "no colon in init= string",
  "projection not named",       /*  -4 */
  "unknown projection id",      /*  -5 */
  "effective eccentricity = 1",      /*  -6 */
  "unknown unit conversion id",     /*  -7 */
  "invalid boolean param argument",   /*  -8 */
  "unknown elliptical parameter name",          /*  -9 */
  "reciprocal flattening (1/f) = 0",    /* -10 */
  "|radius reference latitude| > 90",   /* -11 */
  "squared eccentricity < 0",     /* -12 */
  "major axis or radius = 0 or not given",  /* -13 */
  "latitude or longitude exceeded limits",  /* -14 */
  "invalid x or y",       /* -15 */
  "improperly formed DMS value",      /* -16 */
  "non-convergent inverse meridional dist", /* -17 */
  "non-convergent inverse phi2",      /* -18 */
  "acos/asin: |arg| >1+1e-14",     /* -19 */
  "tolerance condition error",      /* -20 */
  "conic lat_1 = -lat_2",       /* -21 */
  "lat_1 >= 90",          /* -22 */
  "lat_1 = 0",          /* -23 */
  "lat_ts >= 90",         /* -24 */
  "no distance between control points",   /* -25 */
  "projection not selected to be rotated",  /* -26 */
  "W <= 0 or M <= 0",       /* -27 */
  "lsat not in 1-5 range",      /* -28 */
  "path not in range",        /* -29 */
  "h <= 0",         /* -30 */
  "k <= 0",         /* -31 */
  "lat_0 = 0 or 90 or alpha = 90",    /* -32 */
  "lat_1=lat_2 or lat_1=0 or lat_2=90",   /* -33 */
  "elliptical usage required",      /* -34 */
  "invalid UTM zone number",      /* -35 */
  "arg(s) out of range for Tcheby eval",    /* -36 */
  "failed to find projection to be rotated",  /* -37 */
  "failed to load datum shift file",            /* -38 */
  "both n & m must be spec'd and > 0",    /* -39 */
  "n <= 0, n > 1 or not specified",   /* -40 */
  "lat_1 or lat_2 not specified",     /* -41 */
  "|lat_1| == |lat_2|",       /* -42 */
  "lat_0 is pi/2 from mean lat",      /* -43 */
  "unparseable coordinate system definition", /* -44 */
  "geocentric transformation missing z or ellps", /* -45 */
  "unknown prime meridian conversion id",   /* -46 */
  "illegal axis orientation combination",   /* -47 */
  "point not within available datum shift grids", /* -48 */
  "invalid sweep axis, choose x or y"
];


// see pj_transform.c CHECK_RETURN()
function check_fatal_error() {
  var code = ctx.last_errno;
  if (!code) return;
  if (code > 0 || !is_transient_error(code)) {
    e_error(code);
  } else {
    // transient error
    // TODO: consider a strict mode that throws an error
  }
}

function is_transient_error(code) {
  return transient_error.indexOf(code) > -1;
}

var transient_error = [-14, -15, -17, -18, -19, -20, -27, -48];

function pj_ctx_set_errno(code) {
  ctx.last_errno = code;
}

function f_error() {
  pj_ctx_set_errno(-20);
}

function i_error() {
  pj_ctx_set_errno(-20);
}

function error_msg(code) {
  return pj_err_list[~code] || "unknown error";
}

// alias for e_error()
function error(code) {
  e_error(code);
}

// a fatal error
// see projects.h E_ERROR macro
function e_error(code) {
  pj_ctx_set_errno(code);
  fatal();
}

function fatal(msg, o) {
  if (!o) o = {};
  if (!o.code) o.code = ctx.last_errno || 0;
  if (!msg) msg = error_msg(o.code);
  // reset error code, so processing can continue after this error is handled
  ctx.last_errno = 0;
  throw new ProjError(msg, o);
}

function ProjError(msg, o) {
  var err = new Error(msg);
  err.name = 'ProjError';
  Object.keys(o).forEach(function(k) {
    err[k] = o[k];
  });
  return err;
}


function dmstor(str) {
  return dmstod(str) * DEG_TO_RAD;
}

// Parse a formatted value in DMS DM or D to a numeric value
// Delimiters: D|d (degrees), ' (minutes), " (seconds)
function dmstod(str) {
  var match = /(-?[0-9.]+)d?([0-9.]*)'?([0-9.]*)"?([nsew]?)$/i.exec(str);
  var d = NaN;
  var deg, min, sec;
  if (match) {
    deg = match[1] || '0';
    min = match[2] || '0';
    sec = match[3] || '0';
    d = (+deg) + (+min) / 60 + (+sec) / 3600;
    if (/[ws]/i.test(match[4])) {
      d = -d;
    }
  }
  if (isNaN(d)) {
    // throw an exception instead of just setting an error code
    // (assumes this function is called by pj_init() or a cli program,
    // where an exception is more appropriate)
    e_error(-16);
    // pj_ctx_set_errno(-16);
    // d = HUGE_VAL;
  }
  return d;
}



function pj_atof(str) {
  return pj_strtod(str);
}

function pj_strtod(str) {
  return parseFloat(str);
}


/* types
  t  test for presence
  i  integer
  d  simple real
  r  dms or decimal degrees
  s  string
  b  boolean
*/


// see pj_param.c
// this implementation is slightly different
function pj_param(params, code) {
  var type = code[0],
      name = code.substr(1),
      obj = params[name],
      isset = obj !== void 0,
      val, param;

  if (type == 't') {
    val = isset;
  } else if (isset) {
    param = obj.param;
    obj.used = true;
    if (type == 'i') {
      val = parseInt(param);
    } else if (type == 'd') {
      // Proj.4 handles locale-specific decimal mark
      // TODO: what to do about NaNs
      val = pj_atof(param);
    } else if (type == 'r') {
      val = dmstor(param);
    } else if (type == 's') {
      val = String(param);
    } else if (type == 'b') {
      if (param == 'T' || param == 't' || param === true) {
        val = true;
      } else if (param == 'F' || param == 'f') {
        val = false;
      } else {
        pj_ctx_set_errno(-8);
        val = false;
      }
    }
  } else {
    // value is not set; use default
    val = {
      i: 0,
      b: false,
      d: 0,
      r: 0,
      s: ''
    }[type];
  }
  if (val === void 0) {
    fatal("invalid request to pj_param, fatal");
  }
  return val;
}

// convert arguments in a proj4 definition string into object properties
// (not in Proj.4)
function pj_get_params(args) {
  var rxp = /\+([a-z][a-z0-9_]*(?:=[^\s]*)?)/gi;
  var params = {};
  var match;
  while (match = rxp.exec(args)) {
    pj_mkparam(params, match[1]);
  }
  return params;
}

// different from Proj.4
function pj_mkparam(params, token) {
  var parts = token.split('=');
  var name, val;
  if (parts.length == 1) {
    name = token;
    val = true;
  } else {
    name = parts[0];
    val = token.substr(parts[0].length + 1);
  }
  params[name] = {used: false, param: val};
}



var pj_list = {};

function pj_add(func, key, name, desc) {
  pj_list[key] = {
    init: func,
    name: name,
    description: desc
  };
}


/* @pj_param */

function pj_is_latlong(P) {
  return !P || P.is_latlong;
}

function pj_is_geocent(P) {
  return !P || P.is_geocent;
}

function get_geod_defn(P) {
  var got_datum = false,
      defn = '';
  if ('datum' in P.params) {
    got_datum = true;
    defn += get_param(P, 'datum');
  } else if ('ellps' in P.params) {
    defn += get_param(P, 'ellps');
  } else if ('a' in P.params) {
    defn += get_param(P, 'a');
    if ('b' in P.params) {
      defn += get_param(P, 'b');
    } else if ('es' in P.params) {
      defn += get_param(P, 'es');
    } else if ('f' in P.params) {
      defn += get_param(P, 'f');
    } else {
      defn += ' +es=' + P.es;
    }
  } else {
    error(-13);
  }
  if (!got_datum) {
    defn += get_param(P, 'towgs84');
    defn += get_param(P, 'nadgrids');
  }
  defn += get_param(P, 'R');
  defn += get_param(P, 'R_A');
  defn += get_param(P, 'R_V');
  defn += get_param(P, 'R_a');
  defn += get_param(P, 'R_lat_a');
  defn += get_param(P, 'R_lat_g');
  defn += get_param(P, 'pm');
  return defn;
}

// Convert an initialized proj object back to a Proj.4 string
function get_proj_defn(P) {
  // skip geodetic params and some initialization-related params
  var skip = 'datum,ellps,a,b,es,rf,f,towgs84,nadgrids,R,R_A,R_V,R_a,R_lat_a,R_lat_g,pm,init,no_defs'.split(',');
  var defn = '';
  Object.keys(P.params).forEach(function(name) {
    if (skip.indexOf(name) == -1) {
      defn += get_param(P, name);
    }
  });
  // add geodetic params
  defn += get_geod_defn(P);
  return defn.trim();
}

function get_param(P, name) {
  var param = '';
  if (name in P.params) {
    param = ' +' + name;
    if (P.params[name].param !== true) {
      param += '=' + pj_param(P.params, 's' + name);
    }
  }
  return param;
}



var pj_datums = [
  /* id defn ellipse_id comments */
  ["WGS84", "towgs84=0,0,0", "WGS84", "WGS_1984"], // added comment for wkt creation
  ["GGRS87", "towgs84=-199.87,74.79,246.62", "GRS80", "Greek_Geodetic_Reference_System_1987"],
  ["NAD83", "towgs84=0,0,0", "GRS80", "North_American_Datum_1983"],
  // nadgrids not supported; NAD27 will trigger an error
  ["NAD27", "nadgrids=@conus,@alaska,@ntv2_0.gsb,@ntv1_can.dat", "clrk66", "North_American_Datum_1927"],
  ["potsdam", "towgs84=598.1,73.7,418.2,0.202,0.045,-2.455,6.7", "bessel", "Potsdam Rauenberg 1950 DHDN"],
  ["carthage","towgs84=-263.0,6.0,431.0", "clrk80ign", "Carthage 1934 Tunisia"],
  ["hermannskogel", "towgs84=577.326,90.129,463.919,5.137,1.474,5.297,2.4232", "bessel", "Hermannskogel"],
  ["ire65", "towgs84=482.530,-130.596,564.557,-1.042,-0.214,-0.631,8.15", "mod_airy", "Ireland 1965"],
  ["nzgd49", "towgs84=59.47,-5.04,187.44,0.47,-0.1,1.024,-4.5993", "intl", "New Zealand Geodetic Datum 1949"],
  ["OSGB36", "towgs84=446.448,-125.157,542.060,0.1502,0.2470,0.8421,-20.4894", "airy", "OSGB 1936"],
  [null, null, null, null]
];


var pj_prime_meridians = [
  // id definition
  ["greenwich", "0dE"],
  ["lisbon",    "9d07'54.862\"W"],
  ["paris",     "2d20'14.025\"E"],
  ["bogota",    "74d04'51.3\"W"],
  ["madrid",    "3d41'16.58\"W"],
  ["rome",      "12d27'8.4\"E"],
  ["bern",      "7d26'22.5\"E"],
  ["jakarta",   "106d48'27.79\"E"],
  ["ferro",     "17d40'W"],
  ["brussels",  "4d22'4.71\"E"],
  ["stockholm", "18d3'29.8\"E"],
  ["athens",    "23d42'58.815\"E"],
  ["oslo",      "10d43'22.5\"E"],
  [null,        null]
];

function find_prime_meridian(id) {
  var defn = pj_prime_meridians.reduce(function(memo, arr) {
    return arr[0] === id ? arr : memo;
  }, null);
  return defn ? {id: defn[0], definition: defn[1]} : null;
}

function find_datum(id) {
  var defn = pj_datums.reduce(function(memo, arr) {
    return arr[0] === id ? arr : memo;
  }, null);
  return defn ? {id: defn[0], defn: defn[1], ellipse_id: defn[2], name: defn[3]} : null;
}


function pj_datum_set(P) {
  var SEC_TO_RAD = 4.84813681109535993589914102357e-6;
  var params = P.datum_params = [0,0,0,0,0,0,0];
  var name, datum, nadgrids, catalog, towgs84;

  P.datum_type = PJD_UNKNOWN;

  if (name = pj_param(P.params, 'sdatum')) {
    datum = find_datum(name);
    if (!datum) {
      error(-9);
    }
    if (datum.ellipse_id) {
      pj_mkparam(P.params, 'ellps=' + datum.ellipse_id);
    }
    if (datum.defn) {
      pj_mkparam(P.params, datum.defn);
    }
  }

  nadgrids = pj_param(P.params, "snadgrids");
  if (nadgrids && nadgrids != '@null') {
    fatal("+nadgrids is not implemented");
  }
  if (catalog = pj_param(P.params, "scatalog")) {
    fatal("+catalog is not implemented");
  }
  if (towgs84 = pj_param(P.params, "stowgs84")) {
    towgs84.split(',').forEach(function(s, i) {
      params[i] = pj_atof(s) || 0;
    });
    if (params[3] != 0 || params[4] != 0 || params[5] != 0 || params[6] != 0) {
      P.datum_type = PJD_7PARAM;
      params[3] *= SEC_TO_RAD;
      params[4] *= SEC_TO_RAD;
      params[5] *= SEC_TO_RAD;
      params[6] =  params[6] / 1e6 + 1;
    } else {
      P.datum_type = PJD_3PARAM;
      /* Note that pj_init() will later switch datum_type to
         PJD_WGS84 if shifts are all zero, and ellipsoid is WGS84 or GRS80 */
    }
  }
}



var pj_ellps = [
  // id major ell name
  ["MERIT", "a=6378137.0", "rf=298.257", "MERIT 1983"],
  ["SGS85", "a=6378136.0", "rf=298.257", "Soviet Geodetic System 85"],
  ["GRS80", "a=6378137.0", "rf=298.257222101", "GRS 1980(IUGG, 1980)"],
  ["IAU76", "a=6378140.0", "rf=298.257", "IAU 1976"],
  ["airy", "a=6377563.396", "b=6356256.910", "Airy 1830"],
  ["APL4.9", "a=6378137.0", "rf=298.25", "Appl. Physics. 1965"],
  ["NWL9D", "a=6378145.0", "rf=298.25", "Naval Weapons Lab., 1965"],
  ["mod_airy", "a=6377340.189", "b=6356034.446", "Modified Airy"],
  ["andrae", "a=6377104.43", "rf=300.0", "Andrae 1876 (Den., Iclnd.)"],
  ["aust_SA", "a=6378160.0", "rf=298.25", "Australian Natl & S. Amer. 1969"],
  ["GRS67", "a=6378160.0", "rf=298.2471674270", "GRS 67(IUGG 1967)"],
  ["bessel", "a=6377397.155", "rf=299.1528128", "Bessel 1841"],
  ["bess_nam", "a=6377483.865", "rf=299.1528128", "Bessel 1841 (Namibia)"],
  ["clrk66", "a=6378206.4", "b=6356583.8", "Clarke 1866"],
  ["clrk80", "a=6378249.145", "rf=293.4663", "Clarke 1880 mod."],
  ["clrk80ign", "a=6378249.2", "rf=293.4660212936269", "Clarke 1880 (IGN)."],
  ["CPM", "a=6375738.7", "rf=334.29", "Comm. des Poids et Mesures 1799"],
  ["delmbr", "a=6376428", "rf=311.5", "Delambre 1810 (Belgium)"],
  ["engelis", "a=6378136.05", "rf=298.2566", "Engelis 1985"],
  ["evrst30", "a=6377276.345", "rf=300.8017", "Everest 1830"],
  ["evrst48", "a=6377304.063", "rf=300.8017", "Everest 1948"],
  ["evrst56", "a=6377301.243", "rf=300.8017", "Everest 1956"],
  ["evrst69", "a=6377295.664", "rf=300.8017", "Everest 1969"],
  ["evrstSS", "a=6377298.556", "rf=300.8017", "Everest (Sabah & Sarawak)"],
  ["fschr60", "a=6378166", "rf=298.3", "Fischer (Mercury Datum) 1960"],
  ["fschr60m", "a=6378155", "rf=298.3", "Modified Fischer 1960"],
  ["fschr68", "a=6378150", "rf=298.3", "Fischer 1968"],
  ["helmert", "a=6378200", "rf=298.3", "Helmert 1906"],
  ["hough", "a=6378270.0", "rf=297", "Hough"],
  ["intl", "a=6378388.0", "rf=297", "International 1909 (Hayford)"],
  ["krass", "a=6378245.0", "rf=298.3", "Krasovsky 1940"], // Proj.4 has "Krassovsky, 1942"
  ["kaula", "a=6378163", "rf=298.24", "Kaula 1961"],
  ["lerch", "a=6378139", "rf=298.257", "Lerch 1979"],
  ["mprts", "a=6397300", "rf=191", "Maupertius 1738"],
  ["new_intl", "a=6378157.5", "b=6356772.2", "New International 1967"],
  ["plessis", "a=6376523", "b=6355863",  "Plessis 1817 (France)"],
  ["SEasia", "a=6378155.0", "b=6356773.3205", "Southeast Asia"],
  ["walbeck", "a=6376896.0", "b=6355834.8467", "Walbeck"],
  ["WGS60", "a=6378165.0", "rf=298.3", "WGS 60"],
  ["WGS66", "a=6378145.0", "rf=298.25", "WGS 66"],
  ["WGS72", "a=6378135.0", "rf=298.26", "WGS 72"],
  ["WGS84", "a=6378137.0", "rf=298.257223563", "WGS 84"],
  ["sphere", "a=6370997.0", "b=6370997.0", "Normal Sphere (r=6370997)"],
  [null, null,  null,  null]
];

function find_ellps(id) {
  var defn = pj_ellps.reduce(function(memo, arr) {
    return arr[0] === id ? arr : memo;
  }, null);
  return defn ? {id: defn[0], major: defn[1], ell: defn[2], name: defn[3]} : null;
}


function pj_ell_set(P) {
  var SIXTH = 0.1666666666666666667, /* 1/6 */
      RA4 = 0.04722222222222222222, /* 17/360 */
      RA6 = 0.02215608465608465608, /* 67/3024 */
      RV4 = 0.06944444444444444444, /* 5/72 */
      RV6 = 0.04243827160493827160; /* 55/1296 */
  var params = P.params;
  var a = 0;
  var es = 0;
  var name, ellps, tmp, b, i;
  if (pj_param(params, 'tR')) {
    a = pj_param(params, 'dR');
  } else {
    if (name = pj_param(params, 'sellps')) {
      ellps = find_ellps(name);
      if (!ellps) {
        error(-9);
      }
      pj_mkparam(params, ellps.major);
      pj_mkparam(params, ellps.ell);
    }
    a = pj_param(params, 'da');
    if (pj_param(params, 'tes')) {
      es = pj_param(params, 'des');
    } else if (pj_param(params, 'te')) {
      tmp = pj_param(params, 'de');
      es = tmp * tmp;
    } else if (pj_param(params, 'trf')) {
      tmp = pj_param(params, 'drf');
      if (!tmp) {
        error(-10);
      }
      tmp = 1 / tmp;
      es = tmp * (2 - tmp);
    } else if (pj_param(params, 'tf')) {
      tmp = pj_param(params, 'df');
      es = tmp * (2 - tmp);
    } else if (pj_param(params, 'tb')) {
      b = pj_param(params, 'db');
      es = 1 - (b * b) / (a * a);
    }
    if (!b) {
      b = a * sqrt(1 - es);
    }

    if (pj_param(params, 'bR_A')) {
      a *= 1 - es * (SIXTH + es * (RA4 + es * RA6));
      es = 0;
    } else if (pj_param(params, 'bR_V')) {
      a *= 1 - es * (SIXTH + es * (RV4 + es * RV6));
    } else if (pj_param(params, 'bR_a')) {
      a = 0.5 * (a + b);
      es = 0;
    } else if (pj_param(params, 'bR_g')) {
      a = sqrt(a * b);
      es = 0;
    } else if (pj_param(params, 'bR_h')) {
      if (a + b === 0) {
        error(-20);
      }
      a = 2 * a * b / (a + b);
      es = 0;
    } else if (i = pj_param(params, 'tR_lat_a') || pj_param(params, 'tR_lat_g')) {
      tmp = sin(pj_param(params, i ? 'rR_lat_a' : 'rR_lat_g'));
      if (fabs(tmp) > M_HALFPI) {
        error(-11);
      }
      tmp = 1 - es * tmp * tmp;
      a *= i ? 0.5 * (1 - es + tmp) / (tmp * sqrt(tmp)) : sqrt(1 - es) / tmp;
      es = 0;
    }
  }

  if (es < 0) error(-12);
  if (a <= 0) error(-13);
  P.es = es;
  P.a = a;
}



var pj_units = [
  // id to_meter name
  ["km", "1000", "Kilometer"],
  ["m", "1", "Meter"],
  ["dm", "1/10", "Decimeter"],
  ["cm", "1/100", "Centimeter"],
  ["mm", "1/1000", "Millimeter"],
  ["kmi", "1852.0", "International Nautical Mile"],
  ["in", "0.0254", "International Inch"],
  ["ft", "0.3048", "International Foot"],
  ["yd", "0.9144", "International Yard"],
  ["mi", "1609.344", "International Statute Mile"],
  ["fath", "1.8288", "International Fathom"],
  ["ch", "20.1168", "International Chain"],
  ["link", "0.201168", "International Link"],
  ["us-in", "1/39.37", "U.S. Surveyor's Inch"],
  ["us-ft", "0.304800609601219", "U.S. Surveyor's Foot"],
  ["us-yd", "0.914401828803658", "U.S. Surveyor's Yard"],
  ["us-ch", "20.11684023368047", "U.S. Surveyor's Chain"],
  ["us-mi", "1609.347218694437", "U.S. Surveyor's Statute Mile"],
  ["ind-yd", "0.91439523", "Indian Yard"],
  ["ind-ft", "0.30479841", "Indian Foot"],
  ["ind-ch", "20.11669506", "Indian Chain"],
  [null, null, null]
];

function find_units_by_value(val) {
  return pj_units.reduce(function(memo, defn) {
    if (val == +defn[1]) {
      memo = find_units(defn[0]);
    }
    return memo;
  }, null);
}

function find_units(id) {
  var arr = pj_units.reduce(function(memo, defn) {
    return id === defn[0] ? defn : memo;
  }, null);
  return arr ? {id: arr[0], to_meter: arr[1], name: arr[2]} : null;
}



var initcache = {};

function pj_search_initcache(key) {
  return initcache[key.toLowerCase()] || null;
}

function pj_insert_initcache(key, defn) {
  initcache[key.toLowerCase()] = defn;
}


// Replacement functions for Proj.4 pj_open_lib() (see pj_open_lib.c)
// and get_opt() (see pj_init.c)

var libcache = {};

// add a definition library without reading from a file (for use by web app)
function mproj_insert_libcache(libId, contents) {
  libcache[libId] = contents;
}

function mproj_search_libcache(libId) {
  return libcache[libId] || null;
}

function mproj_read_lib_anycase(libFile) {
  var fs = require('fs'),
      path = require('path'),
      // path to library assumes mproj script is in the dist/ directory
      dir = path.join(path.dirname(__filename), '../nad'),
      pathUC = path.join(dir, libFile.toUpperCase()),
      pathLC = path.join(dir, libFile.toLowerCase()),
      contents;
  if (fs.existsSync(pathUC)) {
    contents = fs.readFileSync(pathUC, 'utf8');
  } else if (fs.existsSync(pathLC)) {
    contents = fs.readFileSync(pathLC, 'utf8');
  } else {
    fatal('unable to read from \'init\' file named ' + libFile); // not in Proj.4
  }
  return contents;
}

// Return opts from a section of a config file,
//   or null if not found or unable to read file
function pj_read_init_opts(initStr) {
  var parts = initStr.split(':'),
      libId = parts[0],
      crsId = parts[1],
      libStr, o;
  if (!crsId || !libId) {
    error(-3);
  }
  libId = libId.toLowerCase(); // not in Proj.4
  libStr = mproj_search_libcache(libId);
  if (!libStr) {
    libStr = mproj_read_lib_anycase(libId);
    libcache[libId] = libStr;
  }
  return libStr ? pj_find_opts(libStr, crsId) : null;
}

// Find params in contents of an init file
function pj_find_opts(contents, id) {
  var opts = '', comment = '',
      idx, idx2;
  // get requested parameters
  idx = contents.indexOf('<' + id + '>');
  if (idx > -1) {
    // get comment text
    idx2 = contents.lastIndexOf('#', idx);
    if (idx2 > -1) {
      comment = contents.substring(idx2 + 1, idx).trim();
      if (/\n/.test(comment)) {
        comment = '';
      }
    }
    // get projection params
    opts = contents.substr(idx + id.length + 2);
    opts = opts.substr(0, opts.indexOf('<'));
    // remove comments
    opts = opts.replace(/#.*/g, '');
    // convert all whitespace to single <sp>
    opts = opts.replace(/[\s]+/g, ' ');

    // if '+' is missing from args, add it
    // kludge: protect spaces in +title= opts
    opts = opts.replace(/\+title=[^+]*[^ +]/g, function(match) {
      return match.replace(/ /g, '\t');
    });
    opts = ' ' + opts;
    opts = opts.replace(/ (?=[a-z])/ig, ' +');
    opts = opts.replace(/\t/g, ' ').trim();
  }
  return opts ? {opts: opts, comment: comment} : null;
}


// Returns an initialized projection object
// @args a proj4 string
function pj_init(args) {
  var params = pj_get_params(args);
  var P = {
    params: params,
    is_latlong: false,
    is_geocent: false,
    is_long_wrap_set: false,
    long_wrap_center: 0,
    axis: "enu",
    gridlist: null,
    gridlist_count: 0,
    vgridlist_geoid: null,
    vgridlist_geoid_count: 0
  };
  var name, defn;
  if (!Object.keys(params).length) {
    error(-1);
  }

  if (pj_param(params, "tinit")) {
    get_init(params, pj_param(params, "sinit"));
  }

  name = pj_param(params, "sproj");
  if (!name) {
    error(-4);
  }

  defn = pj_list[name];
  if (!defn) {
    error(-5);
  }

  if (!pj_param(params, "bno_defs")) {
    get_defaults(P.params, name);
  }

  pj_datum_set(P);
  pj_ell_set(P);

  P.a_orig = P.a;
  P.es_orig = P.es;
  P.e = sqrt(P.es);
  P.ra = 1 / P.a;
  P.one_es = 1 - P.es;
  if (!P.one_es) {
    error(-6);
  }
  P.rone_es = 1 / P.one_es;

  if (is_wgs84(P)) {
    P.datum_type = PJD_WGS84;
  }

  P.geoc = !!P.es && pj_param(params, 'bgeoc');
  P.over = pj_param(params, 'bover');
  P.has_geoid_vgrids = pj_param(params, 'tgeoidgrids');
  if (P.has_geoid_vgrids) {
    pj_param(params, "sgeoidgrids"); // mark as used
  }

  P.is_long_wrap_set = pj_param(params, 'tlon_wrap');
  if (P.is_long_wrap_set) {
    P.long_wrap_center = pj_param(params, 'rlon_wrap');
    // Don't accept excessive values otherwise we might perform badly
    // when correcting longitudes around it
    // The test is written this way to error on long_wrap_center "=" NaN
    if (fabs(P.long_wrap_center) < 10 * M_TWOPI === false) {
      error(-14);
    }
  }

  if (pj_param(params, 'saxis')) {
    init_axis(P);
  }

  P.lam0 = pj_param(params, 'rlon_0');
  P.phi0 = pj_param(params, 'rlat_0');
  P.x0 = pj_param(params, 'dx_0');
  P.y0 = pj_param(params, 'dy_0');

  if (pj_param(params, 'tk_0')) {
    P.k0 = pj_param(params, 'dk_0');
  } else if (pj_param(params, 'tk')) {
    P.k0 = pj_param(params, 'dk');
  } else {
    P.k0 = 1;
  }
  if (P.k0 <= 0) {
    error(-31);
  }

  init_units(P);
  init_prime_meridian(P);
  defn.init(P);
  return P;
}

// Merge default params
// NOTE: Proj.4 loads defaults from the file nad/proj_def.dat
// This function applies the default ellipsoid from proj_def.dat but
//   ignores the other defaults, which could be considered undesirable
//   (see e.g. https://github.com/OSGeo/proj.4/issues/201)
function get_defaults(params, name) {
  get_opt(params, '+ellps=WGS84');
}

function get_init(params, initStr) {
  var defn = pj_search_initcache(initStr);
  if (!defn) {
    defn = pj_read_init_opts(initStr);
    pj_insert_initcache(initStr, defn);
  }
  if (!defn) {
    error(-2);
  }
  // merge init params
  get_opt(params, defn.opts);
}

// Merge params from a proj4 string
// (Slightly different interface from Proj.4 get_opts())
function get_opt(params, args) {
  var newParams = pj_get_params(args);
  var geoIsSet = ['datum', 'ellps', 'a', 'b', 'rf', 'f'].reduce(function(memo, key) {
    return memo || key in params;
  }, false);
  Object.keys(newParams).forEach(function(key) {
    // don't override existing params
    if (key in params) return;
    // don't set ellps if earth model info is set
    if (key == 'ellps' && geoIsSet) return;
    params[key] = newParams[key];
  });
}

function init_prime_meridian(P) {
  var params = P.params,
  name, pm, offs;
  name = pj_param(params, 'spm');
  if (name) {
    pm = find_prime_meridian(name);
    offs = dmstor(pm ? pm.definition : name);
    if (isNaN(offs)) {
      error(-46);
    }
    P.from_greenwich = offs;
  } else {
    P.from_greenwich = 0;
  }
}

function init_units(P) {
  var params = P.params;
  var name, s, units;
  if (name = pj_param(params, 'sunits')) {
    units = find_units(name);
    if (!units) {
      error(-7);
    }
    s = units.to_meter;
  }
  if (s || (s = pj_param(params, 'sto_meter'))) {
    P.to_meter = parse_to_meter(s);
    P.fr_meter = 1 / P.to_meter;
  } else {
    P.to_meter = P.fr_meter = 1;
  }

  // vertical units
  s = null;
  if (name = pj_param(params, 'svunits')) {
    units = find_units(name);
    if (!units) {
      error(-7);
    }
    s = units.to_meter;
  }
  if (s || (pj_param(params, 'svto_meter'))) {
    P.vto_meter = parse_to_meter(s);
    P.vfr_meter = 1 / P.vto_meter;
  } else {
    P.vto_meter = P.to_meter;
    P.vfr_meter = P.fr_meter;
  }
}

function parse_to_meter(s) {
  var parts = s.split('/');
  var val = pj_strtod(parts[0]);
  if (parts.length > 1) {
    val /= pj_strtod(parts[1]);
  }
  return val;
}

function init_axis(P) {
  var axis_legal = "ewnsud";
  var axis = pj_param(P.params, 'saxis');
  if (axis.length != 3) {
    error(PJD_ERR_AXIS);
  }
  if (axis_legal.indexOf(axis[0]) == -1 ||
      axis_legal.indexOf(axis[1]) == -1 ||
      axis_legal.indexOf(axis[2]) == -1) {
    error(PJD_ERR_AXIS);
  }
  P.axis = axis;
}

function is_wgs84(P) {
  return P.datum_type == PJD_3PARAM &&
    P.datum_params[0] == P.datum_params[1] == P.datum_params[2] === 0 &&
    P.a == 6378137 && Math.abs(P.es - 0.006694379990) < 0.000000000050;
}



// TODO: remove error codes (Proj.4 doesn't do anything with them)
var GEOCENT_NO_ERROR = 0x0000,
    GEOCENT_LAT_ERROR = 0x0001,
    GEOCENT_LON_ERROR = 0x0002,
    GEOCENT_A_ERROR = 0x0004,
    GEOCENT_B_ERROR = 0x0008,
    GEOCENT_A_LESS_B_ERROR = 0x0010;

// a: Semi-major axis, in meters.
// b: Semi-minor axis, in meters.
function pj_Set_Geocentric_Parameters(a, b) {
  var err = GEOCENT_NO_ERROR,
      a2 = a * a,
      b2 = b * b;
  if (a <= 0.0) err |= GEOCENT_A_ERROR;
  if (b <= 0.0) err |= GEOCENT_B_ERROR;
  if (a < b) err |= GEOCENT_A_LESS_B_ERROR;
  return err ? null : {
    a: a,
    b: b,
    a2: a2,
    b2: b2,
    e2: (a2 - b2) / a2,
    ep2: (a2 - b2) / b2
  };
}


function pj_Convert_Geodetic_To_Geocentric(gi, i, xx, yy, zz) {
  var err = GEOCENT_NO_ERROR,
      lng = xx[i],
      lat = yy[i],
      height = zz[i],
      x, y, z,
      rn, sinlat, sin2lat, coslat;
  if (lat < -M_HALFPI && lat > -1.001 * M_HALFPI) {
    lat = -M_HALFPI;
  } else if (lat > M_HALFPI && lat < 1.001 * M_HALFPI) {
    lat = M_HALFPI;
  } else if (lat < -M_HALFPI || lat > M_HALFPI) {
    err |= GEOCENT_LAT_ERROR;
  }

  if (!err) {
    if (lng > M_PI) lng -= 2 * M_PI;
    sinlat = sin(lat);
    coslat = cos(lat);
    sin2lat = sinlat * sinlat;
    rn = gi.a / sqrt(1 - gi.e2 * sin2lat);
    xx[i] = (rn + height) * coslat * cos(lng);
    yy[i] = (rn + height) * coslat * sin(lng);
    zz[i] = ((rn * (1 - gi.e2)) + height) * sinlat;
  }
  return err;
}


function pj_Convert_Geocentric_To_Geodetic(gi, i, xx, yy, zz) {
  var EPS = 1e-12,
      EPS2 = EPS * EPS,
      MAXITER = 30,
      x = xx[i],
      y = yy[i],
      z = zz[i],
      lat, lng, height,
      p, rr, ct, st, rx, rn, rk, cphi0, sphi0, cphi, sphi, sdphi, iter;

  p = sqrt(x * x + y * y);
  rr = sqrt(x * x + y * y + z * z);

  if (p / gi.a < EPS) {
    lng = 0;
    if (rr / gi.a < EPS) {
      xx[i] = 0;
      yy[i] = M_HALFPI;
      zz[i] = -gi.b;
      return 0;
    }
  } else {
    lng = atan2(y, x);
  }

  ct = z / rr;
  st = p / rr;
  rx = 1 / sqrt(1 - gi.e2 * (2 - gi.e2) * st * st);
  cphi0 = st * (1 - gi.e2) * rx;
  sphi0 = ct * rx;
  iter = 0;

  do {
    iter++;
    rn = gi.a / sqrt(1 - gi.e2 * sphi0 * sphi0);
    height = p * cphi0 + z * sphi0 - rn * (1 - gi.e2 * sphi0 * sphi0);
    rk = gi.e2 * rn / (rn + height);
    rx = 1 / sqrt(1 - rk * (2 - rk) * st * st);
    cphi = st * (1 - rk) * rx;
    sphi = ct * rx;
    sdphi = sphi * cphi0 - cphi * sphi0;
    cphi0 = cphi;
    sphi0 = sphi;
  } while (sdphi * sdphi > EPS2 && iter < MAXITER);
  lat = atan(sphi / fabs(cphi));
  xx[i] = lng;
  yy[i] = lat;
  zz[i] = height;
}



// A convenience function for transforming a single point (not in Proj.4)
// @p an array containing [x, y] or [x, y, z] coordinates
//     latlong coordinates are assumed to be in decimal degrees
function pj_transform_point(srcdefn, dstdefn, p) {
  var z = p.length > 2,
      xx = [p[0]],
      yy = [p[1]],
      zz = [z ? p[2] : 0];
  if (srcdefn.is_latlong) {
    xx[0] *= DEG_TO_RAD;
    yy[0] *= DEG_TO_RAD;
  }
  ctx.last_errno = 0;
  pj_transform(srcdefn, dstdefn, xx, yy, zz);
  if (ctx.last_errno || xx[0] == HUGE_VAL) {
    // throw error if translation fails
    fatal(null, {point: p});
  }
  if (dstdefn.is_latlong) {
    xx[0] *= RAD_TO_DEG;
    yy[0] *= RAD_TO_DEG;
  }
  p[0] = xx[0];
  p[1] = yy[0];
  if (z) p[2] = zz[0];
}

// Transform arrays of coordinates; latlong coords are in radians
// @xx, @yy[, @zz] coordinate arrays
//
function pj_transform(srcdefn, dstdefn, xx, yy, zz) {
  var point_count = xx.length;
  var lp = {};
  var xy = {};
  var err, i, tmp;

  if (srcdefn.axis != 'enu') {
    pj_adjust_axis(srcdefn.axis, false, xx, yy, zz);
  }

  if (srcdefn.vto_meter != 1 && zz) {
   for ( i = 0; i < point_count; i++ )
      zz[i] *= srcdefn.vto_meter;
  }

  // convert to lat/lng, if needed
  if (srcdefn.is_geocent) {
    if (!zz) {
      error(PJD_ERR_GEOCENTRIC);
    }
    if (srcdefn.to_meter != 1) {
      for (i = 0; i < point_count; i++) {
        if (xx[i] != HUGE_VAL ) {
          xx[i] *= srcdefn.to_meter;
          yy[i] *= srcdefn.to_meter;
        }
      }
    }
    pj_geocentric_to_geodetic(srcdefn.a_orig, srcdefn.es_orig, xx, yy, zz);

  } else if (!srcdefn.is_latlong) {
    if (!srcdefn.inv3d && !srcdefn.inv) {
      // Proj.4 returns error code -17 (a bug?)
      fatal("source projection not invertible");
    }
    if (srcdefn.inv3d) {
      fatal("inverse 3d transformations not supported");
    } else {
      for (i=0; i<point_count; i++) {
        xy.x = xx[i];
        xy.y = yy[i];
        tmp = pj_inv(xy, srcdefn);
        xx[i] = tmp.lam;
        yy[i] = tmp.phi;
        check_fatal_error(); // Proj.4 is a bit different
      }
    }
  }

  if (srcdefn.from_greenwich !== 0) {
    for (i=0; i<point_count; i++) {
      if (xx[i] != HUGE_VAL) {
        xx[i] += srcdefn.from_greenwich;
      }
    }
  }

  if (srcdefn.has_geoid_vgrids && zz) {
    fatal("vgrid transformation not supported");
  }

  pj_datum_transform(srcdefn, dstdefn, xx, yy, zz);

  if (dstdefn.has_geoid_vgrids && zz) {
    fatal("vgrid transformation not supported");
  }

  if (dstdefn.from_greenwich !== 0) {
    for (i=0; i<point_count; i++) {
      if (xx[i] != HUGE_VAL) {
        xx[i] -= dstdefn.from_greenwich;
      }
    }
  }

  if (dstdefn.is_geocent) {
    if (!zz) {
      error(PJD_ERR_GEOCENTRIC);
    }
    pj_geodetic_to_geocentric(dstdefn.a_orig, dstdefn.es_orig, xx, yy, zz);

    if (dstdefn.fr_meter != 1) {
      for (i = 0; i<point_count; i++) {
        if (xx[i] != HUGE_VAL) {
          xx[i] *= dstdefn.fr_meter;
          yy[i] *= dstdefn.fr_meter;
        }
      }
    }
  } else if (!dstdefn.is_latlong) {
    if (dstdefn.fwd3d) {
      fatal("3d transformation not supported");
    } else {
      for (i=0; i<point_count; i++) {
        lp.lam = xx[i];
        lp.phi = yy[i];
        tmp = pj_fwd(lp, dstdefn);
        xx[i] = tmp.x;
        yy[i] = tmp.y;
        check_fatal_error(); // Proj.4 is a bit different
      }
    }
  } else if (dstdefn.is_latlong && dstdefn.is_long_wrap_set) {
    for (i=0; i<point_count; i++) {
      if (xx[i] == HUGE_VAL) continue;
      while (xx[i] < dstdefn.long_wrap_center - M_PI) {
        xx[i] += M_TWOPI;
      }
      while (xx[i] > dstdefn.long_wrap_center + M_PI) {
        xx[i] -= M_TWOPI;
      }
    }
  }

  if (dstdefn.vto_meter != 1 && zz) {
    for (i=0; i<point_count; i++) {
      zz[i] *= dstdefn.vfr_meter;
    }
  }
  if (dstdefn.axis != 'enu') {
    pj_adjust_axis(dstdefn.axis, true, xx, yy, zz);
  }

  return point_count == 1 ? ctx.last_errno : 0;
}

function pj_adjust_axis(axis, denormalize_flag, xx, yy, zz) {
  var point_count = xx.length;
  var x_in, y_in, z_in = 0;
  var i, i_axis, value, target;

  if (!denormalize_flag) {
    for (i = 0; i < point_count; i++) {
      x_in = xx[i];
      y_in = yy[i];
      if (x_in == HUGE_VAL) continue; // not in Proj.4
      if (zz)
        z_in = zz[i];

      for (i_axis = 0; i_axis < 3; i_axis++) {
        if (i_axis == 0)
            value = x_in;
        else if (i_axis == 1)
            value = y_in;
        else
            value = z_in;

        switch (axis[i_axis]) {
          case 'e':
            xx[i] = value; break;
          case 'w':
            xx[i] = -value; break;
          case 'n':
            yy[i] = value; break;
          case 's':
            yy[i] = -value; break;
          case 'u':
            if( zz ) zz[i] = value; break;
          case 'd':
            if( zz ) zz[i] = -value; break;
          default:
            error(PJD_ERR_AXIS);
        }
      } /* i_axis */
    } /* i (point) */
  }

  else {/* denormalize */
    for (i = 0; i < point_count; i++) {
      x_in = xx[i];
      y_in = yy[i];
      if (x_in == HUGE_VAL) continue; // not in Proj.4
      if (zz)
        z_in = zz[i];
      for (i_axis = 0; i_axis < 3; i_axis++) {
        if (i_axis == 2 && !zz)
          continue;
        if (i_axis == 0)
            target = xx;
        else if (i_axis == 1)
            target = yy;
        else
            target = zz;
        switch (axis[i_axis]) {
          case 'e':
            target[i] = x_in; break;
          case 'w':
            target[i] = -x_in; break;
          case 'n':
            target[i] = y_in; break;
          case 's':
            target[i] = -y_in; break;
          case 'u':
            target[i] = z_in; break;
          case 'd':
            target[i] = -z_in; break;
          default:
            error(PJD_ERR_AXIS);
        }
      } /* i_axis */
    } /* i (point) */
  }
}

function pj_datum_transform(srcdefn, dstdefn, xx, yy, zz) {
  var point_count = xx.length;
  var src_a, src_es, dst_a, dst_es;
  var z_is_temp = false;
  /*      We cannot do any meaningful datum transformation if either      */
  /*      the source or destination are of an unknown datum type          */
  /*      (ie. only a +ellps declaration, no +datum).  This is new        */
  /*      behavior for PROJ 4.6.0                                        */
  if (srcdefn.datum_type == PJD_UNKNOWN || dstdefn.datum_type == PJD_UNKNOWN) {
    return;
  }

  /*      Short cut if the datums are identical.                          */
  if (pj_compare_datums(srcdefn, dstdefn)) {
    return;
  }
  src_a = srcdefn.a_orig;
  src_es = srcdefn.es_orig;
  dst_a = dstdefn.a_orig;
  dst_es = dstdefn.es_orig;
  /*      Create a temporary Z array if one is not provided.              */
  if (!zz) {
    zz = new Float64Array(point_count);
    z_is_temp = true;
  }

  if (srcdefn.datum_type == PJD_GRIDSHIFT) {
    fatal("gridshift not implemented");
    // pj_apply_gridshift_2()
    src_a = SRS_WGS84_SEMIMAJOR;
    src_es = SRS_WGS84_ESQUARED;
  }

  if (dstdefn.datum_type == PJD_GRIDSHIFT) {
    dst_a = SRS_WGS84_SEMIMAJOR;
    dst_es = SRS_WGS84_ESQUARED;
  }

  /*      Do we need to go through geocentric coordinates?                */
  if (src_es != dst_es || src_a != dst_a ||
      srcdefn.datum_type == PJD_3PARAM || srcdefn.datum_type == PJD_7PARAM ||
      dstdefn.datum_type == PJD_3PARAM || dstdefn.datum_type == PJD_7PARAM) {

    pj_geodetic_to_geocentric(src_a, src_es, xx, yy, zz);

    if (srcdefn.datum_type == PJD_3PARAM || srcdefn.datum_type == PJD_7PARAM) {
      pj_geocentric_to_wgs84(srcdefn, xx, yy, zz);
    }

    if (dstdefn.datum_type == PJD_3PARAM || dstdefn.datum_type == PJD_7PARAM) {
      pj_geocentric_from_wgs84(dstdefn, xx, yy, zz);
    }

    /*      Convert back to geodetic coordinates.                           */
    pj_geocentric_to_geodetic(dst_a, dst_es, xx, yy, zz);

    /*      Apply grid shift to destination if required.                    */
    if (dstdefn.datum_type == PJD_GRIDSHIFT) {
      pj_apply_gridshift_2(dstdefn, 1, xx, yy, zz);
    }
  }
}

// returns true if datums are equivalent
function pj_compare_datums(srcdefn, dstdefn) {
  if (srcdefn.datum_type != dstdefn.datum_type) return false;
  if (srcdefn.a_orig != dstdefn.a_orig ||
    Math.abs(srcdefn.es_orig - dstdefn.es_orig) > 0.000000000050) {
    /* the tolerance for es is to ensure that GRS80 and WGS84 are considered identical */
    return false;
  }
  if (srcdefn.datum_type == PJD_3PARAM) {
    return (srcdefn.datum_params[0] == dstdefn.datum_params[0] &&
        srcdefn.datum_params[1] == dstdefn.datum_params[1] &&
        srcdefn.datum_params[2] == dstdefn.datum_params[2]);
  }
  if (srcdefn.datum_type == PJD_7PARAM) {
    return (srcdefn.datum_params[0] == dstdefn.datum_params[0] &&
      srcdefn.datum_params[1] == dstdefn.datum_params[1] &&
      srcdefn.datum_params[2] == dstdefn.datum_params[2] &&
      srcdefn.datum_params[3] == dstdefn.datum_params[3] &&
      srcdefn.datum_params[4] == dstdefn.datum_params[4] &&
      srcdefn.datum_params[5] == dstdefn.datum_params[5] &&
      srcdefn.datum_params[6] == dstdefn.datum_params[6]);
  }
  if (srcdefn.datum_type == PJD_GRIDSHIFT) {
    return pj_param(srcdefn.params, "snadgrids") ==
        pj_param(dstdefn.params, "snadgrids");
  }
  return true;
}

function pj_geocentric_to_wgs84(defn, xx, yy, zz) {
  var point_count = xx.length,
      pp = defn.datum_params,
      Dx_BF = pp[0],
      Dy_BF = pp[1],
      Dz_BF = pp[2],
      x, y, z, Rx_BF, Ry_BF, Rz_BF, M_BF,
      i;

  if (defn.datum_type == PJD_3PARAM) {
    for (i=0; i<point_count; i++) {
      if (xx[i] == HUGE_VAL) continue;
      xx[i] += Dx_BF;
      yy[i] += Dy_BF;
      zz[i] += Dz_BF;
    }
  } else if (defn.datum_type == PJD_7PARAM) {
    Rx_BF = pp[3];
    Ry_BF = pp[4];
    Rz_BF = pp[5];
    M_BF = pp[6];
    for (i=0; i<point_count; i++) {
      if (xx[i] == HUGE_VAL) continue;
      x = M_BF * (xx[i] - Rz_BF * yy[i] + Ry_BF *  zz[i]) + Dx_BF;
      y = M_BF * (Rz_BF * xx[i] + yy[i] - Rx_BF * zz[i]) + Dy_BF;
      z = M_BF * (-Ry_BF * xx[i] + Rx_BF * yy[i] + zz[i]) + Dz_BF;
      xx[i] = x;
      yy[i] = y;
      zz[i] = z;
    }
  }
}

function pj_geocentric_from_wgs84(defn, xx, yy, zz) {
  var point_count = xx.length,
      pp = defn.datum_params,
      Dx_BF = pp[0],
      Dy_BF = pp[1],
      Dz_BF = pp[2],
      x, y, z, Rx_BF, Ry_BF, Rz_BF, M_BF,
      i;

  if (defn.datum_type == PJD_3PARAM) {
    for (i=0; i<point_count; i++) {
      if (xx[i] == HUGE_VAL) continue;
      xx[i] -= Dx_BF;
      yy[i] -= Dy_BF;
      zz[i] -= Dz_BF;
    }
  } else if (defn.datum_type == PJD_7PARAM) {
    Rx_BF = pp[3];
    Ry_BF = pp[4];
    Rz_BF = pp[5];
    M_BF = pp[6];
    for (i=0; i<point_count; i++) {
      if (xx[i] == HUGE_VAL) continue;
      x = (xx[i] - Dx_BF) / M_BF;
      y = (yy[i] - Dy_BF) / M_BF;
      z = (zz[i] - Dz_BF) / M_BF;
      xx[i] = x + Rz_BF * y - Ry_BF * z;
      yy[i] = -Rz_BF * x + y + Rx_BF * z;
      zz[i] = Ry_BF * x - Rx_BF * y + z;
    }
  }
}

function pj_geocentric_to_geodetic(a, es, xx, yy, zz) {
  var point_count = xx.length;
  var b, i, gi;
  if (es == 0.0)
    b = a;
  else
    b = a * sqrt(1-es);

  gi = pj_Set_Geocentric_Parameters(a, b);
  if (!gi) {
    error(PJD_ERR_GEOCENTRIC);
  }

  for (i = 0; i < point_count; i++) {
    if (xx[i] != HUGE_VAL) {
      pj_Convert_Geocentric_To_Geodetic(gi, i, xx, yy, zz);
    }
  }
}

function pj_geodetic_to_geocentric(a, es, xx, yy, zz) {
  var point_count = xx.length,
      b, i, gi;
  if (es === 0) {
    b = a;
  } else {
    b = a * sqrt(1 - es);
  }
  gi = pj_Set_Geocentric_Parameters(a, b);
  if (!gi) {
    error(PJD_ERR_GEOCENTRIC);
  }
  for (i=0; i<point_count; i++) {
    if (xx[i] == HUGE_VAL) continue;
    if (pj_Convert_Geodetic_To_Geocentric(gi, i, xx, yy, zz)) {
      xx[i] = yy[i] = HUGE_VAL;
    }
  }
}


function adjlon(lon) {
  var SPI = 3.14159265359,
      TWOPI = 6.2831853071795864769,
      ONEPI = 3.14159265358979323846;

  if (fabs(lon) > SPI) {
    lon += ONEPI;  /* adjust to 0.0.2pi rad */
    lon -= TWOPI * floor(lon / TWOPI); /* remove integral # of 'revolutions'*/
    lon -= ONEPI;  /* adjust back to -pi..pi rad */
  }
  return lon;
}


function pj_fwd_deg(lp, P) {
  var lp2 = {lam: lp.lam * DEG_TO_RAD, phi: lp.phi * DEG_TO_RAD};
  return pj_fwd(lp2, P);
}

function pj_fwd(lp, P) {
  var xy = {x: 0, y: 0};
  var EPS = 1e-12;
  var t = fabs(lp.phi) - M_HALFPI;

  // if (t > EPS || fabs(lp.lam) > 10) {
  if (!(t <= EPS && fabs(lp.lam) <= 10)) { // catch NaNs
    pj_ctx_set_errno(-14);
  } else {
    ctx.last_errno = 0; // clear a previous error
    if (fabs(t) <= EPS) {
      lp.phi = lp.phi < 0 ? -M_HALFPI : M_HALFPI;
    } else if (P.geoc) {
      lp.phi = atan(P.rone_es * tan(lp.phi));
    }
    lp.lam -= P.lam0;
    if (!P.over) {
      lp.lam = adjlon(lp.lam);
    }
    if (P.fwd) {
      P.fwd(lp, xy);
      xy.x = P.fr_meter * (P.a * xy.x + P.x0);
      xy.y = P.fr_meter * (P.a * xy.y + P.y0);
    } else {
      xy.x = xy.y = HUGE_VAL;
    }
  }
  if (ctx.last_errno || !isFinite(xy.x) || !isFinite(xy.y)) {
    // isFinite() catches NaN and +/- Infinity but not null
    xy.x = xy.y = HUGE_VAL;
  }
  return xy;
}


function pj_inv_deg(xy, P) {
  var lp = pj_inv(xy, P);
  return {
    lam: lp.lam * RAD_TO_DEG,
    phi: lp.phi * RAD_TO_DEG
  };
}

function pj_inv(xy, P) {
  var EPS = 1e-12;
  var lp = {lam: 0, phi: 0};

  // if (xy.x == HUGE_VAL || xy.y == HUGE_VAL) {
  if (!(xy.x < HUGE_VAL && xy.y < HUGE_VAL)) { // catch NaNs
    pj_ctx_set_errno(-15);
  } else {
    ctx.last_errno = 0;
    if (P.inv) {
      xy.x = (xy.x * P.to_meter - P.x0) * P.ra;
      xy.y = (xy.y * P.to_meter - P.y0) * P.ra;
      P.inv(xy, lp);
      lp.lam += P.lam0;
      if (!P.over) {
        lp.lam = adjlon(lp.lam);
      }
      if (P.geoc && fabs(fabs(lp.phi) - M_HALFPI) > EPS) {
        lp.phi = atan(P.one_es * tan(lp.phi));
      }
    } else {
      lp.lam = lp.phi = HUGE_VAL;
    }
  }
  if (ctx.last_errno || !isFinite(lp.lam) || !isFinite(lp.phi)) {
    // isFinite() catches NaN and +/- Infinity but not null
    lp.lam = lp.phi = HUGE_VAL;
  }
  return lp;
}


function get_rtodms(decimals, fixedWidth, pos, neg) {
  var dtodms = get_dtodms(decimals, fixedWidth, pos, neg);
  return function(r) {
    return dtodms(r * RAD_TO_DEG);
  };
}

// returns function for formatting as DMS
// See Proj.4 rtodms.c
// @pos: 'N' or 'E'
// @neg: 'S' or 'W'
function get_dtodms(decimals, fixedWidth, pos, neg) {
  var RES, CONV, i;
  if (decimals < 0 || decimals >= 9) {
    decimals = 3;
  }
  RES = 1;
  for (i=0; i<decimals; i++) {
    RES *= 10;
  }
  CONV = 3600 * RES;

  return function(r) {
    var sign = '',
        mstr = '',
        sstr = '',
        min, sec, suff, dstr;
    if (r === HUGE_VAL || isNaN(r)) return '';
    if (r < 0) {
      r = -r;
      suff = neg || '';
      if (!suff) {
        sign = '-';
      }
    } else {
      suff = pos || '';
    }
    r = floor(r * CONV + 0.5);
    sec = (r / RES) % 60;
    r = floor(r / (RES * 60));
    min = r % 60;
    dstr = floor(r / 60) + 'd';
    sstr = sec.toFixed(decimals);
    sec = parseFloat(sstr);
    if (sec) {
      sstr = (fixedWidth ? sstr : String(sec)) + '"';
    } else {
      sstr = '';
    }
    if (sec || min) {
      mstr = String(min) + "'";
      if (mstr.length == 2 && fixedWidth) {
        mstr = '0' + mstr;
      }
    }
    return sign + dstr + mstr + sstr + suff;
  };
}


// Support for the proj4js api:
//    proj4(fromProjection[, toProjection, coordinates])

function proj4js(arg1, arg2, arg3) {
  var p, fromStr, toStr, P1, P2, transform;
  if (typeof arg1 != 'string') {
    // E.g. Webpack's require function tries to initialize mproj by calling
    // the module function.
    return api;
  } else if (typeof arg2 != 'string') {
    fromStr = '+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs'; // '+datum=WGS84 +proj=lonlat';
    toStr = arg1;
    p = arg2;
  } else {
    fromStr = arg1;
    toStr = arg2;
    p = arg3;
  }
  P1 = pj_init(fromStr);
  P2 = pj_init(toStr);
  transform = get_proj4js_transform(P1, P2);
  if (p) {
    return transform(p);
  } else {
    return {forward: transform, inverse: get_proj4js_transform(P2, P1)};
  }
}

proj4js.WGS84 = '+proj=longlat +datum=WGS84'; // for compatibility with proj4js tests

// for compatibility with proj4js tests
proj4js.toPoint = function(array) {
  var out = {
    x: array[0],
    y: array[1]
  };
  if (array.length>2) {
    out.z = array[2];
  }
  if (array.length>3) {
    out.m = array[3];
  }
  return out;
};

function get_proj4js_transform(P1, P2) {
  return function(p) {
    var useArray = Array.isArray(p);
    p = useArray ? p.concat() : [p.x, p.y];
    pj_transform_point(P1, P2, p);
    if (!useArray) {
      p = {x: p[0], y: p[1]};
    }
    return p;
  };
}



// Fallback WKT definitions include a Proj.4 string in an EXTENSION property.
// They should be readable by QGIS and gdal/ogr, but will not work
// with most other GIS software.

function get_fallback_wkt_maker(P) {
  // TODO: validate P?
  return make_fallback_wkt;
}

function make_fallback_wkt(P) {
  var projName = P.proj in pj_list ? pj_list[P.proj].name : '';
  var proj4 = get_proj_defn(P);
  var geogcs = wkt_make_geogcs(P);
  // GDAL seems to use "unnamed" all the time
  var name = projName ? geogcs.NAME + ' / ' + projName : 'unnamed';
  return {PROJCS: {
    NAME: name,
    GEOGCS: geogcs,
    PROJECTION: 'custom_proj4',
    PARAMETER: [],
    UNIT: wkt_make_unit(P),
    EXTENSION: ['PROJ4', proj4 + ' +wktext']
  }};
}

function get_fallback_wkt_parser(projcs) {
  var proj4 = get_proj4_from_extension(projcs);
  // TODO: try parsing proj4 string to validate?
  return proj4 ? get_proj4_from_extension : null;
}

function get_proj4_from_extension(projcs) {
  var ext = projcs.EXTENSION;
  if (ext && ext[0] == 'PROJ4') {
    return (ext[1] || '').replace(' +wktext', '');
  }
  return null;
}


// Global collections of WKT parsers and makers
// arr[0] is test function; arr[1] is conversion function
var wkt_makers = [];
var wkt_parsers = [];

// TODO: use utility library
function wkt_is_object(val) {
  return !!val && typeof val == 'object' && !Array.isArray(val);
}

function wkt_is_string(val) {
  return typeof val == 'string';
}

function find_wkt_parser(projcs) {
  var parser = find_wkt_conversion_function(projcs, wkt_parsers);
  if (!parser) {
    parser = get_fallback_wkt_parser(projcs);
  }
  if (!parser) {
    wkt_error('unsupported WKT definition: ' + get_wkt_label(projcs));
  }
  return parser;
}

function find_wkt_maker(P) {
  var maker = find_wkt_conversion_function(P, wkt_makers);
  if (!maker) {
    maker = get_fallback_wkt_maker(P);
  }
  if (!maker) {
    wkt_error('unsupported projection: ' + get_proj_label(P));
  }
  return maker;
}

function find_wkt_conversion_function(o, arr) {
  var is_match;
  for (var i=0; i<arr.length; i++) {
    is_match = arr[i][0];
    if (is_match(o)) return arr[i][1];
  }
  return null;
}

function get_proj_label(P) {
  return get_proj_id(P) || '[unknown]';
}

function get_wkt_label(o) {
  return o.NAME || '[unknown]';
}

function get_proj_id(P) {
  return  pj_param(P.params, 'sproj');
}

function wkt_name_to_slug(name) {
  return name.replace(/[-_ \/]+/g, '_').toLowerCase();
}

function wkt_split_names(names) {
  var arr;
  if (Array.isArray(names)) {
    arr = names;
  } else if (names && names.length > 0) {
    arr = names.split(',');
  }
  return arr;
}

function wkt_error(msg) {
  throw new Error(msg);
}

function wkt_warn(msg) {
  // TODO: consider option to inhibit logging
  //       consider strict mode to throw error
  console.error('[wkt] ' + msg);
}




function wkt_get_unit_defn(projcs) {
  // TODO: consider using unit names
  return {
    to_meter: projcs.UNIT[1]
  };
}

function wkt_convert_unit(PROJCS) {
  var defn = wkt_get_unit_defn(PROJCS);
  var proj4 = "";
  if (defn.to_meter != 1) {
    proj4 = '+to_meter=' + defn.to_meter;
  } else if (!WKT_OMIT_DEFAULTS) {
    proj4 = '+units=m';
  }
  return proj4;
}

function wkt_make_unit(P) {
  return ['Meter', P.to_meter || 1];
}

/*
// OLD -- merge into wkt_make_unit()
function wkt_get_unit(P) {
  var defn = pj_find_units_by_value(P.to_meter);
  var name = defn ? defn.name : 'Unknown';
  return ['UNIT', name, P.to_meter];
}
*/


function wkt_convert_geogcs(geogcs, opts) {
  var datum = geogcs.DATUM,
      spheroid = datum.SPHEROID,
      datumId = wkt_find_datum_id(datum),
      ellId = wkt_find_ellps_id(spheroid),
      aux_sphere = opts && opts.aux_sphere,
      a = spheroid[1],
      rf = spheroid[2],
      str, pm;

  wkt_check_units(geogcs.UNIT, 'degree');
  if (aux_sphere) {
    // TODO: in addition to semimajor, ESRI supports spheres based on
    //   semiminor and authalic radii; could support these
    str = '+a=' + spheroid[1];
  } else if (datumId) {
    str = '+datum=' + datumId;
  } else if (ellId) {
    str = '+ellps=' + ellId;
  } else {
   str = '+a=' + a;
    if (rf > 0) {
      str += ' +rf=' + rf;
    }
  }
  if (datum.TOWGS84 && !aux_sphere && !datumId) {
    str += ' +towgs84=' + datum.TOWGS84.join(',');
  }

  pm = geogcs.PRIMEM ? geogcs.PRIMEM[1] : 0;
  if (pm > 0 || pm < 0) {
    str += ' +pm=' + pm; // assuming degrees
  }
  return str;
}

function wkt_find_ellps_id(spheroid) {
  // TODO: match on ellipsoid parameters rather than name
  var aliases = {
    international1924: "intl"
  };
  var key = wkt_harmonize_geo_name(spheroid[0]);
  var defn;
  if (key in aliases) {
    return aliases[key];
  }
  if (/^grs1980/.test(key)) {
    // handle cases like "GRS 1980(IUGG, 1980)")
    return 'GRS80';
  }
  if (key == 'sphere') {
    // not a well defined ellipsoid
    // TODO: if we check ellipsoid params, this test can go away
    return null;
  }
  for (var i=0; i<pj_ellps.length; i++) {
    defn = pj_ellps[i];
    if (wkt_harmonize_geo_name(defn[3]) == key ||
        wkt_harmonize_geo_name(defn[0]) == key) {
      break;
    }
  }
  return defn ? defn[0] : null;
}

function wkt_find_datum_id(datum) {
  var aliases = { // ESRI aliases
    northamerican1983: 'NAD83',
    newzealand1949: 'nzgd49'
  };
  var key = wkt_harmonize_geo_name(datum.NAME);
  var defn;
  if (key in aliases) {
    return aliases[key];
  }
  for (var i=0; i<pj_datums.length; i++) {
    defn = pj_datums[i];
    if (wkt_harmonize_geo_name(defn[3]) == key ||
        wkt_harmonize_geo_name(defn[0]) == key) {
      break;
    }
  }
  return defn ? defn[0] : null;
}

function wkt_harmonize_geo_name(name) {
  return (name || '').replace(/^(GCS|D)_/i, '').replace(/[ _]/g, '').toLowerCase();
}

function wkt_check_units(UNIT, expect) {
  if (UNIT && UNIT[0].toLowerCase() != expect) {
    wkt_error("unexpected geographic units: " + geogcs.UNIT[0]);
  }
}


// Converts a PROJCS WKT in object format to a Proj.4 string
// Throws an Error if unable to convert
function wkt_convert_projcs(projcs) {
  return find_wkt_parser(projcs)(projcs);
}

function wkt_simple_projcs_converter(projId, paramIds) {
  return wkt_projcs_converter({
    PROJECTION: wkt_simple_projection_converter(projId),
    PARAMETER: wkt_parameter_converter(paramIds)
  });
}

function wkt_simple_projection_converter(id) {
  return function() {return '+proj=' + id;};
}

function wkt_projcs_converter(o) {
  return function(projcs) {
    var projStr = o.PROJECTION(projcs);
    var paramStr = o.PARAMETER(projcs);
    var geogStr = o.GEOGCS ? o.GEOGCS(projcs) : wkt_convert_geogcs(projcs.GEOGCS);
    var unitStr = wkt_convert_unit(projcs);
    return [projStr, paramStr, geogStr, unitStr, '+no_defs'].filter(function(s) {return !!s;}).join(' ');
  };
}


// Functions for exporting a wkt GEOGCS definition

function wkt_make_geogcs(P) {
  var geogcs = {
    NAME: wkt_get_geogcs_name(P),
    DATUM: wkt_make_datum(P),
    PRIMEM: ['Greenwich', 0], // TODO: don't assume greenwich
    UNIT: ['degree', 0.017453292519943295] // TODO: support other units
  };
  return geogcs;
}

function wkt_make_datum(P) {
  var datum = {
    NAME: wkt_get_datum_name(P),
    SPHEROID: wkt_make_spheroid(P)
  };
  var towgs84 = pj_param(P.params, 'stowgs84');
  if (/[1-9]/.test(towgs84)) { // only adding TOWGS84 if transformation is non-zero
    datum.TOWGS84 = towgs84;
  }
  return datum;
}

function wkt_make_spheroid(P) {
  var rf;
  if (pj_param(P.params, 'trf')) {
    rf = pj_param(P.params, 'drf');
  } else if (P.es) {
    rf = 1 / (1 - Math.sqrt(1 - P.es));
  } else {
    rf = 0;
  }
  return [wkt_get_ellps_name(P), P.a, rf];
}

function wkt_get_geogcs_name(P) {
  var name;
  if (pj_is_latlong(P)) {
    name = wkt_get_init_name(P);
  }
  if (!name) {
    name = wkt_get_datum_id(P);
    if (/^[a-z]+$/.test(name)) {
      name = name[0].toUpperCase() + name.substr(1);
    } else {
      name = name.toUpperCase();
    }
  }
  return name || 'UNK';
}

function wkt_get_ellps_name(P) {
  var ellps = find_ellps(wkt_get_ellps_id(P));
  return ellps ? ellps.name : 'Unknown ellipsoid';
}

function wkt_get_datum_name(P) {
  var defn = find_datum(wkt_get_datum_id(P));
  return defn && defn.name || 'Unknown datum';
}

function wkt_get_datum_id(P) {
  return pj_param(P.params, 'sdatum');
}

function wkt_get_ellps_id(P) {
  var datumId = wkt_get_datum_id(P),
      datum = datumId ? find_datum(datumId) : null,
      ellpsId;
  if (datum) {
    ellpsId = datum.ellipse_id;
  } else {
    ellpsId = pj_param(P.params, 'sellps');
  }
  return ellpsId || '';
}


// Converts a Proj object to a WKT in object format
function wkt_make_projcs(P) {
  return find_wkt_maker(P)(P);
}

function wkt_simple_projcs_maker(wktProjection, paramIds) {
  return wkt_projcs_maker({
    PROJECTION: wktProjection,
    PARAMETER: wkt_parameter_maker(paramIds)
  });
}

function wkt_projcs_maker(o) {
  return function(P) {
    var projcs = {
      // if o.NAME GEOGCS exists and returns falsy value, use default function
      GEOGCS: o.GEOGCS && o.GEOGCS(P) || wkt_make_geogcs(P),
      PROJECTION: wkt_is_string(o.PROJECTION) ? o.PROJECTION : o.PROJECTION(P),
      PARAMETER: o.PARAMETER(P),
      UNIT: wkt_make_unit(P)
    };
    // if o.NAME function exists and returns falsy value, use default name
    projcs.NAME = o.NAME && o.NAME(P, projcs) || wkt_make_default_projcs_name(P, projcs);
    return {PROJCS: projcs};
  };
}

// Get CS name from comment in +init source (if +init param is present)
function wkt_get_init_name(P) {
  var o;
  if (pj_param(P.params, 'tinit')) {
    o = pj_read_init_opts(pj_param(P.params, 'sinit'));
  }
  return o ? o.comment : '';
}

function wkt_make_default_projcs_name(P, projcs) {
  var initName = wkt_get_init_name(P);
  return initName || projcs.GEOGCS.NAME + ' / ' + projcs.PROJECTION;
}


function add_simple_wkt_parser(projId, wktProjections, params) {
  var is_match = get_simple_parser_test(wktProjections);
  var convert = wkt_simple_projcs_converter(projId, params);
  add_wkt_parser(is_match, convert);
}

function add_simple_wkt_maker(projId, wktProjection, params) {
  var is_match = get_simple_maker_test(projId);
  var make = wkt_simple_projcs_maker(wktProjection, params);
  // add_wkt_maker(is_match, wkt_make_projcs);
  add_wkt_maker(is_match, make);
}

function get_simple_parser_test(wktNames) {
  var slugs = wkt_split_names(wktNames).map(wkt_name_to_slug);
  return function(obj) {
    var wktName = obj.PROJECTION[0]; // TODO: handle unexpected structure
    return slugs.indexOf(wkt_name_to_slug(wktName)) > -1;
  };
}

function get_simple_maker_test(projId) {
  return function(P) {
    var id = get_proj_id(P);
    return id && id == projId;
  };
}

function add_wkt_parser(is_match, parse) {
  if (typeof is_match != 'function') wkt_error("Missing WKT parser test");
  if (typeof parse != 'function') wkt_error("Missing WKT parse function");
  wkt_parsers.push([is_match, parse]);
}

function add_wkt_maker(is_match, make) {
  if (typeof is_match != 'function') wkt_error("Missing WKT maker test");
  if (typeof make != 'function') wkt_error("Missing WKT maker function");
  wkt_makers.push([is_match, make]);
}


add_wkt_parser(wkt_is_utm, wkt_to_utm);
add_wkt_parser(wkt_is_ups, wkt_to_ups);

add_wkt_maker(get_simple_maker_test('utm'), wkt_from_utm);
add_wkt_maker(get_simple_maker_test('ups'), wkt_from_ups);

var WKT_UTM = /UTM_zone_([0-9]{1,2})(N|S)/i;
var WKT_UPS = /UPS_(North|South)/i;

function wkt_is_utm(projcs) {
  return WKT_UTM.test(wkt_name_to_slug(projcs.NAME));
}

function wkt_is_ups(projcs) {
  return WKT_UPS.test(wkt_name_to_slug(projcs.NAME));
}

function wkt_to_utm(projcs) {
  return wkt_projcs_converter({
    PROJECTION: wkt_simple_projection_converter('utm'),
    PARAMETER: utm_params
  })(projcs);

  function utm_params(projcs) {
    var match = WKT_UTM.exec(wkt_name_to_slug(projcs.NAME));
    var params = '+zone=' + match[1];
    if (match[2].toLowerCase() == 's') params += ' +south';
    return params;
  }
}

function wkt_to_ups(projcs) {
  return wkt_projcs_converter({
    PROJECTION: wkt_simple_projection_converter('ups'),
    PARAMETER: ups_params
  })(projcs);

  function ups_params(projcs) {
    var match = WKT_UPS.exec(wkt_name_to_slug(projcs.NAME));
    return match[1].toLowerCase() == 'south' ? '+south' : '';
  }
}

function wkt_from_utm(P) {
  return wkt_projcs_maker({
    NAME: wkt_make_utm_name,
    PROJECTION: function () {return 'Transverse_Mercator';},
    PARAMETER: wkt_make_utm_params
  })(P);
}

function wkt_from_ups(P) {
  return wkt_projcs_maker({
    NAME: wkt_make_ups_name,
    PROJECTION: function () {return 'Polar_Stereographic';},
    PARAMETER: wkt_make_ups_params
  })(P);
}

function wkt_make_utm_name(P, projcs) {
  return projcs.GEOGCS.NAME + ' / UTM zone ' + pj_param(P.params, 'szone') + (pj_param(P.params, 'tsouth') ? 'S' : 'N');
}

function wkt_make_ups_name(P, projcs) {
  return projcs.GEOGCS.NAME + ' / UPS ' + (pj_param(P.params, 'tsouth') ? 'South' : 'North');
}

function wkt_make_utm_params(P) {
  var lon0 = P.lam0 * 180 / M_PI;
  return [
    ["latitude_of_origin", 0],
    ["central_meridian", lon0],
    ["scale_factor", P.k0],
    ["false_easting", P.x0],
    ["false_northing", P.y0]
  ];
}

function wkt_make_ups_params(P) {
  return [
    ["latitude_of_origin", -90],
    ["central_meridian", 0],
    ["scale_factor", 0.994],
    ["false_easting", 2000000],
    ["false_northing", 2000000]
  ];
}


// Mercator_2SP references:
//    http://geotiff.maptools.org/proj_list/mercator_2sp.html
//    http://www.remotesensing.org/geotiff/proj_list/mercator_2sp.html
//    https://trac.osgeo.org/gdal/ticket/4861

add_wkt_parser(get_simple_parser_test('Mercator_2SP,Mercator_1SP,Mercator,Mercator_Auxiliary_Sphere'),
  wkt_projcs_converter({
    GEOGCS: wkt_convert_merc_geogcs,
    PROJECTION: wkt_simple_projection_converter('merc'),
    PARAMETER: wkt_convert_merc_params
  }));

add_wkt_maker(get_simple_maker_test('merc'),
  wkt_projcs_maker({
    GEOGCS: wkt_make_merc_geogcs,
    PROJECTION: wkt_make_merc_projection,
    PARAMETER: wkt_make_merc_params,
    NAME: wkt_make_merc_name
  }));

function wkt_make_merc_name(P) {
  return wkt_proj4_is_webmercator(P) ? 'WGS 84 / Pseudo-Mercator' : null;
}

function wkt_make_merc_geogcs(P) {
  // PROBLEM: no clear way to get geographic cs from proj4 string
  // ... so assuming WGS 84 (consider using spherical datum instead)
  if (wkt_proj4_is_webmercator(P)) {
    return wkt_make_geogcs(pj_init('+proj=longlat +datum=WGS84'));
  }
  return null;
}

function wkt_convert_merc_geogcs(projcs) {
  var opts = wkt_projcs_is_webmercator(projcs) ? {aux_sphere: true} : null;
  return wkt_convert_geogcs(projcs.GEOGCS, opts);
}

function wkt_make_merc_projection(P) {
  return wkt_proj4_is_merc_2sp(P) ? 'Mercator_2SP' : 'Mercator_1SP';
}

function wkt_convert_merc_params(projcs) {
  // TODO: handle (esri) standard_parallel_1 in 1sp version
  // 1sp version accepts latitude_of_origin (ogc) or standard_parallel_1 (esri)
  // var rules = wkt_projcs_is_merc_2sp(projcs) ? 'lat_ts,lat_0b' : 'lat_tsb,lat_ts';
  var rules = wkt_projcs_is_merc_2sp(projcs) ? 'lat_ts,lat_0b' : 'lat_tsb,lat_ts';
  return wkt_parameter_converter(rules)(projcs);
}

function wkt_make_merc_params(P) {
  var rules = wkt_proj4_is_merc_2sp(P) ? 'lat_ts,lat_0b' : 'lat_tsb';
  return wkt_parameter_maker(rules)(P);
}

function wkt_projcs_is_merc_2sp(projcs) {
  var param = wkt_find_parameter_by_name(projcs, 'standard_parallel_1');
  return param && param[1] != 0;
}

function wkt_proj4_is_merc_2sp(P) {
  return pj_param(P.params, 'tlat_ts') && pj_param(P.params, 'dlat_ts') != 0;
}

function wkt_projcs_is_webmercator(projcs) {
  return /(Web_Mercator|Pseudo_Mercator)/i.test(wkt_name_to_slug(projcs.NAME));
}

// TODO: support other spheroids (web mercator may be used for other planets)
function wkt_proj4_is_webmercator(P) {
  return P.es === 0 && P.a == 6378137;
}




// Reference:
// http://proj4.org/parameters.html

var wkt_common_params = [
  ['x_0', 'false_easting', 'm'],
  ['y_0', 'false_northing', 'm'],
  ['k_0', 'scale_factor', 'f'],
  ['lat_0', 'latitude_of_center'],
  ['lon_0', 'central_meridian']
];

var wkt_param_table = {
  lat_0b:  ['lat_0', 'latitude_of_origin'],
  lat_0c:  ['lat_0', null], // lcc 1sp, stere
  lat_0d:  ['lat_0', 'standard_parallel_1'],  // stere (esri), merc (esri)
  lat_1:   ['lat_1', 'standard_parallel_1'],
  lat_1b:  ['lat_1', 'latitude_of_point_1'],  // omerc,tpeqd
  lat_1c:  ['lat_1', 'latitude_of_origin'],   // lcc
  lat_2:   ['lat_2', 'standard_parallel_2'],
  lat_2b:  ['lat_2', 'latitude_of_point_2'],  // omerc,tpeqd
  lat_ts:  ['lat_ts', 'standard_parallel_1'], // cea,eqc,merc,stere,wag3,wink1
  lat_tsb: ['lat_ts', 'latitude_of_origin'],  // merc
  lonc:    ['lonc', 'central_meridian'],      // omerc,ocea
  lon_1:   ['lon_1', 'longitude_of_point_1'], // omerc,tpeqd
  lon_2:   ['lon_2', 'longitude_of_point_2'], // omerc,tpeqd
  alpha:   ['alpha', 'azimuth'],              // omerc,ocea
  gamma:   ['gamma', 'rectified_grid_angle'], // omerc
  h:       ['h', 'height', 'f'] // nsper
};

// non-standard name -> standard name
// TODO: consider accepting standard_parallel_1 as (esri) alias for latitude_of_center / latitude_of_origin
var wkt_param_aliases = {
  longitude_of_center: 'central_meridian',
  latitude_of_origin: 'latitude_of_center',
  latitude_of_center: 'latitude_of_origin',
  longitude_of_1st_point: 'longitude_of_point_1',
  longitude_of_2nd_point: 'longitude_of_point_2',
  latitude_of_1st_point: 'latitude_of_point_1',
  latitude_of_2nd_point: 'latitude_of_point_2',
  // proj4
  k: 'k_0'
};

// Convert a wkt PARAMETER name to a proj4 param id
function wkt_convert_param_name_old(wktName, proj) {
  var defn = wkt_find_param_defn_old(proj, function(defn) {
    return defn[1] == wktName;
  });
  return defn ? defn[0] : '';
}

// @proj Proj.4 projection id
function wkt_find_param_defn_old(proj, test) {
  var defn, projs;
  for (var i=0; i<wkt_params.length; i++) {
    defn = wkt_params[i];
    projs = defn[3];
    if (projs && projs.split(',').indexOf(proj) == -1) continue;
    if (test(defn)) return defn;
  }
  return null;
}


function wkt_find_defn(name, idx, arr) {
  for (var i=0; i<arr.length; i++) {
    // returns first match (additional matches -- aliases -- may be present)
    if (arr[i][idx] === name) return arr[i];
  }
  return null;
}

function wkt_find_parameter_defn(name, idx, rules) {
  var defn = null;
  name = name.toLowerCase();
  defn = wkt_find_defn(name, idx, rules);
  if (!defn && (name in wkt_param_aliases)) {
    defn = wkt_find_defn(wkt_param_aliases[name], idx, rules);
  }
  return defn;
}

function wkt_convert_parameter(defn, value, unitDefn) {
  var name = defn[0],
      type = defn[2];
  if (type == 'm') {
    value *= unitDefn.to_meter;
  }
  if (WKT_OMIT_DEFAULTS) {
    if ('x_0,y_0,lat_0,lon_0'.indexOf(name) > -1 && value === 0 ||
      name == 'k_0' && value == 1) {
      return;
    }
  }
  return '+' + name + '=' + value;
}

function wkt_make_parameter(defn, strVal, toMeter) {
  var type = defn[2],
      val;
  if (type == 'm') {
    val = parseFloat(strVal) / toMeter;
  } else if (type == 'f') {
    val = parseFloat(strVal);
  } else {
    val = dmstod(strVal); // default is decimal degrees or DMS
  }
  return [defn[1], val];
}

function wkt_find_parameter_by_name(projcs, name) {
  var params = projcs.PARAMETER || [];
  var paramName;
  for (var i=0; i<params.length; i++) {
    paramName = params[i][0].toLowerCase();
    if (name === paramName || name === wkt_param_aliases[paramName]) {
      return params[i];
    }
  }
  return null;
}

function wkt_get_parameter_value(projcs, name) {
  var param = wkt_find_parameter_by_name(projcs, name);
  return param === null ? null : param[1];
}

function wkt_get_parameter_rules(ids) {
  var rules = null;
  if (ids) {
    rules = wkt_split_names(ids).reduce(function(memo, id) {
      var rule = wkt_param_table[id];
      if (!rule) wkt_error("missing parameter rule: " + id);
      memo.push(rule);
      return memo;
    }, []);
  }
  return (rules || []).concat(wkt_common_params);
}

function wkt_parameter_converter(extraRules) {
  return function(projcs) {
    var parts = [];
    var rules = wkt_get_parameter_rules(extraRules);
    var unitDefn = wkt_get_unit_defn(projcs);
    (projcs.PARAMETER || []).forEach(function(param) { // handle no params
      var defn = wkt_find_parameter_defn(param[0], 1, rules);
      var proj4;
      if (!defn) {
        wkt_warn('unhandled parameter: ' + param[0]);
      } else {
        proj4 = wkt_convert_parameter(defn, param[1], unitDefn);
        if (proj4) parts.push(proj4);
      }
    });
    return parts.join(' ');
  };
}

function wkt_parameter_maker(extraRules) {
  return function(P) {
    var params = [];
    var rules = wkt_get_parameter_rules(extraRules);
    // TODO: think about how to add default params omitted from proj4 defn
    // TODO: think about detecting unused params in proj4 defn
    Object.keys(P.params).forEach(function(key) {
      var defn = wkt_find_parameter_defn(key, 0, rules);
      var sval;
      if (defn && defn[1]) { // handle dummy rules with null wkt param name (see wkt_lcc.js)
        sval = pj_param(P.params, 's' + key);
        params.push(wkt_make_parameter(defn, sval, P.to_meter));
      }
    });
    return params;
  };
}


add_wkt_parser(get_simple_parser_test(
  'Lambert_Conformal_Conic,Lambert_Conformal_Conic_1SP,Lambert_Conformal_Conic_2SP'),
  wkt_projcs_converter({
    PROJECTION: wkt_simple_projection_converter('lcc'),
    PARAMETER: wkt_convert_lcc_params
  }));

add_wkt_maker(get_simple_maker_test('lcc'),
  wkt_projcs_maker({
    PROJECTION: wkt_make_lcc_projection,
    PARAMETER: wkt_make_lcc_params
  }));

function wkt_make_lcc_params(P) {
  var params = wkt_proj4_is_lcc_1sp(P) ? 'lat_1c,lat_0c' : 'lat_0b,lat_1,lat_2';
  return wkt_parameter_maker(params)(P);
}

function wkt_convert_lcc_params(projcs) {
  var params = wkt_projcs_is_lcc_1sp(projcs) ? 'lat_1c' : 'lat_0b,lat_1,lat_2';
  return wkt_parameter_converter(params)(projcs);
}

function wkt_make_lcc_projection(P) {
  return wkt_proj4_is_lcc_1sp(P) ? 'Lambert_Conformal_Conic_1SP' : 'Lambert_Conformal_Conic_2SP';
}

function wkt_projcs_is_lcc_1sp(projcs) {
  return !wkt_find_parameter_by_name(projcs, 'standard_parallel_2');
}

function wkt_proj4_is_lcc_1sp(P) {
  return !('lat_1' in P.params && 'lat_2' in P.params);
}


// Type A
add_wkt_parser(
  get_simple_parser_test('Hotine_Oblique_Mercator,Hotine_Oblique_Mercator_Azimuth_Natural_Origin'),
  wkt_projcs_converter({
    PROJECTION: wkt_simple_projection_converter('omerc'),
    PARAMETER: function(P) {return wkt_parameter_converter('alpha,gamma,lonc')(P) + ' +no_uoff';}
  })
);
add_wkt_maker(wkt_proj4_is_omerc_A, wkt_simple_projcs_maker('Hotine_Oblique_Mercator', 'alpha,gamma,lonc'));

// Type B
add_simple_wkt_parser('omerc', 'Oblique_Mercator,Hotine_Oblique_Mercator_Azimuth_Center', 'alpha,gamma,lonc');
add_wkt_maker(wkt_proj4_is_omerc_B, wkt_simple_projcs_maker('Oblique_Mercator', 'alpha,gamma,lonc'));

// Two-point version
add_simple_wkt_parser('omerc', 'Hotine_Oblique_Mercator_Two_Point_Natural_Origin', 'lat_1b,lat_2b,lon_1,lon_2');
add_wkt_maker(
  wkt_proj4_is_omerc_2pt,
  wkt_simple_projcs_maker('Hotine_Oblique_Mercator_Two_Point_Natural_Origin', 'lat_1b,lat_2b,lon_1,lon_2')
);

function wkt_proj4_is_omerc_2pt(P) {
  return get_proj_id(P) == 'omerc' && 'lat_2' in P.params && 'lon_2' in P.params;
}

function wkt_proj4_is_omerc(P) {
  return get_proj_id(P) == 'omerc' && ('alpha' in P.params || 'gamma' in P.params);
}

function wkt_proj4_is_omerc_A(P) {
  return wkt_proj4_is_omerc(P) && ('no_uoff' in P.params || 'no_off' in P.params);
}

function wkt_proj4_is_omerc_B(P) {
  return wkt_proj4_is_omerc(P) && !wkt_proj4_is_omerc_A(P);
}


// add_simple_wkt_parser('stere', ['Stereographic', 'Polar_Stereographic', 'Stereographic_North_Pole', 'Stereographic_South_Pole']);

/*
  Stereographic vs. Polar Stereographic from geotiff
  http://geotiff.maptools.org/proj_list/polar_stereographic.html
  http://geotiff.maptools.org/proj_list/stereographic.html
  http://geotiff.maptools.org/proj_list/random_issues.html#stereographic
*/

add_wkt_parser(get_simple_parser_test('Stereographic,Polar_Stereographic,Stereographic_North_Pole,Stereographic_South_Pole'),
  wkt_projcs_converter({
    PROJECTION: wkt_simple_projection_converter('stere'),
    PARAMETER: wkt_convert_stere_params
  }));

add_wkt_maker(get_simple_maker_test('stere'),
  wkt_projcs_maker({
    PROJECTION: wkt_make_stere_projection,
    PARAMETER: wkt_make_stere_params
  }));

function wkt_convert_stere_params(projcs) {
  // assuming not oblique; TOOD: verify not oblique
  var params = wkt_parameter_converter('lat_ts,lat_tsb')(projcs);
  var match = /lat_ts=([^ ]+)/.exec(params);
  if (match && params.indexOf('lat_0=') == -1) {
    // Add +lat_0=90 or +lat_0=-90
    params = '+lat_0=' + (parseFloat(match[1]) < 0 ? -90 : 90) + ' ' + params;
  }
  return params;
}

function wkt_make_stere_projection(P) {
  // switching to stere -> Stereographic, to match ogr2ogr output
  // return wkt_proj4_is_stere_polar(P) ? 'Polar_Stereographic' : 'Oblique_Stereographic';
  return wkt_proj4_is_stere_polar(P) ? 'Polar_Stereographic' : 'Stereographic';
}

function wkt_make_stere_params(P) {
  return wkt_proj4_is_stere_polar(P) ?
    wkt_parameter_maker('lat_tsb,lat_0c')(P) : // lat_ts -> latitude_of_origin, lat_0 -> null
    wkt_parameter_maker('lat_0b')(P);      // lat_0 -> latitude_of_origin
}

function wkt_proj4_is_stere_polar(P) {
  return pj_param(P.params, 'tlat_ts');
}


add_simple_wkt_maker('vandg', 'VanDerGrinten');
add_wkt_parser(
  get_simple_parser_test('VanDerGrinten,Van_der_Grinten_I'),
  wkt_projcs_converter({
    PROJECTION: wkt_simple_projection_converter('vandg'),
    PARAMETER: function(P) {
      var params = wkt_parameter_converter('')(P);
      if (params) params += ' ';
      return params + '+R_A';
    }
  })
);


/*
// projections still missing WKT conversion
[
  ['airy', ''],
  ['boggs', ''],
  ['crast', 'Craster_Parabolic'],
  ['gn_sinu', ''],
  ['gstmerc', 'Gauss_Schreiber_Transverse_Mercator'], // https://trac.osgeo.org/gdal/ticket/2663
  ['geos', 'Geostationary_Satellite'],
  ['goode', 'Goode_Homolosine'],
  ['igh', 'Interrupted_Goode_Homolosine'],
  ['imw_p', 'International_Map_of_the_World_Polyconic'],
  ['kav7', ''],
  ['krovak', 'Krovak'],
  ['laborde', 'Laborde_Oblique_Mercator'],
  ['mbtfps', ''],
  ['nell_h', ''],
  ['ocea', ''], // see OneNote notes
  ['qua_aut', 'Quartic_Authalic'],
  ['', 'Swiss_Oblique_Cylindrical'], // http://www.remotesensing.org/geotiff/proj_list/swiss_oblique_cylindrical.html
  ['', 'Transverse_Mercator_South_Orientated'], // http://www.remotesensing.org/geotiff/proj_list/transverse_mercator_south_oriented.html
]
*/

// Add simple conversion functions
// optional third field gives alternate parameters (defined in wkt_parameters.js)
[
  ['aitoff', 'Aitoff', 'lat1'],
  ['aea', 'Albers_Conic_Equal_Area,Albers', 'lat_1,lat_2'],
  ['aeqd', 'Azimuthal_Equidistant'],
  ['bonne', 'Bonne', 'lat_1'],
  ['cass', 'Cassini_Soldner,Cassini'],
  ['cea', 'Cylindrical_Equal_Area', 'lat_ts'],
  ['eck1', 'Eckert_I'],
  ['eck2', 'Eckert_II'],
  ['eck3', 'Eckert_III'],
  ['eck4', 'Eckert_IV'],
  ['eck5', 'Eckert_V'],
  ['eck6', 'Eckert_VI'],
  ['eqdc', 'Equidistant_Conic', 'lat_1,lat_2'],
  ['eqc', 'Plate_Carree,Equirectangular,Equidistant_Cylindrical', 'lat_ts'],
  ['gall', 'Gall_Stereographic'],
  ['gnom', 'Gnomonic'],
  ['laea', 'Lambert_Azimuthal_Equal_Area'],
  ['loxim', 'Loximuthal', 'lat_1'],
  ['mill', 'Miller_Cylindrical'],
  ['moll', 'Mollweide'],
  ['nsper', 'Vertical_Near_Side_Perspective', 'h'],
  ['nzmg', 'New_Zealand_Map_Grid', 'lat_0b'],
  ['ortho', 'Orthographic', 'lat_0b'],
  ['poly', 'Polyconic'],
  ['robin', 'Robinson'],
  ['sinu', 'Sinusoidal'],
  ['sterea', 'Oblique_Stereographic,Double_Stereographic'], // http://geotiff.maptools.org/proj_list/oblique_stereographic.html
  ['tmerc', 'Transverse_Mercator,Gauss_Kruger', 'lat_0b'],
  ['tpeqd', 'Two_Point_Equidistant', 'lat_1b,lat_2b,lon_1,lon_2'],
  // ['vandg', 'VanDerGrinten,Van_der_Grinten_I'], // slight complication, see wkt_vandg.js
  ['wag1', 'Wagner_I'],
  ['wag2', 'Wagner_II'],
  ['wag3', 'Wagner_III', 'lat_ts'],
  ['wag4', 'Wagner_IV'],
  ['wag5', 'Wagner_V'],
  ['wag6', 'Wagner_VI'],
  ['wag7', 'Wagner_VII'],
  ['wink1', 'Winkel_I', 'lat_ts'],
  ['wink2', 'Winkel_II'],
  ['wintri', 'Winkel_Tripel', 'lat_1']
].forEach(function(arr) {
  var alternateParams = arr[2] || null;
  add_simple_wkt_parser(arr[0], arr[1], alternateParams);
  add_simple_wkt_maker(arr[0], arr[1].split(',')[0], alternateParams);
});



function wkt_stringify(o) {
  var str = JSON.stringify(wkt_stringify_reorder(o));
  str = str.replace(/\["([A-Z0-9]+)",/g, '$1['); // convert JSON arrays to WKT
  // remove quotes from AXIS values (not supported: UP|DOWN|OTHER etc.)
  // see (http://www.geoapi.org/apidocs/org/opengis/referencing/doc-files/WKT.html)
  str = str.replace(/"(EAST|NORTH|SOUTH|WEST)"/g, '$1');
  return str;
}

function wkt_sort_order(key) {
  // supported WKT names in sorted order
  var names = 'NAME,PROJCS,GEOGCS,GEOCCS,DATUM,SPHEROID,PRIMEM,PROJECTION,PARAMETER,UNIT,AXIS';
  return names.indexOf(key) + 1 || 999;
}

function wkt_keys(o) {
  var keys = Object.keys(o);
  return keys.sort(function(a, b) {
    return wkt_sort_order(a) - wkt_sort_order(b);
  });
}

// Rearrange a generated WKT object for easier string conversion
// inverse of wkt_parse_reorder()
function wkt_stringify_reorder(o, depth) {
  var arr = [], e;
  depth = depth || 0;
  wkt_keys(o).forEach(function(name) {
    var val = o[name];
    if (wkt_is_object(val)) {
      arr.push([name].concat(wkt_stringify_reorder(val, depth + 1)));
    } else if (name == 'NAME') {
      arr.push(wkt_is_string(val) ? val : val[0]);
    } else if (name == 'PARAMETER' || name == 'AXIS') {
      val.forEach(function(param) {
        arr.push([name].concat(param));
      });
    } else if (wkt_is_string(val)) {
      arr.push([name, val]);
    } else if (Array.isArray(val)) {
       arr.push([name].concat(val));
    } else {
      e = {};
      e[name] = val;
      wkt_error("Incorrectly formatted WKT element: " + JSON.stringify(e));
    }
  });
  if (depth === 0 && arr.length == 1) {
    arr = arr[0]; // kludge to remove top-level array
  }
  return arr;
}




function wkt_parse(str) {
  var obj = {};
  wkt_unpack(str).forEach(function(part) {
    wkt_parse_reorder(part, obj);
  });
  return obj;
}

// Convert WKT string to a JS object
// WKT format: http://docs.opengeospatial.org/is/12-063r5/12-063r5.html#11
function wkt_unpack(str) {
  var obj;
  // Convert WKT escaped quotes to JSON escaped quotes
  // str = str.replace(/""/g, '\\"'); // BUGGY
  str = convert_wkt_quotes(str);

  // Convert WKT entities to JSON arrays
  str = str.replace(/([A-Z0-9]+)\[/g, '["$1",');

  // Enclose axis keywords in quotes to create valid JSON strings
  str = str.replace(/, *([a-zA-Z]+) *(?=[,\]])/g, ',"$1"');

  // str = str.replace(/[^\]]*$/, ''); // esri .prj string may have extra stuff appended

  // WKT may have a "VERTCS" section after "PROJCS" section; enclosing contents
  //   in brackets to create valid JSON array.
  str = '[' + str + ']';

  try {
    obj = JSON.parse(str);
  } catch(e) {
    wkt_error('unparsable WKT format');
  }
  return obj;
}

// Convert WKT escaped quotes to JSON escaped quotes ("" -> \")
function convert_wkt_quotes(str) {
  var c = 0;
  return str.replace(/"+/g, function(s) {
    var even = c % 2 == 0;
    c += s.length;
    // ordinary, unescaped quotes
    if (s == '"' || s == '""' && even) return s;
    // WKT-escaped quotes
    if (even) {
      return '"' + s.substring(1).replace(/""/g, '\\"');
    } else {
      return s.replace(/""/g, '\\"');
    }
  });
}

// Rearrange a subarray of a parsed WKT file for easier traversal
// E.g.
//   ["WGS84", ...]  to  {NAME: "WGS84"}
//   ["PROJECTION", "Mercator"]  to  {PROJECTION: "Mercator"}
//   ["PARAMETER", <param1>], ...  to  {PARAMETER: [<param1>, ...]}
function wkt_parse_reorder(arr, obj) {
  var name = arr[0], // TODO: handle alternate OGC names
      i;
  if (name == 'GEOGCS' || name == 'GEOCCS' || name == 'PROJCS' || name == 'DATUM' || name == 'VERTCS') {
    obj[name] = {
      NAME: arr[1]
    };
    for (i=2; i<arr.length; i++) {
      if (Array.isArray(arr[i])) {
        wkt_parse_reorder(arr[i], obj[name]);
      } else {
        throw wkt_error("WKT parse error");
      }
    }
  } else if (name == 'AXIS' || name == 'PARAMETER') {
    if (name in obj === false) {
      obj[name] = [];
    }
    obj[name].push(arr.slice(1));

  } else {
    obj[name] = arr.slice(1);
  }
  return obj;
}


var WKT_OMIT_DEFAULTS = true;

function wkt_from_proj4(P) {
  var obj;
  if (P.length) P = pj_init(P); // convert proj4 string
  if (pj_is_latlong(P)) {
    obj = {GEOGCS: wkt_make_geogcs(P)};
  } else {
    obj = wkt_make_projcs(P);
  }
  return wkt_stringify(obj);
}

// @str A WKT CRS definition string (e.g. contents of a .prj file)
function wkt_to_proj4(str) {
  var o = wkt_parse(str);
  var proj4;

  if (o.PROJCS) {
    proj4 = wkt_convert_projcs(o.PROJCS);

  } else if (o.GEOGCS) {
    proj4 = '+proj=longlat ' + wkt_convert_geogcs(o.GEOGCS);

  } else if (o.GEOCCS) {
    wkt_error('geocentric coordinates are not supported');

  } else {
    wkt_error('missing a supported WKT CS type');
  }
  return proj4;
}



/*
 * Math.js
 * Transcription of Math.hpp, Constants.hpp, and Accumulator.hpp into
 * JavaScript.
 *
 * Copyright (c) Charles Karney (2011-2017) <charles@karney.com> and licensed
 * under the MIT/X11 License.  For more information, see
 * https://geographiclib.sourceforge.io/
 */

/**
 * @namespace GeographicLib
 * @description The parent namespace for the following modules:
 * - {@link module:GeographicLib/Geodesic GeographicLib/Geodesic} The main
 *   engine for solving geodesic problems via the
 *   {@link module:GeographicLib/Geodesic.Geodesic Geodesic} class.
 * - {@link module:GeographicLib/GeodesicLine GeographicLib/GeodesicLine}
 *   computes points along a single geodesic line via the
 *   {@link module:GeographicLib/GeodesicLine.GeodesicLine GeodesicLine}
 *   class.
 * - {@link module:GeographicLib/PolygonArea GeographicLib/PolygonArea}
 *   computes the area of a geodesic polygon via the
 *   {@link module:GeographicLib/PolygonArea.PolygonArea PolygonArea}
 *   class.
 * - {@link module:GeographicLib/DMS GeographicLib/DMS} handles the decoding
 *   and encoding of angles in degree, minutes, and seconds, via static
 *   functions in this module.
 * - {@link module:GeographicLib/Constants GeographicLib/Constants} defines
 *   constants specifying the version numbers and the parameters for the WGS84
 *   ellipsoid.
 *
 * The following modules are used internally by the package:
 * - {@link module:GeographicLib/Math GeographicLib/Math} defines various
 *   mathematical functions.
 * - {@link module:GeographicLib/Accumulator GeographicLib/Accumulator}
 *   interally used by
 *   {@link module:GeographicLib/PolygonArea.PolygonArea PolygonArea} (via the
 *   {@link module:GeographicLib/Accumulator.Accumulator Accumulator} class)
 *   for summing the contributions to the area of a polygon.
 */
"use strict";
var GeographicLib = {};
GeographicLib.Constants = {};
GeographicLib.Math = {};
GeographicLib.Accumulator = {};

(function(
  /**
   * @exports GeographicLib/Constants
   * @description Define constants defining the version and WGS84 parameters.
   */
  c) {

  /**
   * @constant
   * @summary WGS84 parameters.
   * @property {number} a the equatorial radius (meters).
   * @property {number} f the flattening.
   */
  c.WGS84 = { a: 6378137, f: 1/298.257223563 };
  /**
   * @constant
   * @summary an array of version numbers.
   * @property {number} major the major version number.
   * @property {number} minor the minor version number.
   * @property {number} patch the patch number.
   */
  c.version = { major: 1, minor: 48, patch: 0 };
  /**
   * @constant
   * @summary version string
   */
  c.version_string = "1.48";
})(GeographicLib.Constants);

(function(
  /**
   * @exports GeographicLib/Math
   * @description Some useful mathematical constants and functions (mainly for
   *   internal use).
   */
  m) {

  /**
   * @summary The number of digits of precision in floating-point numbers.
   * @constant {number}
   */
  m.digits = 53;
  /**
   * @summary The machine epsilon.
   * @constant {number}
   */
  m.epsilon = Math.pow(0.5, m.digits - 1);
  /**
   * @summary The factor to convert degrees to radians.
   * @constant {number}
   */
  m.degree = Math.PI/180;

  /**
   * @summary Square a number.
   * @param {number} x the number.
   * @returns {number} the square.
   */
  m.sq = function(x) { return x * x; };

  /**
   * @summary The hypotenuse function.
   * @param {number} x the first side.
   * @param {number} y the second side.
   * @returns {number} the hypotenuse.
   */
  m.hypot = function(x, y) {
    var a, b;
    x = Math.abs(x);
    y = Math.abs(y);
    a = Math.max(x, y); b = Math.min(x, y) / (a ? a : 1);
    return a * Math.sqrt(1 + b * b);
  };

  /**
   * @summary Cube root function.
   * @param {number} x the argument.
   * @returns {number} the real cube root.
   */
  m.cbrt = function(x) {
    var y = Math.pow(Math.abs(x), 1/3);
    return x < 0 ? -y : y;
  };

  /**
   * @summary The log1p function.
   * @param {number} x the argument.
   * @returns {number} log(1 + x).
   */
  m.log1p = function(x) {
    var y = 1 + x,
        z = y - 1;
    // Here's the explanation for this magic: y = 1 + z, exactly, and z
    // approx x, thus log(y)/z (which is nearly constant near z = 0) returns
    // a good approximation to the true log(1 + x)/x.  The multiplication x *
    // (log(y)/z) introduces little additional error.
    return z === 0 ? x : x * Math.log(y) / z;
  };

  /**
   * @summary Inverse hyperbolic tangent.
   * @param {number} x the argument.
   * @returns {number} tanh<sup>&minus;1</sup> x.
   */
  m.atanh = function(x) {
    var y = Math.abs(x);          // Enforce odd parity
    y = m.log1p(2 * y/(1 - y))/2;
    return x < 0 ? -y : y;
  };

  /**
   * @summary Copy the sign.
   * @param {number} x gives the magitude of the result.
   * @param {number} y gives the sign of the result.
   * @returns {number} value with the magnitude of x and with the sign of y.
   */
  m.copysign = function(x, y) {
    return Math.abs(x) * (y < 0 || (y === 0 && 1/y < 0) ? -1 : 1);
  };

  /**
   * @summary An error-free sum.
   * @param {number} u
   * @param {number} v
   * @returns {object} sum with sum.s = round(u + v) and sum.t is u + v &minus;
   *   round(u + v)
   */
  m.sum = function(u, v) {
    var s = u + v,
        up = s - v,
        vpp = s - up,
        t;
    up -= u;
    vpp -= v;
    t = -(up + vpp);
    // u + v =       s      + t
    //       = round(u + v) + t
    return {s: s, t: t};
  };

  /**
   * @summary Evaluate a polynomial.
   * @param {integer} N the order of the polynomial.
   * @param {array} p the coefficient array (of size N + 1) (leading
   *   order coefficient first)
   * @param {number} x the variable.
   * @returns {number} the value of the polynomial.
   */
  m.polyval = function(N, p, s, x) {
    var y = N < 0 ? 0 : p[s++];
    while (--N >= 0) y = y * x + p[s++];
    return y;
  };

  /**
   * @summary Coarsen a value close to zero.
   * @param {number} x
   * @returns {number} the coarsened value.
   */
  m.AngRound = function(x) {
    // The makes the smallest gap in x = 1/16 - nextafter(1/16, 0) = 1/2^57 for
    // reals = 0.7 pm on the earth if x is an angle in degrees.  (This is about
    // 1000 times more resolution than we get with angles around 90 degrees.)
    // We use this to avoid having to deal with near singular cases when x is
    // non-zero but tiny (e.g., 1.0e-200).  This converts -0 to +0; however
    // tiny negative numbers get converted to -0.
    if (x === 0) return x;
    var z = 1/16,
        y = Math.abs(x);
    // The compiler mustn't "simplify" z - (z - y) to y
    y = y < z ? z - (z - y) : y;
    return x < 0 ? -y : y;
  };

  /**
   * @summary Normalize an angle.
   * @param {number} x the angle in degrees.
   * @returns {number} the angle reduced to the range (&minus;180&deg;,
   *   180&deg;].
   */
  m.AngNormalize = function(x) {
    // Place angle in [-180, 180).
    x = x % 360;
    return x <= -180 ? x + 360 : (x <= 180 ? x : x - 360);
  };

  /**
   * @summary Normalize a latitude.
   * @param {number} x the angle in degrees.
   * @returns {number} x if it is in the range [&minus;90&deg;, 90&deg;],
   *   otherwise return NaN.
   */
  m.LatFix = function(x) {
    // Replace angle with NaN if outside [-90, 90].
    return Math.abs(x) > 90 ? Number.NaN : x;
  };

  /**
   * @summary The exact difference of two angles reduced to (&minus;180&deg;,
   *   180&deg;]
   * @param {number} x the first angle in degrees.
   * @param {number} y the second angle in degrees.
   * @return {object} diff the exact difference, y &minus; x.
   *
   * This computes z = y &minus; x exactly, reduced to (&minus;180&deg;,
   * 180&deg;]; and then sets diff.s = d = round(z) and diff.t = e = z &minus;
   * round(z).  If d = &minus;180, then e &gt; 0; If d = 180, then e &le; 0.
   */
  m.AngDiff = function(x, y) {
    // Compute y - x and reduce to [-180,180] accurately.
    var r = m.sum(m.AngNormalize(-x), m.AngNormalize(y)),
        d = m.AngNormalize(r.s),
        t = r.t;
    return m.sum(d === 180 && t > 0 ? -180 : d, t);
  };

  /**
   * @summary Evaluate the sine and cosine function with the argument in
   *   degrees
   * @param {number} x in degrees.
   * @returns {object} r with r.s = sin(x) and r.c = cos(x).
   */
  m.sincosd = function(x) {
    // In order to minimize round-off errors, this function exactly reduces
    // the argument to the range [-45, 45] before converting it to radians.
    var r, q, s, c, sinx, cosx;
    r = x % 360;
    q = Math.floor(r / 90 + 0.5);
    r -= 90 * q;
    // now abs(r) <= 45
    r *= this.degree;
    // Possibly could call the gnu extension sincos
    s = Math.sin(r); c = Math.cos(r);
    switch (q & 3) {
      case 0:  sinx =  s; cosx =  c; break;
      case 1:  sinx =  c; cosx = -s; break;
      case 2:  sinx = -s; cosx = -c; break;
      default: sinx = -c; cosx =  s; break; // case 3
    }
    if (x) { sinx += 0; cosx += 0; }
    return {s: sinx, c: cosx};
  };

  /**
   * @summary Evaluate the atan2 function with the result in degrees
   * @param {number} y
   * @param {number} x
   * @returns atan2(y, x) in degrees, in the range (&minus;180&deg;
   *   180&deg;].
   */
  m.atan2d = function(y, x) {
    // In order to minimize round-off errors, this function rearranges the
    // arguments so that result of atan2 is in the range [-pi/4, pi/4] before
    // converting it to degrees and mapping the result to the correct
    // quadrant.
    var q = 0, t, ang;
    if (Math.abs(y) > Math.abs(x)) { t = x; x = y; y = t; q = 2; }
    if (x < 0) { x = -x; ++q; }
    // here x >= 0 and x >= abs(y), so angle is in [-pi/4, pi/4]
    ang = Math.atan2(y, x) / this.degree;
    switch (q) {
      // Note that atan2d(-0.0, 1.0) will return -0.  However, we expect that
      // atan2d will not be called with y = -0.  If need be, include
      //
      //   case 0: ang = 0 + ang; break;
      //
      // and handle mpfr as in AngRound.
      case 1: ang = (y >= 0 ? 180 : -180) - ang; break;
      case 2: ang =  90 - ang; break;
      case 3: ang = -90 + ang; break;
    }
    return ang;
  };
})(GeographicLib.Math);

(function(
  /**
   * @exports GeographicLib/Accumulator
   * @description Accurate summation via the
   *   {@link module:GeographicLib/Accumulator.Accumulator Accumulator} class
   *   (mainly for internal use).
   */
  a, m) {

  /**
   * @class
   * @summary Accurate summation of many numbers.
   * @classdesc This allows many numbers to be added together with twice the
   *   normal precision.  In the documentation of the member functions, sum
   *   stands for the value currently held in the accumulator.
   * @param {number | Accumulator} [y = 0]  set sum = y.
   */
  a.Accumulator = function(y) {
    this.Set(y);
  };

  /**
   * @summary Set the accumulator to a number.
   * @param {number | Accumulator} [y = 0] set sum = y.
   */
  a.Accumulator.prototype.Set = function(y) {
    if (!y) y = 0;
    if (y.constructor === a.Accumulator) {
      this._s = y._s;
      this._t = y._t;
    } else {
      this._s = y;
      this._t = 0;
    }
  };

  /**
   * @summary Add a number to the accumulator.
   * @param {number} [y = 0] set sum += y.
   */
  a.Accumulator.prototype.Add = function(y) {
    // Here's Shewchuk's solution...
    // Accumulate starting at least significant end
    var u = m.sum(y, this._t),
        v = m.sum(u.s, this._s);
    u = u.t;
    this._s = v.s;
    this._t = v.t;
    // Start is _s, _t decreasing and non-adjacent.  Sum is now (s + t + u)
    // exactly with s, t, u non-adjacent and in decreasing order (except
    // for possible zeros).  The following code tries to normalize the
    // result.  Ideally, we want _s = round(s+t+u) and _u = round(s+t+u -
    // _s).  The follow does an approximate job (and maintains the
    // decreasing non-adjacent property).  Here are two "failures" using
    // 3-bit floats:
    //
    // Case 1: _s is not equal to round(s+t+u) -- off by 1 ulp
    // [12, -1] - 8 -> [4, 0, -1] -> [4, -1] = 3 should be [3, 0] = 3
    //
    // Case 2: _s+_t is not as close to s+t+u as it shold be
    // [64, 5] + 4 -> [64, 8, 1] -> [64,  8] = 72 (off by 1)
    //                    should be [80, -7] = 73 (exact)
    //
    // "Fixing" these problems is probably not worth the expense.  The
    // representation inevitably leads to small errors in the accumulated
    // values.  The additional errors illustrated here amount to 1 ulp of
    // the less significant word during each addition to the Accumulator
    // and an additional possible error of 1 ulp in the reported sum.
    //
    // Incidentally, the "ideal" representation described above is not
    // canonical, because _s = round(_s + _t) may not be true.  For
    // example, with 3-bit floats:
    //
    // [128, 16] + 1 -> [160, -16] -- 160 = round(145).
    // But [160, 0] - 16 -> [128, 16] -- 128 = round(144).
    //
    if (this._s === 0)          // This implies t == 0,
      this._s = u;              // so result is u
    else
      this._t += u;             // otherwise just accumulate u to t.
  };

  /**
   * @summary Return the result of adding a number to sum (but
   *   don't change sum).
   * @param {number} [y = 0] the number to be added to the sum.
   * @return sum + y.
   */
  a.Accumulator.prototype.Sum = function(y) {
    var b;
    if (!y)
      return this._s;
    else {
      b = new a.Accumulator(this);
      b.Add(y);
      return b._s;
    }
  };

  /**
   * @summary Set sum = &minus;sum.
   */
  a.Accumulator.prototype.Negate = function() {
    this._s *= -1;
    this._t *= -1;
  };
})(GeographicLib.Accumulator, GeographicLib.Math);


/*
 * Geodesic.js
 * Transcription of Geodesic.[ch]pp into JavaScript.
 *
 * See the documentation for the C++ class.  The conversion is a literal
 * conversion from C++.
 *
 * The algorithms are derived in
 *
 *    Charles F. F. Karney,
 *    Algorithms for geodesics, J. Geodesy 87, 43-55 (2013);
 *    https://doi.org/10.1007/s00190-012-0578-z
 *    Addenda: https://geographiclib.sourceforge.io/geod-addenda.html
 *
 * Copyright (c) Charles Karney (2011-2017) <charles@karney.com> and licensed
 * under the MIT/X11 License.  For more information, see
 * https://geographiclib.sourceforge.io/
 */

// Load AFTER Math.js

GeographicLib.Geodesic = {};
GeographicLib.GeodesicLine = {};
GeographicLib.PolygonArea = {};

(function(
  /**
   * @exports GeographicLib/Geodesic
   * @description Solve geodesic problems via the
   *   {@link module:GeographicLib/Geodesic.Geodesic Geodesic} class.
   */
  g, l, p, m, c) {

  var GEOGRAPHICLIB_GEODESIC_ORDER = 6,
      nA1_ = GEOGRAPHICLIB_GEODESIC_ORDER,
      nA2_ = GEOGRAPHICLIB_GEODESIC_ORDER,
      nA3_ = GEOGRAPHICLIB_GEODESIC_ORDER,
      nA3x_ = nA3_,
      nC3x_, nC4x_,
      maxit1_ = 20,
      maxit2_ = maxit1_ + m.digits + 10,
      tol0_ = m.epsilon,
      tol1_ = 200 * tol0_,
      tol2_ = Math.sqrt(tol0_),
      tolb_ = tol0_ * tol1_,
      xthresh_ = 1000 * tol2_,
      CAP_NONE = 0,
      CAP_ALL  = 0x1F,
      CAP_MASK = CAP_ALL,
      OUT_ALL  = 0x7F80,
      astroid,
      A1m1f_coeff, C1f_coeff, C1pf_coeff,
      A2m1f_coeff, C2f_coeff,
      A3_coeff, C3_coeff, C4_coeff;

  g.tiny_ = Math.sqrt(Number.MIN_VALUE);
  g.nC1_ = GEOGRAPHICLIB_GEODESIC_ORDER;
  g.nC1p_ = GEOGRAPHICLIB_GEODESIC_ORDER;
  g.nC2_ = GEOGRAPHICLIB_GEODESIC_ORDER;
  g.nC3_ = GEOGRAPHICLIB_GEODESIC_ORDER;
  g.nC4_ = GEOGRAPHICLIB_GEODESIC_ORDER;
  nC3x_ = (g.nC3_ * (g.nC3_ - 1)) / 2;
  nC4x_ = (g.nC4_ * (g.nC4_ + 1)) / 2;
  g.CAP_C1   = 1<<0;
  g.CAP_C1p  = 1<<1;
  g.CAP_C2   = 1<<2;
  g.CAP_C3   = 1<<3;
  g.CAP_C4   = 1<<4;

  g.NONE          = 0;
  g.ARC           = 1<<6;
  g.LATITUDE      = 1<<7  | CAP_NONE;
  g.LONGITUDE     = 1<<8  | g.CAP_C3;
  g.AZIMUTH       = 1<<9  | CAP_NONE;
  g.DISTANCE      = 1<<10 | g.CAP_C1;
  g.STANDARD      = g.LATITUDE | g.LONGITUDE | g.AZIMUTH | g.DISTANCE;
  g.DISTANCE_IN   = 1<<11 | g.CAP_C1 | g.CAP_C1p;
  g.REDUCEDLENGTH = 1<<12 | g.CAP_C1 | g.CAP_C2;
  g.GEODESICSCALE = 1<<13 | g.CAP_C1 | g.CAP_C2;
  g.AREA          = 1<<14 | g.CAP_C4;
  g.ALL           = OUT_ALL| CAP_ALL;
  g.LONG_UNROLL   = 1<<15;
  g.OUT_MASK      = OUT_ALL| g.LONG_UNROLL;

  g.SinCosSeries = function(sinp, sinx, cosx, c) {
    // Evaluate
    // y = sinp ? sum(c[i] * sin( 2*i    * x), i, 1, n) :
    //            sum(c[i] * cos((2*i+1) * x), i, 0, n-1)
    // using Clenshaw summation.  N.B. c[0] is unused for sin series
    // Approx operation count = (n + 5) mult and (2 * n + 2) add
    var k = c.length,           // Point to one beyond last element
        n = k - (sinp ? 1 : 0),
        ar = 2 * (cosx - sinx) * (cosx + sinx), // 2 * cos(2 * x)
        y0 = n & 1 ? c[--k] : 0, y1 = 0;        // accumulators for sum
    // Now n is even
    n = Math.floor(n/2);
    while (n--) {
      // Unroll loop x 2, so accumulators return to their original role
      y1 = ar * y0 - y1 + c[--k];
      y0 = ar * y1 - y0 + c[--k];
    }
    return (sinp ? 2 * sinx * cosx * y0 : // sin(2 * x) * y0
            cosx * (y0 - y1));            // cos(x) * (y0 - y1)
  };

  astroid = function(x, y) {
    // Solve k^4+2*k^3-(x^2+y^2-1)*k^2-2*y^2*k-y^2 = 0 for positive
    // root k.  This solution is adapted from Geocentric::Reverse.
    var k,
        p = m.sq(x),
        q = m.sq(y),
        r = (p + q - 1) / 6,
        S, r2, r3, disc, u, T3, T, ang, v, uv, w;
    if ( !(q === 0 && r <= 0) ) {
      // Avoid possible division by zero when r = 0 by multiplying
      // equations for s and t by r^3 and r, resp.
      S = p * q / 4;            // S = r^3 * s
      r2 = m.sq(r);
      r3 = r * r2;
      // The discriminant of the quadratic equation for T3.  This is
      // zero on the evolute curve p^(1/3)+q^(1/3) = 1
      disc = S * (S + 2 * r3);
      u = r;
      if (disc >= 0) {
        T3 = S + r3;
        // Pick the sign on the sqrt to maximize abs(T3).  This
        // minimizes loss of precision due to cancellation.  The
        // result is unchanged because of the way the T is used
        // in definition of u.
        T3 += T3 < 0 ? -Math.sqrt(disc) : Math.sqrt(disc);    // T3 = (r * t)^3
        // N.B. cbrt always returns the real root.  cbrt(-8) = -2.
        T = m.cbrt(T3);     // T = r * t
        // T can be zero; but then r2 / T -> 0.
        u += T + (T !== 0 ? r2 / T : 0);
      } else {
        // T is complex, but the way u is defined the result is real.
        ang = Math.atan2(Math.sqrt(-disc), -(S + r3));
        // There are three possible cube roots.  We choose the
        // root which avoids cancellation.  Note that disc < 0
        // implies that r < 0.
        u += 2 * r * Math.cos(ang / 3);
      }
      v = Math.sqrt(m.sq(u) + q);       // guaranteed positive
      // Avoid loss of accuracy when u < 0.
      uv = u < 0 ? q / (v - u) : u + v; // u+v, guaranteed positive
      w = (uv - q) / (2 * v);           // positive?
      // Rearrange expression for k to avoid loss of accuracy due to
      // subtraction.  Division by 0 not possible because uv > 0, w >= 0.
      k = uv / (Math.sqrt(uv + m.sq(w)) + w); // guaranteed positive
    } else {                                  // q == 0 && r <= 0
      // y = 0 with |x| <= 1.  Handle this case directly.
      // for y small, positive root is k = abs(y)/sqrt(1-x^2)
      k = 0;
    }
    return k;
  };

  A1m1f_coeff = [
    // (1-eps)*A1-1, polynomial in eps2 of order 3
      +1, 4, 64, 0, 256
  ];

  // The scale factor A1-1 = mean value of (d/dsigma)I1 - 1
  g.A1m1f = function(eps) {
    var p = Math.floor(nA1_/2),
        t = m.polyval(p, A1m1f_coeff, 0, m.sq(eps)) / A1m1f_coeff[p + 1];
    return (t + eps) / (1 - eps);
  };

  C1f_coeff = [
    // C1[1]/eps^1, polynomial in eps2 of order 2
      -1, 6, -16, 32,
    // C1[2]/eps^2, polynomial in eps2 of order 2
      -9, 64, -128, 2048,
    // C1[3]/eps^3, polynomial in eps2 of order 1
      +9, -16, 768,
    // C1[4]/eps^4, polynomial in eps2 of order 1
      +3, -5, 512,
    // C1[5]/eps^5, polynomial in eps2 of order 0
      -7, 1280,
    // C1[6]/eps^6, polynomial in eps2 of order 0
      -7, 2048
  ];

  // The coefficients C1[l] in the Fourier expansion of B1
  g.C1f = function(eps, c) {
    var eps2 = m.sq(eps),
        d = eps,
        o = 0,
        l, p;
    for (l = 1; l <= g.nC1_; ++l) {     // l is index of C1p[l]
      p = Math.floor((g.nC1_ - l) / 2); // order of polynomial in eps^2
      c[l] = d * m.polyval(p, C1f_coeff, o, eps2) / C1f_coeff[o + p + 1];
      o += p + 2;
      d *= eps;
    }
  };

  C1pf_coeff = [
    // C1p[1]/eps^1, polynomial in eps2 of order 2
      +205, -432, 768, 1536,
    // C1p[2]/eps^2, polynomial in eps2 of order 2
      +4005, -4736, 3840, 12288,
    // C1p[3]/eps^3, polynomial in eps2 of order 1
      -225, 116, 384,
    // C1p[4]/eps^4, polynomial in eps2 of order 1
      -7173, 2695, 7680,
    // C1p[5]/eps^5, polynomial in eps2 of order 0
      +3467, 7680,
    // C1p[6]/eps^6, polynomial in eps2 of order 0
      +38081, 61440
  ];

  // The coefficients C1p[l] in the Fourier expansion of B1p
  g.C1pf = function(eps, c) {
    var eps2 = m.sq(eps),
        d = eps,
        o = 0,
        l, p;
    for (l = 1; l <= g.nC1p_; ++l) {     // l is index of C1p[l]
      p = Math.floor((g.nC1p_ - l) / 2); // order of polynomial in eps^2
      c[l] = d * m.polyval(p, C1pf_coeff, o, eps2) / C1pf_coeff[o + p + 1];
      o += p + 2;
      d *= eps;
    }
  };

  A2m1f_coeff = [
    // (eps+1)*A2-1, polynomial in eps2 of order 3
      -11, -28, -192, 0, 256
  ];

  // The scale factor A2-1 = mean value of (d/dsigma)I2 - 1
  g.A2m1f = function(eps) {
    var p = Math.floor(nA2_/2),
        t = m.polyval(p, A2m1f_coeff, 0, m.sq(eps)) / A2m1f_coeff[p + 1];
    return (t - eps) / (1 + eps);
  };

  C2f_coeff = [
    // C2[1]/eps^1, polynomial in eps2 of order 2
      +1, 2, 16, 32,
    // C2[2]/eps^2, polynomial in eps2 of order 2
      +35, 64, 384, 2048,
    // C2[3]/eps^3, polynomial in eps2 of order 1
      +15, 80, 768,
    // C2[4]/eps^4, polynomial in eps2 of order 1
      +7, 35, 512,
    // C2[5]/eps^5, polynomial in eps2 of order 0
      +63, 1280,
    // C2[6]/eps^6, polynomial in eps2 of order 0
      +77, 2048
  ];

  // The coefficients C2[l] in the Fourier expansion of B2
  g.C2f = function(eps, c) {
    var eps2 = m.sq(eps),
        d = eps,
        o = 0,
        l, p;
    for (l = 1; l <= g.nC2_; ++l) {     // l is index of C2[l]
      p = Math.floor((g.nC2_ - l) / 2); // order of polynomial in eps^2
      c[l] = d * m.polyval(p, C2f_coeff, o, eps2) / C2f_coeff[o + p + 1];
      o += p + 2;
      d *= eps;
    }
  };

  /**
   * @class
   * @property {number} a the equatorial radius (meters).
   * @property {number} f the flattening.
   * @summary Initialize a Geodesic object for a specific ellipsoid.
   * @classdesc Performs geodesic calculations on an ellipsoid of revolution.
   *   The routines for solving the direct and inverse problems return an
   *   object with some of the following fields set: lat1, lon1, azi1, lat2,
   *   lon2, azi2, s12, a12, m12, M12, M21, S12.  See {@tutorial 2-interface},
   *   "The results".
   * @example
   * var GeographicLib = require("geographiclib"),
   *     geod = GeographicLib.Geodesic.WGS84;
   * var inv = geod.Inverse(1,2,3,4);
   * console.log("lat1 = " + inv.lat1 + ", lon1 = " + inv.lon1 +
   *             ", lat2 = " + inv.lat2 + ", lon2 = " + inv.lon2 +
   *             ",\nazi1 = " + inv.azi1 + ", azi2 = " + inv.azi2 +
   *             ", s12 = " + inv.s12);
   * @param {number} a the equatorial radius of the ellipsoid (meters).
   * @param {number} f the flattening of the ellipsoid.  Setting f = 0 gives
   *   a sphere (on which geodesics are great circles).  Negative f gives a
   *   prolate ellipsoid.
   * @throws an error if the parameters are illegal.
   */
  g.Geodesic = function(a, f) {
    this.a = a;
    this.f = f;
    this._f1 = 1 - this.f;
    this._e2 = this.f * (2 - this.f);
    this._ep2 = this._e2 / m.sq(this._f1); // e2 / (1 - e2)
    this._n = this.f / ( 2 - this.f);
    this._b = this.a * this._f1;
    // authalic radius squared
    this._c2 = (m.sq(this.a) + m.sq(this._b) *
                (this._e2 === 0 ? 1 :
                 (this._e2 > 0 ? m.atanh(Math.sqrt(this._e2)) :
                  Math.atan(Math.sqrt(-this._e2))) /
                 Math.sqrt(Math.abs(this._e2))))/2;
    // The sig12 threshold for "really short".  Using the auxiliary sphere
    // solution with dnm computed at (bet1 + bet2) / 2, the relative error in
    // the azimuth consistency check is sig12^2 * abs(f) * min(1, 1-f/2) / 2.
    // (Error measured for 1/100 < b/a < 100 and abs(f) >= 1/1000.  For a given
    // f and sig12, the max error occurs for lines near the pole.  If the old
    // rule for computing dnm = (dn1 + dn2)/2 is used, then the error increases
    // by a factor of 2.)  Setting this equal to epsilon gives sig12 = etol2.
    // Here 0.1 is a safety factor (error decreased by 100) and max(0.001,
    // abs(f)) stops etol2 getting too large in the nearly spherical case.
    this._etol2 = 0.1 * tol2_ /
      Math.sqrt( Math.max(0.001, Math.abs(this.f)) *
                 Math.min(1.0, 1 - this.f/2) / 2 );
    if (!(isFinite(this.a) && this.a > 0))
      throw new Error("Equatorial radius is not positive");
    if (!(isFinite(this._b) && this._b > 0))
      throw new Error("Polar semi-axis is not positive");
    this._A3x = new Array(nA3x_);
    this._C3x = new Array(nC3x_);
    this._C4x = new Array(nC4x_);
    this.A3coeff();
    this.C3coeff();
    this.C4coeff();
  };

  A3_coeff = [
    // A3, coeff of eps^5, polynomial in n of order 0
      -3, 128,
    // A3, coeff of eps^4, polynomial in n of order 1
      -2, -3, 64,
    // A3, coeff of eps^3, polynomial in n of order 2
      -1, -3, -1, 16,
    // A3, coeff of eps^2, polynomial in n of order 2
      +3, -1, -2, 8,
    // A3, coeff of eps^1, polynomial in n of order 1
      +1, -1, 2,
    // A3, coeff of eps^0, polynomial in n of order 0
      +1, 1
  ];

  // The scale factor A3 = mean value of (d/dsigma)I3
  g.Geodesic.prototype.A3coeff = function() {
    var o = 0, k = 0,
        j, p;
    for (j = nA3_ - 1; j >= 0; --j) { // coeff of eps^j
      p = Math.min(nA3_ - j - 1, j);  // order of polynomial in n
      this._A3x[k++] = m.polyval(p, A3_coeff, o, this._n) /
        A3_coeff[o + p + 1];
      o += p + 2;
    }
  };

  C3_coeff = [
    // C3[1], coeff of eps^5, polynomial in n of order 0
      +3, 128,
    // C3[1], coeff of eps^4, polynomial in n of order 1
      +2, 5, 128,
    // C3[1], coeff of eps^3, polynomial in n of order 2
      -1, 3, 3, 64,
    // C3[1], coeff of eps^2, polynomial in n of order 2
      -1, 0, 1, 8,
    // C3[1], coeff of eps^1, polynomial in n of order 1
      -1, 1, 4,
    // C3[2], coeff of eps^5, polynomial in n of order 0
      +5, 256,
    // C3[2], coeff of eps^4, polynomial in n of order 1
      +1, 3, 128,
    // C3[2], coeff of eps^3, polynomial in n of order 2
      -3, -2, 3, 64,
    // C3[2], coeff of eps^2, polynomial in n of order 2
      +1, -3, 2, 32,
    // C3[3], coeff of eps^5, polynomial in n of order 0
      +7, 512,
    // C3[3], coeff of eps^4, polynomial in n of order 1
      -10, 9, 384,
    // C3[3], coeff of eps^3, polynomial in n of order 2
      +5, -9, 5, 192,
    // C3[4], coeff of eps^5, polynomial in n of order 0
      +7, 512,
    // C3[4], coeff of eps^4, polynomial in n of order 1
      -14, 7, 512,
    // C3[5], coeff of eps^5, polynomial in n of order 0
      +21, 2560
  ];

  // The coefficients C3[l] in the Fourier expansion of B3
  g.Geodesic.prototype.C3coeff = function() {
    var o = 0, k = 0,
        l, j, p;
    for (l = 1; l < g.nC3_; ++l) {        // l is index of C3[l]
      for (j = g.nC3_ - 1; j >= l; --j) { // coeff of eps^j
        p = Math.min(g.nC3_ - j - 1, j);  // order of polynomial in n
        this._C3x[k++] = m.polyval(p, C3_coeff, o, this._n) /
          C3_coeff[o + p + 1];
        o += p + 2;
      }
    }
  };

  C4_coeff = [
    // C4[0], coeff of eps^5, polynomial in n of order 0
      +97, 15015,
    // C4[0], coeff of eps^4, polynomial in n of order 1
      +1088, 156, 45045,
    // C4[0], coeff of eps^3, polynomial in n of order 2
      -224, -4784, 1573, 45045,
    // C4[0], coeff of eps^2, polynomial in n of order 3
      -10656, 14144, -4576, -858, 45045,
    // C4[0], coeff of eps^1, polynomial in n of order 4
      +64, 624, -4576, 6864, -3003, 15015,
    // C4[0], coeff of eps^0, polynomial in n of order 5
      +100, 208, 572, 3432, -12012, 30030, 45045,
    // C4[1], coeff of eps^5, polynomial in n of order 0
      +1, 9009,
    // C4[1], coeff of eps^4, polynomial in n of order 1
      -2944, 468, 135135,
    // C4[1], coeff of eps^3, polynomial in n of order 2
      +5792, 1040, -1287, 135135,
    // C4[1], coeff of eps^2, polynomial in n of order 3
      +5952, -11648, 9152, -2574, 135135,
    // C4[1], coeff of eps^1, polynomial in n of order 4
      -64, -624, 4576, -6864, 3003, 135135,
    // C4[2], coeff of eps^5, polynomial in n of order 0
      +8, 10725,
    // C4[2], coeff of eps^4, polynomial in n of order 1
      +1856, -936, 225225,
    // C4[2], coeff of eps^3, polynomial in n of order 2
      -8448, 4992, -1144, 225225,
    // C4[2], coeff of eps^2, polynomial in n of order 3
      -1440, 4160, -4576, 1716, 225225,
    // C4[3], coeff of eps^5, polynomial in n of order 0
      -136, 63063,
    // C4[3], coeff of eps^4, polynomial in n of order 1
      +1024, -208, 105105,
    // C4[3], coeff of eps^3, polynomial in n of order 2
      +3584, -3328, 1144, 315315,
    // C4[4], coeff of eps^5, polynomial in n of order 0
      -128, 135135,
    // C4[4], coeff of eps^4, polynomial in n of order 1
      -2560, 832, 405405,
    // C4[5], coeff of eps^5, polynomial in n of order 0
      +128, 99099
  ];

  g.Geodesic.prototype.C4coeff = function() {
    var o = 0, k = 0,
        l, j, p;
    for (l = 0; l < g.nC4_; ++l) {        // l is index of C4[l]
      for (j = g.nC4_ - 1; j >= l; --j) { // coeff of eps^j
        p = g.nC4_ - j - 1;               // order of polynomial in n
        this._C4x[k++] = m.polyval(p, C4_coeff, o, this._n) /
          C4_coeff[o + p + 1];
        o += p + 2;
      }
    }
  };

  g.Geodesic.prototype.A3f = function(eps) {
    // Evaluate A3
    return m.polyval(nA3x_ - 1, this._A3x, 0, eps);
  };

  g.Geodesic.prototype.C3f = function(eps, c) {
    // Evaluate C3 coeffs
    // Elements c[1] thru c[nC3_ - 1] are set
    var mult = 1,
        o = 0,
        l, p;
    for (l = 1; l < g.nC3_; ++l) { // l is index of C3[l]
      p = g.nC3_ - l - 1;          // order of polynomial in eps
      mult *= eps;
      c[l] = mult * m.polyval(p, this._C3x, o, eps);
      o += p + 1;
    }
  };

  g.Geodesic.prototype.C4f = function(eps, c) {
    // Evaluate C4 coeffs
    // Elements c[0] thru c[g.nC4_ - 1] are set
    var mult = 1,
        o = 0,
        l, p;
    for (l = 0; l < g.nC4_; ++l) { // l is index of C4[l]
      p = g.nC4_ - l - 1;          // order of polynomial in eps
      c[l] = mult * m.polyval(p, this._C4x, o, eps);
      o += p + 1;
      mult *= eps;
    }
  };

  // return s12b, m12b, m0, M12, M21
  g.Geodesic.prototype.Lengths = function(eps, sig12,
                                          ssig1, csig1, dn1, ssig2, csig2, dn2,
                                          cbet1, cbet2, outmask,
                                          C1a, C2a) {
    // Return m12b = (reduced length)/_b; also calculate s12b =
    // distance/_b, and m0 = coefficient of secular term in
    // expression for reduced length.
    outmask &= g.OUT_MASK;
    var vals = {},
        m0x = 0, J12 = 0, A1 = 0, A2 = 0,
        B1, B2, l, csig12, t;
    if (outmask & (g.DISTANCE | g.REDUCEDLENGTH | g.GEODESICSCALE)) {
      A1 = g.A1m1f(eps);
      g.C1f(eps, C1a);
      if (outmask & (g.REDUCEDLENGTH | g.GEODESICSCALE)) {
        A2 = g.A2m1f(eps);
        g.C2f(eps, C2a);
        m0x = A1 - A2;
        A2 = 1 + A2;
      }
      A1 = 1 + A1;
    }
    if (outmask & g.DISTANCE) {
      B1 = g.SinCosSeries(true, ssig2, csig2, C1a) -
        g.SinCosSeries(true, ssig1, csig1, C1a);
      // Missing a factor of _b
      vals.s12b = A1 * (sig12 + B1);
      if (outmask & (g.REDUCEDLENGTH | g.GEODESICSCALE)) {
        B2 = g.SinCosSeries(true, ssig2, csig2, C2a) -
          g.SinCosSeries(true, ssig1, csig1, C2a);
        J12 = m0x * sig12 + (A1 * B1 - A2 * B2);
      }
    } else if (outmask & (g.REDUCEDLENGTH | g.GEODESICSCALE)) {
      // Assume here that nC1_ >= nC2_
      for (l = 1; l <= g.nC2_; ++l)
        C2a[l] = A1 * C1a[l] - A2 * C2a[l];
      J12 = m0x * sig12 + (g.SinCosSeries(true, ssig2, csig2, C2a) -
                           g.SinCosSeries(true, ssig1, csig1, C2a));
    }
    if (outmask & g.REDUCEDLENGTH) {
      vals.m0 = m0x;
      // Missing a factor of _b.
      // Add parens around (csig1 * ssig2) and (ssig1 * csig2) to ensure
      // accurate cancellation in the case of coincident points.
      vals.m12b = dn2 * (csig1 * ssig2) - dn1 * (ssig1 * csig2) -
        csig1 * csig2 * J12;
    }
    if (outmask & g.GEODESICSCALE) {
      csig12 = csig1 * csig2 + ssig1 * ssig2;
      t = this._ep2 * (cbet1 - cbet2) * (cbet1 + cbet2) / (dn1 + dn2);
      vals.M12 = csig12 + (t * ssig2 - csig2 * J12) * ssig1 / dn1;
      vals.M21 = csig12 - (t * ssig1 - csig1 * J12) * ssig2 / dn2;
    }
    return vals;
  };

  // return sig12, salp1, calp1, salp2, calp2, dnm
  g.Geodesic.prototype.InverseStart = function(sbet1, cbet1, dn1,
                                               sbet2, cbet2, dn2,
                                               lam12, slam12, clam12,
                                               C1a, C2a) {
    // Return a starting point for Newton's method in salp1 and calp1
    // (function value is -1).  If Newton's method doesn't need to be
    // used, return also salp2 and calp2 and function value is sig12.
    // salp2, calp2 only updated if return val >= 0.
    var vals = {},
        // bet12 = bet2 - bet1 in [0, pi); bet12a = bet2 + bet1 in (-pi, 0]
        sbet12 = sbet2 * cbet1 - cbet2 * sbet1,
        cbet12 = cbet2 * cbet1 + sbet2 * sbet1,
        sbet12a, shortline, omg12, sbetm2, somg12, comg12, t, ssig12, csig12,
        x, y, lamscale, betscale, k2, eps, cbet12a, bet12a, m12b, m0, nvals,
        k, omg12a, lam12x;
    vals.sig12 = -1;        // Return value
    // Volatile declaration needed to fix inverse cases
    // 88.202499451857 0 -88.202499451857 179.981022032992859592
    // 89.262080389218 0 -89.262080389218 179.992207982775375662
    // 89.333123580033 0 -89.333123580032997687 179.99295812360148422
    // which otherwise fail with g++ 4.4.4 x86 -O3
    sbet12a = sbet2 * cbet1;
    sbet12a += cbet2 * sbet1;

    shortline = cbet12 >= 0 && sbet12 < 0.5 && cbet2 * lam12 < 0.5;
    if (shortline) {
      sbetm2 = m.sq(sbet1 + sbet2);
      // sin((bet1+bet2)/2)^2
      // =  (sbet1 + sbet2)^2 / ((sbet1 + sbet2)^2 + (cbet1 + cbet2)^2)
      sbetm2 /= sbetm2 + m.sq(cbet1 + cbet2);
      vals.dnm = Math.sqrt(1 + this._ep2 * sbetm2);
      omg12 = lam12 / (this._f1 * vals.dnm);
      somg12 = Math.sin(omg12); comg12 = Math.cos(omg12);
    } else {
      somg12 = slam12; comg12 = clam12;
    }

    vals.salp1 = cbet2 * somg12;
    vals.calp1 = comg12 >= 0 ?
      sbet12 + cbet2 * sbet1 * m.sq(somg12) / (1 + comg12) :
      sbet12a - cbet2 * sbet1 * m.sq(somg12) / (1 - comg12);

    ssig12 = m.hypot(vals.salp1, vals.calp1);
    csig12 = sbet1 * sbet2 + cbet1 * cbet2 * comg12;
    if (shortline && ssig12 < this._etol2) {
      // really short lines
      vals.salp2 = cbet1 * somg12;
      vals.calp2 = sbet12 - cbet1 * sbet2 *
        (comg12 >= 0 ? m.sq(somg12) / (1 + comg12) : 1 - comg12);
      // norm(vals.salp2, vals.calp2);
      t = m.hypot(vals.salp2, vals.calp2); vals.salp2 /= t; vals.calp2 /= t;
      // Set return value
      vals.sig12 = Math.atan2(ssig12, csig12);
    } else if (Math.abs(this._n) > 0.1 || // Skip astroid calc if too eccentric
               csig12 >= 0 ||
               ssig12 >= 6 * Math.abs(this._n) * Math.PI * m.sq(cbet1)) {
      // Nothing to do, zeroth order spherical approximation is OK
    } else {
      // Scale lam12 and bet2 to x, y coordinate system where antipodal
      // point is at origin and singular point is at y = 0, x = -1.
      lam12x = Math.atan2(-slam12, -clam12); // lam12 - pi
      if (this.f >= 0) {       // In fact f == 0 does not get here
        // x = dlong, y = dlat
        k2 = m.sq(sbet1) * this._ep2;
        eps = k2 / (2 * (1 + Math.sqrt(1 + k2)) + k2);
        lamscale = this.f * cbet1 * this.A3f(eps) * Math.PI;
        betscale = lamscale * cbet1;

        x = lam12x / lamscale;
        y = sbet12a / betscale;
      } else {                  // f < 0
        // x = dlat, y = dlong
        cbet12a = cbet2 * cbet1 - sbet2 * sbet1;
        bet12a = Math.atan2(sbet12a, cbet12a);
        // In the case of lon12 = 180, this repeats a calculation made
        // in Inverse.
        nvals = this.Lengths(this._n, Math.PI + bet12a,
                             sbet1, -cbet1, dn1, sbet2, cbet2, dn2,
                             cbet1, cbet2, g.REDUCEDLENGTH, C1a, C2a);
        m12b = nvals.m12b; m0 = nvals.m0;
        x = -1 + m12b / (cbet1 * cbet2 * m0 * Math.PI);
        betscale = x < -0.01 ? sbet12a / x :
          -this.f * m.sq(cbet1) * Math.PI;
        lamscale = betscale / cbet1;
        y = lam12 / lamscale;
      }

      if (y > -tol1_ && x > -1 - xthresh_) {
        // strip near cut
        if (this.f >= 0) {
          vals.salp1 = Math.min(1, -x);
          vals.calp1 = -Math.sqrt(1 - m.sq(vals.salp1));
        } else {
          vals.calp1 = Math.max(x > -tol1_ ? 0 : -1, x);
          vals.salp1 = Math.sqrt(1 - m.sq(vals.calp1));
        }
      } else {
        // Estimate alp1, by solving the astroid problem.
        //
        // Could estimate alpha1 = theta + pi/2, directly, i.e.,
        //   calp1 = y/k; salp1 = -x/(1+k);  for f >= 0
        //   calp1 = x/(1+k); salp1 = -y/k;  for f < 0 (need to check)
        //
        // However, it's better to estimate omg12 from astroid and use
        // spherical formula to compute alp1.  This reduces the mean number of
        // Newton iterations for astroid cases from 2.24 (min 0, max 6) to 2.12
        // (min 0 max 5).  The changes in the number of iterations are as
        // follows:
        //
        // change percent
        //    1       5
        //    0      78
        //   -1      16
        //   -2       0.6
        //   -3       0.04
        //   -4       0.002
        //
        // The histogram of iterations is (m = number of iterations estimating
        // alp1 directly, n = number of iterations estimating via omg12, total
        // number of trials = 148605):
        //
        //  iter    m      n
        //    0   148    186
        //    1 13046  13845
        //    2 93315 102225
        //    3 36189  32341
        //    4  5396      7
        //    5   455      1
        //    6    56      0
        //
        // Because omg12 is near pi, estimate work with omg12a = pi - omg12
        k = astroid(x, y);
        omg12a = lamscale * ( this.f >= 0 ? -x * k/(1 + k) : -y * (1 + k)/k );
        somg12 = Math.sin(omg12a); comg12 = -Math.cos(omg12a);
        // Update spherical estimate of alp1 using omg12 instead of
        // lam12
        vals.salp1 = cbet2 * somg12;
        vals.calp1 = sbet12a -
          cbet2 * sbet1 * m.sq(somg12) / (1 - comg12);
      }
    }
    // Sanity check on starting guess.  Backwards check allows NaN through.
    if (!(vals.salp1 <= 0.0)) {
      // norm(vals.salp1, vals.calp1);
      t = m.hypot(vals.salp1, vals.calp1); vals.salp1 /= t; vals.calp1 /= t;
    } else {
      vals.salp1 = 1; vals.calp1 = 0;
    }
    return vals;
  };

  // return lam12, salp2, calp2, sig12, ssig1, csig1, ssig2, csig2, eps,
  // domg12, dlam12,
  g.Geodesic.prototype.Lambda12 = function(sbet1, cbet1, dn1, sbet2, cbet2, dn2,
                                           salp1, calp1, slam120, clam120,
                                           diffp, C1a, C2a, C3a) {
    var vals = {},
        t, salp0, calp0,
        somg1, comg1, somg2, comg2, somg12, comg12, B312, eta, k2, nvals;
    if (sbet1 === 0 && calp1 === 0)
      // Break degeneracy of equatorial line.  This case has already been
      // handled.
      calp1 = -g.tiny_;

    // sin(alp1) * cos(bet1) = sin(alp0)
    salp0 = salp1 * cbet1;
    calp0 = m.hypot(calp1, salp1 * sbet1); // calp0 > 0

    // tan(bet1) = tan(sig1) * cos(alp1)
    // tan(omg1) = sin(alp0) * tan(sig1) = tan(omg1)=tan(alp1)*sin(bet1)
    vals.ssig1 = sbet1; somg1 = salp0 * sbet1;
    vals.csig1 = comg1 = calp1 * cbet1;
    // norm(vals.ssig1, vals.csig1);
    t = m.hypot(vals.ssig1, vals.csig1); vals.ssig1 /= t; vals.csig1 /= t;
    // norm(somg1, comg1); -- don't need to normalize!

    // Enforce symmetries in the case abs(bet2) = -bet1.  Need to be careful
    // about this case, since this can yield singularities in the Newton
    // iteration.
    // sin(alp2) * cos(bet2) = sin(alp0)
    vals.salp2 = cbet2 !== cbet1 ? salp0 / cbet2 : salp1;
    // calp2 = sqrt(1 - sq(salp2))
    //       = sqrt(sq(calp0) - sq(sbet2)) / cbet2
    // and subst for calp0 and rearrange to give (choose positive sqrt
    // to give alp2 in [0, pi/2]).
    vals.calp2 = cbet2 !== cbet1 || Math.abs(sbet2) !== -sbet1 ?
      Math.sqrt(m.sq(calp1 * cbet1) + (cbet1 < -sbet1 ?
                                       (cbet2 - cbet1) * (cbet1 + cbet2) :
                                       (sbet1 - sbet2) * (sbet1 + sbet2))) /
      cbet2 : Math.abs(calp1);
    // tan(bet2) = tan(sig2) * cos(alp2)
    // tan(omg2) = sin(alp0) * tan(sig2).
    vals.ssig2 = sbet2; somg2 = salp0 * sbet2;
    vals.csig2 = comg2 = vals.calp2 * cbet2;
    // norm(vals.ssig2, vals.csig2);
    t = m.hypot(vals.ssig2, vals.csig2); vals.ssig2 /= t; vals.csig2 /= t;
    // norm(somg2, comg2); -- don't need to normalize!

    // sig12 = sig2 - sig1, limit to [0, pi]
    vals.sig12 = Math.atan2(Math.max(0, vals.csig1 * vals.ssig2 -
                                        vals.ssig1 * vals.csig2),
                                        vals.csig1 * vals.csig2 +
                                        vals.ssig1 * vals.ssig2);

    // omg12 = omg2 - omg1, limit to [0, pi]
    somg12 = Math.max(0, comg1 * somg2 - somg1 * comg2);
    comg12 =             comg1 * comg2 + somg1 * somg2;
    // eta = omg12 - lam120
    eta = Math.atan2(somg12 * clam120 - comg12 * slam120,
                     comg12 * clam120 + somg12 * slam120);
    k2 = m.sq(calp0) * this._ep2;
    vals.eps = k2 / (2 * (1 + Math.sqrt(1 + k2)) + k2);
    this.C3f(vals.eps, C3a);
    B312 = (g.SinCosSeries(true, vals.ssig2, vals.csig2, C3a) -
            g.SinCosSeries(true, vals.ssig1, vals.csig1, C3a));
    vals.domg12 =  -this.f * this.A3f(vals.eps) * salp0 * (vals.sig12 + B312);
    vals.lam12 = eta + vals.domg12;
    if (diffp) {
      if (vals.calp2 === 0)
        vals.dlam12 = -2 * this._f1 * dn1 / sbet1;
      else {
        nvals = this.Lengths(vals.eps, vals.sig12,
                             vals.ssig1, vals.csig1, dn1,
                             vals.ssig2, vals.csig2, dn2,
                             cbet1, cbet2, g.REDUCEDLENGTH, C1a, C2a);
        vals.dlam12 = nvals.m12b;
        vals.dlam12 *= this._f1 / (vals.calp2 * cbet2);
      }
    }
    return vals;
  };

  /**
   * @summary Solve the inverse geodesic problem.
   * @param {number} lat1 the latitude of the first point in degrees.
   * @param {number} lon1 the longitude of the first point in degrees.
   * @param {number} lat2 the latitude of the second point in degrees.
   * @param {number} lon2 the longitude of the second point in degrees.
   * @param {bitmask} [outmask = STANDARD] which results to include.
   * @returns {object} the requested results
   * @description The lat1, lon1, lat2, lon2, and a12 fields of the result are
   *   always set.  For details on the outmask parameter, see {@tutorial
   *   2-interface}, "The outmask and caps parameters".
   */
  g.Geodesic.prototype.Inverse = function(lat1, lon1, lat2, lon2, outmask) {
    var r, vals;
    if (!outmask) outmask = g.STANDARD;
    if (outmask === g.LONG_UNROLL) outmask |= g.STANDARD;
    outmask &= g.OUT_MASK;
    r = this.InverseInt(lat1, lon1, lat2, lon2, outmask);
    vals = r.vals;
    if (outmask & g.AZIMUTH) {
      vals.azi1 = m.atan2d(r.salp1, r.calp1);
      vals.azi2 = m.atan2d(r.salp2, r.calp2);
    }
    return vals;
  };

  g.Geodesic.prototype.InverseInt = function(lat1, lon1, lat2, lon2, outmask) {
    var vals = {},
        lon12, lon12s, lonsign, t, swapp, latsign,
        sbet1, cbet1, sbet2, cbet2, s12x, m12x,
        dn1, dn2, lam12, slam12, clam12,
        sig12, calp1, salp1, calp2, salp2, C1a, C2a, C3a, meridian, nvals,
        ssig1, csig1, ssig2, csig2, eps, omg12, dnm,
        numit, salp1a, calp1a, salp1b, calp1b,
        tripn, tripb, v, dv, dalp1, sdalp1, cdalp1, nsalp1,
        lengthmask, salp0, calp0, alp12, k2, A4, C4a, B41, B42,
        somg12, comg12, domg12, dbet1, dbet2, salp12, calp12, sdomg12, cdomg12;
    // Compute longitude difference (AngDiff does this carefully).  Result is
    // in [-180, 180] but -180 is only for west-going geodesics.  180 is for
    // east-going and meridional geodesics.
    vals.lat1 = lat1 = m.LatFix(lat1); vals.lat2 = lat2 = m.LatFix(lat2);
    // If really close to the equator, treat as on equator.
    lat1 = m.AngRound(lat1);
    lat2 = m.AngRound(lat2);
    lon12 = m.AngDiff(lon1, lon2); lon12s = lon12.t; lon12 = lon12.s;
    if (outmask & g.LONG_UNROLL) {
      vals.lon1 = lon1; vals.lon2 = (lon1 + lon12) + lon12s;
    } else {
      vals.lon1 = m.AngNormalize(lon1); vals.lon2 = m.AngNormalize(lon2);
    }
    // Make longitude difference positive.
    lonsign = lon12 >= 0 ? 1 : -1;
    // If very close to being on the same half-meridian, then make it so.
    lon12 = lonsign * m.AngRound(lon12);
    lon12s = m.AngRound((180 - lon12) - lonsign * lon12s);
    lam12 = lon12 * m.degree;
    t = m.sincosd(lon12 > 90 ? lon12s : lon12);
    slam12 = t.s; clam12 = (lon12 > 90 ? -1 : 1) * t.c;

    // Swap points so that point with higher (abs) latitude is point 1
    // If one latitude is a nan, then it becomes lat1.
    swapp = Math.abs(lat1) < Math.abs(lat2) ? -1 : 1;
    if (swapp < 0) {
      lonsign *= -1;
      t = lat1;
      lat1 = lat2;
      lat2 = t;
      // swap(lat1, lat2);
    }
    // Make lat1 <= 0
    latsign = lat1 < 0 ? 1 : -1;
    lat1 *= latsign;
    lat2 *= latsign;
    // Now we have
    //
    //     0 <= lon12 <= 180
    //     -90 <= lat1 <= 0
    //     lat1 <= lat2 <= -lat1
    //
    // longsign, swapp, latsign register the transformation to bring the
    // coordinates to this canonical form.  In all cases, 1 means no change was
    // made.  We make these transformations so that there are few cases to
    // check, e.g., on verifying quadrants in atan2.  In addition, this
    // enforces some symmetries in the results returned.

    t = m.sincosd(lat1); sbet1 = this._f1 * t.s; cbet1 = t.c;
    // norm(sbet1, cbet1);
    t = m.hypot(sbet1, cbet1); sbet1 /= t; cbet1 /= t;
    // Ensure cbet1 = +epsilon at poles
    cbet1 = Math.max(g.tiny_, cbet1);

    t = m.sincosd(lat2); sbet2 = this._f1 * t.s; cbet2 = t.c;
    // norm(sbet2, cbet2);
    t = m.hypot(sbet2, cbet2); sbet2 /= t; cbet2 /= t;
    // Ensure cbet2 = +epsilon at poles
    cbet2 = Math.max(g.tiny_, cbet2);

    // If cbet1 < -sbet1, then cbet2 - cbet1 is a sensitive measure of the
    // |bet1| - |bet2|.  Alternatively (cbet1 >= -sbet1), abs(sbet2) + sbet1 is
    // a better measure.  This logic is used in assigning calp2 in Lambda12.
    // Sometimes these quantities vanish and in that case we force bet2 = +/-
    // bet1 exactly.  An example where is is necessary is the inverse problem
    // 48.522876735459 0 -48.52287673545898293 179.599720456223079643
    // which failed with Visual Studio 10 (Release and Debug)

    if (cbet1 < -sbet1) {
      if (cbet2 === cbet1)
        sbet2 = sbet2 < 0 ? sbet1 : -sbet1;
    } else {
      if (Math.abs(sbet2) === -sbet1)
        cbet2 = cbet1;
    }

    dn1 = Math.sqrt(1 + this._ep2 * m.sq(sbet1));
    dn2 = Math.sqrt(1 + this._ep2 * m.sq(sbet2));

    // index zero elements of these arrays are unused
    C1a = new Array(g.nC1_ + 1);
    C2a = new Array(g.nC2_ + 1);
    C3a = new Array(g.nC3_);

    meridian = lat1 === -90 || slam12 === 0;
    if (meridian) {

      // Endpoints are on a single full meridian, so the geodesic might
      // lie on a meridian.

      calp1 = clam12; salp1 = slam12; // Head to the target longitude
      calp2 = 1; salp2 = 0;           // At the target we're heading north

      // tan(bet) = tan(sig) * cos(alp)
      ssig1 = sbet1; csig1 = calp1 * cbet1;
      ssig2 = sbet2; csig2 = calp2 * cbet2;

      // sig12 = sig2 - sig1
      sig12 = Math.atan2(Math.max(0, csig1 * ssig2 - ssig1 * csig2),
                                     csig1 * csig2 + ssig1 * ssig2);
      nvals = this.Lengths(this._n, sig12,
                           ssig1, csig1, dn1, ssig2, csig2, dn2, cbet1, cbet2,
                           outmask | g.DISTANCE | g.REDUCEDLENGTH,
                           C1a, C2a);
      s12x = nvals.s12b;
      m12x = nvals.m12b;
      // Ignore m0
      if ((outmask & g.GEODESICSCALE) !== 0) {
        vals.M12 = nvals.M12;
        vals.M21 = nvals.M21;
      }
      // Add the check for sig12 since zero length geodesics might yield
      // m12 < 0.  Test case was
      //
      //    echo 20.001 0 20.001 0 | GeodSolve -i
      //
      // In fact, we will have sig12 > pi/2 for meridional geodesic
      // which is not a shortest path.
      if (sig12 < 1 || m12x >= 0) {
        // Need at least 2, to handle 90 0 90 180
        if (sig12 < 3 * g.tiny_)
          sig12 = m12x = s12x = 0;
        m12x *= this._b;
        s12x *= this._b;
        vals.a12 = sig12 / m.degree;
      } else
        // m12 < 0, i.e., prolate and too close to anti-podal
        meridian = false;
    }

    somg12 = 2;
    if (!meridian &&
        sbet1 === 0 &&           // and sbet2 == 0
        (this.f <= 0 || lon12s >= this.f * 180)) {

      // Geodesic runs along equator
      calp1 = calp2 = 0; salp1 = salp2 = 1;
      s12x = this.a * lam12;
      sig12 = omg12 = lam12 / this._f1;
      m12x = this._b * Math.sin(sig12);
      if (outmask & g.GEODESICSCALE)
        vals.M12 = vals.M21 = Math.cos(sig12);
      vals.a12 = lon12 / this._f1;

    } else if (!meridian) {

      // Now point1 and point2 belong within a hemisphere bounded by a
      // meridian and geodesic is neither meridional or equatorial.

      // Figure a starting point for Newton's method
      nvals = this.InverseStart(sbet1, cbet1, dn1, sbet2, cbet2, dn2,
                                lam12, slam12, clam12, C1a, C2a);
      sig12 = nvals.sig12;
      salp1 = nvals.salp1;
      calp1 = nvals.calp1;

      if (sig12 >= 0) {
        salp2 = nvals.salp2;
        calp2 = nvals.calp2;
        // Short lines (InverseStart sets salp2, calp2, dnm)

        dnm = nvals.dnm;
        s12x = sig12 * this._b * dnm;
        m12x = m.sq(dnm) * this._b * Math.sin(sig12 / dnm);
        if (outmask & g.GEODESICSCALE)
          vals.M12 = vals.M21 = Math.cos(sig12 / dnm);
        vals.a12 = sig12 / m.degree;
        omg12 = lam12 / (this._f1 * dnm);
      } else {

        // Newton's method.  This is a straightforward solution of f(alp1) =
        // lambda12(alp1) - lam12 = 0 with one wrinkle.  f(alp) has exactly one
        // root in the interval (0, pi) and its derivative is positive at the
        // root.  Thus f(alp) is positive for alp > alp1 and negative for alp <
        // alp1.  During the course of the iteration, a range (alp1a, alp1b) is
        // maintained which brackets the root and with each evaluation of
        // f(alp) the range is shrunk if possible.  Newton's method is
        // restarted whenever the derivative of f is negative (because the new
        // value of alp1 is then further from the solution) or if the new
        // estimate of alp1 lies outside (0,pi); in this case, the new starting
        // guess is taken to be (alp1a + alp1b) / 2.
        numit = 0;
        // Bracketing range
        salp1a = g.tiny_; calp1a = 1; salp1b = g.tiny_; calp1b = -1;
        for (tripn = false, tripb = false; numit < maxit2_; ++numit) {
          // the WGS84 test set: mean = 1.47, sd = 1.25, max = 16
          // WGS84 and random input: mean = 2.85, sd = 0.60
          nvals = this.Lambda12(sbet1, cbet1, dn1, sbet2, cbet2, dn2,
                                salp1, calp1, slam12, clam12, numit < maxit1_,
                                C1a, C2a, C3a);
          v = nvals.lam12;
          salp2 = nvals.salp2;
          calp2 = nvals.calp2;
          sig12 = nvals.sig12;
          ssig1 = nvals.ssig1;
          csig1 = nvals.csig1;
          ssig2 = nvals.ssig2;
          csig2 = nvals.csig2;
          eps = nvals.eps;
          domg12 = nvals.domg12;
          dv = nvals.dlam12;

          // 2 * tol0 is approximately 1 ulp for a number in [0, pi].
          // Reversed test to allow escape with NaNs
          if (tripb || !(Math.abs(v) >= (tripn ? 8 : 1) * tol0_))
            break;
          // Update bracketing values
          if (v > 0 && (numit < maxit1_ || calp1/salp1 > calp1b/salp1b)) {
            salp1b = salp1; calp1b = calp1;
          } else if (v < 0 &&
                     (numit < maxit1_ || calp1/salp1 < calp1a/salp1a)) {
            salp1a = salp1; calp1a = calp1;
          }
          if (numit < maxit1_ && dv > 0) {
            dalp1 = -v/dv;
            sdalp1 = Math.sin(dalp1); cdalp1 = Math.cos(dalp1);
            nsalp1 = salp1 * cdalp1 + calp1 * sdalp1;
            if (nsalp1 > 0 && Math.abs(dalp1) < Math.PI) {
              calp1 = calp1 * cdalp1 - salp1 * sdalp1;
              salp1 = nsalp1;
              // norm(salp1, calp1);
              t = m.hypot(salp1, calp1); salp1 /= t; calp1 /= t;
              // In some regimes we don't get quadratic convergence because
              // slope -> 0.  So use convergence conditions based on epsilon
              // instead of sqrt(epsilon).
              tripn = Math.abs(v) <= 16 * tol0_;
              continue;
            }
          }
          // Either dv was not positive or updated value was outside legal
          // range.  Use the midpoint of the bracket as the next estimate.
          // This mechanism is not needed for the WGS84 ellipsoid, but it does
          // catch problems with more eccentric ellipsoids.  Its efficacy is
          // such for the WGS84 test set with the starting guess set to alp1 =
          // 90deg:
          // the WGS84 test set: mean = 5.21, sd = 3.93, max = 24
          // WGS84 and random input: mean = 4.74, sd = 0.99
          salp1 = (salp1a + salp1b)/2;
          calp1 = (calp1a + calp1b)/2;
          // norm(salp1, calp1);
          t = m.hypot(salp1, calp1); salp1 /= t; calp1 /= t;
          tripn = false;
          tripb = (Math.abs(salp1a - salp1) + (calp1a - calp1) < tolb_ ||
                   Math.abs(salp1 - salp1b) + (calp1 - calp1b) < tolb_);
        }
        lengthmask = outmask |
            (outmask & (g.REDUCEDLENGTH | g.GEODESICSCALE) ?
             g.DISTANCE : g.NONE);
        nvals = this.Lengths(eps, sig12,
                             ssig1, csig1, dn1, ssig2, csig2, dn2, cbet1, cbet2,
                             lengthmask, C1a, C2a);
        s12x = nvals.s12b;
        m12x = nvals.m12b;
        // Ignore m0
        if ((outmask & g.GEODESICSCALE) !== 0) {
          vals.M12 = nvals.M12;
          vals.M21 = nvals.M21;
        }
        m12x *= this._b;
        s12x *= this._b;
        vals.a12 = sig12 / m.degree;
        if (outmask & g.AREA) {
          // omg12 = lam12 - domg12
          sdomg12 = Math.sin(domg12); cdomg12 = Math.cos(domg12);
          somg12 = slam12 * cdomg12 - clam12 * sdomg12;
          comg12 = clam12 * cdomg12 + slam12 * sdomg12;
        }
      }
    }

    if (outmask & g.DISTANCE)
      vals.s12 = 0 + s12x;      // Convert -0 to 0

    if (outmask & g.REDUCEDLENGTH)
      vals.m12 = 0 + m12x;      // Convert -0 to 0

    if (outmask & g.AREA) {
      // From Lambda12: sin(alp1) * cos(bet1) = sin(alp0)
      salp0 = salp1 * cbet1;
      calp0 = m.hypot(calp1, salp1 * sbet1); // calp0 > 0
      if (calp0 !== 0 && salp0 !== 0) {
        // From Lambda12: tan(bet) = tan(sig) * cos(alp)
        ssig1 = sbet1; csig1 = calp1 * cbet1;
        ssig2 = sbet2; csig2 = calp2 * cbet2;
        k2 = m.sq(calp0) * this._ep2;
        eps = k2 / (2 * (1 + Math.sqrt(1 + k2)) + k2);
        // Multiplier = a^2 * e^2 * cos(alpha0) * sin(alpha0).
        A4 = m.sq(this.a) * calp0 * salp0 * this._e2;
        // norm(ssig1, csig1);
        t = m.hypot(ssig1, csig1); ssig1 /= t; csig1 /= t;
        // norm(ssig2, csig2);
        t = m.hypot(ssig2, csig2); ssig2 /= t; csig2 /= t;
        C4a = new Array(g.nC4_);
        this.C4f(eps, C4a);
        B41 = g.SinCosSeries(false, ssig1, csig1, C4a);
        B42 = g.SinCosSeries(false, ssig2, csig2, C4a);
        vals.S12 = A4 * (B42 - B41);
      } else
        // Avoid problems with indeterminate sig1, sig2 on equator
        vals.S12 = 0;
      if (!meridian && somg12 > 1) {
        somg12 = Math.sin(omg12); comg12 = Math.cos(omg12);
      }
      if (!meridian &&
          comg12 > -0.7071 &&      // Long difference not too big
          sbet2 - sbet1 < 1.75) { // Lat difference not too big
        // Use tan(Gamma/2) = tan(omg12/2)
        // * (tan(bet1/2)+tan(bet2/2))/(1+tan(bet1/2)*tan(bet2/2))
        // with tan(x/2) = sin(x)/(1+cos(x))
        domg12 = 1 + comg12; dbet1 = 1 + cbet1; dbet2 = 1 + cbet2;
        alp12 = 2 * Math.atan2( somg12 * (sbet1*dbet2 + sbet2*dbet1),
                                domg12 * (sbet1*sbet2 + dbet1*dbet2) );
      } else {
        // alp12 = alp2 - alp1, used in atan2 so no need to normalize
        salp12 = salp2 * calp1 - calp2 * salp1;
        calp12 = calp2 * calp1 + salp2 * salp1;
        // The right thing appears to happen if alp1 = +/-180 and alp2 = 0, viz
        // salp12 = -0 and alp12 = -180.  However this depends on the sign
        // being attached to 0 correctly.  The following ensures the correct
        // behavior.
        if (salp12 === 0 && calp12 < 0) {
          salp12 = g.tiny_ * calp1;
          calp12 = -1;
        }
        alp12 = Math.atan2(salp12, calp12);
      }
      vals.S12 += this._c2 * alp12;
      vals.S12 *= swapp * lonsign * latsign;
      // Convert -0 to 0
      vals.S12 += 0;
    }

    // Convert calp, salp to azimuth accounting for lonsign, swapp, latsign.
    if (swapp < 0) {
      t = salp1;
      salp1 = salp2;
      salp2 = t;
      // swap(salp1, salp2);
      t = calp1;
      calp1 = calp2;
      calp2 = t;
      // swap(calp1, calp2);
      if (outmask & g.GEODESICSCALE) {
        t = vals.M12;
        vals.M12 = vals.M21;
        vals.M21 = t;
        // swap(vals.M12, vals.M21);
      }
    }

    salp1 *= swapp * lonsign; calp1 *= swapp * latsign;
    salp2 *= swapp * lonsign; calp2 *= swapp * latsign;

    return {vals: vals,
            salp1: salp1, calp1: calp1,
            salp2: salp2, calp2: calp2};
  };

  /**
   * @summary Solve the general direct geodesic problem.
   * @param {number} lat1 the latitude of the first point in degrees.
   * @param {number} lon1 the longitude of the first point in degrees.
   * @param {number} azi1 the azimuth at the first point in degrees.
   * @param {bool} arcmode is the next parameter an arc length?
   * @param {number} s12_a12 the (arcmode ? arc length : distance) from the
   *   first point to the second in (arcmode ? degrees : meters).
   * @param {bitmask} [outmask = STANDARD] which results to include.
   * @returns {object} the requested results.
   * @description The lat1, lon1, azi1, and a12 fields of the result are always
   *   set; s12 is included if arcmode is false.  For details on the outmask
   *   parameter, see {@tutorial 2-interface}, "The outmask and caps
   *   parameters".
   */
  g.Geodesic.prototype.GenDirect = function(lat1, lon1, azi1,
                                            arcmode, s12_a12, outmask) {
    var line;
    if (!outmask) outmask = g.STANDARD;
    else if (outmask === g.LONG_UNROLL) outmask |= g.STANDARD;
    // Automatically supply DISTANCE_IN if necessary
    if (!arcmode) outmask |= g.DISTANCE_IN;
    line = new l.GeodesicLine(this, lat1, lon1, azi1, outmask);
    return line.GenPosition(arcmode, s12_a12, outmask);
  };

  /**
   * @summary Solve the direct geodesic problem.
   * @param {number} lat1 the latitude of the first point in degrees.
   * @param {number} lon1 the longitude of the first point in degrees.
   * @param {number} azi1 the azimuth at the first point in degrees.
   * @param {number} s12 the distance from the first point to the second in
   *   meters.
   * @param {bitmask} [outmask = STANDARD] which results to include.
   * @returns {object} the requested results.
   * @description The lat1, lon1, azi1, s12, and a12 fields of the result are
   *   always set.  For details on the outmask parameter, see {@tutorial
   *   2-interface}, "The outmask and caps parameters".
   */
  g.Geodesic.prototype.Direct = function(lat1, lon1, azi1, s12, outmask) {
    return this.GenDirect(lat1, lon1, azi1, false, s12, outmask);
  };

  /**
   * @summary Solve the direct geodesic problem with arc length.
   * @param {number} lat1 the latitude of the first point in degrees.
   * @param {number} lon1 the longitude of the first point in degrees.
   * @param {number} azi1 the azimuth at the first point in degrees.
   * @param {number} a12 the arc length from the first point to the second in
   *   degrees.
   * @param {bitmask} [outmask = STANDARD] which results to include.
   * @returns {object} the requested results.
   * @description The lat1, lon1, azi1, and a12 fields of the result are
   *   always set.  For details on the outmask parameter, see {@tutorial
   *   2-interface}, "The outmask and caps parameters".
   */
  g.Geodesic.prototype.ArcDirect = function(lat1, lon1, azi1, a12, outmask) {
    return this.GenDirect(lat1, lon1, azi1, true, a12, outmask);
  };

  /**
   * @summary Create a {@link module:GeographicLib/GeodesicLine.GeodesicLine
   *   GeodesicLine} object.
   * @param {number} lat1 the latitude of the first point in degrees.
   * @param {number} lon1 the longitude of the first point in degrees.
   * @param {number} azi1 the azimuth at the first point in degrees.
   *   degrees.
   * @param {bitmask} [caps = STANDARD | DISTANCE_IN] which capabilities to
   *   include.
   * @returns {object} the
   *   {@link module:GeographicLib/GeodesicLine.GeodesicLine
   *   GeodesicLine} object
   * @description For details on the caps parameter, see {@tutorial
   *   2-interface}, "The outmask and caps parameters".
   */
  g.Geodesic.prototype.Line = function(lat1, lon1, azi1, caps) {
    return new l.GeodesicLine(this, lat1, lon1, azi1, caps);
  };

  /**
   * @summary Define a {@link module:GeographicLib/GeodesicLine.GeodesicLine
   *   GeodesicLine} in terms of the direct geodesic problem specified in terms
   *   of distance.
   * @param {number} lat1 the latitude of the first point in degrees.
   * @param {number} lon1 the longitude of the first point in degrees.
   * @param {number} azi1 the azimuth at the first point in degrees.
   *   degrees.
   * @param {number} s12 the distance between point 1 and point 2 (meters); it
   *   can be negative.
   * @param {bitmask} [caps = STANDARD | DISTANCE_IN] which capabilities to
   *   include.
   * @returns {object} the
   *   {@link module:GeographicLib/GeodesicLine.GeodesicLine
   *   GeodesicLine} object
   * @description This function sets point 3 of the GeodesicLine to correspond
   *   to point 2 of the direct geodesic problem.  For details on the caps
   *   parameter, see {@tutorial 2-interface}, "The outmask and caps
   *   parameters".
   */
  g.Geodesic.prototype.DirectLine = function(lat1, lon1, azi1, s12, caps) {
    return this.GenDirectLine(lat1, lon1, azi1, false, s12, caps);
  };

  /**
   * @summary Define a {@link module:GeographicLib/GeodesicLine.GeodesicLine
   *   GeodesicLine} in terms of the direct geodesic problem specified in terms
   *   of arc length.
   * @param {number} lat1 the latitude of the first point in degrees.
   * @param {number} lon1 the longitude of the first point in degrees.
   * @param {number} azi1 the azimuth at the first point in degrees.
   *   degrees.
   * @param {number} a12 the arc length between point 1 and point 2 (degrees);
   *   it can be negative.
   * @param {bitmask} [caps = STANDARD | DISTANCE_IN] which capabilities to
   *   include.
   * @returns {object} the
   *   {@link module:GeographicLib/GeodesicLine.GeodesicLine
   *   GeodesicLine} object
   * @description This function sets point 3 of the GeodesicLine to correspond
   *   to point 2 of the direct geodesic problem.  For details on the caps
   *   parameter, see {@tutorial 2-interface}, "The outmask and caps
   *   parameters".
   */
  g.Geodesic.prototype.ArcDirectLine = function(lat1, lon1, azi1, a12, caps) {
    return this.GenDirectLine(lat1, lon1, azi1, true, a12, caps);
  };

  /**
   * @summary Define a {@link module:GeographicLib/GeodesicLine.GeodesicLine
   *   GeodesicLine} in terms of the direct geodesic problem specified in terms
   *   of either distance or arc length.
   * @param {number} lat1 the latitude of the first point in degrees.
   * @param {number} lon1 the longitude of the first point in degrees.
   * @param {number} azi1 the azimuth at the first point in degrees.
   *   degrees.
   * @param {bool} arcmode boolean flag determining the meaning of the
   *   s12_a12.
   * @param {number} s12_a12 if arcmode is false, this is the distance between
   *   point 1 and point 2 (meters); otherwise it is the arc length between
   *   point 1 and point 2 (degrees); it can be negative.
   * @param {bitmask} [caps = STANDARD | DISTANCE_IN] which capabilities to
   *   include.
   * @returns {object} the
   *   {@link module:GeographicLib/GeodesicLine.GeodesicLine
   *   GeodesicLine} object
   * @description This function sets point 3 of the GeodesicLine to correspond
   *   to point 2 of the direct geodesic problem.  For details on the caps
   *   parameter, see {@tutorial 2-interface}, "The outmask and caps
   *   parameters".
   */
  g.Geodesic.prototype.GenDirectLine = function(lat1, lon1, azi1,
                                                arcmode, s12_a12, caps) {
    var t;
    if (!caps) caps = g.STANDARD | g.DISTANCE_IN;
    // Automatically supply DISTANCE_IN if necessary
    if (!arcmode) caps |= g.DISTANCE_IN;
    t = new l.GeodesicLine(this, lat1, lon1, azi1, caps);
    t.GenSetDistance(arcmode, s12_a12);
    return t;
  };

  /**
   * @summary Define a {@link module:GeographicLib/GeodesicLine.GeodesicLine
   *   GeodesicLine} in terms of the inverse geodesic problem.
   * @param {number} lat1 the latitude of the first point in degrees.
   * @param {number} lon1 the longitude of the first point in degrees.
   * @param {number} lat2 the latitude of the second point in degrees.
   * @param {number} lon2 the longitude of the second point in degrees.
   * @param {bitmask} [caps = STANDARD | DISTANCE_IN] which capabilities to
   *   include.
   * @returns {object} the
   *   {@link module:GeographicLib/GeodesicLine.GeodesicLine
   *   GeodesicLine} object
   * @description This function sets point 3 of the GeodesicLine to correspond
   *   to point 2 of the inverse geodesic problem.  For details on the caps
   *   parameter, see {@tutorial 2-interface}, "The outmask and caps
   *   parameters".
   */
  g.Geodesic.prototype.InverseLine = function(lat1, lon1, lat2, lon2, caps) {
    var r, t, azi1;
    if (!caps) caps = g.STANDARD | g.DISTANCE_IN;
    r = this.InverseInt(lat1, lon1, lat2, lon2, g.ARC);
    azi1 = m.atan2d(r.salp1, r.calp1);
    // Ensure that a12 can be converted to a distance
    if (caps & (g.OUT_MASK & g.DISTANCE_IN)) caps |= g.DISTANCE;
    t = new l.GeodesicLine(this, lat1, lon1, azi1, caps, r.salp1, r.calp1);
    t.SetArc(r.vals.a12);
    return t;
  };

  /**
   * @summary Create a {@link module:GeographicLib/PolygonArea.PolygonArea
   *   PolygonArea} object.
   * @param {bool} [polyline = false] if true the new PolygonArea object
   *   describes a polyline instead of a polygon.
   * @returns {object} the
   *   {@link module:GeographicLib/PolygonArea.PolygonArea
   *   PolygonArea} object
   */
  g.Geodesic.prototype.Polygon = function(polyline) {
    return new p.PolygonArea(this, polyline);
  };

  /**
   * @summary a {@link module:GeographicLib/Geodesic.Geodesic Geodesic} object
   *   initialized for the WGS84 ellipsoid.
   * @constant {object}
   */
  g.WGS84 = new g.Geodesic(c.WGS84.a, c.WGS84.f);
})(GeographicLib.Geodesic, GeographicLib.GeodesicLine,
   GeographicLib.PolygonArea, GeographicLib.Math, GeographicLib.Constants);


/*
 * GeodesicLine.js
 * Transcription of GeodesicLine.[ch]pp into JavaScript.
 *
 * See the documentation for the C++ class.  The conversion is a literal
 * conversion from C++.
 *
 * The algorithms are derived in
 *
 *    Charles F. F. Karney,
 *    Algorithms for geodesics, J. Geodesy 87, 43-55 (2013);
 *    https://doi.org/10.1007/s00190-012-0578-z
 *    Addenda: https://geographiclib.sourceforge.io/geod-addenda.html
 *
 * Copyright (c) Charles Karney (2011-2016) <charles@karney.com> and licensed
 * under the MIT/X11 License.  For more information, see
 * https://geographiclib.sourceforge.io/
 */

// Load AFTER GeographicLib/Math.js, GeographicLib/Geodesic.js

(function(
  g,
  /**
   * @exports GeographicLib/GeodesicLine
   * @description Solve geodesic problems on a single geodesic line via the
   *   {@link module:GeographicLib/GeodesicLine.GeodesicLine GeodesicLine}
   *   class.
   */
  l, m) {

  /**
   * @class
   * @property {number} a the equatorial radius (meters).
   * @property {number} f the flattening.
   * @property {number} lat1 the initial latitude (degrees).
   * @property {number} lon1 the initial longitude (degrees).
   * @property {number} azi1 the initial azimuth (degrees).
   * @property {number} salp1 the sine of the azimuth at the first point.
   * @property {number} calp1 the cosine the azimuth at the first point.
   * @property {number} s13 the distance to point 3 (meters).
   * @property {number} a13 the arc length to point 3 (degrees).
   * @property {bitmask} caps the capabilities of the object.
   * @summary Initialize a GeodesicLine object.  For details on the caps
   *   parameter, see {@tutorial 2-interface}, "The outmask and caps
   *   parameters".
   * @classdesc Performs geodesic calculations along a given geodesic line.
   *   This object is usually instantiated by
   *   {@link module:GeographicLib/Geodesic.Geodesic#Line Geodesic.Line}.
   *   The methods
   *   {@link module:GeographicLib/Geodesic.Geodesic#DirectLine
   *   Geodesic.DirectLine} and
   *   {@link module:GeographicLib/Geodesic.Geodesic#InverseLine
   *   Geodesic.InverseLine} set in addition the position of a reference point
   *   3.
   * @param {object} geod a {@link module:GeographicLib/Geodesic.Geodesic
   *   Geodesic} object.
   * @param {number} lat1 the latitude of the first point in degrees.
   * @param {number} lon1 the longitude of the first point in degrees.
   * @param {number} azi1 the azimuth at the first point in degrees.
   * @param {bitmask} [caps = STANDARD | DISTANCE_IN] which capabilities to
   *   include; LATITUDE | AZIMUTH are always included.
   */
  l.GeodesicLine = function(geod, lat1, lon1, azi1, caps, salp1, calp1) {
    var t, cbet1, sbet1, eps, s, c;
    if (!caps) caps = g.STANDARD | g.DISTANCE_IN;

    this.a = geod.a;
    this.f = geod.f;
    this._b = geod._b;
    this._c2 = geod._c2;
    this._f1 = geod._f1;
    this.caps = caps | g.LATITUDE | g.AZIMUTH | g.LONG_UNROLL;

    this.lat1 = m.LatFix(lat1);
    this.lon1 = lon1;
    if (typeof salp1 === 'undefined' || typeof calp1 === 'undefined') {
      this.azi1 = m.AngNormalize(azi1);
      t = m.sincosd(m.AngRound(this.azi1)); this.salp1 = t.s; this.calp1 = t.c;
    } else {
      this.azi1 = azi1; this.salp1 = salp1; this.calp1 = calp1;
    }
    t = m.sincosd(m.AngRound(this.lat1)); sbet1 = this._f1 * t.s; cbet1 = t.c;
    // norm(sbet1, cbet1);
    t = m.hypot(sbet1, cbet1); sbet1 /= t; cbet1 /= t;
    // Ensure cbet1 = +epsilon at poles
    cbet1 = Math.max(g.tiny_, cbet1);
    this._dn1 = Math.sqrt(1 + geod._ep2 * m.sq(sbet1));

    // Evaluate alp0 from sin(alp1) * cos(bet1) = sin(alp0),
    this._salp0 = this.salp1 * cbet1; // alp0 in [0, pi/2 - |bet1|]
    // Alt: calp0 = hypot(sbet1, calp1 * cbet1).  The following
    // is slightly better (consider the case salp1 = 0).
    this._calp0 = m.hypot(this.calp1, this.salp1 * sbet1);
    // Evaluate sig with tan(bet1) = tan(sig1) * cos(alp1).
    // sig = 0 is nearest northward crossing of equator.
    // With bet1 = 0, alp1 = pi/2, we have sig1 = 0 (equatorial line).
    // With bet1 =  pi/2, alp1 = -pi, sig1 =  pi/2
    // With bet1 = -pi/2, alp1 =  0 , sig1 = -pi/2
    // Evaluate omg1 with tan(omg1) = sin(alp0) * tan(sig1).
    // With alp0 in (0, pi/2], quadrants for sig and omg coincide.
    // No atan2(0,0) ambiguity at poles since cbet1 = +epsilon.
    // With alp0 = 0, omg1 = 0 for alp1 = 0, omg1 = pi for alp1 = pi.
    this._ssig1 = sbet1; this._somg1 = this._salp0 * sbet1;
    this._csig1 = this._comg1 =
      sbet1 !== 0 || this.calp1 !== 0 ? cbet1 * this.calp1 : 1;
    // norm(this._ssig1, this._csig1); // sig1 in (-pi, pi]
    t = m.hypot(this._ssig1, this._csig1);
    this._ssig1 /= t; this._csig1 /= t;
    // norm(this._somg1, this._comg1); -- don't need to normalize!

    this._k2 = m.sq(this._calp0) * geod._ep2;
    eps = this._k2 / (2 * (1 + Math.sqrt(1 + this._k2)) + this._k2);

    if (this.caps & g.CAP_C1) {
      this._A1m1 = g.A1m1f(eps);
      this._C1a = new Array(g.nC1_ + 1);
      g.C1f(eps, this._C1a);
      this._B11 = g.SinCosSeries(true, this._ssig1, this._csig1, this._C1a);
      s = Math.sin(this._B11); c = Math.cos(this._B11);
      // tau1 = sig1 + B11
      this._stau1 = this._ssig1 * c + this._csig1 * s;
      this._ctau1 = this._csig1 * c - this._ssig1 * s;
      // Not necessary because C1pa reverts C1a
      //    _B11 = -SinCosSeries(true, _stau1, _ctau1, _C1pa);
    }

    if (this.caps & g.CAP_C1p) {
      this._C1pa = new Array(g.nC1p_ + 1);
      g.C1pf(eps, this._C1pa);
    }

    if (this.caps & g.CAP_C2) {
      this._A2m1 = g.A2m1f(eps);
      this._C2a = new Array(g.nC2_ + 1);
      g.C2f(eps, this._C2a);
      this._B21 = g.SinCosSeries(true, this._ssig1, this._csig1, this._C2a);
    }

    if (this.caps & g.CAP_C3) {
      this._C3a = new Array(g.nC3_);
      geod.C3f(eps, this._C3a);
      this._A3c = -this.f * this._salp0 * geod.A3f(eps);
      this._B31 = g.SinCosSeries(true, this._ssig1, this._csig1, this._C3a);
    }

    if (this.caps & g.CAP_C4) {
      this._C4a = new Array(g.nC4_); // all the elements of _C4a are used
      geod.C4f(eps, this._C4a);
      // Multiplier = a^2 * e^2 * cos(alpha0) * sin(alpha0)
      this._A4 = m.sq(this.a) * this._calp0 * this._salp0 * geod._e2;
      this._B41 = g.SinCosSeries(false, this._ssig1, this._csig1, this._C4a);
    }

    this.a13 = this.s13 = Number.NaN;
  };

  /**
   * @summary Find the position on the line (general case).
   * @param {bool} arcmode is the next parameter an arc length?
   * @param {number} s12_a12 the (arcmode ? arc length : distance) from the
   *   first point to the second in (arcmode ? degrees : meters).
   * @param {bitmask} [outmask = STANDARD] which results to include; this is
   *   subject to the capabilities of the object.
   * @returns {object} the requested results.
   * @description The lat1, lon1, azi1, and a12 fields of the result are
   *   always set; s12 is included if arcmode is false.  For details on the
   *   outmask parameter, see {@tutorial 2-interface}, "The outmask and caps
   *   parameters".
   */
  l.GeodesicLine.prototype.GenPosition = function(arcmode, s12_a12,
                                                  outmask) {
    var vals = {},
        sig12, ssig12, csig12, B12, AB1, ssig2, csig2, tau12, s, c, serr,
        omg12, lam12, lon12, E, sbet2, cbet2, somg2, comg2, salp2, calp2, dn2,
        B22, AB2, J12, t, B42, salp12, calp12;
    if (!outmask) outmask = g.STANDARD;
    else if (outmask === g.LONG_UNROLL) outmask |= g.STANDARD;
    outmask &= this.caps & g.OUT_MASK;
    vals.lat1 = this.lat1; vals.azi1 = this.azi1;
    vals.lon1 = outmask & g.LONG_UNROLL ?
      this.lon1 : m.AngNormalize(this.lon1);
    if (arcmode)
      vals.a12 = s12_a12;
    else
      vals.s12 = s12_a12;
    if (!( arcmode || (this.caps & g.DISTANCE_IN & g.OUT_MASK) )) {
      // Uninitialized or impossible distance calculation requested
      vals.a12 = Number.NaN;
      return vals;
    }

    // Avoid warning about uninitialized B12.
    B12 = 0; AB1 = 0;
    if (arcmode) {
      // Interpret s12_a12 as spherical arc length
      sig12 = s12_a12 * m.degree;
      t = m.sincosd(s12_a12); ssig12 = t.s; csig12 = t.c;
    } else {
      // Interpret s12_a12 as distance
      tau12 = s12_a12 / (this._b * (1 + this._A1m1));
      s = Math.sin(tau12);
      c = Math.cos(tau12);
      // tau2 = tau1 + tau12
      B12 = -g.SinCosSeries(true,
                            this._stau1 * c + this._ctau1 * s,
                            this._ctau1 * c - this._stau1 * s,
                            this._C1pa);
      sig12 = tau12 - (B12 - this._B11);
      ssig12 = Math.sin(sig12); csig12 = Math.cos(sig12);
      if (Math.abs(this.f) > 0.01) {
        // Reverted distance series is inaccurate for |f| > 1/100, so correct
        // sig12 with 1 Newton iteration.  The following table shows the
        // approximate maximum error for a = WGS_a() and various f relative to
        // GeodesicExact.
        //     erri = the error in the inverse solution (nm)
        //     errd = the error in the direct solution (series only) (nm)
        //     errda = the error in the direct solution (series + 1 Newton) (nm)
        //
        //       f     erri  errd errda
        //     -1/5    12e6 1.2e9  69e6
        //     -1/10  123e3  12e6 765e3
        //     -1/20   1110 108e3  7155
        //     -1/50  18.63 200.9 27.12
        //     -1/100 18.63 23.78 23.37
        //     -1/150 18.63 21.05 20.26
        //      1/150 22.35 24.73 25.83
        //      1/100 22.35 25.03 25.31
        //      1/50  29.80 231.9 30.44
        //      1/20   5376 146e3  10e3
        //      1/10  829e3  22e6 1.5e6
        //      1/5   157e6 3.8e9 280e6
        ssig2 = this._ssig1 * csig12 + this._csig1 * ssig12;
        csig2 = this._csig1 * csig12 - this._ssig1 * ssig12;
        B12 = g.SinCosSeries(true, ssig2, csig2, this._C1a);
        serr = (1 + this._A1m1) * (sig12 + (B12 - this._B11)) -
          s12_a12 / this._b;
        sig12 = sig12 - serr / Math.sqrt(1 + this._k2 * m.sq(ssig2));
        ssig12 = Math.sin(sig12); csig12 = Math.cos(sig12);
        // Update B12 below
      }
    }

    // sig2 = sig1 + sig12
    ssig2 = this._ssig1 * csig12 + this._csig1 * ssig12;
    csig2 = this._csig1 * csig12 - this._ssig1 * ssig12;
    dn2 = Math.sqrt(1 + this._k2 * m.sq(ssig2));
    if (outmask & (g.DISTANCE | g.REDUCEDLENGTH | g.GEODESICSCALE)) {
      if (arcmode || Math.abs(this.f) > 0.01)
        B12 = g.SinCosSeries(true, ssig2, csig2, this._C1a);
      AB1 = (1 + this._A1m1) * (B12 - this._B11);
    }
    // sin(bet2) = cos(alp0) * sin(sig2)
    sbet2 = this._calp0 * ssig2;
    // Alt: cbet2 = hypot(csig2, salp0 * ssig2);
    cbet2 = m.hypot(this._salp0, this._calp0 * csig2);
    if (cbet2 === 0)
      // I.e., salp0 = 0, csig2 = 0.  Break the degeneracy in this case
      cbet2 = csig2 = g.tiny_;
    // tan(alp0) = cos(sig2)*tan(alp2)
    salp2 = this._salp0; calp2 = this._calp0 * csig2; // No need to normalize

    if (arcmode && (outmask & g.DISTANCE))
      vals.s12 = this._b * ((1 + this._A1m1) * sig12 + AB1);

    if (outmask & g.LONGITUDE) {
      // tan(omg2) = sin(alp0) * tan(sig2)
      somg2 = this._salp0 * ssig2; comg2 = csig2; // No need to normalize
      E = m.copysign(1, this._salp0);
      // omg12 = omg2 - omg1
      omg12 = outmask & g.LONG_UNROLL ?
        E * (sig12 -
             (Math.atan2(ssig2, csig2) -
              Math.atan2(this._ssig1, this._csig1)) +
             (Math.atan2(E * somg2, comg2) -
              Math.atan2(E * this._somg1, this._comg1))) :
        Math.atan2(somg2 * this._comg1 - comg2 * this._somg1,
                     comg2 * this._comg1 + somg2 * this._somg1);
      lam12 = omg12 + this._A3c *
        ( sig12 + (g.SinCosSeries(true, ssig2, csig2, this._C3a) -
                   this._B31));
      lon12 = lam12 / m.degree;
      vals.lon2 = outmask & g.LONG_UNROLL ? this.lon1 + lon12 :
        m.AngNormalize(m.AngNormalize(this.lon1) + m.AngNormalize(lon12));
    }

    if (outmask & g.LATITUDE)
      vals.lat2 = m.atan2d(sbet2, this._f1 * cbet2);

    if (outmask & g.AZIMUTH)
      vals.azi2 = m.atan2d(salp2, calp2);

    if (outmask & (g.REDUCEDLENGTH | g.GEODESICSCALE)) {
      B22 = g.SinCosSeries(true, ssig2, csig2, this._C2a);
      AB2 = (1 + this._A2m1) * (B22 - this._B21);
      J12 = (this._A1m1 - this._A2m1) * sig12 + (AB1 - AB2);
      if (outmask & g.REDUCEDLENGTH)
        // Add parens around (_csig1 * ssig2) and (_ssig1 * csig2) to ensure
        // accurate cancellation in the case of coincident points.
        vals.m12 = this._b * ((      dn2 * (this._csig1 * ssig2) -
                               this._dn1 * (this._ssig1 * csig2)) -
                              this._csig1 * csig2 * J12);
      if (outmask & g.GEODESICSCALE) {
        t = this._k2 * (ssig2 - this._ssig1) * (ssig2 + this._ssig1) /
          (this._dn1 + dn2);
        vals.M12 = csig12 + (t * ssig2 - csig2 * J12) * this._ssig1 / this._dn1;
        vals.M21 = csig12 - (t * this._ssig1 - this._csig1 * J12) * ssig2 / dn2;
      }
    }

    if (outmask & g.AREA) {
      B42 = g.SinCosSeries(false, ssig2, csig2, this._C4a);
      if (this._calp0 === 0 || this._salp0 === 0) {
        // alp12 = alp2 - alp1, used in atan2 so no need to normalize
        salp12 = salp2 * this.calp1 - calp2 * this.salp1;
        calp12 = calp2 * this.calp1 + salp2 * this.salp1;
      } else {
        // tan(alp) = tan(alp0) * sec(sig)
        // tan(alp2-alp1) = (tan(alp2) -tan(alp1)) / (tan(alp2)*tan(alp1)+1)
        // = calp0 * salp0 * (csig1-csig2) / (salp0^2 + calp0^2 * csig1*csig2)
        // If csig12 > 0, write
        //   csig1 - csig2 = ssig12 * (csig1 * ssig12 / (1 + csig12) + ssig1)
        // else
        //   csig1 - csig2 = csig1 * (1 - csig12) + ssig12 * ssig1
        // No need to normalize
        salp12 = this._calp0 * this._salp0 *
          (csig12 <= 0 ? this._csig1 * (1 - csig12) + ssig12 * this._ssig1 :
           ssig12 * (this._csig1 * ssig12 / (1 + csig12) + this._ssig1));
        calp12 = m.sq(this._salp0) + m.sq(this._calp0) * this._csig1 * csig2;
      }
      vals.S12 = this._c2 * Math.atan2(salp12, calp12) +
        this._A4 * (B42 - this._B41);
    }

    if (!arcmode)
      vals.a12 = sig12 / m.degree;
    return vals;
  };

  /**
   * @summary Find the position on the line given s12.
   * @param {number} s12 the distance from the first point to the second in
   *   meters.
   * @param {bitmask} [outmask = STANDARD] which results to include; this is
   *   subject to the capabilities of the object.
   * @returns {object} the requested results.
   * @description The lat1, lon1, azi1, s12, and a12 fields of the result are
   *   always set; s12 is included if arcmode is false.  For details on the
   *   outmask parameter, see {@tutorial 2-interface}, "The outmask and caps
   *   parameters".
   */
  l.GeodesicLine.prototype.Position = function(s12, outmask) {
    return this.GenPosition(false, s12, outmask);
  };

  /**
   * @summary Find the position on the line given a12.
   * @param {number} a12 the arc length from the first point to the second in
   *   degrees.
   * @param {bitmask} [outmask = STANDARD] which results to include; this is
   *   subject to the capabilities of the object.
   * @returns {object} the requested results.
   * @description The lat1, lon1, azi1, and a12 fields of the result are
   *   always set.  For details on the outmask parameter, see {@tutorial
   *   2-interface}, "The outmask and caps parameters".
   */
  l.GeodesicLine.prototype.ArcPosition = function(a12, outmask) {
    return this.GenPosition(true, a12, outmask);
  };

  /**
   * @summary Specify position of point 3 in terms of either distance or arc
   *   length.
   * @param {bool} arcmode boolean flag determining the meaning of the second
   *   parameter; if arcmode is false, then the GeodesicLine object must have
   *   been constructed with caps |= DISTANCE_IN.
   * @param {number} s13_a13 if arcmode is false, this is the distance from
   *   point 1 to point 3 (meters); otherwise it is the arc length from
   *   point 1 to point 3 (degrees); it can be negative.
   **********************************************************************/
  l.GeodesicLine.prototype.GenSetDistance = function(arcmode, s13_a13) {
    if (arcmode)
      this.SetArc(s13_a13);
    else
      this.SetDistance(s13_a13);
  };

  /**
   * @summary Specify position of point 3 in terms distance.
   * @param {number} s13 the distance from point 1 to point 3 (meters); it
   *   can be negative.
   **********************************************************************/
  l.GeodesicLine.prototype.SetDistance = function(s13) {
    var r;
    this.s13 = s13;
    r = this.GenPosition(false, this.s13, g.ARC);
    this.a13 = 0 + r.a12;       // the 0+ converts undefined into NaN
  };

  /**
   * @summary Specify position of point 3 in terms of arc length.
   * @param {number} a13 the arc length from point 1 to point 3 (degrees);
   *   it can be negative.
   **********************************************************************/
  l.GeodesicLine.prototype.SetArc = function(a13) {
    var r;
    this.a13 = a13;
    r = this.GenPosition(true, this.a13, g.DISTANCE);
    this.s13 = 0 + r.s12;       // the 0+ converts undefined into NaN
  };

})(GeographicLib.Geodesic, GeographicLib.GeodesicLine, GeographicLib.Math);


/*
 * PolygonArea.js
 * Transcription of PolygonArea.[ch]pp into JavaScript.
 *
 * See the documentation for the C++ class.  The conversion is a literal
 * conversion from C++.
 *
 * The algorithms are derived in
 *
 *    Charles F. F. Karney,
 *    Algorithms for geodesics, J. Geodesy 87, 43-55 (2013);
 *    https://doi.org/10.1007/s00190-012-0578-z
 *    Addenda: https://geographiclib.sourceforge.io/geod-addenda.html
 *
 * Copyright (c) Charles Karney (2011-2017) <charles@karney.com> and licensed
 * under the MIT/X11 License.  For more information, see
 * https://geographiclib.sourceforge.io/
 */

// Load AFTER GeographicLib/Math.js and GeographicLib/Geodesic.js

(function(
  /**
   * @exports GeographicLib/PolygonArea
   * @description Compute the area of geodesic polygons via the
   *   {@link module:GeographicLib/PolygonArea.PolygonArea PolygonArea}
   *   class.
   */
  p, g, m, a) {

  var transit, transitdirect;
  transit = function(lon1, lon2) {
    // Return 1 or -1 if crossing prime meridian in east or west direction.
    // Otherwise return zero.
    var lon12, cross;
    // Compute lon12 the same way as Geodesic::Inverse.
    lon1 = m.AngNormalize(lon1);
    lon2 = m.AngNormalize(lon2);
    lon12 = m.AngDiff(lon1, lon2).s;
    cross = lon1 <= 0 && lon2 > 0 && lon12 > 0 ? 1 :
      (lon2 <= 0 && lon1 > 0 && lon12 < 0 ? -1 : 0);
    return cross;
  };

  // an alternate version of transit to deal with longitudes in the direct
  // problem.
  transitdirect = function(lon1, lon2) {
    // We want to compute exactly
    //   int(floor(lon2 / 360)) - int(floor(lon1 / 360))
    // Since we only need the parity of the result we can use std::remquo but
    // this is buggy with g++ 4.8.3 and requires C++11.  So instead we do
    lon1 = lon1 % 720.0; lon2 = lon2 % 720.0;
    return ( ((lon2 >= 0 && lon2 < 360) || lon2 < -360 ? 0 : 1) -
             ((lon1 >= 0 && lon1 < 360) || lon1 < -360 ? 0 : 1) );
  };

  /**
   * @class
   * @property {number} a the equatorial radius (meters).
   * @property {number} f the flattening.
   * @property {bool} polyline whether the PolygonArea object describes a
   *   polyline or a polygon.
   * @property {number} num the number of vertices so far.
   * @property {number} lat the current latitude (degrees).
   * @property {number} lon the current longitude (degrees).
   * @summary Initialize a PolygonArea object.
   * @classdesc Computes the area and perimeter of a geodesic polygon.
   *   This object is usually instantiated by
   *   {@link module:GeographicLib/Geodesic.Geodesic#Polygon Geodesic.Polygon}.
   * @param {object} geod a {@link module:GeographicLib/Geodesic.Geodesic
   *   Geodesic} object.
   * @param {bool} [polyline = false] if true the new PolygonArea object
   *   describes a polyline instead of a polygon.
   */
  p.PolygonArea = function(geod, polyline) {
    this._geod = geod;
    this.a = this._geod.a;
    this.f = this._geod.f;
    this._area0 = 4 * Math.PI * geod._c2;
    this.polyline = !polyline ? false : polyline;
    this._mask = g.LATITUDE | g.LONGITUDE | g.DISTANCE |
          (this.polyline ? g.NONE : g.AREA | g.LONG_UNROLL);
    if (!this.polyline)
      this._areasum = new a.Accumulator(0);
    this._perimetersum = new a.Accumulator(0);
    this.Clear();
  };

  /**
   * @summary Clear the PolygonArea object, setting the number of vertices to
   *   0.
   */
  p.PolygonArea.prototype.Clear = function() {
    this.num = 0;
    this._crossings = 0;
    if (!this.polyline)
      this._areasum.Set(0);
    this._perimetersum.Set(0);
    this._lat0 = this._lon0 = this.lat = this.lon = Number.NaN;
  };

  /**
   * @summary Add the next vertex to the polygon.
   * @param {number} lat the latitude of the point (degrees).
   * @param {number} lon the longitude of the point (degrees).
   * @description This adds an edge from the current vertex to the new vertex.
   */
  p.PolygonArea.prototype.AddPoint = function(lat, lon) {
    var t;
    if (this.num === 0) {
      this._lat0 = this.lat = lat;
      this._lon0 = this.lon = lon;
    } else {
      t = this._geod.Inverse(this.lat, this.lon, lat, lon, this._mask);
      this._perimetersum.Add(t.s12);
      if (!this.polyline) {
        this._areasum.Add(t.S12);
        this._crossings += transit(this.lon, lon);
      }
      this.lat = lat;
      this.lon = lon;
    }
    ++this.num;
  };

  /**
   * @summary Add the next edge to the polygon.
   * @param {number} azi the azimuth at the current the point (degrees).
   * @param {number} s the length of the edge (meters).
   * @description This specifies the new vertex in terms of the edge from the
   *   current vertex.
   */
  p.PolygonArea.prototype.AddEdge = function(azi, s) {
    var t;
    if (this.num) {
      t = this._geod.Direct(this.lat, this.lon, azi, s, this._mask);
      this._perimetersum.Add(s);
      if (!this.polyline) {
        this._areasum.Add(t.S12);
        this._crossings += transitdirect(this.lon, t.lon2);
      }
      this.lat = t.lat2;
      this.lon = t.lon2;
    }
    ++this.num;
  };

  /**
   * @summary Compute the perimeter and area of the polygon.
   * @param {bool} reverse if true then clockwise (instead of
   *   counter-clockwise) traversal counts as a positive area.
   * @param {bool} sign if true then return a signed result for the area if the
   *   polygon is traversed in the "wrong" direction instead of returning the
   *   area for the rest of the earth.
   * @returns {object} r where r.number is the number of vertices, r.perimeter
   *   is the perimeter (meters), and r.area (only returned if polyline is
   *   false) is the area (meters<sup>2</sup>).
   * @description If the object is a polygon (and not a polygon), the perimeter
   *   includes the length of a final edge connecting the current point to the
   *   initial point.  If the object is a polyline, then area is nan.  More
   *   points can be added to the polygon after this call.
   */
  p.PolygonArea.prototype.Compute = function(reverse, sign) {
    var vals = {number: this.num}, t, tempsum, crossings;
    if (this.num < 2) {
      vals.perimeter = 0;
      if (!this.polyline)
        vals.area = 0;
      return vals;
    }
    if (this.polyline) {
      vals.perimeter = this._perimetersum.Sum();
      return vals;
    }
    t = this._geod.Inverse(this.lat, this.lon, this._lat0, this._lon0,
                           this._mask);
    vals.perimeter = this._perimetersum.Sum(t.s12);
    tempsum = new a.Accumulator(this._areasum);
    tempsum.Add(t.S12);
    crossings = this._crossings + transit(this.lon, this._lon0);
    if (crossings & 1)
      tempsum.Add( (tempsum.Sum() < 0 ? 1 : -1) * this._area0/2 );
    // area is with the clockwise sense.  If !reverse convert to
    // counter-clockwise convention.
    if (!reverse)
      tempsum.Negate();
    // If sign put area in (-area0/2, area0/2], else put area in [0, area0)
    if (sign) {
      if (tempsum.Sum() > this._area0/2)
        tempsum.Add( -this._area0 );
      else if (tempsum.Sum() <= -this._area0/2)
        tempsum.Add( +this._area0 );
    } else {
      if (tempsum.Sum() >= this._area0)
        tempsum.Add( -this._area0 );
      else if (tempsum < 0)
        tempsum.Add( -this._area0 );
    }
    vals.area = tempsum.Sum();
    return vals;
  };

  /**
   * @summary Compute the perimeter and area of the polygon with a tentative
   *   new vertex.
   * @param {number} lat the latitude of the point (degrees).
   * @param {number} lon the longitude of the point (degrees).
   * @param {bool} reverse if true then clockwise (instead of
   *   counter-clockwise) traversal counts as a positive area.
   * @param {bool} sign if true then return a signed result for the area if the
   *   polygon is traversed in the "wrong" direction instead of returning the
   * @returns {object} r where r.number is the number of vertices, r.perimeter
   *   is the perimeter (meters), and r.area (only returned if polyline is
   *   false) is the area (meters<sup>2</sup>).
   * @description A new vertex is *not* added to the polygon.
   */
  p.PolygonArea.prototype.TestPoint = function(lat, lon, reverse, sign) {
    var vals = {number: this.num + 1}, t, tempsum, crossings, i;
    if (this.num === 0) {
      vals.perimeter = 0;
      if (!this.polyline)
        vals.area = 0;
      return vals;
    }
    vals.perimeter = this._perimetersum.Sum();
    tempsum = this.polyline ? 0 : this._areasum.Sum();
    crossings = this._crossings;
    for (i = 0; i < (this.polyline ? 1 : 2); ++i) {
      t = this._geod.Inverse(
       i === 0 ? this.lat : lat, i === 0 ? this.lon : lon,
       i !== 0 ? this._lat0 : lat, i !== 0 ? this._lon0 : lon,
       this._mask);
      vals.perimeter += t.s12;
      if (!this.polyline) {
        tempsum += t.S12;
        crossings += transit(i === 0 ? this.lon : lon,
                               i !== 0 ? this._lon0 : lon);
      }
    }

    if (this.polyline)
      return vals;

    if (crossings & 1)
      tempsum += (tempsum < 0 ? 1 : -1) * this._area0/2;
    // area is with the clockwise sense.  If !reverse convert to
    // counter-clockwise convention.
    if (!reverse)
      tempsum *= -1;
    // If sign put area in (-area0/2, area0/2], else put area in [0, area0)
    if (sign) {
      if (tempsum > this._area0/2)
        tempsum -= this._area0;
      else if (tempsum <= -this._area0/2)
        tempsum += this._area0;
    } else {
      if (tempsum >= this._area0)
        tempsum -= this._area0;
      else if (tempsum < 0)
        tempsum += this._area0;
    }
    vals.area = tempsum;
    return vals;
  };

  /**
   * @summary Compute the perimeter and area of the polygon with a tentative
   *   new edge.
   * @param {number} azi the azimuth of the edge (degrees).
   * @param {number} s the length of the edge (meters).
   * @param {bool} reverse if true then clockwise (instead of
   *   counter-clockwise) traversal counts as a positive area.
   * @param {bool} sign if true then return a signed result for the area if the
   *   polygon is traversed in the "wrong" direction instead of returning the
   * @returns {object} r where r.number is the number of vertices, r.perimeter
   *   is the perimeter (meters), and r.area (only returned if polyline is
   *   false) is the area (meters<sup>2</sup>).
   * @description A new vertex is *not* added to the polygon.
   */
  p.PolygonArea.prototype.TestEdge = function(azi, s, reverse, sign) {
    var vals = {number: this.num ? this.num + 1 : 0}, t, tempsum, crossings;
    if (this.num === 0)
      return vals;
    vals.perimeter = this._perimetersum.Sum() + s;
    if (this.polyline)
      return vals;

    tempsum = this._areasum.Sum();
    crossings = this._crossings;
    t = this._geod.Direct(this.lat, this.lon, azi, s, this._mask);
    tempsum += t.S12;
    crossings += transitdirect(this.lon, t.lon2);
    t = this._geod.Inverse(t.lat2, t.lon2, this._lat0, this._lon0, this._mask);
    vals.perimeter += t.s12;
    tempsum += t.S12;
    crossings += transit(t.lon2, this._lon0);

    if (crossings & 1)
      tempsum += (tempsum < 0 ? 1 : -1) * this._area0/2;
    // area is with the clockwise sense.  If !reverse convert to
    // counter-clockwise convention.
    if (!reverse)
      tempsum *= -1;
    // If sign put area in (-area0/2, area0/2], else put area in [0, area0)
    if (sign) {
      if (tempsum > this._area0/2)
        tempsum -= this._area0;
      else if (tempsum <= -this._area0/2)
        tempsum += this._area0;
    } else {
      if (tempsum >= this._area0)
        tempsum -= this._area0;
      else if (tempsum < 0)
        tempsum += this._area0;
    }
    vals.area = tempsum;
    return vals;
  };

})(GeographicLib.PolygonArea, GeographicLib.Geodesic,
   GeographicLib.Math, GeographicLib.Accumulator);


function pj_qsfn(sinphi, e, one_es) {
  var EPS = 1e-7;
  var con;
  if (e >= EPS) {
    con = e * sinphi;
    // Proj.4 check for div0 and returns HUGE_VAL
    // this returns +/- Infinity; effect should be same
    return (one_es * (sinphi / (1 - con * con) -
       (0.5 / e) * log ((1 - con) / (1 + con))));
  } else
    return (sinphi + sinphi);
}


function pj_msfn(sinphi, cosphi, es) {
  return (cosphi / sqrt (1 - es * sinphi * sinphi));
}


pj_add(pj_aea, 'aea', 'Albers Equal Area', 'Conic Sph&Ell\nlat_1= lat_2=');
pj_add(pj_leac, 'leac', 'Lambert Equal Area Conic', 'Conic, Sph&Ell\nlat_1= south');

function pj_aea(P) {
  var phi1 = pj_param(P.params, "rlat_1");
  var phi2 = pj_param(P.params, "rlat_2");
  pj_aea_init(P, phi1, phi2);
}

function pj_leac(P) {
  var phi1 = pj_param(P.params, "rlat_1");
  var phi2 = pj_param(P.params, "bsouth") ? -M_HALFPI : M_HALFPI;
  pj_aea_init(P, phi1, phi2);
}

function pj_aea_init(P, phi1, phi2) {
  var ec, n, c, dd, n2, rho0, rho, en, ellips,
      cosphi, sinphi, secant, ml2, m2, ml1, m1;

  P.fwd = e_fwd;
  P.inv = e_inv;

  if (fabs(phi1 + phi2) < EPS10) e_error(-21);
  n = sinphi = sin(phi1);
  cosphi = cos(phi1);
  secant = fabs(phi1 - phi2) >= EPS10;
  if ((ellips = (P.es > 0))) {
    en = pj_enfn(P.es);
    m1 = pj_msfn(sinphi, cosphi, P.es);
    ml1 = pj_qsfn(sinphi, P.e, P.one_es);
    if (secant) { /* secant cone */
      sinphi = sin(phi2);
      cosphi = cos(phi2);
      m2 = pj_msfn(sinphi, cosphi, P.es);
      ml2 = pj_qsfn(sinphi, P.e, P.one_es);
      // Ignoring Proj.4 div0 check (above checks should prevent this)
      n = (m1 * m1 - m2 * m2) / (ml2 - ml1);
    }
    ec = 1 - 0.5 * P.one_es * log((1 - P.e) / (1 + P.e)) / P.e;
    c = m1 * m1 + n * ml1;
    dd = 1 / n;
    rho0 = dd * sqrt(c - n * pj_qsfn(sin(P.phi0), P.e, P.one_es));
  } else {
    if (secant) n = 0.5 * (n + sin(phi2));
    n2 = n + n;
    c = cosphi * cosphi + n2 * sinphi;
    dd = 1 / n;
    rho0 = dd * sqrt(c - n2 * sin(P.phi0));
  }

  function e_fwd(lp, xy) {
    var lam = lp.lam;
    var rho;
    if ((rho = c - (ellips ? n * pj_qsfn(sin(lp.phi),
      P.e, P.one_es) : n2 * sin(lp.phi))) < 0) f_error();
    rho = dd * sqrt(rho);
    xy.x = rho * sin(lam *= n);
    xy.y = rho0 - rho * cos(lam);
  }

  function e_inv(xy, lp) {
    var TOL7 = 1e-7,
        x = xy.x,
        y = rho0 - xy.y,
        rho = hypot(x, y);
    if (rho != 0) {
      if (n < 0) {
        rho = -rho;
        x = -x;
        y = -y;
      }
      lp.phi = rho / dd;
      if (ellips) {
        lp.phi = (c - lp.phi * lp.phi) / n;
        if (fabs(ec - fabs(lp.phi)) > TOL7) {
          if ((lp.phi = phi1_(lp.phi, P.e, P.one_es)) == HUGE_VAL)
            i_error();
        } else
          lp.phi = lp.phi < 0 ? -M_HALFPI : M_HALFPI;
      } else if (fabs(lp.phi = (c - lp.phi * lp.phi) / n2) <= 1)
        lp.phi = asin(lp.phi);
      else
        lp.phi = lp.phi < 0 ? -M_HALFPI : M_HALFPI;
      lp.lam = atan2(x, y) / n;
    } else {
      lp.lam = 0;
      lp.phi = n > 0 ? M_HALFPI : -M_HALFPI;
    }
  }

  /* determine latitude angle phi-1 */
  function phi1_(qs, Te, Tone_es) {
    var N_ITER = 15,
        EPSILON = 1e-7,
        TOL = 1e-10;
    var Phi, sinpi, cospi, con, com, dphi, i;
    Phi = asin (0.5 * qs);
    if (Te < EPSILON)
      return Phi;
    i = N_ITER;
    do {
      sinpi = sin(Phi);
      cospi = cos(Phi);
      con = Te * sinpi;
      com = 1 - con * con;
      dphi = 0.5 * com * com / cospi * (qs / Tone_es -
         sinpi / com + 0.5 / Te * log ((1 - con) / (1 + con)));
      Phi += dphi;
    } while (fabs(dphi) > TOL && --i);
    return i ? Phi : HUGE_VAL;
  }
}



function pj_enfn(es) {
  var C00 = 1,
      C02 = 0.25,
      C04 = 0.046875,
      C06 = 0.01953125,
      C08 = 0.01068115234375,
      C22 = 0.75,
      C44 = 0.46875,
      C46 = 0.01302083333333333333,
      C48 = 0.00712076822916666666,
      C66 = 0.36458333333333333333,
      C68 = 0.00569661458333333333,
      C88 = 0.3076171875;
  var en = [], t;
  en[0] = C00 - es * (C02 + es * (C04 + es * (C06 + es * C08)));
  en[1] = es * (C22 - es * (C04 + es * (C06 + es * C08)));
  en[2] = (t = es * es) * (C44 - es * (C46 + es * C48));
  en[3] = (t *= es) * (C66 - es * C68);
  en[4] = t * es * C88;
  return en;
}

function pj_mlfn(phi, sphi, cphi, en) {
  cphi *= sphi;
  sphi *= sphi;
  return (en[0] * phi - cphi * (en[1] + sphi*(en[2] + sphi*(en[3] + sphi*en[4]))));
}

function pj_inv_mlfn(arg, es, en) {
  var EPS = 1e-11,
      MAX_ITER = 10,
      EN_SIZE = 5;

  var k = 1 / (1 - es),
      s, t, phi;

  phi = arg;
  for (var i = MAX_ITER; i>0; --i) { /* rarely goes over 2 iterations */
    s = sin(phi);
    t = 1 - es * s * s;
    phi -= t = (pj_mlfn(phi, s, cos(phi), en) - arg) * (t * sqrt(t)) * k;
    if (fabs(t) < EPS) {
      return phi;
    }
  }
  pj_ctx_set_errno( ctx, -17 );
  return phi;
}



function aasin(v) {
  var ONE_TOL = 1.00000000000001;
  var av = fabs(v);
  if (av >= 1) {
    if (av > ONE_TOL) pj_ctx_set_errno(-19);
    return v < 0 ? -M_HALFPI : M_HALFPI;
  }
  return asin(v);
}

function aacos(v) {
  var ONE_TOL = 1.00000000000001;
  var av = fabs(v);
  if (av >= 1) {
    if (av > ONE_TOL) pj_ctx_set_errno(-19);
    return (v < 0 ? M_PI : 0);
  }
  return acos(v);
}

function asqrt(v) { return ((v <= 0) ? 0 : sqrt(v)); }

function aatan2(n, d) {
  var ATOL = 1e-50;
  return ((fabs(n) < ATOL && fabs(d) < ATOL) ? 0 : atan2(n,d));
}


pj_add(pj_aeqd, 'aeqd', 'Azimuthal Equidistant', 'Azi, Sph&Ell\nlat_0 guam');

function pj_aeqd(P) {
  var EPS10 = 1.e-10,
      TOL = 1.e-14,
      N_POLE = 0,
      S_POLE = 1,
      EQUIT = 2,
      OBLIQ = 3;

  var sinph0, cosph0, M1, N1, Mp, He, G, mode, en, g;
  P.phi0 = pj_param(P.params, "rlat_0");
  if (fabs(fabs(P.phi0) - M_HALFPI) < EPS10) {
    mode = P.phi0 < 0 ? S_POLE : N_POLE;
    sinph0 = P.phi0 < 0 ? -1 : 1;
    cosph0 = 0;
  } else if (fabs(P.phi0) < EPS10) {
    mode = EQUIT;
    sinph0 = 0;
    cosph0 = 1;
  } else {
    mode = OBLIQ;
    sinph0 = sin(P.phi0);
    cosph0 = cos(P.phi0);
  }
  if (!P.es) {
    P.inv = s_inv;
    P.fwd = s_fwd;
  } else {
    g = new GeographicLib.Geodesic.Geodesic(P.a, P.es / (1 + sqrt(P.one_es)));
    en = pj_enfn(P.es);
    if (pj_param(P.params, "bguam")) {
      M1 = pj_mlfn(P.phi0, sinph0, cosph0, en);
      P.inv = e_guam_inv;
      P.fwd = e_guam_fwd;
    } else {
      switch (mode) {
        case N_POLE:
          Mp = pj_mlfn(M_HALFPI, 1, 0, en);
          break;
        case S_POLE:
          Mp = pj_mlfn(-M_HALFPI, -1, 0, en);
          break;
        case EQUIT:
        case OBLIQ:
          P.inv = e_inv;
          P.fwd = e_fwd;
          N1 = 1 / sqrt(1 - P.es * sinph0 * sinph0);
          G = sinph0 * (He = P.e / sqrt(P.one_es));
          He *= cosph0;
          break;
      }
      P.inv = e_inv;
      P.fwd = e_fwd;
    }
  }

  function e_fwd(lp, xy) {
    var coslam, cosphi, sinphi, rho;
    var azi1, azi2, s12;
    var lam1, phi1, lam2, phi2;
    var vars;

    coslam = cos(lp.lam);
    cosphi = cos(lp.phi);
    sinphi = sin(lp.phi);
    switch (mode) {
      case N_POLE:
        coslam = - coslam;
        /* falls through */
      case S_POLE:
        xy.x = (rho = fabs(Mp - pj_mlfn(lp.phi, sinphi, cosphi, en))) *
            sin(lp.lam);
        xy.y = rho * coslam;
        break;
      case EQUIT:
      case OBLIQ:
        if (fabs(lp.lam) < EPS10 && fabs(lp.phi - P.phi0) < EPS10) {
            xy.x = xy.y = 0;
            break;
        }
        phi1 = P.phi0 / DEG_TO_RAD; lam1 = P.lam0 / DEG_TO_RAD;
        phi2 = lp.phi / DEG_TO_RAD;  lam2 = (lp.lam+P.lam0) / DEG_TO_RAD;
        vars = g.Inverse(phi1, lam1, phi2, lam2, g.AZIMUTH); // , &s12, &azi1, &azi2);
        azi1 = vars.azi1 * DEG_TO_RAD;
        s12 = vars.s12;
        xy.x = s12 * sin(azi1) / P.a;
        xy.y = s12 * cos(azi1) / P.a;
        break;
    }
  }

  function e_inv(xy, lp) {
    var c, azi1, azi2, s12, x2, y2, lat1, lon1, lat2, lon2;
    var vars;
    if ((c = hypot(xy.x, xy.y)) < EPS10) {
      lp.phi = P.phi0;
      lp.lam = 0;
      return (lp);
    }
    if (mode == OBLIQ || mode == EQUIT) {
      x2 = xy.x * P.a;
      y2 = xy.y * P.a;
      lat1 = P.phi0 / DEG_TO_RAD;
      lon1 = P.lam0 / DEG_TO_RAD;
      azi1 = atan2(x2, y2) / DEG_TO_RAD;
      s12 = sqrt(x2 * x2 + y2 * y2);
      vars = g.Direct(lat1, lon1, azi1, s12, g.STANDARD); // , &lat2, &lon2, &azi2);
      lp.phi = vars.lat2 * DEG_TO_RAD;
      lp.lam = vars.lon2 * DEG_TO_RAD;
      lp.lam -= P.lam0;
    } else { /* Polar */
      lp.phi = pj_inv_mlfn(mode == N_POLE ? Mp - c : Mp + c,
          P.es, en);
      lp.lam = atan2(xy.x, mode == N_POLE ? -xy.y : xy.y);
    }
  }

  function s_fwd(lp, xy) {
    var coslam, cosphi, sinphi;
    sinphi = sin(lp.phi);
    cosphi = cos(lp.phi);
    coslam = cos(lp.lam);
    switch (mode) {
      case EQUIT:
      case OBLIQ:
        if (mode == EQUIT) {
          xy.y = cosphi * coslam;
        } else {
          xy.y = sinph0 * sinphi + cosph0 * cosphi * coslam;
        }
        if (fabs(fabs(xy.y) - 1) < TOL)
            if (xy.y < 0) f_error();
            else xy.x = xy.y = 0;
        else {
          xy.y = acos(xy.y);
          xy.y /= sin(xy.y);
          xy.x = xy.y * cosphi * sin(lp.lam);
          xy.y *= (mode == EQUIT) ? sinphi :
              cosph0 * sinphi - sinph0 * cosphi * coslam;
        }
        break;
      case N_POLE:
        lp.phi = -lp.phi;
        coslam = -coslam;
        /* falls through */
      case S_POLE:
        if (fabs(lp.phi - M_HALFPI) < EPS10) f_error();
        xy.x = (xy.y = (M_HALFPI + lp.phi)) * sin(lp.lam);
        xy.y *= coslam;
        break;
    }
  }

  function s_inv(xy, lp) {
    var x = xy.x, y = xy.y;
    var cosc, c_rh, sinc;
    if ((c_rh = hypot(x, y)) > M_PI) {
        if (c_rh - EPS10 > M_PI) i_error();
        c_rh = M_PI;
    } else if (c_rh < EPS10) {
      lp.phi = P.phi0;
      lp.lam = 0;
      return;
    }
    if (mode == OBLIQ || mode == EQUIT) {
      sinc = sin(c_rh);
      cosc = cos(c_rh);
      if (mode == EQUIT) {
        lp.phi = aasin(y * sinc / c_rh);
        x *= sinc;
        y = cosc * c_rh;
      } else {
        lp.phi = aasin(cosc * sinph0 + y * sinc * cosph0 / c_rh);
        y = (cosc - sinph0 * sin(lp.phi)) * c_rh;
        x *= sinc * cosph0;
      }
      lp.lam = y == 0 ? 0 : atan2(x, y);
    } else if (mode == N_POLE) {
      lp.phi = M_HALFPI - c_rh;
      lp.lam = atan2(x, -y);
    } else {
      lp.phi = c_rh - M_HALFPI;
      lp.lam = atan2(x, y);
    }
  }

  function e_guam_fwd(lp, xy) {
    var cosphi, sinphi, t;
    cosphi = cos(lp.phi);
    sinphi = sin(lp.phi);
    t = 1 / sqrt(1 - P.es * sinphi * sinphi);
    xy.x = lp.lam * cosphi * t;
    xy.y = pj_mlfn(lp.phi, sinphi, cosphi, en) - M1 +
        0.5 * lp.lam * lp.lam * cosphi * sinphi * t;
  }

  function e_guam_inv(xy, lp) {
    var x2, t, i;
    x2 = 0.5 * xy.x * xy.x;
    lp.phi = P.phi0;
    for (i = 0; i < 3; ++i) {
      t = P.e * sin(lp.phi);
      lp.phi = pj_inv_mlfn(M1 + xy.y -
        x2 * tan(lp.phi) * (t = sqrt(1 - t * t)), P.es, en);
    }
    lp.lam = xy.x * t / cos(lp.phi);
  }
}


pj_add(pj_airy, 'airy', 'Airy', 'Misc Sph, no inv.\nno_cut lat_b=');

function pj_airy(P) {
  var EPS = 1e-10,
      N_POLE = 0,
      S_POLE = 1,
      EQUIT = 2,
      OBLIQ = 3,
      p_halfphi, sinph0, cosph0, Cb, mode, no_cut, beta;

  P.es = 0;
  P.fwd = s_fwd;

  no_cut = pj_param(P.params, "bno_cut");
  beta = 0.5 * (M_HALFPI - pj_param(P.params, "rlat_b"));
  if (fabs(beta) < EPS)
    Cb = -0.5;
  else {
    Cb = 1/tan(beta);
    Cb *= Cb * log(cos(beta));
  }

  if (fabs(fabs(P.phi0) - M_HALFPI) < EPS)
    if (P.phi0 < 0) {
      p_halfpi = -M_HALFPI;
      mode = S_POLE;
    } else {
      p_halfpi =  M_HALFPI;
      mode = N_POLE;
    }
  else {
    if (fabs(P.phi0) < EPS)
      mode = EQUIT;
    else {
      mode = OBLIQ;
      sinph0 = sin(P.phi0);
      cosph0 = cos(P.phi0);
    }
  }

  function s_fwd(lp, xy) {
    var sinlam, coslam, cosphi, sinphi, t, s, Krho, cosz;
    sinlam = sin(lp.lam);
    coslam = cos(lp.lam);
    switch (mode) {
      case EQUIT:
      case OBLIQ:
        sinphi = sin(lp.phi);
        cosphi = cos(lp.phi);
        cosz = cosphi * coslam;
        if (mode == OBLIQ)
          cosz = sinph0 * sinphi + cosph0 * cosz;
        if (!no_cut && cosz < -EPS)
          f_error();
        if (fabs(s = 1 - cosz) > EPS) {
          t = 0.5 * (1 + cosz);
          Krho = -log(t)/s - Cb / t;
        } else {
          Krho = 0.5 - Cb;
        }
        xy.x = Krho * cosphi * sinlam;
        if (mode == OBLIQ)
          xy.y = Krho * (cosph0 * sinphi - sinph0 * cosphi * coslam);
        else
          xy.y = Krho * sinphi;
        break;
      case S_POLE:
      case N_POLE:
        lp.phi = fabs(p_halfpi - lp.phi);
        if (!no_cut && (lp.phi - EPS) > M_HALFPI)
          f_error();
        if ((lp.phi *= 0.5) > EPS) {
          t = tan(lp.phi);
          Krho = -2*(log(cos(lp.phi)) / t + t * Cb);
          xy.x = Krho * sinlam;
          xy.y = Krho * coslam;
          if (mode == N_POLE)
            xy.y = -xy.y;
        } else
          xy.x = xy.y = 0;
    }
  }
}


pj_add(pj_wintri, 'wintri', 'Winkel Tripel', 'Misc Sph\nlat_1');
pj_add(pj_aitoff, 'aitoff', 'Aitoff', 'Misc Sph');

function pj_wintri(P) {
  var Q = P.opaque = {mode: 1};
  if (pj_param(P.params, "tlat_1")) {
    if ((Q.cosphi1 = cos(pj_param(P.params, "rlat_1"))) === 0) {
      e_error(-22);
    }
  } else { /* 50d28' or acos(2/pi) */
    Q.cosphi1 = 0.636619772367581343;
  }
  pj_aitoff(P);
}

function pj_aitoff(P) {
  var Q = P.opaque || {mode: 0};

  P.inv = s_inv;
  P.fwd = s_fwd;
  P.es = 0;

  function s_fwd(lp, xy) {
    var c, d;
    if((d = acos(cos(lp.phi) * cos(c = 0.5 * lp.lam)))) {/* basic Aitoff */
      xy.x = 2 * d * cos(lp.phi) * sin(c) * (xy.y = 1 / sin(d));
      xy.y *= d * sin(lp.phi);
    } else
      xy.x = xy.y = 0;
    if (Q.mode) { /* Winkel Tripel */
      xy.x = (xy.x + lp.lam * Q.cosphi1) * 0.5;
      xy.y = (xy.y + lp.phi) * 0.5;
    }
  }

  function s_inv(xy, lp) {
    var MAXITER = 10,
        MAXROUND = 20,
        EPSILON = 1e-12,
        round = 0,
        iter, D, C, f1, f2, f1p, f1l, f2p, f2l, dp, dl, sl, sp, cp, cl, x, y;

    if ((fabs(xy.x) < EPSILON) && (fabs(xy.y) < EPSILON )) {
      lp.phi = 0;
      lp.lam = 0;
      return;
    }

    /* intial values for Newton-Raphson method */
    lp.phi = xy.y; lp.lam = xy.x;
    do {
      iter = 0;
      do {
        sl = sin(lp.lam * 0.5); cl = cos(lp.lam * 0.5);
        sp = sin(lp.phi); cp = cos(lp.phi);
        D = cp * cl;
        C = 1 - D * D;
        D = acos(D) / pow(C, 1.5);
        f1 = 2 * D * C * cp * sl;
        f2 = D * C * sp;
        f1p = 2 * (sl * cl * sp * cp / C - D * sp * sl);
        f1l = cp * cp * sl * sl / C + D * cp * cl * sp * sp;
        f2p = sp * sp * cl / C + D * sl * sl * cp;
        f2l = 0.5 * (sp * cp * sl / C - D * sp * cp * cp * sl * cl);
        if (Q.mode) { /* Winkel Tripel */
          f1 = 0.5 * (f1 + lp.lam * Q.cosphi1);
          f2 = 0.5 * (f2 + lp.phi);
          f1p *= 0.5;
          f1l = 0.5 * (f1l + Q.cosphi1);
          f2p = 0.5 * (f2p + 1);
          f2l *= 0.5;
        }
        f1 -= xy.x; f2 -= xy.y;
        dl = (f2 * f1p - f1 * f2p) / (dp = f1p * f2l - f2p * f1l);
        dp = (f1 * f2l - f2 * f1l) / dp;
        while (dl > M_PI) dl -= M_PI; /* set to interval [-M_PI, M_PI]  */
        while (dl < -M_PI) dl += M_PI; /* set to interval [-M_PI, M_PI]  */
        lp.phi -= dp; lp.lam -= dl;
      } while ((fabs(dp) > EPSILON || fabs(dl) > EPSILON) && (iter++ < MAXITER));
      if (lp.phi > M_HALFPI) lp.phi -= 2*(lp.phi-M_HALFPI); /* correct if symmetrical solution for Aitoff */
      if (lp.phi < -M_HALFPI) lp.phi -= 2*(lp.phi+M_HALFPI); /* correct if symmetrical solution for Aitoff */
      if ((fabs(fabs(lp.phi) - M_HALFPI) < EPSILON) && (!Q.mode)) lp.lam = 0; /* if pole in Aitoff, return longitude of 0 */

      /* calculate x,y coordinates with solution obtained */
      if((D = acos(cos(lp.phi) * cos(C = 0.5 * lp.lam)))) {/* Aitoff */
        x = 2 * D * cos(lp.phi) * sin(C) * (y = 1 / sin(D));
        y *= D * sin(lp.phi);
      } else
        x = y = 0;
      if (Q.mode) { /* Winkel Tripel */
        x = (x + lp.lam * Q.cosphi1) * 0.5;
        y = (y + lp.phi) * 0.5;
      }
    /* if too far from given values of x,y, repeat with better approximation of phi,lam */
    } while (((fabs(xy.x-x) > EPSILON) || (fabs(xy.y-y) > EPSILON)) && (round++ < MAXROUND));

    if (iter == MAXITER && round == MAXROUND) {
      // not ported: warning message
      // fprintf(stderr, "Warning: Accuracy of 1e-12 not reached. Last increments: dlat=%e and dlon=%e\n", dp, dl);
    }
  }
}


pj_add(pj_august, 'august', 'August Epicycloidal', 'Misc Sph, no inv.');

function pj_august(P) {
  P.fwd = s_fwd;
  P.es = 0;

  function s_fwd(lp, xy) {
    var M = 4 / 3;
    var lam = lp.lam;
    var t, c1, c, x1, x12, y1, y12;
    t = tan(0.5 * lp.phi);
    c1 = sqrt(1 - t * t);
    c = 1 + c1 * cos(lam *= 0.5);
    x1 = sin(lam) *  c1 / c;
    y1 =  t / c;
    xy.x = M * x1 * (3 + (x12 = x1 * x1) - 3 * (y12 = y1 *  y1));
    xy.y = M * y1 * (3 + 3 * x12 - y12);
  }
}


pj_add(pj_apian, 'apian', 'Apian Globular I', 'Misc Sph, no inv.');
pj_add(pj_ortel, 'ortel', 'Ortelius Oval', 'Misc Sph, no inv.');
pj_add(pj_bacon, 'bacon', 'Bacon Globular', 'Misc Sph, no inv.');

function pj_bacon(P) {
  pj_bacon_init(P, true, false);
}

function pj_apian(P) {
  pj_bacon_init(P, false, false);
}

function pj_ortel(P) {
  pj_bacon_init(P, false, true);
}

function pj_bacon_init(P, bacn, ortl) {
  P.es = 0;
  P.fwd = s_fwd;

  function s_fwd(lp, xy) {
    var HLFPI2 = 2.46740110027233965467; /* (pi/2)^2 */
    var EPS = 1e-10;
    var ax, f;
    xy.y = bacn ? M_HALFPI * sin(lp.phi) : lp.phi;
    if ((ax = fabs(lp.lam)) >= EPS) {
      if (ortl && ax >= M_HALFPI)
        xy.x = sqrt(HLFPI2 - lp.phi * lp.phi + EPS) + ax - M_HALFPI;
      else {
        f = 0.5 * (HLFPI2 / ax + ax);
        xy.x = ax - f + sqrt(f * f - xy.y * xy.y);
      }
      if (lp.lam < 0) xy.x = - xy.x;
    } else
      xy.x = 0;
  }
}



/*
  Created by Jacques Bertin in 1953, this projection was the go-to choice
  of the French cartographic school when they wished to represent phenomena
  on a global scale.

  Formula designed by Philippe Rivire, 2017.
  https://visionscarto.net/bertin-projection-1953
  Port to PROJ by Philippe Rivire, 21 September 2018
  Port to JavaScript by Matthew Bloch October 2018
*/
pj_add(pj_bertin1953, 'bertin1953', 'Bertin 1953', 'Misc., Sph., NoInv.');

function pj_bertin1953(P) {
  var cos_delta_phi, sin_delta_phi, cos_delta_gamma, sin_delta_gamma;

  P.es = 0;
  P.fwd = s_fwd;
  P.lam0 = 0;
  P.phi0 = DEG_TO_RAD * -42;

  cos_delta_phi = cos(P.phi0);
  sin_delta_phi = sin(P.phi0);
  cos_delta_gamma = 1;
  sin_delta_gamma = 0;

  function s_fwd(lp, xy) {
    var fu = 1.4, k = 12, w = 1.68, d;
    /* Rotate */
    var cosphi, x, y, z, z0;
    lp.lam += DEG_TO_RAD * -16.5;
    cosphi = cos(lp.phi);
    x = cos(lp.lam) * cosphi;
    y = sin(lp.lam) * cosphi;
    z = sin(lp.phi);
    z0 = z * cos_delta_phi + x * sin_delta_phi;
    lp.lam = atan2(y * cos_delta_gamma - z0 * sin_delta_gamma,
       x * cos_delta_phi - z * sin_delta_phi);
    z0 = z0 * cos_delta_gamma + y * sin_delta_gamma;
    lp.phi = asin(z0);
    lp.lam = adjlon(lp.lam);

    /* Adjust pre-projection */
    if (lp.lam + lp.phi < -fu) {
      d = (lp.lam - lp.phi + 1.6) * (lp.lam + lp.phi + fu) / 8;
      lp.lam += d;
      lp.phi -= 0.8 * d * sin(lp.phi + M_PI / 2);
    }

    /* Project with Hammer (1.68,2) */
    cosphi = cos(lp.phi);
    d = sqrt(2/(1 + cosphi * cos(lp.lam / 2)));
    xy.x = w * d * cosphi * sin(lp.lam / 2);
    xy.y = d * sin(lp.phi);

    /* Adjust post-projection */
    d = (1 - cos(lp.lam * lp.phi)) / k;
    if (xy.y < 0) {
      xy.x *= 1 + d;
    }
    if (xy.y > 0) {
      xy.y *= 1 + d / 1.5 * xy.x * xy.x;
    }

    return xy;
  }
}


pj_add(pj_boggs, 'boggs', 'Boggs Eumorphic', 'PCyl., no inv., Sph.');

function pj_boggs(P) {
  var NITER = 20,
      EPS = 1e-7,
      ONETOL = 1.000001,
      M_SQRT2 = sqrt(2),
      FXC = 2.00276,
      FXC2 = 1.11072,
      FYC = 0.49931;
  P.fwd = s_fwd;
  P.es = 0;

  function s_fwd(lp, xy) {
    var theta, th1, c, i;
    theta = lp.phi;
    if (fabs(fabs(lp.phi) - M_HALFPI) < EPS)
      xy.x = 0;
    else {
      c = sin(theta) * M_PI;
      for (i = NITER; i; --i) {
        theta -= th1 = (theta + sin(theta) - c) /
          (1 + cos(theta));
        if (fabs(th1) < EPS) break;
      }
      theta *= 0.5;
      xy.x = FXC * lp.lam / (1 / cos(lp.phi) + FXC2 / cos(theta));
    }
    xy.y = FYC * (lp.phi + M_SQRT2 * sin(theta));
  }
}


pj_add(pj_bonne, 'bonne', 'Bonne (Werner lat_1=90)', 'Conic Sph&Ell\nlat_1=');

function pj_bonne(P) {
  var EPS10 = 1e-10;
  var phi1, cphi1, am1, m1, en, c;

  phi1 = pj_param(P.params, "rlat_1");
  if (fabs(phi1) < EPS10) e_error(-23);
  if (P.es) {
    en = pj_enfn(P.es);
    m1 = pj_mlfn(phi1, am1 = sin(phi1),
      c = cos(phi1), en);
    am1 = c / (sqrt(1 - P.es * am1 * am1) * am1);
    P.inv = e_inv;
    P.fwd = e_fwd;
  } else {
    if (fabs(phi1) + EPS10 >= M_HALFPI)
      cphi1 = 0;
    else
      cphi1 = 1 / tan(phi1);
    P.inv = s_inv;
    P.fwd = s_fwd;
  }

  function e_fwd(lp, xy) {
    var rh, E, c;
    rh = am1 + m1 - pj_mlfn(lp.phi, E = sin(lp.phi), c = cos(lp.phi), en);
    E = c * lp.lam / (rh * sqrt(1 - P.es * E * E));
    xy.x = rh * sin(E);
    xy.y = am1 - rh * cos(E);
  }

  function e_inv(xy, lp) {
    var s, rh;
    rh = hypot(xy.x, xy.y = am1 - xy.y);
    lp.phi = pj_inv_mlfn(am1 + m1 - rh, P.es, en);
    if ((s = fabs(lp.phi)) < M_HALFPI) {
      s = sin(lp.phi);
      lp.lam = rh * atan2(xy.x, xy.y) * sqrt(1 - P.es * s * s) / cos(lp.phi);
    } else if (fabs(s - M_HALFPI) <= EPS10)
      lp.lam = 0;
    else i_error();
  }

  function s_fwd(lp, xy) {
    var E, rh;
    rh = cphi1 + phi1 - lp.phi;
    if (fabs(rh) > EPS10) {
      xy.x = rh * sin(E = lp.lam * cos(lp.phi) / rh);
      xy.y = cphi1 - rh * cos(E);
    } else
      xy.x = xy.y = 0;
  }

  function s_inv(xy, lp) {
    var rh = hypot(xy.x, xy.y = cphi1 - xy.y);
    lp.phi = cphi1 + phi1 - rh;
    if (fabs(lp.phi) > M_HALFPI) i_error();
    if (fabs(fabs(lp.phi) - M_HALFPI) <= EPS10)
      lp.lam = 0;
    else
      lp.lam = rh * atan2(xy.x, xy.y) / cos(lp.phi);
  }
}


pj_add(pj_cass, 'cass', 'Cassini', 'Cyl, Sph&Ell');

function pj_cass(P) {
  var C1 = 0.16666666666666666666,
      C2 = 0.00833333333333333333,
      C3 = 0.04166666666666666666,
      C4 = 0.33333333333333333333,
      C5 = 0.06666666666666666666;
  var m0, en;

  if (P.es) {
    en = pj_enfn(P.es);
    m0 = pj_mlfn(P.phi0,  sin(P.phi0),  cos(P.phi0), en);
    P.fwd = e_fwd;
    P.inv = e_inv;
  } else {
    P.fwd = s_fwd;
    P.inv = s_inv;
  }

  function e_fwd(lp, xy) {
    var n, t, a1, c, a2, tn;
    xy.y = pj_mlfn(lp.phi, n = sin(lp.phi), c = cos(lp.phi), en);

    n  = 1/sqrt(1 - P.es * n*n);
    tn = tan(lp.phi); t = tn * tn;
    a1 = lp.lam * c;
    c *= P.es * c / (1 - P.es);
    a2 = a1 * a1;

    xy.x = n * a1 * (1 - a2 * t * (C1 - (8 - t + 8 * c) * a2 * C2));
    xy.y -= m0 - n * tn * a2 * (0.5 + (5 - t + 6 * c) * a2 * C3);
  }

  function e_inv(xy, lp) {
    var n, t, r, dd, d2, tn, ph1;
    ph1 = pj_inv_mlfn (m0 + xy.y, P.es, en);
    tn  = tan(ph1); t = tn*tn;
    n   = sin(ph1);
    r   = 1 / (1 - P.es * n * n);
    n   = sqrt (r);
    r  *= (1 - P.es) * n;
    dd  = xy.x / n;
    d2  = dd * dd;
    lp.phi = ph1 - (n * tn / r) * d2 *(0.5 - (1 + 3 * t) * d2 * C3);
    lp.lam = dd * (1 + t * d2 * (-C4 + (1 + 3 * t) * d2 * C5)) / cos(ph1);
  }

  function s_fwd(lp, xy) {
    xy.x  =  asin(cos(lp.phi) * sin(lp.lam));
    xy.y  =  atan2(tan(lp.phi), cos(lp.lam)) - P.phi0;
  }

  function s_inv(xy, lp) {
    var dd =  xy.y + P.phi0;
    lp.phi = asin(sin(dd) * cos(xy.x));
    lp.lam = atan2(tan(xy.x), cos(dd));
  }
}



function pj_authset(es) {
  var P00 = 0.33333333333333333333 /*   1 /     3 */,
      P01 = 0.17222222222222222222 /*  31 /   180 */,
      P02 = 0.10257936507936507937 /* 517 /  5040 */,
      P10 = 0.06388888888888888888 /*  23 /   360 */,
      P11 = 0.06640211640211640212 /* 251 /  3780 */,
      P20 = 0.01677689594356261023 /* 761 / 45360 */,
      APA = [];
  var t;

  APA[0] = es * P00;
  t = es * es;
  APA[0] += t * P01;
  APA[1] = t * P10;
  t *= es;
  APA[0] += t * P02;
  APA[1] += t * P11;
  APA[2] = t * P20;
  return APA;
}

function pj_authlat(beta, APA) {
  var t = beta + beta;
  return(beta + APA[0] * sin(t) + APA[1] * sin(t+t) + APA[2] * sin(t+t+t));
}


pj_add(pj_cea, 'cea', 'Equal Area Cylindrical', 'Cyl, Sph&Ell\nlat_ts=');

function pj_cea(P) {
  var t = 0, qp, apa;
  if (pj_param(P.params, "tlat_ts")) {
    P.k0 = cos(t = pj_param(P.params, "rlat_ts"));
    if (P.k0 < 0) {
      e_error(-24);
    }
  }
  if (P.es) {
    t = sin(t);
    P.k0 /= sqrt(1 - P.es * t * t);
    P.e = sqrt(P.es);
    if (!(apa = pj_authset(P.es))) e_error_0();
    qp = pj_qsfn(1, P.e, P.one_es);
    P.fwd = e_fwd;
    P.inv = e_inv;
  } else {
    P.fwd = s_fwd;
    P.inv = s_inv;
  }

  function e_fwd(lp, xy) {
    xy.x = P.k0 * lp.lam;
    xy.y = 0.5 * pj_qsfn(sin (lp.phi), P.e, P.one_es) / P.k0;
  }

  function e_inv(xy, lp) {
    lp.phi = pj_authlat(asin(2 * xy.y * P.k0 / qp), apa);
    lp.lam = xy.x / P.k0;
  }

  function s_fwd(lp, xy) {
    xy.x = P.k0 * lp.lam;
    xy.y = sin(lp.phi) / P.k0;
  }

  function s_inv(xy, lp) {
    var x = xy.x, y = xy.y;
    var t;
    if ((t = fabs(y *= P.k0)) - EPS10 <= 1) {
      if (t >= 1)
        lp.phi = y < 0 ? -M_HALFPI : M_HALFPI;
      else
        lp.phi = asin(y);
      lp.lam = x / P.k0;
    } else i_error();
  }
}


pj_add(pj_chamb, 'chamb', 'Chamberlin Trimetric', 'Misc Sph, no inv.\nlat_1= lon_1= lat_2= lon_2= lat_3= lon_3=');

function pj_chamb(P) {
  var THIRD  = 1/3,
      TOL = 1e-9,
      c = [],
      x0, y0,
      v, beta_0, beta_1, beta_2, i, j;

  for (i = 0; i < 3; ++i) { /* get control point locations */
    c[i] = {p: {}};
    c[i].phi = pj_param(P.params, 'rlat_' + (i+1));
    c[i].lam = pj_param(P.params, 'rlon_' + (i+1));
    c[i].lam = adjlon(c[i].lam - P.lam0);
    c[i].cosphi = cos(c[i].phi);
    c[i].sinphi = sin(c[i].phi);
  }
  for (i = 0; i < 3; ++i) { /* inter ctl pt. distances and azimuths */
    j = i == 2 ? 0 : i + 1;
    c[i].v = vect(c[j].phi - c[i].phi, c[i].cosphi, c[i].sinphi,
        c[j].cosphi, c[j].sinphi, c[j].lam - c[i].lam);

    if (!c[i].v.r) e_error(-25);
    /* co-linearity problem ignored for now */
  }
  beta_0 = lc(c[0].v.r, c[2].v.r, c[1].v.r);
  beta_1 = lc(c[0].v.r, c[1].v.r, c[2].v.r);
  beta_2 = M_PI - beta_0;
  y0 = 2 * (c[0].p.y = c[1].p.y = c[2].v.r * sin(beta_0));
  c[2].p.y = 0;
  c[0].p.x = -(c[1].p.x = 0.5 * c[0].v.r);
  x0 = c[2].p.x = c[0].p.x + c[2].v.r * cos(beta_0);

  P.es = 0;
  P.fwd = s_fwd;

  function s_fwd(lp, xy) {
    var sinphi, cosphi, a, i, j, x, y;
    var v = [];
    sinphi = sin(lp.phi);
    cosphi = cos(lp.phi);
    for (i = 0; i < 3; ++i) { /* dist/azimiths from control */
      v[i] = vect(lp.phi - c[i].phi, c[i].cosphi, c[i].sinphi,
          cosphi, sinphi, lp.lam - c[i].lam);
      if (!v[i].r)
          break;
      v[i].Az = adjlon(v[i].Az - c[i].v.Az);
    }
    if (i < 3) { /* current point at control point */
      x = c[i].p.x;
      y = c[i].p.y;
    } else { /* point mean of intercepts */
      x = x0;
      y = y0;
      for (i = 0; i < 3; ++i) {
        j = i == 2 ? 0 : i + 1;
        a = lc(c[i].v.r, v[i].r, v[j].r);
        if (v[i].Az < 0)
          a = -a;
        if (! i) { /* coord comp unique to each arc */
          x += v[i].r * cos(a);
          y -= v[i].r * sin(a);
        } else if (i == 1) {
          a = beta_1 - a;
          x -= v[i].r * cos(a);
          y -= v[i].r * sin(a);
        } else {
          a = beta_2 - a;
          x += v[i].r * cos(a);
          y += v[i].r * sin(a);
        }
      }
      x *= THIRD; /* mean of arc intercepts */
      y *= THIRD;
    }
    xy.x = x;
    xy.y = y;
  }

  function vect(dphi, c1, s1, c2, s2, dlam) {
    var v = {};
    var cdl, dp, dl;
    cdl = cos(dlam);
    if (fabs(dphi) > 1 || fabs(dlam) > 1)
      v.r = aacos(cs1 * s2 + c1 * c2 * cdl);
    else { /* more accurate for smaller distances */
      dp = sin(0.5 * dphi);
      dl = sin(0.5 * dlam);
      v.r = 2 * aasin(sqrt(dp * dp + c1 * c2 * dl * dl));
    }
    if (fabs(v.r) > TOL)
      v.Az = atan2(c2 * sin(dlam), c1 * s2 - s1 * c2 * cdl);
    else
      v.r = v.Az = 0;
    return v;
  }

  /* law of cosines */
  function lc(b, c, a) {
    return aacos(0.5 * (b * b + c * c - a * a) / (b * c));
  }
}


pj_add(pj_crast, 'crast', 'Craster Parabolic (Putnins P4)', 'PCyl., Sph.');

function pj_crast(P) {
  var XM = 0.97720502380583984317;
  var RXM = 1.02332670794648848847;
  var YM = 3.06998012383946546542;
  var RYM = 0.32573500793527994772;
  var THIRD = 1/3;
  P.inv = s_inv;
  P.fwd = s_fwd;
  P.es = 0;

  function s_fwd(lp, xy) {
    lp.phi *= THIRD;
    xy.x = XM * lp.lam * (2 * cos(lp.phi + lp.phi) - 1);
    xy.y = YM * sin(lp.phi);
  }

  function s_inv(xy, lp) {
    lp.phi = 3 * asin(xy.y * RYM);
    lp.lam = xy.x * RXM / (2 * cos((lp.phi + lp.phi) * THIRD) - 1);
  }
}


pj_add(pj_cupola, 'cupola', 'Cupola', 'PCyl., Sph., NoInv.');

// Source: https://www.tandfonline.com/eprint/EE7Y8RK4GXA4ITWUTQPY/full?target=10.1080/23729333.2020.1862962
// See also: http://www.at-a-lanta.nl/weia/cupola.html

function pj_cupola(P) {
  var de = 0.5253;  // part of the equator on intermediate sphere, default = 1
  var dp = 0.7264;  // sin of angle of polar line, default = 1
  var ri = 1 / Math.sqrt(de * dp);
  var he = 0.4188; // height of equator (can be negative, default = 0)
  var se = 0.9701; // stretch in plane, default = 1
  var phi0 = 22 * DEG_TO_RAD; // phi of projection center
  // center of projection on intermediate sphere
  var pc = calcP(phi0);
  var qc = calcQ(0);
  var spc = sin(pc);
  var cpc = cos(pc);

  // apply default central meridian
  if (!pj_param(P.params, 'tlon_0')) {
    P.lam0 = 11.023 * DEG_TO_RAD;
  }

  P.es = 0;
  P.fwd = s_fwd;

  function calcP(phi) {
    return asin(dp * sin(phi) + he * sqrt(de * dp));
  }

  function calcQ(lam) {
    return de * lam;
  }

  function s_fwd(lp, xy) {
    var p = calcP(lp.phi);
    var q = calcQ(lp.lam);
    var sp = sin(p);
    var cp = cos(p);
    var sqqc = sin(q - qc);
    var cqqc = cos(q - qc);
    var K = sqrt(2 / (1 + sin(pc) * sp + cpc * cp * cqqc));
    xy.x = ri * K * cp * sqqc * se;
    xy.y = ri * K * (cpc * sp - spc * cp * cqqc) / se;
  }
}


pj_add(pj_denoy, 'denoy', 'Denoyer Semi-Elliptical', 'PCyl, Sph., no inv.');

function pj_denoy(P) {
  P.fwd = s_fwd;
  P.es = 0;

  function s_fwd(lp, xy) {
    var C0 = 0.95;
    var C1 = -0.08333333333333333333;
    var C3 = 0.00166666666666666666;
    var D1 = 0.9;
    var D5 = 0.03;
    var lam = fabs(lp.lam);
    xy.y = lp.phi;
    xy.x = lp.lam;
    xy.x *= cos((C0 + lam * (C1 + lam * lam * C3)) *
            (lp.phi * (D1 + D5 * lp.phi * lp.phi * lp.phi * lp.phi)));

  }
}


pj_add(pj_eck1, 'eck1', 'Eckert I', 'PCyl Sph');
pj_add(pj_eck2, 'eck2', 'Eckert II', 'PCyl Sph');
pj_add(pj_eck3, 'eck3', 'Eckert III', 'PCyl Sph');
pj_add(pj_wag6, 'wag6', 'Wagner VI', 'PCyl Sph');
pj_add(pj_kav7, 'kav7', 'Kavraisky VII', 'PCyl Sph');
pj_add(pj_putp1, 'putp1', 'Putnins P1', 'PCyl Sph');
pj_add(pj_eck4, 'eck4', 'Eckert IV', 'PCyl Sph');
pj_add(pj_eck5, 'eck5', 'Eckert V', 'PCyl Sph');

function pj_eck1(P) {
  var FC = 0.92131773192356127802,
      RP = 0.31830988618379067154;
  P.es = 0;
  P.fwd = s_fwd;
  P.inv = s_inv;

  function s_fwd(lp, xy) {
    xy.x = FC * lp.lam * (1 - RP * fabs(lp.phi));
    xy.y = FC * lp.phi;
  }

  function s_inv(xy, lp) {
    lp.phi = xy.y / FC;
    lp.lam = xy.x / (FC * (1 - RP * fabs(lp.phi)));
  }
}

function pj_eck2(P) {
  var FXC = 0.46065886596178063902,
      FYC = 1.44720250911653531871,
      C13 = 0.33333333333333333333,
      ONEEPS = 1.0000001;
  P.es = 0;
  P.fwd = s_fwd;
  P.inv = s_inv;

  function s_fwd(lp, xy) {
    xy.x = FXC * lp.lam * (xy.y = sqrt(4 - 3 * sin(fabs(lp.phi))));
    xy.y = FYC * (2 - xy.y);
    if (lp.phi < 0) xy.y = -xy.y;
  }

  function s_inv(xy, lp) {
    lp.lam = xy.x / (FXC * (lp.phi = 2 - fabs(xy.y) / FYC));
    lp.phi = (4 - lp.phi * lp.phi) * C13;
    if (fabs(lp.phi) >= 1) {
      if (fabs(lp.phi) > ONEEPS) i_error();
      else
        lp.phi = lp.phi < 0 ? -M_HALFPI : M_HALFPI;
    } else
      lp.phi = asin(lp.phi);
    if (xy.y < 0)
      lp.phi = -lp.phi;
  }
}

function pj_eck3(P) {
  var Q = {
    C_x: 0.42223820031577120149,
    C_y: 0.84447640063154240298,
    A: 1,
    B: 0.4052847345693510857755
  };
  pj_eck3_init(P, Q);
}

function pj_kav7(P) {
  var Q = {
    C_x: 0.8660254037844,
    C_y: 1,
    A: 0,
    B: 0.30396355092701331433
  };
  pj_eck3_init(P, Q);
}

function pj_wag6(P) {
  var Q = {
    C_x: 0.94745,
    C_y: 0.94745,
    A: 0,
    B: 0.30396355092701331433
  };
  pj_eck3_init(P, Q);
}

function pj_putp1(P) {
  var Q = {
    C_x: 1.89490,
    C_y: 0.94745,
    A: -0.5,
    B: 0.30396355092701331433
  };
  pj_eck3_init(P, Q);
}

function pj_eck3_init(P, Q) {
  P.es = 0;
  P.fwd = s_fwd;
  P.inv = s_inv;

  function s_fwd(lp, xy) {
    xy.y = Q.C_y * lp.phi;
    xy.x = Q.C_x * lp.lam * (Q.A + asqrt(1 - Q.B * lp.phi * lp.phi));
  }

  function s_inv(xy, lp) {
    lp.phi = xy.y / Q.C_y;
    lp.lam = xy.x / (Q.C_x * (Q.A + asqrt(1 - Q.B * lp.phi * lp.phi)));
  }
}

function pj_eck4(P) {
  var C_x = 0.42223820031577120149,
      C_y = 1.32650042817700232218,
      RC_y = 0.75386330736002178205,
      C_p = 3.57079632679489661922,
      RC_p = 0.28004957675577868795,
      EPS = 1e-7,
      NITER = 6;

  P.es = 0;
  P.fwd = s_fwd;
  P.inv = s_inv;

  function s_fwd(lp, xy) {
    var p, V, s, c, i;
    p = C_p * sin(lp.phi);
    V = lp.phi * lp.phi;
    lp.phi *= 0.895168 + V * ( 0.0218849 + V * 0.00826809 );
    for (i = NITER; i; --i) {
      c = cos(lp.phi);
      s = sin(lp.phi);
      lp.phi -= V = (lp.phi + s * (c + 2) - p) /
          (1 + c * (c + 2) - s * s);
      if (fabs(V) < EPS)
        break;
    }
    if (!i) {
      xy.x = C_x * lp.lam;
      xy.y = lp.phi < 0 ? -C_y : C_y;
    } else {
      xy.x = C_x * lp.lam * (1 + cos(lp.phi));
      xy.y = C_y * sin(lp.phi);
    }
  }

  function s_inv(xy, lp) {
    var c;
    lp.phi = aasin(xy.y / C_y);
    lp.lam = xy.x / (C_x * (1 + (c = cos(lp.phi))));
    lp.phi = aasin((lp.phi + sin(lp.phi) * (c + 2)) / C_p);
  }
}

function pj_eck5(P) {
  var XF = 0.44101277172455148219,
      RXF = 2.26750802723822639137,
      YF = 0.88202554344910296438,
      RYF = 1.13375401361911319568;

  P.es = 0;
  P.fwd = s_fwd;
  P.inv = s_inv;

  function s_fwd(lp, xy) {
    xy.x = XF * (1 + cos(lp.phi)) * lp.lam;
    xy.y = YF * lp.phi;
  }

  function s_inv(xy, lp) {
    lp.lam = RXF * xy.x / (1 + cos(lp.phi = RYF * xy.y));
  }
}


pj_add(pj_eqc, 'eqc', 'Equidistant Cylindrical (Plate Caree)', 'Cyl, Sph\nlat_ts=[, lat_0=0]');

function pj_eqc(P) {
  var rc = cos(pj_param(P.params, "rlat_ts"));
  if (rc <= 0) e_error(-24);
  P.es = 0;
  P.fwd = s_fwd;
  P.inv = s_inv;

  function s_fwd(lp, xy) {
    xy.x = rc * lp.lam;
    xy.y = lp.phi -P.phi0;
  }

  function s_inv(xy, lp) {
    lp.lam = xy.x / rc;
    lp.phi = xy.y + P.phi0;
  }
}


pj_add(pj_eqdc, 'eqdc', 'Equidistant Conic', 'Conic, Sph&Ell\nlat_1= lat_2=');

function pj_eqdc(P) {
  var phi1, phi2, n, rho, rho0, c, en, ellips, cosphi, sinphi, secant;
  var ml1, m1;
  phi1 = pj_param(P.params, "rlat_1");
  phi2 = pj_param(P.params, "rlat_2");
  if (fabs(phi1 + phi2) < EPS10) e_error(-21);
  if (!(en = pj_enfn(P.es)))
      e_error_0();
  n = sinphi = sin(phi1);
  cosphi = cos(phi1);
  secant = fabs(phi1 - phi2) >= EPS10;
  if ((ellips = (P.es > 0)) ) {
    m1 = pj_msfn(sinphi, cosphi, P.es);
    ml1 = pj_mlfn(phi1, sinphi, cosphi, en);
    if (secant) { /* secant cone */
      sinphi = sin(phi2);
      cosphi = cos(phi2);
      n = (m1 - pj_msfn(sinphi, cosphi, P.es)) /
          (pj_mlfn(phi2, sinphi, cosphi, en) - ml1);
    }
    c = ml1 + m1 / n;
    rho0 = c - pj_mlfn(P.phi0, sin(P.phi0),
      cos(P.phi0), en);
  } else {
    if (secant)
       n = (cosphi - cos(phi2)) / (phi2 - phi1);
    c = phi1 + cos(phi1) / n;
    rho0 = c - P.phi0;
  }

  P.fwd = e_fwd;
  P.inv = e_inv;

  function e_fwd(lp, xy) {
    rho = c - (ellips ? pj_mlfn(lp.phi, sin(lp.phi),
        cos(lp.phi), en) : lp.phi);
    xy.x = rho * sin( lp.lam *= n );
    xy.y = rho0 - rho * cos(lp.lam);
  }

  function e_inv(xy, lp) {
    if ((rho = hypot(xy.x, xy.y = rho0 - xy.y)) != 0.0 ) {
      if (n < 0) {
        rho = -rho;
        xy.x = -xy.x;
        xy.y = -xy.y;
      }
      lp.phi = c - rho;
      if (ellips)
        lp.phi = pj_inv_mlfn(lp.phi, P.es, en);
      lp.lam = atan2(xy.x, xy.y) / n;
    } else {
      lp.lam = 0;
      lp.phi = n > 0 ? M_HALFPI : -M_HALFPI;
    }
  }
}


/**
 * Copyright 2018 Bernie Jenny, Monash University, Melbourne, Australia.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 * Equal Earth is a projection inspired by the Robinson projection, but unlike
 * the Robinson projection retains the relative size of areas. The projection
 * was designed in 2018 by Bojan Savric, Tom Patterson and Bernhard Jenny.
 *
 * Publication:
 * Bojan Savric, Tom Patterson & Bernhard Jenny (2018). The Equal Earth map
 * projection, International Journal of Geographical Information Science,
 * DOI: 10.1080/13658816.2018.1504949
 *
 * Code released August 2018
 * Ported to JavaScript and adapted for mapshaper-proj by Matthew Bloch August 2018
 */
pj_add(pj_eqearth, 'eqearth', 'Equal Earth', 'PCyl., Sph.');

function pj_eqearth(P) {
  var A1 = 1.340264,
      A2 = -0.081106,
      A3 = 0.000893,
      A4 = 0.003796,
      M = Math.sqrt(3) / 2.0;

  P.es = 0;
  P.fwd = s_fwd;
  P.inv = s_inv;

  function s_fwd(lp, xy) {
    var paramLat = Math.asin(M * Math.sin(lp.phi)),
        paramLatSq = paramLat * paramLat,
        paramLatPow6 = paramLatSq * paramLatSq * paramLatSq;
    xy.x = lp.lam * Math.cos(paramLat) /
            (M * (A1 + 3 * A2 * paramLatSq + paramLatPow6 * (7 * A3 + 9 * A4 * paramLatSq)));
    xy.y = paramLat * (A1 + A2 * paramLatSq + paramLatPow6 * (A3 + A4 * paramLatSq));
  }

  function s_inv(xy, lp) {
    var EPS = 1e-9,
        NITER = 12,
        paramLat = xy.y,
        paramLatSq, paramLatPow6, fy, fpy, dlat, i;

    for (i = 0; i < NITER; ++i) {
      paramLatSq = paramLat * paramLat;
      paramLatPow6 = paramLatSq * paramLatSq * paramLatSq;
      fy = paramLat * (A1 + A2 * paramLatSq + paramLatPow6 * (A3 + A4 * paramLatSq)) - xy.y;
      fpy = A1 + 3 * A2 * paramLatSq + paramLatPow6 * (7 * A3 + 9 * A4 * paramLatSq);
      paramLat -= dlat = fy / fpy;
      if (Math.abs(dlat) < EPS) {
          break;
      }
    }
    paramLatSq = paramLat * paramLat;
    paramLatPow6 = paramLatSq * paramLatSq * paramLatSq;
    lp.lam = M * xy.x * (A1 + 3 * A2 * paramLatSq + paramLatPow6 * (7 * A3 + 9 * A4 * paramLatSq)) /
            Math.cos(paramLat);
    lp.phi = Math.asin(Math.sin(paramLat) / M);
  }
}


pj_add(pj_etmerc, 'etmerc', 'Extended Transverse Mercator', 'Cyl, Sph\nlat_ts=(0)\nlat_0=(0)');

function pj_etmerc(P) {
  var cgb = [],
      cbg = [],
      utg = [],
      gtu = [],
      Qn, Zb, f, n, np, Z;
  if (P.es <= 0) e_error(-34);
  /* flattening */
  f = P.es / (1 + sqrt(1 - P.es)); /* Replaces: f = 1 - sqrt(1-P.es); */
  /* third flattening */
  np = n = f/(2 - f);
  /* COEF. OF TRIG SERIES GEO <-> GAUSS */
  /* cgb := Gaussian -> Geodetic, KW p190 - 191 (61) - (62) */
  /* cbg := Geodetic -> Gaussian, KW p186 - 187 (51) - (52) */
  /* PROJ_ETMERC_ORDER = 6th degree : Engsager and Poder: ICC2007 */
  cgb[0] = n*(2 + n*(-2/3 + n * (-2 + n*(116/45 + n * (26/45 + n*(-2854/675 ))))));
  cbg[0] = n*(-2 + n*( 2/3 + n*( 4/3 + n*(-82/45 + n*(32/45 + n*(4642/4725))))));
  np *= n;
  cgb[1] = np*(7/3 + n*(-8/5 + n*(-227/45 + n*(2704/315 + n*(2323/945)))));
  cbg[1] = np*(5/3 + n*(-16/15 + n*( -13/9 + n*(904/315 + n*(-1522/945)))));
  np *= n;
  /* n^5 coeff corrected from 1262/105 -> -1262/105 */
  cgb[2] = np*(56/15 + n*(-136/35 + n*(-1262/105 + n*(73814/2835))));
  cbg[2] = np*(-26/15 + n*(34/21 + n*(8/5 + n*(-12686/2835))));
  np *= n;
  /* n^5 coeff corrected from 322/35 -> 332/35 */
  cgb[3] = np*(4279/630 + n*(-332/35 + n*(-399572/14175)));
  cbg[3] = np*(1237/630 + n*(-12/5 + n*( -24832/14175)));
  np *= n;
  cgb[4] = np*(4174/315 + n*(-144838/6237));
  cbg[4] = np*(-734/315 + n*(109598/31185));
  np *= n;
  cgb[5] = np*(601676/22275);
  cbg[5] = np*(444337/155925);

  /* Constants of the projections */
  /* Transverse Mercator (UTM, ITM, etc) */
  np = n*n;
  /* Norm. mer. quad, K&W p.50 (96), p.19 (38b), p.5 (2) */
  Qn = P.k0/(1 + n) * (1 + np*(1/4 + np*(1/64 + np/256)));
  /* coef of trig series */
  /* utg := ell. N, E -> sph. N, E,  KW p194 (65) */
  /* gtu := sph. N, E -> ell. N, E,  KW p196 (69) */
  utg[0] = n*(-0.5 + n*( 2/3 + n*(-37/96 + n*( 1/360 + n*(81/512 + n*(-96199/604800))))));
  gtu[0] = n*(0.5 + n*(-2/3 + n*(5/16 + n*(41/180 + n*(-127/288 + n*(7891/37800))))));
  utg[1] = np*(-1/48 + n*(-1/15 + n*(437/1440 + n*(-46/105 + n*(1118711/3870720)))));
  gtu[1] = np*(13/48 + n*(-3/5 + n*(557/1440 + n*(281/630 + n*(-1983433/1935360)))));
  np *= n;
  utg[2] = np*(-17/480 + n*(37/840 + n*(209/4480 + n*(-5569/90720 ))));
  gtu[2] = np*(61/240 + n*(-103/140 + n*(15061/26880 + n*(167603/181440))));
  np *= n;
  utg[3] = np*(-4397/161280 + n*(11/504 + n*(830251/7257600)));
  gtu[3] = np*(49561/161280 + n*(-179/168 + n*(6601661/7257600)));
  np *= n;
  utg[4] = np*(-4583/161280 + n*(108847/3991680));
  gtu[4] = np*(34729/80640  + n*(-3418889/1995840));
  np *= n;
  utg[5] = np*(-20648693/638668800);
  gtu[5] = np*(212378941/319334400);

   /* Gaussian latitude value of the origin latitude */
  Z = gatg(cbg, P.phi0);

  /* Origin northing minus true northing at the origin latitude */
  /* i.e. true northing = N - P.Zb  */
  Zb = -Qn*(Z + clens(gtu, 2*Z));
  P.fwd = e_fwd;
  P.inv = e_inv;

  function e_fwd(lp, xy) {
    var sin_Cn, cos_Cn, cos_Ce, sin_Ce, tmp;
    var Cn = lp.phi, Ce = lp.lam;

    /* ell. LAT, LNG -> Gaussian LAT, LNG */
    Cn = gatg(cbg, Cn);
    /* Gaussian LAT, LNG -> compl. sph. LAT */
    sin_Cn = sin(Cn);
    cos_Cn = cos(Cn);
    sin_Ce = sin(Ce);
    cos_Ce = cos(Ce);
    Cn = atan2(sin_Cn, cos_Ce*cos_Cn);
    Ce = atan2(sin_Ce*cos_Cn, hypot(sin_Cn, cos_Cn*cos_Ce));
    /* compl. sph. N, E -> ell. norm. N, E */
    Ce = asinhy(tan(Ce));
    tmp = clenS(gtu, 2*Cn, 2*Ce);
    Cn += tmp[0];
    Ce += tmp[1];
    if (fabs (Ce) <= 2.623395162778) {
        xy.y  = Qn * Cn + Zb;  /* Northing */
        xy.x  = Qn * Ce;       /* Easting  */
    } else {
      xy.x = xy.y = HUGE_VAL;
    }
  }

  function e_inv(xy, lp) {
    var sin_Cn, cos_Cn, cos_Ce, sin_Ce, tmp;
    var Cn = xy.y, Ce = xy.x;
    /* normalize N, E */
    Cn = (Cn - Zb)/Qn;
    Ce = Ce/Qn;
    if (fabs(Ce) <= 2.623395162778) { /* 150 degrees */
      /* norm. N, E -> compl. sph. LAT, LNG */
      tmp = clenS(utg, 2*Cn, 2*Ce);
      Cn += tmp[0];
      Ce += tmp[1];
      Ce = atan(sinh(Ce)); /* Replaces: Ce = 2*(atan(exp(Ce)) - M_FORTPI); */
      /* compl. sph. LAT -> Gaussian LAT, LNG */
      sin_Cn = sin(Cn);
      cos_Cn = cos(Cn);
      sin_Ce = sin(Ce);
      cos_Ce = cos(Ce);
      Ce = atan2(sin_Ce, cos_Ce*cos_Cn);
      Cn = atan2(sin_Cn*cos_Ce, hypot(sin_Ce, cos_Ce*cos_Cn));
      /* Gaussian LAT, LNG -> ell. LAT, LNG */
      lp.phi = gatg (cgb, Cn);
      lp.lam = Ce;
    }
    else {
      lp.phi = lp.lam = HUGE_VAL;
    }
  }

  function log1py(x) {
    var y = 1 + x,
        z = y - 1;
    return z === 0 ? x : x * log(y) / z;
  }

  function asinhy(x) {
    var y = fabs(x);
    y = log1py(y * (1 + y/(hypot(1, y) + 1)));
    return x < 0 ? -y : y;
  }

  function gatg(pp, B) {
    var cos_2B = 2 * cos(2 * B),
        i = pp.length - 1,
        h1 = pp[i],
        h2 = 0,
        h;
    while (--i >= 0) {
      h = -h2 + cos_2B * h1 + pp[i];
      h2 = h1;
      h1 = h;
    }
    return (B + h * sin(2 * B));
  }

  function clens(pp, arg_r) {
    var r = 2 * cos(arg_r),
        i = pp.length - 1,
        hr1 = pp[i],
        hr2 = 0,
        hr;
    while (--i >= 0) {
      hr = -hr2 + r * hr1 + pp[i];
      hr2 = hr1;
      hr1 = hr;
    }
    return sin(arg_r) * hr;
  }

  function clenS(pp, arg_r, arg_i) {
    var sin_arg_r = sin(arg_r),
        cos_arg_r = cos(arg_r),
        sinh_arg_i = sinh(arg_i),
        cosh_arg_i = cosh(arg_i),
        r = 2 * cos_arg_r * cosh_arg_i,
        i = -2 * sin_arg_r * sinh_arg_i,
        j = pp.length - 1,
        hr = pp[j],
        hi1 = 0,
        hr1 = 0,
        hi = 0,
        hr2, hi2;
    while (--j >= 0) {
      hr2 = hr1;
      hi2 = hi1;
      hr1 = hr;
      hi1 = hi;
      hr = -hr2 + r*hr1 - i * hi1 + pp[j];
      hi = -hi2 + i*hr1 + r * hi1;
    }
    r = sin_arg_r * cosh_arg_i;
    i = cos_arg_r * sinh_arg_i;
    return [r * hr - i * hi, r * hi + i * hr];
  }
}


pj_add(pj_gall, 'gall', 'Gall (Gall Stereographic)', 'Cyl, Sph');

function pj_gall(P) {
  var YF = 1.70710678118654752440,
      XF = 0.70710678118654752440,
      RYF = 0.58578643762690495119,
      RXF = 1.41421356237309504880;

  P.fwd = s_fwd;
  P.inv = s_inv;
  P.es = 0;

  function s_fwd(lp, xy) {
    xy.x = XF * lp.lam;
    xy.y = YF * tan(0.5 * lp.phi);
  }

  function s_inv(xy, lp) {
    lp.lam = RXF * xy.x;
    lp.phi = 2 * atan(xy.y * RYF);
  }
}


pj_add(pj_geocent, 'geocent', 'Geocentric', '');

function pj_geocent(P) {
  P.is_geocent = true;
  P.x0 = 0;
  P.y0 = 0;

  P.fwd = function (lp, xy) {
    xy.x = lp.lam;
    xy.y = lp.phi;
  };

  P.inv = function(xy, lp) {
    lp.phi = xy.y;
    lp.lam = xy.x;
  };
}


// from

pj_add(pj_gilbert, 'gilbert', 'Gilbert Two World Perspective', 'PCyl., Sph., NoInv.\nlat_1=');

function pj_gilbert(P) {
  var lat1 = pj_param(P.params, 'tlat_1') ? pj_param(P.params, 'rlat_1') : 0,
      phi1 = phiprime(lat1),
      sp1 = sin(phi1),
      cp1 = cos(phi1);
  P.fwd = s_fwd;
  P.es = 0;

  function s_fwd(lp, xy) {
    var lam = lp.lam * 0.5,
        phi = phiprime(lp.phi),
        sp = sin(phi),
        cp = cos(phi),
        cl = cos(lam);
    if ((sp1*sp + cp1*cp*cl) >= 0) {
      xy.x = cp * sin(lam);
      xy.y = cp1 * sp - sp1 * cp * cl;
    } else {
      f_error();
    }
  }

  function phiprime(phi) {
    return aasin(tan(0.5 * phi));
  }
}


pj_add(pj_gins8, 'gins8', 'Ginsburg VIII (TsNIIGAiK)', 'PCyl, Sph., no inv.');

function pj_gins8(P) {
  P.fwd = s_fwd;
  P.es = 0;

  function s_fwd(lp, xy) {
    var Cl = 0.000952426;
    var Cp = 0.162388;
    var C12 = 0.08333333333333333;
    var t = lp.phi * lp.phi;
    xy.y = lp.phi * (1 + t * C12);
    xy.x = lp.lam * (1 - Cp * t);
    t = lp.lam * lp.lam;
    xy.x *= (0.87 - Cl * t * t);
  }
}


pj_add(pj_gn_sinu, 'gn_sinu', 'General Sinusoidal Series', 'PCyl, Sph.\nm= n=');
pj_add(pj_sinu, 'sinu', 'Sinusoidal (Sanson-Flamsteed)', 'PCyl, Sph&Ell');
pj_add(pj_eck6, 'eck6', 'Eckert VI', 'PCyl, Sph.\nm= n=');
pj_add(pj_mbtfps, 'mbtfps', 'McBryde-Thomas Flat-Polar Sinusoidal', 'PCyl, Sph.');

function pj_gn_sinu(P) {
  if (pj_param(P.params, 'tn'), pj_param(P.params, 'tm')) {
    pj_sinu_init(P, pj_param(P.params, 'dm'), pj_param(P.params, 'dn'));
  } else {
    e_error(-99);
  }
}

function pj_sinu(P) {
  var en;
  if (P.es) {
    en = pj_enfn(P.es);
    P.fwd = e_fwd;
    P.inv = e_inv;
  } else {
    pj_sinu_init(P, 0, 1);
  }

  function e_fwd(lp, xy) {
    var s, c;
    xy.y = pj_mlfn(lp.phi, s = sin(lp.phi), c = cos(lp.phi), en);
    xy.x = lp.lam * c / sqrt(1 - P.es * s * s);
  }

  function e_inv(xy, lp) {
    var s = fabs(lp.phi = pj_inv_mlfn(xy.y, P.es, en));
    if (s < M_HALFPI) {
        s = sin(lp.phi);
        lp.lam = xy.x * sqrt(1 - P.es * s * s) / cos(lp.phi);
    } else if ((s - EPS10) < M_HALFPI) {
        lp.lam = 0;
    } else {
        i_error();
    }
  }
}

function pj_eck6(P) {
  pj_sinu_init(P, 1, 2.570796326794896619231321691);
}

function pj_mbtfps(P) {
  pj_sinu_init(P, 0.5, 1.785398163397448309615660845);
}

function pj_sinu_init(P, m, n) {
  var MAX_ITER = 8,
      LOOP_TOL = 1e-7,
      C_x, C_y;
  C_x = (C_y = sqrt((m + 1) / n))/(m + 1);
  P.es = 0;
  P.fwd = s_fwd;
  P.inv = s_inv;

  function s_fwd(lp, xy) {
    var k, V, i;
    if (!m)
      lp.phi = n != 1 ? aasin(n * sin(lp.phi)): lp.phi;
    else {
        k = n * sin(lp.phi);
        for (i = MAX_ITER; i ; --i) {
            lp.phi -= V = (m * lp.phi + sin(lp.phi) - k) /
                (m + cos(lp.phi));
            if (fabs(V) < LOOP_TOL)
                break;
        }
        if (!i)
          f_error();
    }
    xy.x = C_x * lp.lam * (m + cos(lp.phi));
    xy.y = C_y * lp.phi;
  }

  function s_inv(xy, lp) {
    xy.y /= C_y;
    lp.phi = m ? aasin((m * xy.y + sin(xy.y)) / n) :
        ( n != 1 ? aasin(sin(xy.y) / n) : xy.y );
    lp.lam = xy.x / (C_x * (m + cos(xy.y)));
  }
}



pj_add(pj_gnom, 'gnom', 'Gnomonic', 'Azi, Sph.');

function pj_gnom(P) {
  var EPS10 = 1.e-10,
      N_POLE = 0,
      S_POLE = 1,
      EQUIT = 2,
      OBLIQ = 3;
  var sinphi0, cosph0, mode;
  if (fabs(fabs(P.phi0) - M_HALFPI) < EPS10) {
      mode = P.phi0 < 0 ? S_POLE : N_POLE;
  } else if (fabs(P.phi0) < EPS10) {
      mode = EQUIT;
  } else {
      mode = OBLIQ;
      sinph0 = sin(P.phi0);
      cosph0 = cos(P.phi0);
  }

  P.inv = s_inv;
  P.fwd = s_fwd;
  P.es = 0;

  function s_fwd(lp, xy) {
    var coslam, cosphi, sinphi;
    sinphi = sin(lp.phi);
    cosphi = cos(lp.phi);
    coslam = cos(lp.lam);

    switch (mode) {
        case EQUIT:
            xy.y = cosphi * coslam;
            break;
        case OBLIQ:
            xy.y = sinph0 * sinphi + cosph0 * cosphi * coslam;
            break;
        case S_POLE:
            xy.y = - sinphi;
            break;
        case N_POLE:
            xy.y = sinphi;
            break;
    }

    if (xy.y <= EPS10) f_error();

    xy.x = (xy.y = 1 / xy.y) * cosphi * sin(lp.lam);
    switch (mode) {
        case EQUIT:
            xy.y *= sinphi;
            break;
        case OBLIQ:
            xy.y *= cosph0 * sinphi - sinph0 * cosphi * coslam;
            break;
        case N_POLE:
            coslam = - coslam;
            /* falls through */
        case S_POLE:
            xy.y *= cosphi * coslam;
            break;
    }
  }

  function s_inv(xy, lp) {
    var x = xy.x, y = xy.y; // modified below
    var rh, cosz, sinz;
    rh = hypot(x, y);
    sinz = sin(lp.phi = atan(rh));
    cosz = sqrt(1 - sinz * sinz);

    if (fabs(rh) <= EPS10) {
        lp.phi = P.phi0;
        lp.lam = 0;
    } else {
        switch (mode) {
            case OBLIQ:
                lp.phi = cosz * sinph0 + y * sinz * cosph0 / rh;
                if (fabs(lp.phi) >= 1)
                    lp.phi = lp.phi > 0 ? M_HALFPI : -M_HALFPI;
                else
                    lp.phi = asin(lp.phi);
                y = (cosz - sinph0 * sin(lp.phi)) * rh;
                x *= sinz * cosph0;
                break;
            case EQUIT:
                lp.phi = y * sinz / rh;
                if (fabs(lp.phi) >= 1)
                    lp.phi = lp.phi > 0 ? M_HALFPI : -M_HALFPI;
                else
                    lp.phi = asin(lp.phi);
                y = cosz * rh;
                x *= sinz;
                break;
            case S_POLE:
                lp.phi -= M_HALFPI;
                break;
            case N_POLE:
                lp.phi = M_HALFPI - lp.phi;
                y = -y;
                break;
        }
        lp.lam = atan2(x, y);
    }
  }
}


pj_add(pj_moll, 'moll', 'Mollweide', 'PCyl Sph');
pj_add(pj_wag4, 'wag4', 'Wagner IV', 'PCyl Sph');
pj_add(pj_wag5, 'wag5', 'Wagner V', 'PCyl Sph');

function pj_moll(P) {
  pj_moll_init(P, pj_moll_init_Q(P, M_HALFPI));
}

function pj_wag4(P) {
  pj_moll_init(P, pj_moll_init_Q(P, M_PI/3));
}

function pj_wag5(P) {
  var Q = {
    C_x: 0.90977,
    C_y: 1.65014,
    C_p: 3.00896
  };
  pj_moll_init(P, Q);
}

function pj_moll_init_Q(P, p) {
  var sp = sin(p),
      p2 = p + p,
      r = sqrt(M_TWOPI * sp / (p2 + sin(p2)));
  return {
    C_x: 2 * r / M_PI,
    C_y: r / sp,
    C_p: p2 + sin(p2)
  };
}

function pj_moll_init(P, Q) {
  var MAX_ITER = 10,
      LOOP_TOL = 1e-7;
  P.fwd = s_fwd;
  P.inv = s_inv;
  P.es = 0;

  function s_fwd(lp, xy) {
    var k, V, i;
    k = Q.C_p * sin(lp.phi);
    for (i = MAX_ITER; i;--i) {
      lp.phi -= V = (lp.phi + sin(lp.phi) - k) /
        (1 + cos(lp.phi));
      if (fabs(V) < LOOP_TOL)
        break;
    }
    if (!i)
      lp.phi = (lp.phi < 0) ? -M_HALFPI : M_HALFPI;
    else
      lp.phi *= 0.5;
    xy.x = Q.C_x * lp.lam * cos(lp.phi);
    xy.y = Q.C_y * sin(lp.phi);
  }

  function s_inv(xy, lp) {
    lp.phi = aasin(xy.y / Q.C_y);
    lp.lam = xy.x / (Q.C_x * cos(lp.phi));
    // if (fabs(lp.lam) < M_PI) { // from Proj.4; fails for edge coordinates
    if (fabs(lp.lam) - M_PI < EPS10) { // allows inv projection of world layer
      lp.phi += lp.phi;
      lp.phi = aasin((lp.phi + sin(lp.phi)) / Q.C_p);
    } else {
      lp.lam = lp.phi = HUGE_VAL;
    }
  }
}


pj_add(pj_goode, 'goode', 'Goode Homolosine', 'PCyl, Sph.');

function pj_goode(P) {
  var Y_COR = 0.05280,
      PHI_LIM = 0.71093078197902358062,
      sinuFwd, sinuInv, mollFwd, mollInv;
  P.es = 0;
  pj_sinu(P);
  sinuFwd = P.fwd;
  sinuInv = P.inv;
  pj_moll(P);
  mollFwd = P.fwd;
  mollInv = P.inv;
  P.fwd = function(lp, xy) {
    if (fabs(lp.phi) < PHI_LIM) {
      sinuFwd(lp, xy);
    } else {
      mollFwd(lp, xy);
      xy.y -= lp.phi > 0 ? Y_COR : -Y_COR;
    }
  };
  P.inv = function(xy, lp) {
    if (fabs(xy.y) <= PHI_LIM) {
      sinuInv(xy, lp);
    } else {
      xy.y += xy.y > 0 ? Y_COR : -Y_COR;
      mollInv(xy, lp);
    }
  };
}


pj_add(pj_hammer, 'hammer', 'Hammer & Eckert-Greifendorff', 'Misc Sph,\nW= M=');

function pj_hammer(P) {
  var w, m, rm;
  var EPS = 1e-10;
  P.inv = s_inv;
  P.fwd = s_fwd;
  P.es = 0;

  if (pj_param(P.params, "tW")) {
    if ((w = fabs(pj_param(P.params, "dW"))) <= 0) e_error(-27);
  } else
    w = 0.5;
  if (pj_param(P.params, "tM")) {
      if ((m = fabs(pj_param(P.params, "dM"))) <= 0) e_error(-27);
  } else
      m = 1;
  rm = 1 / m;
  m /= w;

  function s_fwd(lp, xy) {
    var cosphi, d;
    d = sqrt(2/(1 + (cosphi = cos(lp.phi)) * cos(lp.lam *= w)));
    xy.x = m * d * cosphi * sin(lp.lam);
    xy.y = rm * d * sin(lp.phi);
  }

  function s_inv(xy, lp) {
    var z = sqrt(1 - 0.25*w*w*xy.x*xy.x - 0.25*xy.y*xy.y);
    if (fabs(2*z*z-1) < EPS) {
      lp.lam = HUGE_VAL;
      lp.phi = HUGE_VAL;
      pj_errno = -14;
    } else {
      lp.lam = aatan2(w * xy.x * z,2 * z * z - 1)/w;
      lp.phi = aasin(z * xy.y);
    }
  }
}


pj_add(pj_hatano, 'hatano', 'Hatano Asymmetrical Equal Area', 'PCyl., Sph.');

function pj_hatano(P) {
  var NITER = 20;
  var EPS = 1e-7;
  var ONETOL = 1.000001;
  var CN = 2.67595;
  var CS = 2.43763;
  var RCN = 0.37369906014686373063;
  var RCS = 0.41023453108141924738;
  var FYCN = 1.75859;
  var FYCS = 1.93052;
  var RYCN = 0.56863737426006061674;
  var RYCS = 0.51799515156538134803;
  var FXC = 0.85;
  var RXC = 1.17647058823529411764;

  P.inv = s_inv;
  P.fwd = s_fwd;
  P.es = 0;

  function s_fwd(lp, xy) {
    var th1, c;
    var i;
    c = sin(lp.phi) * (lp.phi < 0 ? CS : CN);
    for (i = NITER; i; --i) {
      lp.phi -= th1 = (lp.phi + sin(lp.phi) - c) / (1 + cos(lp.phi));
      if (fabs(th1) < EPS) break;
    }
    xy.x = FXC * lp.lam * cos(lp.phi *= 0.5);
    xy.y = sin(lp.phi) * (lp.phi < 0 ? FYCS : FYCN);
  }

  function s_inv(xy, lp) {
    var th = xy.y * (xy.y < 0 ? RYCS : RYCN);
    if (fabs(th) > 1) {
      if (fabs(th) > ONETOL) {
        i_error();
      } else {
        th = th > 0 ? M_HALFPI : -M_HALFPI;
      }
    } else {
      th = asin(th);
    }

    lp.lam = RXC * xy.x / cos(th);
    th += th;
    lp.phi = (th + sin(th)) * (xy.y < 0 ? RCS : RCN);
    if (fabs(lp.phi) > 1) {
      if (fabs(lp.phi) > ONETOL) {
        i_error();
      } else {
        lp.phi = lp.phi > 0 ? M_HALFPI : -M_HALFPI;
      }
    } else {
      lp.phi = asin(lp.phi);
    }
  }
}


pj_add(pj_healpix, 'healpix', 'HEALPix', 'Sph., Ellps.');
pj_add(pj_rhealpix, 'rhealpix', 'rHEALPix', 'Sph., Ellps.\nnorth_square= south_square=');

function pj_rhealpix(P) {
  pj_healpix(P, true);
}

function pj_healpix(P, rhealpix) {
  var R1 = [
    [0, -1],
    [1, 0]
  ];
  var R2 = [
    [-1, 0],
    [0, -1]
  ];
  var R3 = [
    [0, 1],
    [-1, 0]
  ];
  var IDENT = [
    [1, 0],
    [0, 1]
  ];
  var rot = [IDENT, R1, R2, R3, R3, R2, R1];
  var EPS = 1e-15;

  var north_square;
  var south_square;
  var qp;
  var apa;
  var vertsJit;

  if (rhealpix) {
    north_square = pj_param(P.params, "inorth_square");
    south_square = pj_param(P.params, "isouth_square");

    /* Check for valid north_square and south_square inputs. */
    if (north_square < 0 || north_square > 3) {
      e_error(-47);
    }
    if (south_square < 0 || south_square > 3) {
      e_error(-47);
    }
    vertsJit = [
      [-M_PI - EPS, M_FORTPI + EPS],
      [-M_PI + north_square * M_HALFPI - EPS, M_FORTPI + EPS],
      [-M_PI + north_square * M_HALFPI - EPS, 3 * M_FORTPI + EPS],
      [-M_PI + (north_square + 1.0) * M_HALFPI + EPS, 3 * M_FORTPI + EPS],
      [-M_PI + (north_square + 1.0) * M_HALFPI + EPS, M_FORTPI + EPS],
      [M_PI + EPS, M_FORTPI + EPS],
      [M_PI + EPS, -M_FORTPI - EPS],
      [-M_PI + (south_square + 1.0) * M_HALFPI + EPS, -M_FORTPI - EPS],
      [-M_PI + (south_square + 1.0) * M_HALFPI + EPS, -3 * M_FORTPI - EPS],
      [-M_PI + south_square * M_HALFPI - EPS, -3 * M_FORTPI - EPS],
      [-M_PI + south_square * M_HALFPI - EPS, -M_FORTPI - EPS],
      [-M_PI - EPS, -M_FORTPI - EPS]
    ];

    if (P.es != 0.0) {
      apa = pj_authset(P.es); /* For auth_lat(). */
      qp = pj_qsfn(1.0, P.e, P.one_es); /* For auth_lat(). */
      P.a = P.a * sqrt(0.5 * qp); /* Set P.a to authalic radius. */
      P.ra = 1.0 / P.a;
      P.fwd = e_rhealpix_forward;
      P.inv = e_rhealpix_inverse;
    } else {
      P.fwd = s_rhealpix_forward;
      P.inv = s_rhealpix_inverse;
    }

  } else { // healpix
    vertsJit = [
      [-M_PI - EPS, M_FORTPI],
      [-3 * M_FORTPI, M_HALFPI + EPS],
      [-M_HALFPI, M_FORTPI + EPS],
      [-M_FORTPI, M_HALFPI + EPS],
      [0.0, M_FORTPI + EPS],
      [M_FORTPI, M_HALFPI + EPS],
      [M_HALFPI, M_FORTPI + EPS],
      [3 * M_FORTPI, M_HALFPI + EPS],
      [M_PI + EPS, M_FORTPI],
      [M_PI + EPS, -M_FORTPI],
      [3 * M_FORTPI, -M_HALFPI - EPS],
      [M_HALFPI, -M_FORTPI - EPS],
      [M_FORTPI, -M_HALFPI - EPS],
      [0.0, -M_FORTPI - EPS],
      [-M_FORTPI, -M_HALFPI - EPS],
      [-M_HALFPI, -M_FORTPI - EPS],
      [-3 * M_FORTPI, -M_HALFPI - EPS],
      [-M_PI - EPS, -M_FORTPI]
    ];

    if (P.es != 0.0) {
      apa = pj_authset(P.es); /* For auth_lat(). */
      qp = pj_qsfn(1.0, P.e, P.one_es); /* For auth_lat(). */
      P.a = P.a * sqrt(0.5 * qp); /* Set P.a to authalic radius. */
      P.ra = 1.0 / P.a;
      P.fwd = e_healpix_forward;
      P.inv = e_healpix_inverse;
    } else {
      P.fwd = s_healpix_forward;
      P.inv = s_healpix_inverse;
    }
  }

  function s_healpix_forward(lp, xy) {
    healpix_sphere(lp, xy);
  }

  function e_healpix_forward(lp, xy) {
    lp.phi = auth_lat(P, lp.phi, 0);
    healpix_sphere(lp, xy);
  }

  function s_healpix_inverse(xy, lp) {
    if (!in_image(xy.x, xy.y)) {
      lp.lam = HUGE_VAL;
      lp.phi = HUGE_VAL;
      pj_ctx_set_errno(-15);
      return;
    }
    healpix_sphere_inverse(xy, lp);
  }

  function e_healpix_inverse(xy, lp) {
    if (!in_image(xy.x, xy.y)) {
      lp.lam = HUGE_VAL;
      lp.phi = HUGE_VAL;
      pj_ctx_set_errno(-15);
      return;
    }
    healpix_sphere_inverse(xy, lp);
    lp.phi = auth_lat(P, lp.phi, 1);
  }

  function s_rhealpix_forward(lp, xy) {
    healpix_sphere(lp, xy);
    combine_caps(xy, north_square, south_square, 0);
  }

  function e_rhealpix_forward(lp, xy) {
    lp.phi = auth_lat(P, lp.phi, 0);
    healpix_sphere(lp, xy);
    return combine_caps(xy, north_square, south_square, 0);
  }

  function s_rhealpix_inverse(xy, lp) {
    if (!in_image(xy.x, xy.y)) {
      lp.lam = HUGE_VAL;
      lp.phi = HUGE_VAL;
      pj_ctx_set_errno(-15);
      return;
    }
    combine_caps(xy, north_square, south_square, 1);
    healpix_sphere_inverse(xy, lp);
  }

  function e_rhealpix_inverse(xy, lp) {
    if (!in_image(xy.x, xy.y)) {
      lp.lam = HUGE_VAL;
      lp.phi = HUGE_VAL;
      pj_ctx_set_errno(-15);
      return;
    }
    combine_caps(xy, north_square, south_square, 1);
    healpix_sphere_inverse(xy, lp);
    lp.phi = auth_lat(P, lp.phi, 1);
  }

  function healpix_sphere(lp, xy) {
    var lam = lp.lam;
    var phi = lp.phi;
    var phi0 = asin(2.0 / 3.0);

    /* equatorial region */
    if (fabs(phi) <= phi0) {
      xy.x = lam;
      xy.y = 3 * M_PI / 8 * sin(phi);
    } else {
      var lamc;
      var sigma = sqrt(3 * (1 - fabs(sin(phi))));
      var cn = floor(2 * lam / M_PI + 2);
      if (cn >= 4) {
        cn = 3;
      }
      lamc = -3 * M_FORTPI + M_HALFPI * cn;
      xy.x = lamc + (lam - lamc) * sigma;
      xy.y = pj_sign(phi) * M_FORTPI * (2 - sigma);
    }
  }

  function healpix_sphere_inverse(xy, lp) {
    var x = xy.x;
    var y = xy.y;
    var y0 = M_FORTPI;

    /* Equatorial region. */
    if (fabs(y) <= y0) {
      lp.lam = x;
      lp.phi = asin(8 * y / (3 * M_PI));
    } else if (fabs(y) < M_HALFPI) {
      var cn = floor(2 * x / M_PI + 2);
      var xc, tau;
      if (cn >= 4) {
        cn = 3;
      }
      xc = -3 * M_FORTPI + M_HALFPI * cn;
      tau = 2.0 - 4 * fabs(y) / M_PI;
      lp.lam = xc + (x - xc) / tau;
      lp.phi = pj_sign(y) * asin(1.0 - pow(tau, 2) / 3.0);
    } else {
      lp.lam = -M_PI;
      lp.phi = pj_sign(y) * M_HALFPI;
    }
  }

  function pj_sign(v) {
    return v > 0 ? 1 : (v < 0 ? -1 : 0);
  }

  /**
   * Return the index of the matrix in ROT.
   * @param index ranges from -3 to 3.
   */
  function get_rotate_index(index) {
    switch (index) {
      case 0:
        return 0;
      case 1:
        return 1;
      case 2:
        return 2;
      case 3:
        return 3;
      case -1:
        return 4;
      case -2:
        return 5;
      case -3:
        return 6;
    }
    return 0;
  }

  /**
   * Return true if point (testx, testy) lies in the interior of the polygon
   * determined by the vertices in vert, and return false otherwise.
   * See http://paulbourke.net/geometry/polygonmesh/ for more details.
   * @param nvert the number of vertices in the polygon.
   * @param vert the (x, y)-coordinates of the polygon's vertices
   **/
  function pnpoly(vert, testx, testy) {
    var counter = 0;
    var nvert = vert.length;
    var x1, y1, x2, y2;
    var xinters;
    var i;

    /* Check for boundary cases */
    for (i = 0; i < nvert; i++) {
      if (testx == vert[i][0] && testy == vert[i][1]) {
        return true;
      }
    }

    x1 = vert[0][0];
    y1 = vert[0][1];

    for (i = 1; i < nvert; i++) {
      x2 = vert[i % nvert][0];
      y2 = vert[i % nvert][1];
      if (testy > MIN(y1, y2) &&
        testy <= MAX(y1, y2) &&
        testx <= MAX(x1, x2) &&
        y1 != y2) {
        xinters = (testy - y1) * (x2 - x1) / (y2 - y1) + x1;
        if (x1 == x2 || testx <= xinters)
          counter++;
      }
      x1 = x2;
      y1 = y2;
    }
    return counter % 2 != 0;
  }

  function in_image(x, y) {
    return pnpoly(vertsJit, x, y);
  }

  /**
   * Return the authalic latitude of latitude alpha (if inverse=0) or
   * return the approximate latitude of authalic latitude alpha (if inverse=1).
   * P contains the relevant ellipsoid parameters.
   **/
  function auth_lat(P, alpha, inverse) {
    if (!inverse) {
      /* Authalic latitude. */
      var q = pj_qsfn(sin(alpha), P.e, 1.0 - P.es);
      var ratio = q / qp;

      if (fabs(ratio) > 1) {
        /* Rounding error. */
        ratio = pj_sign(ratio);
      }
      return asin(ratio);
    } else {
      /* Approximation to inverse authalic latitude. */
      return pj_authlat(alpha, apa);
    }
  }

  function vector_add(a, b) {
    return [a[0] + b[0], a[1] + b[1]];
  }

  function vector_sub(a, b) {
    return [a[0] - b[0], a[1] - b[1]];
  }

  function dot_product(a, b) {
    var i, j;
    var ret = [0, 0];
    for (i = 0; i < 2; i++) {
      for (j = 0; j < 2; j++) {
        ret[i] += a[i][j] * b[j];
      }
    }
    return ret;
  }

  /**
   * Return the number of the polar cap, the pole point coordinates, and
   * the region that (x, y) lies in.
   * If inverse=0, then assume (x,y) lies in the image of the HEALPix
   * projection of the unit sphere.
   * If inverse=1, then assume (x,y) lies in the image of the
   * (north_square, south_square)-rHEALPix projection of the unit sphere.
   **/
  function get_cap(x, y, north_square, south_square, inverse) {
    var capmap = {};
    var c;
    capmap.x = x;
    capmap.y = y;
    if (!inverse) {
      if (y > M_FORTPI) {
        capmap.region = 'north';
        c = M_HALFPI;
      } else if (y < -M_FORTPI) {
        capmap.region = 'south';
        c = -M_HALFPI;
      } else {
        capmap.region = 'equatorial';
        capmap.cn = 0;
        return capmap;
      }
      /* polar region */
      if (x < -M_HALFPI) {
        capmap.cn = 0;
        capmap.x = (-3 * M_FORTPI);
        capmap.y = c;
      } else if (x >= -M_HALFPI && x < 0) {
        capmap.cn = 1;
        capmap.x = -M_FORTPI;
        capmap.y = c;
      } else if (x >= 0 && x < M_HALFPI) {
        capmap.cn = 2;
        capmap.x = M_FORTPI;
        capmap.y = c;
      } else {
        capmap.cn = 3;
        capmap.x = 3 * M_FORTPI;
        capmap.y = c;
      }
    } else {
      if (y > M_FORTPI) {
        capmap.region = 'north';
        capmap.x = -3 * M_FORTPI + north_square * M_HALFPI;
        capmap.y = M_HALFPI;
        x = x - north_square * M_HALFPI;
      } else if (y < -M_FORTPI) {
        capmap.region = 'south';
        capmap.x = -3 * M_FORTPI + south_square * M_HALFPI;
        capmap.y = -M_HALFPI;
        x = x - south_square * M_HALFPI;
      } else {
        capmap.region = 'equatorial';
        capmap.cn = 0;
        return capmap;
      }
      /* Polar Region, find the HEALPix polar cap number that
         x, y moves to when rHEALPix polar square is disassembled. */
      if (capmap.region == 'north') {
        if (y >= -x - M_FORTPI - EPS && y < x + 5 * M_FORTPI - EPS) {
          capmap.cn = (north_square + 1) % 4;
        } else if (y > -x - M_FORTPI + EPS && y >= x + 5 * M_FORTPI - EPS) {
          capmap.cn = (north_square + 2) % 4;
        } else if (y <= -x - M_FORTPI + EPS && y > x + 5 * M_FORTPI + EPS) {
          capmap.cn = (north_square + 3) % 4;
        } else {
          capmap.cn = north_square;
        }
      } else if (capmap.region == 'south') {
        if (y <= x + M_FORTPI + EPS && y > -x - 5 * M_FORTPI + EPS) {
          capmap.cn = (south_square + 1) % 4;
        } else if (y < x + M_FORTPI - EPS && y <= -x - 5 * M_FORTPI + EPS) {
          capmap.cn = (south_square + 2) % 4;
        } else if (y >= x + M_FORTPI - EPS && y < -x - 5 * M_FORTPI - EPS) {
          capmap.cn = (south_square + 3) % 4;
        } else {
          capmap.cn = south_square;
        }
      }
    }
    return capmap;
  }

  /**
   * Rearrange point (x, y) in the HEALPix projection by
   * combining the polar caps into two polar squares.
   * Put the north polar square in position north_square and
   * the south polar square in position south_square.
   * If inverse=1, then uncombine the polar caps.
   * @param north_square integer between 0 and 3.
   * @param south_square integer between 0 and 3.
   **/
  function combine_caps(xy, north_square, south_square, inverse) {
    var v, c, vector, v_min_c, ret_dot, tmpRot, a;
    var pole = 0;
    var capmap = get_cap(xy.x, xy.y, north_square, south_square, inverse);
    if (capmap.region == 'equatorial') {
      xy.x = capmap.x;
      xy.y = capmap.y;
      return;
    }
    v = [xy.x, xy.y];
    c = [capmap.x, capmap.y];

    if (!inverse) {
      /* Rotate (x, y) about its polar cap tip and then translate it to
         north_square or south_square. */

      if (capmap.region == 'north') {
        pole = north_square;
        tmpRot = rot[get_rotate_index(capmap.cn - pole)];
      } else {
        pole = south_square;
        tmpRot = rot[get_rotate_index(-1 * (capmap.cn - pole))];
      }
    } else {
      /* Inverse function.
       Unrotate (x, y) and then translate it back. */

      /* disassemble */
      if (capmap.region == 'north') {
        pole = north_square;
        tmpRot = rot[get_rotate_index(-1 * (capmap.cn - pole))];
      } else {
        pole = south_square;
        tmpRot = rot[get_rotate_index(capmap.cn - pole)];
      }
    }
    v_min_c = vector_sub(v, c);
    ret_dot = dot_product(tmpRot, v_min_c);
    a = [-3 * M_FORTPI + ((!inverse) ? 0 : capmap.cn) * M_HALFPI, M_HALFPI];
    vector = vector_add(ret_dot, a);
    xy.x = vector[0];
    xy.y = vector[1];
  }
}


pj_add(pj_hill, 'hill', 'Hill Eucyclic', 'PCyl., Sph.');

// Adapted from: https://github.com/d3/d3-geo-projection/blob/master/src/hill.js
// License: https://github.com/d3/d3-geo-projection/blob/master/LICENSE

function pj_hill(P) {
  var K = 1, // TODO: expose as parameter
      L = 1 + K,
      sinBt = sin(1 / L),
      Bt = asin(sinBt),
      A = 2 * sqrt(M_PI / (B = M_PI + 4 * Bt * L)),
      B,
      rho0 = 0.5 * A * (L + sqrt(K * (2 + K))),
      K2 = K * K,
      L2 = L * L,
      EPS = 1e-12;

  P.es = 0;
  P.fwd = s_fwd;
  P.inv = s_inv;

  function s_fwd(lp, xy) {
    var t = 1 - sin(lp.phi),
        rho, omega;
    if (t && t < 2) {
      var theta = M_HALFPI - lp.phi,
          i = 25,
          delta, sinTheta, cosTheta, C, Bt_Bt1;
      do {
        sinTheta = sin(theta);
        cosTheta = cos(theta);
        Bt_Bt1 = Bt + atan2(sinTheta, L - cosTheta);
        C = 1 + L2 - 2 * L * cosTheta;
        theta -= delta = (theta - K2 * Bt - L * sinTheta + C * Bt_Bt1 -0.5 * t * B) / (2 * L * sinTheta * Bt_Bt1);
      } while (fabs(delta) > EPS && --i > 0);
      rho = A * sqrt(C);
      omega = lp.lam * Bt_Bt1 / M_PI;
    } else {
      rho = A * (K + t);
      omega = lp.lam * Bt / M_PI;
    }

    xy.x = rho * sin(omega);
    xy.y = rho0 - rho * cos(omega);
  }

  function s_inv(xy, lp) {
    var x = xy.x,
        y = xy.y,
        rho2 = x * x + (y -= rho0) * y,
        cosTheta = (1 + L2 - rho2 / (A * A)) / (2 * L),
        theta = acos(cosTheta),
        sinTheta = sin(theta),
        Bt_Bt1 = Bt + atan2(sinTheta, L - cosTheta);
    lp.lam = asin(x / sqrt(rho2)) * M_PI / Bt_Bt1,
    lp.phi = asin(1 - 2 * (theta - K2 * Bt - L * sinTheta + (1 + L2 - 2 * L * cosTheta) * Bt_Bt1) / B);
  }
}


pj_add(pj_krovak, 'krovak', 'Krovak', 'PCyl., Ellps.');

function pj_krovak(P) {
  var u0, n0, g;
  var alpha, k, n, rho0, ad, czech;
  var EPS = 1e-15;
  var S45 = 0.785398163397448; /* 45 deg */
  var S90 = 1.570796326794896; /* 90 deg */
  var UQ = 1.04216856380474;   /* DU(2, 59, 42, 42.69689) */
  var S0 = 1.37008346281555;   /* Latitude of pseudo standard parallel 78deg 30'00" N */

  /* we want Bessel as fixed ellipsoid */
  P.a = 6377397.155;
  P.e = sqrt(P.es = 0.006674372230614);

  /* if latitude of projection center is not set, use 49d30'N */
  if (!pj_param(P.params, "tlat_0"))
    P.phi0 = 0.863937979737193;

  /* if center long is not set use 42d30'E of Ferro - 17d40' for Ferro */
  /* that will correspond to using longitudes relative to greenwich    */
  /* as input and output, instead of lat/long relative to Ferro */
  if (!pj_param(P.params, "tlon_0"))
          P.lam0 = 0.7417649320975901 - 0.308341501185665;

  /* if scale not set default to 0.9999 */
  if (!pj_param(P.params, "tk"))
          P.k0 = 0.9999;
  czech = 1;
  if (!pj_param(P.params, "tczech"))
    czech = -1;

  /* Set up shared parameters between forward and inverse */
  alpha = sqrt(1 + (P.es * pow(cos(P.phi0), 4)) / (1 - P.es));
  u0 = asin(sin(P.phi0) / alpha);
  g = pow((1 + P.e * sin(P.phi0)) / (1 - P.e * sin(P.phi0)), alpha * P.e / 2);
  k = tan( u0 / 2 + S45) / pow  (tan(P.phi0 / 2 + S45) , alpha) * g;
  n0 = sqrt(1 - P.es) / (1 - P.es * pow(sin(P.phi0), 2));
  n = sin(S0);
  rho0 = P.k0 * n0 / tan(S0);
  ad = S90 - UQ;
  P.inv = e_inv;
  P.fwd = e_fwd;

  function e_fwd(lp, xy) {
    var gfi, u, deltav, s, d, eps, rho;

    gfi = pow ( (1 + P.e * sin(lp.phi)) / (1 - P.e * sin(lp.phi)), alpha * P.e / 2);

    u = 2 * (atan(k * pow( tan(lp.phi / 2 + S45), alpha) / gfi)-S45);
    deltav = -lp.lam * alpha;

    s = asin(cos(ad) * sin(u) + sin(ad) * cos(u) * cos(deltav));
    d = asin(cos(u) * sin(deltav) / cos(s));
    eps = n * d;
    rho = rho0 * pow(tan(S0 / 2 + S45) , n) / pow(tan(s / 2 + S45) , n);
    xy.y = rho * cos(eps);
    xy.x = rho * sin(eps);
    xy.y *= czech;
    xy.x *= czech;
  }

  function e_inv(xy, lp) {
    var u, deltav, s, d, eps, rho, fi1, xy0;
    var ok;
    xy0 = xy.x;
    xy.x = xy.y;
    xy.y = xy0;
    xy.x *= czech;
    xy.y *= czech;

    rho = sqrt(xy.x * xy.x + xy.y * xy.y);
    eps = atan2(xy.y, xy.x);
    d = eps / sin(S0);
    s = 2 * (atan(  pow(rho0 / rho, 1 / n) * tan(S0 / 2 + S45)) - S45);
    u = asin(cos(ad) * sin(s) - sin(ad) * cos(s) * cos(d));
    deltav = asin(cos(s) * sin(d) / cos(u));
    lp.lam = P.lam0 - deltav / alpha;

    /* ITERATION FOR lp.phi */
    fi1 = u;
    ok = 0;
    do {
      lp.phi = 2 * (atan(pow( k, -1 / alpha) * pow( tan(u / 2 + S45), 1 / alpha) *
        pow( (1 + P.e * sin(fi1)) / (1 - P.e * sin(fi1)) , P.e / 2))  - S45);
      if (fabs(fi1 - lp.phi) < EPS) ok=1;
      fi1 = lp.phi;
   } while (ok===0);
   lp.lam -= P.lam0;
  }
}


pj_add(pj_laea, 'laea', 'Lambert Azimuthal Equal Area', 'Azi, Sph&Ell');

function pj_laea(P) {
  var EPS10 = 1e-10,
      NITER = 20,
      CONV = 1e-10,
      N_POLE = 0,
      S_POLE = 1,
      EQUIT = 2,
      OBLIQ = 3;
  var sinb1, cosb1, xmf, ymf, mmf, qp, dd, rq, apa, mode, t, sinphi;

  t = fabs(P.phi0);
  if (fabs(t - M_HALFPI) < EPS10)
      mode = P.phi0 < 0 ? S_POLE : N_POLE;
  else if (fabs(t) < EPS10)
      mode = EQUIT;
  else
      mode = OBLIQ;
  if (P.es) {
      P.e = sqrt(P.es);
      qp = pj_qsfn(1, P.e, P.one_es);
      mmf = 0.5 / (1 - P.es);
      apa = pj_authset(P.es);
      switch (mode) {
        case N_POLE:
        case S_POLE:
          dd = 1;
          break;
        case EQUIT:
          dd = 1 / (rq = sqrt(0.5 * qp));
          xmf = 1;
          ymf = 0.5 * qp;
          break;
        case OBLIQ:
          rq = sqrt(0.5 * qp);
          sinphi = sin(P.phi0);
          sinb1 = pj_qsfn(sinphi, P.e, P.one_es) / qp;
          cosb1 = sqrt(1 - sinb1 * sinb1);
          dd = cos(P.phi0) / (sqrt(1 - P.es * sinphi * sinphi) *
             rq * cosb1);
          ymf = (xmf = rq) / dd;
          xmf *= dd;
          break;
      }
      P.inv = e_inv;
      P.fwd = e_fwd;
  } else {
      if (mode == OBLIQ) {
          sinb1 = sin(P.phi0);
          cosb1 = cos(P.phi0);
      }
      P.inv = s_inv;
      P.fwd = s_fwd;
  }

  function e_fwd(lp, xy) {
    var coslam, sinlam, sinphi, q, sinb=0.0, cosb=0.0, b=0.0;
    coslam = cos(lp.lam);
    sinlam = sin(lp.lam);
    sinphi = sin(lp.phi);
    q = pj_qsfn(sinphi, P.e, P.one_es);

    if (mode == OBLIQ || mode == EQUIT) {
        sinb = q / qp;
        cosb = sqrt(1 - sinb * sinb);
    }

    switch (mode) {
      case OBLIQ:
        b = 1 + sinb1 * sinb + cosb1 * cosb * coslam;
        break;
      case EQUIT:
        b = 1 + cosb * coslam;
        break;
      case N_POLE:
        b = M_HALFPI + lp.phi;
        q = qp - q;
        break;
      case S_POLE:
        b = lp.phi - M_HALFPI;
        q = qp + q;
        break;
    }
    if (fabs(b) < EPS10) f_error();

    switch (mode) {
      case OBLIQ:
      case EQUIT:
        if (mode == OBLIQ) {
          b = sqrt(2 / b);
          xy.y = ymf * b * (cosb1 * sinb - sinb1 * cosb * coslam);
        } else {
          b = sqrt(2 / (1 + cosb * coslam));
          xy.y = b * sinb * ymf;
        }
        xy.x = xmf * b * cosb * sinlam;
        break;
      case N_POLE:
      case S_POLE:
        if (q >= 0) {
            b = sqrt(q);
            xy.x = b * sinlam;
            xy.y = coslam * (mode == S_POLE ? b : -b);
        } else
            xy.x = xy.y = 0;
        break;
    }
  }

  function e_inv(xy, lp) {
    var cCe, sCe, q, rho, ab=0.0;

    switch (mode) {
      case EQUIT:
      case OBLIQ:
        xy.x /= dd;
        xy.y *=  dd;
        rho = hypot(xy.x, xy.y);
        if (rho < EPS10) {
            lp.lam = 0;
            lp.phi = P.phi0;
            return lp;
        }
        sCe = 2 * asin(0.5 * rho / rq);
        cCe = cos(sCe);
        sCe = sin(sCe);
        xy.x *= sCe;
        if (mode == OBLIQ) {
            ab = cCe * sinb1 + xy.y * sCe * cosb1 / rho;
            xy.y = rho * cosb1 * cCe - xy.y * sinb1 * sCe;
        } else {
            ab = xy.y * sCe / rho;
            xy.y = rho * cCe;
        }
        break;
      case N_POLE:
        xy.y = -xy.y;
        /* falls through */
      case S_POLE:
        q = (xy.x * xy.x + xy.y * xy.y);
        if (!q) {
            lp.lam = 0;
            lp.phi = P.phi0;
            return (lp);
        }
        ab = 1 - q / qp;
        if (mode == S_POLE)
            ab = - ab;
        break;
    }
    lp.lam = atan2(xy.x, xy.y);
    lp.phi = pj_authlat(asin(ab), apa);
    return lp;
  }

  function s_fwd(lp, xy) {
    var coslam, cosphi, sinphi;
    sinphi = sin(lp.phi);
    cosphi = cos(lp.phi);
    coslam = cos(lp.lam);
    switch (mode) {
      case EQUIT:
      case OBLIQ:
        if (mode == EQUIT) {
          xy.y = 1 + cosphi * coslam;
        } else {
          xy.y = 1 + sinb1 * sinphi + cosb1 * cosphi * coslam;
        }
        if (xy.y <= EPS10) f_error();
        xy.y = sqrt(2 / xy.y);
        xy.x = xy.y * cosphi * sin(lp.lam);
        xy.y *= mode == EQUIT ? sinphi :
           cosb1 * sinphi - sinb1 * cosphi * coslam;
        break;
      case N_POLE:
        coslam = -coslam;
        /* falls through */
      case S_POLE:
        if (fabs(lp.phi + P.phi0) < EPS10) f_error();
        xy.y = M_FORTPI - lp.phi * 0.5;
        xy.y = 2 * (mode == S_POLE ? cos(xy.y) : sin(xy.y));
        xy.x = xy.y * sin(lp.lam);
        xy.y *= coslam;
        break;
    }
  }

  function s_inv(xy, lp) {
    var cosz=0.0, rh, sinz=0.0;

    rh = hypot(xy.x, xy.y);
    if ((lp.phi = rh * 0.5 ) > 1) i_error();
    lp.phi = 2 * asin(lp.phi);
    if (mode == OBLIQ || mode == EQUIT) {
        sinz = sin(lp.phi);
        cosz = cos(lp.phi);
    }
    switch (mode) {
      case EQUIT:
        lp.phi = fabs(rh) <= EPS10 ? 0 : asin(xy.y * sinz / rh);
        xy.x *= sinz;
        xy.y = cosz * rh;
        break;
      case OBLIQ:
        lp.phi = fabs(rh) <= EPS10 ? P.phi0 :
           asin(cosz * sinb1 + xy.y * sinz * cosb1 / rh);
        xy.x *= sinz * cosb1;
        xy.y = (cosz - sin(lp.phi) * sinb1) * rh;
        break;
      case N_POLE:
        xy.y = -xy.y;
        lp.phi = M_HALFPI - lp.phi;
        break;
      case S_POLE:
        lp.phi -= M_HALFPI;
        break;
    }
    lp.lam = (xy.y == 0 && (mode == EQUIT || mode == OBLIQ)) ?
        0 : atan2(xy.x, xy.y);
  }
}


pj_add(pj_lonlat, 'lonlat', 'Lat/long (Geodetic)', '');
pj_add(pj_lonlat, 'longlat', 'Lat/long (Geodetic alias)', '');
pj_add(pj_lonlat, 'latlon', 'Lat/long (Geodetic alias)', '');
pj_add(pj_lonlat, 'latlong', 'Lat/long (Geodetic alias)', '');

function pj_lonlat(P) {
  P.x0 = 0;
  P.y0 = 0;
  P.is_latlong = true;

  P.fwd = function(lp, xy) {
    xy.x = lp.lam / P.a;
    xy.y = lp.phi / P.a;
  };

  P.inv = function(xy, lp) {
    lp.lam = xy.x * P.a;
    lp.phi = xy.y * P.a;
  };
}



function pj_tsfn(phi, sinphi, e) {
	sinphi *= e;
  // Proj.4 returns HUGE_VAL on div0; this returns +/- Infinity; effect should be same
	return (tan(0.5 * (M_HALFPI - phi)) /
	  pow((1 - sinphi) / (1 + sinphi), 0.5 * e));
}


pj_add(pj_lcc, 'lcc', 'Lambert Conformal Conic', 'Conic, Sph&Ell\nlat_1= and lat_2= or lat_0=');

function pj_lcc(P) {
  var EPS10 = 1e-10;
  var cosphi, sinphi, secant;
  var phi1, phi2, n, rho0, c, ellips, ml1, m1;

  P.inv = e_inv;
  P.fwd = e_fwd;

  phi1 = pj_param(P.params, "rlat_1");
  if (pj_param(P.params, "tlat_2"))
    phi2 = pj_param(P.params, "rlat_2");
  else {
    phi2 = phi1;
    if (!pj_param(P.params, "tlat_0"))
      P.phi0 = phi1;
  }
  if (fabs(phi1 + phi2) < EPS10) e_error(-21);
  n = sinphi = sin(phi1);
  cosphi = cos(phi1);
  secant = fabs(phi1 - phi2) >= EPS10;
  if ((ellips = (P.es != 0))) {
    P.e = sqrt(P.es);
    m1 = pj_msfn(sinphi, cosphi, P.es);
    ml1 = pj_tsfn(phi1, sinphi, P.e);
    if (secant) { /* secant cone */
      sinphi = sin(phi2);
      n = log(m1 / pj_msfn(sinphi, cos(phi2), P.es));
      n /= log(ml1 / pj_tsfn(phi2, sinphi, P.e));
    }
    c = (rho0 = m1 * pow(ml1, -n) / n);
    rho0 *= (fabs(fabs(P.phi0) - M_HALFPI) < EPS10) ? 0 :
        pow(pj_tsfn(P.phi0, sin(P.phi0), P.e), n);
  } else {
    if (secant)
      n = log(cosphi / cos(phi2)) /
          log(tan(M_FORTPI + 0.5 * phi2) /
          tan(M_FORTPI + 0.5 * phi1));
    c = cosphi * pow(tan(M_FORTPI + 0.5 * phi1), n) / n;
    rho0 = (fabs(fabs(P.phi0) - M_HALFPI) < EPS10) ? 0 :
        c * pow(tan(M_FORTPI + 0.5 * P.phi0), -n);
  }

  function e_fwd(lp, xy) {
    var lam = lp.lam;
    var rho;
    if (fabs(fabs(lp.phi) - M_HALFPI) < EPS10) {
      if ((lp.phi * n) <= 0) f_error();
      rho = 0;
    } else {
      rho = c * (ellips ? pow(pj_tsfn(lp.phi, sin(lp.phi),
            P.e), n) : pow(tan(M_FORTPI + 0.5 * lp.phi), -n));
    }
    lam *= n;
    xy.x = P.k0 * (rho * sin(lam));
    xy.y = P.k0 * (rho0 - rho * cos(lam));
  }

  function e_inv(xy, lp) {
    var x = xy.x, y = xy.y;
    var rho;
    x /= P.k0;
    y /= P.k0;

    y = rho0 - y;
    rho = hypot(x, y);
    if (rho != 0) {
      if (n < 0) {
        rho = -rho;
        x = -x;
        y = -y;
      }
      if (ellips) {
        lp.phi = pj_phi2(pow(rho / c, 1/n), P.e);
        if (lp.phi == HUGE_VAL) i_error();
      } else
        lp.phi = 2 * atan(pow(c / rho, 1/n)) - M_HALFPI;
      lp.lam = atan2(x, y) / n;
    } else {
      lp.lam = 0;
      lp.phi = n > 0 ? M_HALFPI : -M_HALFPI;
    }
  }

}


pj_add(pj_loxim, 'loxim', 'Loximuthal', 'PCyl Sph');

function pj_loxim(P) {
  var EPS = 1e-8;
  var phi1, cosphi1, tanphi1;
      phi1 = pj_param(P.params, "rlat_1");
      cosphi1 = cos(phi1);
      tanphi1 = tan(M_FORTPI + 0.5 * phi1);
  if (cosphi1 < EPS) e_error(-22);
  P.fwd = s_fwd;
  P.inv = s_inv;
  P.es = 0;

  function s_fwd(lp, xy) {
    xy.y = lp.phi - phi1;
    if (fabs(xy.y) < EPS)
      xy.x = lp.lam * cosphi1;
    else {
      xy.x = M_FORTPI + 0.5 * lp.phi;
      if (fabs(xy.x) < EPS || fabs(fabs(xy.x) - M_HALFPI) < EPS)
        xy.x = 0;
      else
        xy.x = lp.lam * xy.y / log(tan(xy.x) / tanphi1);
    }
  }

  function s_inv(xy, lp) {
    lp.phi = xy.y + phi1;
    if (fabs(xy.y) < EPS) {
      lp.lam = xy.x / cosphi1;
    } else {
      lp.lam = M_FORTPI + 0.5 * lp.phi;
      if (fabs(lp.lam) < EPS || fabs(fabs(lp.lam) - M_HALFPI) < EPS)
        lp.lam = 0;
      else
        lp.lam = xy.x * log(tan(lp.lam) / tanphi1) / xy.y;
    }
  }
}


pj_add(pj_mbt_fpp, 'mbt_fpp', 'McBride-Thomas Flat-Polar Parabolic', 'Cyl., Sph.');

function pj_mbt_fpp(P) {
  var CS = 0.95257934441568037152,
      FXC = 0.92582009977255146156,
      FYC = 3.40168025708304504493,
      C23 = 2 / 3,
      C13 = 1 / 3,
      ONEEPS = 1.0000001;

  P.fwd = s_fwd;
  P.inv = s_inv;
  P.es = 0;

  function s_fwd(lp, xy) {
    lp.phi = asin(CS * sin(lp.phi));
    xy.x = FXC * lp.lam * (2 * cos(C23 * lp.phi) - 1);
    xy.y = FYC * sin(C13 * lp.phi);
  }

  function s_inv(xy, lp) {
    lp.phi = xy.y / FYC;
    if (fabs(lp.phi) >= 1) {
      if (fabs(lp.phi) > ONEEPS)
        i_error();
      else
        lp.phi = (lp.phi < 0) ? -M_HALFPI : M_HALFPI;
    } else
      lp.phi = asin(lp.phi);

    lp.lam = xy.x / (FXC * (2 * cos(C23 * (lp.phi *= 3)) - 1));
    if (fabs(lp.phi = sin(lp.phi) / CS) >= 1) {
      if (fabs(lp.phi) > ONEEPS)
        i_error();
      else
        lp.phi = (lp.phi < 0) ? -M_HALFPI : M_HALFPI;
    } else
      lp.phi = asin(lp.phi);
  }
}


pj_add(pj_mbt_fpq, 'mbt_fpq', 'McBryde-Thomas Flat-Polar Quartic', 'Cyl., Sph.');

function pj_mbt_fpq(P) {
  var NITER = 20,
      EPS = 1e-7,
      ONETOL = 1.000001,
      C = 1.70710678118654752440,
      RC = 0.58578643762690495119,
      FYC = 1.87475828462269495505,
      RYC = 0.53340209679417701685,
      FXC = 0.31245971410378249250,
      RXC = 3.20041258076506210122;

  P.fwd = s_fwd;
  P.inv = s_inv;
  P.es = 0;

  function s_fwd(lp, xy) {
    var th1, c, i;
    c = C * sin(lp.phi);
    for (i = NITER; i; --i) {
      lp.phi -= th1 = (sin(0.5 * lp.phi) + sin(lp.phi) - c) /
        (0.5 * cos(0.5 * lp.phi) + cos(lp.phi));
      if (fabs(th1) < EPS) break;
    }
    xy.x = FXC * lp.lam * (1.0 + 2 * cos(lp.phi) / cos(0.5 * lp.phi));
    xy.y = FYC * sin(0.5 * lp.phi);
  }

  function s_inv(xy, lp) {
    var t;
    lp.phi = RYC * xy.y;
    if (fabs(lp.phi) > 1) {
      if (fabs(lp.phi) > ONETOL) i_error();
      else if (lp.phi < 0) {
        t = -1;
        lp.phi = -M_PI;
      } else {
        t = 1;
        lp.phi = M_PI;
      }
    } else
      lp.phi = 2 * asin(t = lp.phi);
    lp.lam = RXC * xy.x / (1 + 2 * cos(lp.phi) / cos(0.5 * lp.phi));
    lp.phi = RC * (t + sin(lp.phi));
    if (fabs(lp.phi) > 1)
      if (fabs(lp.phi) > ONETOL) i_error();
      else
        lp.phi = lp.phi < 0 ? -M_HALFPI : M_HALFPI;
    else
      lp.phi = asin(lp.phi);
  }
}


pj_add(pj_mbt_fps, 'mbt_fps', 'McBryde-Thomas Flat-Pole Sine (No. 2)', 'Cyl., Sph.');

function pj_mbt_fps(P) {
  var MAX_ITER = 10,
      LOOP_TOL = 1e-7,
      C1 = 0.45503,
      C2 = 1.36509,
      C3 = 1.41546,
      C_x = 0.22248,
      C_y = 1.44492,
      C1_2 = 1 / 3;

  P.fwd = s_fwd;
  P.inv = s_inv;
  P.es = 0;

  function s_fwd(lp, xy) {
    var k, V, t, i;
    k = C3 * sin(lp.phi);
    for (i = MAX_ITER; i; --i) {
      t = lp.phi / C2;
      lp.phi -= V = (C1 * sin(t) + sin(lp.phi) - k) /
        (C1_2 * cos(t) + cos(lp.phi));
      if (fabs(V) < LOOP_TOL)
        break;
    }
    t = lp.phi / C2;
    xy.x = C_x * lp.lam * (1 + 3 * cos(lp.phi) / cos(t));
    xy.y = C_y * sin(t);
  }

  function s_inv(xy, lp) {
    var t;
    lp.phi = C2 * (t = aasin(xy.y / C_y));
    lp.lam = xy.x / (C_x * (1 + 3 * cos(lp.phi) / cos(t)));
    lp.phi = aasin((C1 * sin(t) + sin(lp.phi)) / C3);
  }
}


function pj_phi2(ts, e) {
  var N_ITER = 15,
      TOL = 1e-10,
      eccnth = 0.5 * e,
      Phi = M_HALFPI - 2 * atan(ts),
      i = N_ITER,
      con, dphi;

  do {
    con = e * sin(Phi);
    dphi = M_HALFPI - 2 * atan(ts * pow((1 - con) /
       (1 + con), eccnth)) - Phi;
    Phi += dphi;
  } while (fabs(dphi) > TOL && --i);
  if (i <= 0) {
    pj_ctx_set_errno(-18);
  }
  return Phi;
}


pj_add(pj_merc, 'merc', 'Mercator', 'Cyl, Sph&Ell\nlat_ts=');

function pj_merc(P) {
  var EPS10 = 1e-10;
  var phits = 0;
  var is_phits = pj_param(P.params, 'tlat_ts');

  if (is_phits) {
    phits = pj_param(P.params, 'rlat_ts');
    if (phits >= M_HALFPI) {
      e_error(-24);
    }
  }

  if (P.es) { // ellipsoid
    if (is_phits) {
      P.k0 = pj_msfn(sin(phits), cos(phits), P.es);
    }
    P.inv = e_inv;
    P.fwd = e_fwd;
  } else {
    P.inv = s_inv;
    P.fwd = s_fwd;
  }

  function e_fwd(lp, xy) {
    if (fabs(fabs(lp.phi) - M_HALFPI) <= EPS10) {
      f_error();
    }
    xy.x = P.k0 * lp.lam;
    xy.y = -P.k0 * log(pj_tsfn(lp.phi, sin(lp.phi), P.e));
  }

  function e_inv(xy, lp) {
    lp.phi = pj_phi2(exp(-xy.y / P.k0), P.e);
    if (lp.phi === HUGE_VAL) {
      i_error();
    }
    lp.lam = xy.x / P.k0;
  }

  function s_fwd(lp, xy) {
    if (fabs(fabs(lp.phi) - M_HALFPI) <= EPS10) {
      f_error();
    }
    xy.x = P.k0 * lp.lam;
    xy.y = P.k0 * log(tan(M_FORTPI + 0.5 * lp.phi));
  }

  function s_inv(xy, lp) {
    lp.phi = M_HALFPI - 2 * atan(exp(-xy.y / P.k0));
    lp.lam = xy.x / P.k0;
  }
}


pj_add(pj_mill, 'mill', 'Miller Cylindrical', 'Cyl, Sph');

function pj_mill(P) {

  P.fwd = s_fwd;
  P.inv = s_inv;
  P.es = 0;

  function s_fwd(lp, xy) {
    xy.x = lp.lam;
    xy.y = log(tan(M_FORTPI + lp.phi * 0.4)) * 1.25;
  }

  function s_inv(xy, lp) {
    lp.lam = xy.x;
    lp.phi = 2.5 * (atan(exp(0.8 * xy.y)) - M_FORTPI);
  }
}


/* evaluate complex polynomial */

/* note: coefficients are always from C_1 to C_n
**  i.e. C_0 == (0., 0)
**  n should always be >= 1 though no checks are made
*/
// z: Complex number (object with r and i properties)
// C: Array of complex numbers
// returns: complex number
function pj_zpoly1(z, C) {
  var t, r, i;
  var n = C.length - 1;
  r = C[n][0];
  i = C[n][1];
  while (--n >= 0) {
    t = r;
    r = C[n][0] + z.r * t - z.i * i;
    i = C[n][1] + z.r * i + z.i * t;
  }
  return {
    r: z.r * r - z.i * i,
    i: z.r * i + z.i * r
  };
}

/* evaluate complex polynomial and derivative */
function pj_zpolyd1(z, C, der) {
  var ai, ar, bi, br, t;
  var first = true;
  var n = C.length - 1;
  ar = br = C[n][0];
  ai = bi = C[n][1];
  while (--n >= 0) {
    if (first) {
      first = false;
    } else {
      br = ar + z.r * (t = br) - z.i * bi;
      bi = ai + z.r * bi + z.i * t;
    }
    ar = C[n][0] + z.r * (t = ar) - z.i * ai;
    ai = C[n][1] + z.r * ai + z.i * t;
  }
  der.r = ar + z.r * br - z.i * bi;
  der.i = ai + z.r * bi + z.i * br;
  return {
    r: z.r * ar - z.i * ai,
    i: z.r * ai + z.i * ar
  };
}


pj_add(pj_mil_os, 'mil_os', 'Miller Oblated Stereographic', 'Azi(mod)');
pj_add(pj_lee_os, 'lee_os', 'Lee Oblated Stereographic', 'Azi(mod)');
pj_add(pj_gs48, 'gs48', 'Mod Stereographic of 48 U.S.', 'Azi(mod)');
pj_add(pj_alsk, 'alsk', 'Mod Stereographic of Alaska', 'Azi(mod)');
pj_add(pj_gs50, 'gs50', 'Mod Stereographic of 50 U.S.', 'Azi(mod)');

function pj_mil_os(P) {
  var AB = [
    [0.924500, 0],
    [0,        0],
    [0.019430, 0]
  ];
  P.lam0 = DEG_TO_RAD * 20;
  P.phi0 = DEG_TO_RAD * 18;
  P.es = 0;
  pj_mod_ster(P, AB);
}

function pj_lee_os(P) {
  var AB = [
    [0.721316,    0],
    [0,           0],
    [-0.0088162, -0.00617325]
  ];
  P.lam0 = DEG_TO_RAD * -165;
  P.phi0 = DEG_TO_RAD * -10;
  P.es = 0;
  pj_mod_ster(P, AB);
}

function pj_gs48(P) {
  var AB = [
    [0.98879,   0],
    [0,         0],
    [-0.050909, 0],
    [0,         0],
    [0.075528,  0]
  ];
  P.lam0 = DEG_TO_RAD * -96;
  P.phi0 = DEG_TO_RAD * 39;
  P.es = 0;
  P.a = 6370997;
  pj_mod_ster(P, AB);
}

function pj_alsk(P) {
  var ABe = [ /* Alaska ellipsoid */
    [ 0.9945303, 0],
    [ 0.0052083, -0.0027404],
    [ 0.0072721,  0.0048181],
    [-0.0151089, -0.1932526],
    [ 0.0642675, -0.1381226],
    [ 0.3582802, -0.2884586],
  ];
  var ABs = [ /* Alaska sphere */
    [ 0.9972523,  0],
    [ 0.0052513, -0.0041175],
    [ 0.0074606,  0.0048125],
    [-0.0153783, -0.1968253],
    [ 0.0636871, -0.1408027],
    [ 0.3660976, -0.2937382]
  ];
  var AB;
  P.lam0 = DEG_TO_RAD * -152;
  P.phi0 = DEG_TO_RAD * 64;
  if (P.es != 0.0) { /* fixed ellipsoid/sphere */
    AB = ABe;
    P.a = 6378206.4;
    P.e = sqrt(P.es = 0.00676866);
  } else {
    AB = ABs;
    P.a = 6370997;
  }
  pj_mod_ster(P, AB);
}

function pj_gs50(P) {
  var ABe = [
    [ 0.9827497,  0],
    [ 0.0210669,  0.0053804],
    [-0.1031415, -0.0571664],
    [-0.0323337, -0.0322847],
    [ 0.0502303,  0.1211983],
    [ 0.0251805,  0.0895678],
    [-0.0012315, -0.1416121],
    [ 0.0072202, -0.1317091],
    [-0.0194029,  0.0759677],
    [-0.0210072,  0.0834037]
  ];
  var ABs = [
    [ 0.9842990,  0],
    [ 0.0211642,  0.0037608],
    [-0.1036018, -0.0575102],
    [-0.0329095, -0.0320119],
    [ 0.0499471,  0.1223335],
    [ 0.0260460,  0.0899805],
    [ 0.0007388, -0.1435792],
    [ 0.0075848, -0.1334108],
    [-0.0216473,  0.0776645],
    [-0.0225161,  0.0853673]
  ];
  var AB;
  P.lam0 = DEG_TO_RAD * -120;
  P.phi0 = DEG_TO_RAD * 45;
  if (P.es != 0.0) { /* fixed ellipsoid/sphere */
    AB = ABe;
    P.a = 6378206.4;
    P.e = sqrt(P.es = 0.00676866);
  } else {
    AB = ABs;
    P.a = 6370997;
  }
  pj_mod_ster(P, AB);
}

function pj_mod_ster(P, zcoeff) {
  var EPSLN = 1e-12;
  var esphi, chio;
  var cchio, schio;
  if (P.es != 0.0) {
    esphi = P.e * sin(P.phi0);
    chio = 2 * atan(tan((M_HALFPI + P.phi0) * 0.5) *
        pow((1 - esphi) / (1 + esphi), P.e * 0.5)) - M_HALFPI;
  } else
    chio = P.phi0;
  schio = sin(chio);
  cchio = cos(chio);
  P.inv = e_inv;
  P.fwd = e_fwd;

  function e_fwd(lp, xy) {
    var sinlon, coslon, esphi, chi, schi, cchi, s;
    var p = {};

    sinlon = sin(lp.lam);
    coslon = cos(lp.lam);
    esphi = P.e * sin(lp.phi);
    chi = 2 * atan(tan((M_HALFPI + lp.phi) * 0.5) *
        pow((1 - esphi) / (1 + esphi), P.e * 0.5)) - M_HALFPI;
    schi = sin(chi);
    cchi = cos(chi);
    s = 2 / (1 + schio * schi + cchio * cchi * coslon);
    p.r = s * cchi * sinlon;
    p.i = s * (cchio * schi - schio * cchi * coslon);
    p = pj_zpoly1(p, zcoeff);
    xy.x = p.r;
    xy.y = p.i;
  }

  function e_inv(xy, lp) {
    var nn;
    var p = {}, fxy, fpxy = {}, dp = {}; // complex numbers
    var den, rh = 0.0, z, sinz = 0.0, cosz = 0.0, chi, phi = 0.0, esphi;
    var dphi;

    p.r = xy.x;
    p.i = xy.y;
    for (nn = 20; nn ;--nn) {
      fxy = pj_zpolyd1(p, zcoeff, fpxy);
      fxy.r -= xy.x;
      fxy.i -= xy.y;
      den = fpxy.r * fpxy.r + fpxy.i * fpxy.i;
      dp.r = -(fxy.r * fpxy.r + fxy.i * fpxy.i) / den;
      dp.i = -(fxy.i * fpxy.r - fxy.r * fpxy.i) / den;
      p.r += dp.r;
      p.i += dp.i;
      if ((fabs(dp.r) + fabs(dp.i)) <= EPSLN)
          break;
    }
    if (nn) {
      rh = hypot(p.r, p.i);
      z = 2 * atan(0.5 * rh);
      sinz = sin(z);
      cosz = cos(z);
      lp.lam = P.lam0;
      if (fabs(rh) <= EPSLN) {
        /* if we end up here input coordinates were (0,0).
         * pj_inv() adds P.lam0 to lp.lam, this way we are
         * sure to get the correct offset */
        lp.lam = 0.0;
        lp.phi = P.phi0;
        return;
      }
      chi = aasin(cosz * schio + p.i * sinz * cchio / rh);
      phi = chi;
      for (nn = 20; nn ;--nn) {
        esphi = P.e * sin(phi);
        dphi = 2 * atan(tan((M_HALFPI + chi) * 0.5) *
            pow((1 + esphi) / (1 - esphi), P.e * 0.5)) - M_HALFPI - phi;
        phi += dphi;
        if (fabs(dphi) <= EPSLN)
          break;
      }
    }
    if (nn) {
      lp.phi = phi;
      lp.lam = atan2(p.r * sinz, rh * cchio * cosz - p.i * schio * sinz);
    } else
      lp.lam = lp.phi = HUGE_VAL;
  }
}


pj_add(pj_natearth, 'natearth', 'Natural Earth', 'PCyl., Sph.');
pj_add(pj_natearth2, 'natearth2', 'Natural Earth 2', 'PCyl., Sph.');

function pj_natearth(P) {
  var A0 = 0.8707,
  A1 = -0.131979,
  A2 = -0.013791,
  A3 = 0.003971,
  A4 = -0.001529,
  B0 = 1.007226,
  B1 = 0.015085,
  B2 = -0.044475,
  B3 = 0.028874,
  B4 = -0.005916,
  C0 = B0,
  C1 = (3 * B1),
  C2 = (7 * B2),
  C3 = (9 * B3),
  C4 = (11 * B4),
  EPS = 1e-11,
  MAX_Y = (0.8707 * 0.52 * M_PI);

  P.es = 0;
  P.fwd = s_fwd;
  P.inv = s_inv;

  function s_fwd(lp, xy) {
    var phi2, phi4;
    phi2 = lp.phi * lp.phi;
    phi4 = phi2 * phi2;
    xy.x = lp.lam * (A0 + phi2 * (A1 + phi2 * (A2 + phi4 * phi2 * (A3 + phi2 * A4))));
    xy.y = lp.phi * (B0 + phi2 * (B1 + phi4 * (B2 + B3 * phi2 + B4 * phi4)));
  }

  function s_inv(xy, lp) {
    var x = xy.x, y = xy.y;
    var yc, tol, y2, y4, f, fder;
    if (y > MAX_Y) {
      y = MAX_Y;
    } else if (y < -MAX_Y) {
      y = -MAX_Y;
    }

    yc = y;
      for (;;) { /* Newton-Raphson */
      y2 = yc * yc;
      y4 = y2 * y2;
      f = (yc * (B0 + y2 * (B1 + y4 * (B2 + B3 * y2 + B4 * y4)))) - y;
      fder = C0 + y2 * (C1 + y4 * (C2 + C3 * y2 + C4 * y4));
      yc -= tol = f / fder;
      if (fabs(tol) < EPS) {
          break;
      }
    }
    lp.phi = yc;
    y2 = yc * yc;
    lp.lam = x / (A0 + y2 * (A1 + y2 * (A2 + y2 * y2 * y2 * (A3 + y2 * A4))));
  }
}

function pj_natearth2(P) {
  var A0 = 0.84719,
      A1 = -0.13063,
      A2 = -0.04515,
      A3 = 0.05494,
      A4 = -0.02326,
      A5 = 0.00331,
      B0 = 1.01183,
      B1 = -0.02625,
      B2 = 0.01926,
      B3 = -0.00396,
      C0 = B0,
      C1 = (9 * B1),
      C2 = (11 * B2),
      C3 = (13 * B3),
      EPS = 1e-11,
      MAX_Y = (0.84719 * 0.535117535153096 * M_PI);

  P.es = 0;
  P.fwd = s_fwd;
  P.inv = s_inv;

  function s_fwd(lp, xy) {
    var phi2, phi4, phi6;
    phi2 = lp.phi * lp.phi;
    phi4 = phi2 * phi2;
    phi6 = phi2 * phi4;
    xy.x = lp.lam * (A0 + A1 * phi2 + phi6 * phi6 * (A2 + A3 * phi2 + A4 * phi4 + A5 * phi6));
    xy.y = lp.phi * (B0 + phi4 * phi4 * (B1 + B2 * phi2 + B3 * phi4));
  }

  function s_inv(xy, lp) {
    var x = xy.x, y = xy.y;
    var yc, tol, y2, y4, y6, f, fder;
    if (y > MAX_Y) {
      y = MAX_Y;
    } else if (y < -MAX_Y) {
      y = -MAX_Y;
    }
    yc = y;
    for (;;) { /* Newton-Raphson */
      y2 = yc * yc;
      y4 = y2 * y2;
      f = (yc * (B0 + y4 * y4 * (B1 + B2 * y2 + B3 * y4))) - y;
      fder = C0 + y4 * y4 * (C1 + C2 * y2 + C3 * y4);
      yc -= tol = f / fder;
      if (fabs(tol) < EPS) {
        break;
      }
    }
    lp.phi = yc;
    y2 = yc * yc;
    y4 = y2 * y2;
    y6 = y2 * y4;
    lp.lam = x / (A0 + A1 * y2 + y6 * y6 * (A2 + A3 * y2 + A4 * y4 + A5 * y6));
  }
}


pj_add(pj_nell, 'nell', 'Nell', 'PCyl., Sph.');

function pj_nell(P) {
  var MAX_ITER = 10;
  var LOOP_TOL = 1e-7;
  P.inv = s_inv;
  P.fwd = s_fwd;
  P.es = 0;

  function s_fwd(lp, xy) {
    var k, V, i;
    k = 2 * sin(lp.phi);
    V = lp.phi * lp.phi;
    lp.phi *= 1.00371 + V * (-0.0935382 + V * -0.011412);
    for (i = MAX_ITER; i ; --i) {
        lp.phi -= V = (lp.phi + sin(lp.phi) - k) /
            (1 + cos(lp.phi));
        if (fabs(V) < LOOP_TOL)
            break;
    }
    xy.x = 0.5 * lp.lam * (1 + cos(lp.phi));
    xy.y = lp.phi;
  }

  function s_inv(xy, lp) {
    lp.lam = 2 * xy.x / (1 + cos(xy.y));
    lp.phi = aasin(0.5 * (xy.y + sin(xy.y)));
  }
}


pj_add(pj_nell_h, 'nell_h', 'Nell-Hammer', 'PCyl., Sph.');

function pj_nell_h(P) {
var NITER = 9,
    EPS = 1e-7;
  P.es = 0;
  P.fwd = s_fwd;
  P.inv = s_inv;

  function s_fwd(lp, xy) {
    xy.x = 0.5 * lp.lam * (1 + cos(lp.phi));
    xy.y = 2.0 * (lp.phi - tan(0.5 *lp.phi));
  }

  function s_inv(xy, lp) {
    var V, c, p, i;
    p = 0.5 * xy.y;
    for (i = NITER; i>0; --i) {
      c = cos(0.5 * lp.phi);
      lp.phi -= V = (lp.phi - tan(lp.phi/2) - p)/(1 - 0.5/(c*c));
      if (fabs(V) < EPS)
        break;
    }
    if (!i) {
      lp.phi = p < 0 ? -M_HALFPI : M_HALFPI;
      lp.lam = 2 * xy.x;
    } else
      lp.lam = 2 * xy.x / (1 + cos(lp.phi));
  }
}


pj_add(pj_nsper, 'nsper', 'Near-sided perspective', 'Azi, Sph\nh=');
pj_add(pj_tpers, 'tpers', 'Tilted perspective', 'Azi, Sph\ntilt= azi= h=');

function pj_nsper(P) {
  pj_tpers_init(P, pj_param(P.params, "dh"));
}

function pj_tpers(P) {
  var tilt = pj_param(P.params, 'dtilt') * DEG_TO_RAD;
  var azi = pj_param(P.params, 'dazi') * DEG_TO_RAD;
  var height = pj_param(P.params, "dh");
  pj_tpers_init(P, height, tilt, azi);
}

function pj_tpers_init(P, height, tiltAngle, azimuth) {
  var N_POLE = 0,
      S_POLE = 1,
      EIT = 2,
      OBLI= 3,
      tilt = !isNaN(tiltAngle) && !isNaN(azimuth),
      mode, sinph0, cosph0, p, rp, pn1, pfact, h, cg, sg, sw, cw;

  if (height <= 0) e_error(-30);
  if (tilt) {
    cg = cos(azimuth);
    sg = sin(azimuth);
    cw = cos(tiltAngle);
    sw = sin(tiltAngle);
  }
  if (fabs(fabs(P.phi0) - M_HALFPI) < EPS10)
    mode = P.phi0 < 0 ? S_POLE : N_POLE;
  else if (fabs(P.phi0) < EPS10)
    mode = EIT;
  else {
    mode = OBLI;
    sinph0 = sin(P.phi0);
    cosph0 = cos(P.phi0);
  }
  pn1 = height / P.a; /* normalize by radius */
  p = 1 + pn1;
  rp = 1 / p;
  h = 1 / pn1;
  pfact = (p + 1) * h;

  P.fwd = s_fwd;
  P.inv = s_inv;
  P.es = 0;

  function s_fwd(lp, xy) {
    var coslam, cosphi, sinphi;
    var yt, ba;
    sinphi = sin(lp.phi);
    cosphi = cos(lp.phi);
    coslam = cos(lp.lam);
    switch (mode) {
      case OBLI:
        xy.y = sinph0 * sinphi + cosph0 * cosphi * coslam;
        break;
      case EIT:
        xy.y = cosphi * coslam;
        break;
      case S_POLE:
        xy.y = - sinphi;
        break;
      case N_POLE:
        xy.y = sinphi;
        break;
    }
    if (xy.y < rp) f_error();
    xy.y = pn1 / (p - xy.y);
    xy.x = xy.y * cosphi * sin(lp.lam);
    switch (mode) {
      case OBLI:
        xy.y *= (cosph0 * sinphi -
           sinph0 * cosphi * coslam);
        break;
      case EIT:
        xy.y *= sinphi;
        break;
      case N_POLE:
        coslam = - coslam;
        /* falls through */
      case S_POLE:
        xy.y *= cosphi * coslam;
        break;
    }
    if (tilt) {
      yt = xy.y * cg + xy.x * sg;
      ba = 1 / (yt * sw * h + cw);
      xy.x = (xy.x * cg - xy.y * sg) * cw * ba;
      xy.y = yt * ba;
    }
  }

  function s_inv(xy, lp) {
    var rh, cosz, sinz;
    var bm, bq, yt;
    if (tilt) {
      yt = 1/(pn1 - xy.y * sw);
      bm = pn1 * xy.x * yt;
      bq = pn1 * xy.y * cw * yt;
      xy.x = bm * cg + bq * sg;
      xy.y = bq * cg - bm * sg;
    }
    rh = hypot(xy.x, xy.y);
    if ((sinz = 1 - rh * rh * pfact) < 0) i_error();
    sinz = (p - sqrt(sinz)) / (pn1 / rh + rh / pn1);
    cosz = sqrt(1 - sinz * sinz);
    if (fabs(rh) <= EPS10) {
        lp.lam = 0;
        lp.phi = P.phi0;
    } else {
      switch (mode) {
        case OBLI:
          lp.phi = asin(cosz * sinph0 + xy.y * sinz * cosph0 / rh);
          xy.y = (cosz - sinph0 * sin(lp.phi)) * rh;
          xy.x *= sinz * cosph0;
          break;
        case EIT:
          lp.phi = asin(xy.y * sinz / rh);
          xy.y = cosz * rh;
          xy.x *= sinz;
          break;
        case N_POLE:
          lp.phi = asin(cosz);
          xy.y = -xy.y;
          break;
        case S_POLE:
          lp.phi = - asin(cosz);
          break;
      }
      lp.lam = atan2(xy.x, xy.y);
    }
  }
}


pj_add(pj_nzmg, 'nzmg', 'New Zealand Map Grid', 'fixed Earth');

function pj_nzmg(P) {
  var EPSLN = 1e-10;
  var SEC5_TO_RAD = 0.4848136811095359935899141023;
  var RAD_TO_SEC5 = 2.062648062470963551564733573;
  var bf = [
    [ 0.7557853228, 0.0],
    [ 0.249204646,  0.003371507],
    [-0.001541739,  0.041058560],
    [-0.10162907,   0.01727609],
    [-0.26623489,  -0.36249218],
    [-0.6870983,   -1.1651967]];

  var tphi= [1.5627014243, 0.5185406398, -0.03333098,
    -0.1052906, -0.0368594, 0.007317, 0.01220, 0.00394, -0.0013];

  var tpsi = [0.6399175073, -0.1358797613, 0.063294409, -0.02526853, 0.0117879,
    -0.0055161, 0.0026906, -0.001333, 0.00067, -0.00034];

  /* force to International major axis */
  P.ra = 1 / (P.a = 6378388.0);
  P.lam0 = DEG_TO_RAD * 173;
  P.phi0 = DEG_TO_RAD * -41;
  P.x0 = 2510000;
  P.y0 = 6023150;

  P.inv = e_inv;
  P.fwd = e_fwd;

  function e_fwd(lp, xy) {
    var i = tpsi.length - 1;
    var p = {r: tpsi[i]};
    var phi = (lp.phi - P.phi0) * RAD_TO_SEC5;
    for (--i; i >= 0; --i)
      p.r = tpsi[i] + phi * p.r;
    p.r *= phi;
    p.i = lp.lam;
    p = pj_zpoly1(p, bf);
    xy.x = p.i;
    xy.y = p.r;
  }

  function e_inv(xy, lp) {
    var nn, i, dr, di, f, den;
    var p = {r: xy.y, i: xy.x};
    var fp = {};
    for (nn = 20; nn > 0 ;--nn) {
      f = pj_zpolyd1(p, bf, fp);
      f.r -= xy.y;
      f.i -= xy.x;
      den = fp.r * fp.r + fp.i * fp.i;
      p.r += dr = -(f.r * fp.r + f.i * fp.i) / den;
      p.i += di = -(f.i * fp.r - f.r * fp.i) / den;
      if ((fabs(dr) + fabs(di)) <= EPSLN) break;
    }
    if (nn > 0) {
      lp.lam = p.i;
      i = tphi.length - 1;
      lp.phi = tphi[i];
      for (--i; i >= 0; --i)
        lp.phi = tphi[i] + p.r * lp.phi;
      lp.phi = P.phi0 + p.r * lp.phi * SEC5_TO_RAD;
    } else
      lp.lam = lp.phi = HUGE_VAL;
  }
}


pj_add(pj_ob_tran, 'ob_tran', 'General Oblique Transformation', 'Misc Sph\n' +
  'o_proj= plus parameters for projection\n' +
  'o_lat_p= o_lon_p= (new pole) or\n' +
  'o_alpha= o_lon_c= o_lat_c= or\n' +
  'o_lon_1= o_lat_1= o_lon_2= o_lat_2=');

function pj_ob_tran(P) {
  var name, defn, P2;
  var lamp, cphip, sphip, phip;
  var lamc, phic, alpha;
  var lam1, lam2, phi1, phi2, con;
  var TOL = 1e-10;

  name = pj_param(P.params, 'so_proj');
  defn = pj_list[name];
  if (!name) e_error(-26);
  if (!defn || name == 'ob_tran') e_error(-37);
  P.es = 0;
  // copy params to second object
  P2 = {};
  Object.keys(P).forEach(function(key) {
    // TODO: remove o_ params?
    P2[key] = P[key];
  });
  defn.init(P2);

  // NOT in Proj.4
  // fix output units when doing latlong transform (see pj_transform.js)
  if (P2.is_latlong && P.to_meter == 1) {
    P.to_meter = DEG_TO_RAD;
    P.fr_meter = RAD_TO_DEG;
  }

  if (pj_param(P.params, 'to_alpha')) {
    lamc  = pj_param(P.params, 'ro_lon_c');
    phic  = pj_param(P.params, 'ro_lat_c');
    alpha = pj_param(P.params, 'ro_alpha');

    if (fabs(fabs(phic) - M_HALFPI) <= TOL) e_error(-32);
    lamp = lamc + aatan2(-cos(alpha), -sin(alpha) * sin(phic));
    phip = aasin(cos(phic) * sin(alpha));

  } else if (pj_param(P.params, 'to_lat_p')) { /* specified new pole */
    lamp = pj_param(P.params, 'ro_lon_p');
    phip = pj_param(P.params, 'ro_lat_p');

  } else { /* specified new 'equator' points */

    lam1 = pj_param(P.params, 'ro_lon_1');
    phi1 = pj_param(P.params, 'ro_lat_1');
    lam2 = pj_param(P.params, 'ro_lon_2');
    phi2 = pj_param(P.params, 'ro_lat_2');
    if (fabs(phi1 - phi2) <= TOL ||
        (con = fabs(phi1)) <= TOL ||
        fabs(con - M_HALFPI) <= TOL ||
        fabs(fabs(phi2) - M_HALFPI) <= TOL) e_error(-33);
    lamp = atan2(cos(phi1) * sin(phi2) * cos(lam1) -
        sin(phi1) * cos(phi2) * cos(lam2),
        sin(phi1) * cos(phi2) * sin(lam2) -
        cos(phi1) * sin(phi2) * sin(lam1));
    phip = atan(-cos(lamp - lam1) / tan(phi1));
  }
  if (fabs(phip) > TOL) { /* oblique */
    cphip = cos(phip);
    sphip = sin(phip);
    P.fwd = o_fwd;
    P.inv = P2.inv ? o_inv : null;
  } else { /* transverse */
    P.fwd = t_fwd;
    P.inv = P2.inv ? t_inv : null;
  }

  function o_fwd(lp, xy) {
    var coslam, sinphi, cosphi;
    coslam = cos(lp.lam);
    sinphi = sin(lp.phi);
    cosphi = cos(lp.phi);
    lp.lam = adjlon(aatan2(cosphi * sin(lp.lam), sphip * cosphi * coslam +
        cphip * sinphi) + lamp);
    lp.phi = aasin(sphip * sinphi - cphip * cosphi * coslam);
    P2.fwd(lp, xy);
  }

  function t_fwd(lp, xy) {
    var cosphi, coslam;
    cosphi = cos(lp.phi);
    coslam = cos(lp.lam);
    lp.lam = adjlon(aatan2(cosphi * sin(lp.lam), sin(lp.phi)) + lamp);
    lp.phi = aasin(-cosphi * coslam);
    P2.fwd(lp, xy);
  }

  function o_inv(xy, lp) {
    var coslam, sinphi, cosphi;
    P2.inv(xy, lp);
    if (lp.lam != HUGE_VAL) {
      coslam = cos(lp.lam -= lamp);
      sinphi = sin(lp.phi);
      cosphi = cos(lp.phi);
      lp.phi = aasin(sphip * sinphi + cphip * cosphi * coslam);
      lp.lam = aatan2(cosphi * sin(lp.lam), sphip * cosphi * coslam -
        cphip * sinphi);
    }
  }

  function t_inv(xy, lp) {
    var cosphi, t;
    P2.inv(xy, lp);
    if (lp.lam != HUGE_VAL) {
      cosphi = cos(lp.phi);
      t = lp.lam - lamp;
      lp.lam = aatan2(cosphi * sin(t), - sin(lp.phi));
      lp.phi = aasin(cosphi * cos(t));
    }
  }
}


pj_add(pj_ocea, 'ocea', 'Oblique Cylindrical Equal Area', 'Cyl, Sph lonc= alpha= or\nlat_1= lat_2= lon_1= lon_2=');

function pj_ocea(P) {
  var phi_0 = 0,
      phi_1, phi_2, lam_1, lam_2, lonz, alpha,
      rok, rtk, sinphi, cosphi, singam, cosgam;
  rok = 1 / P.k0;
  rtk = P.k0;
  /*If the keyword "alpha" is found in the sentence then use 1point+1azimuth*/
  if (pj_param(P.params, "talpha")) {
    /*Define Pole of oblique transformation from 1 point & 1 azimuth*/
    alpha   = pj_param(P.params, "ralpha");
    lonz = pj_param(P.params, "rlonc");
    /*Equation 9-8 page 80 (http://pubs.usgs.gov/pp/1395/report.pdf)*/
    singam = atan(-cos(alpha)/(-sin(phi_0) * sin(alpha))) + lonz;
    /*Equation 9-7 page 80 (http://pubs.usgs.gov/pp/1395/report.pdf)*/
    sinphi = asin(cos(phi_0) * sin(alpha));
  /*If the keyword "alpha" is NOT found in the sentence then use 2points*/
  } else {
    /*Define Pole of oblique transformation from 2 points*/
    phi_1 = pj_param(P.params, "rlat_1");
    phi_2 = pj_param(P.params, "rlat_2");
    lam_1 = pj_param(P.params, "rlon_1");
    lam_2 = pj_param(P.params, "rlon_2");
    /*Equation 9-1 page 80 (http://pubs.usgs.gov/pp/1395/report.pdf)*/
    singam = atan2(cos(phi_1) * sin(phi_2) * cos(lam_1) -
      sin(phi_1) * cos(phi_2) * cos(lam_2),
      sin(phi_1) * cos(phi_2) * sin(lam_2) -
      cos(phi_1) * sin(phi_2) * sin(lam_1) );

    /* take care of P->lam0 wrap-around when +lam_1=-90*/
    if (lam_1 == -M_HALFPI)
      singam = -singam;

    /*Equation 9-2 page 80 (http://pubs.usgs.gov/pp/1395/report.pdf)*/
    sinphi = atan(-cos(singam - lam_1) / tan(phi_1));
  }
  P.lam0 = singam + M_HALFPI;
  cosphi = cos(sinphi);
  sinphi = sin(sinphi);
  cosgam = cos(singam);
  singam = sin(singam);
  P.es = 0;
  P.fwd = s_fwd;
  P.inv = s_inv;

  function s_fwd(lp, xy) {
    var t;
    xy.y = sin(lp.lam);
    t = cos(lp.lam);
    xy.x = atan((tan(lp.phi) * cosphi + sinphi * xy.y) / t);
    if (t < 0)
        xy.x += M_PI;
    xy.x *= rtk;
    xy.y = rok * (sinphi * sin(lp.phi) - cosphi * cos(lp.phi) * xy.y);
  }

  function s_inv(xy, lp) {
    var t, s;
    xy.y /= rok;
    xy.x /= rtk;
    t = sqrt(1 - xy.y * xy.y);
    lp.phi = asin(xy.y * sinphi + t * cosphi * (s = sin(xy.x)));
    lp.lam = atan2(t * sinphi * s - xy.y * cosphi,
        t * cos(xy.x));
  }
}


pj_add(pj_omerc, 'omerc', 'Oblique Mercator', 'Cyl, Sph&Ell no_rot\n' +
    'alpha= [gamma=] [no_off] lonc= or\nlon_1= lat_1= lon_2= lat_2=');

function pj_omerc(P) {
  var TOL = 1e-7;
  var con, com, cosph0, D, F, H, L, sinph0, p, J, gamma=0,
      gamma0, lamc=0, lam1=0, lam2=0, phi1=0, phi2=0, alpha_c=0;
  var alp, gam, no_off = 0;
  var A, B, E, AB, ArB, BrA, rB, singam, cosgam, sinrot, cosrot;
  var v_pole_n, v_pole_s, u_0;
  var no_rot;

  no_rot = pj_param(P.params, "tno_rot");
  if ((alp = pj_param(P.params, "talpha")) != 0)
  alpha_c = pj_param(P.params, "ralpha");
  if ((gam = pj_param(P.params, "tgamma")) != 0)
  gamma = pj_param(P.params, "rgamma");
  if (alp || gam) {
    lamc = pj_param(P.params, "rlonc");
    no_off =
      /* For libproj4 compatibility ... for backward compatibility */
      pj_param(P.params, "tno_off") || pj_param(P.params, "tno_uoff");
    if (no_off) {
      /* Mark the parameter as used, so that the pj_get_def() return them */
      pj_param(P.params, "sno_uoff");
      pj_param(P.params, "sno_off");
    }
  } else {
    lam1 = pj_param(P.params, "rlon_1");
    phi1 = pj_param(P.params, "rlat_1");
    lam2 = pj_param(P.params, "rlon_2");
    phi2 = pj_param(P.params, "rlat_2");
    if (fabs(phi1 - phi2) <= TOL || (con = fabs(phi1)) <= TOL ||
        fabs(con - M_HALFPI) <= TOL || fabs(fabs(P.phi0) - M_HALFPI) <= TOL ||
        fabs(fabs(phi2) - M_HALFPI) <= TOL) e_error(-33);
  }
  com = sqrt(P.one_es);
  if (fabs(P.phi0) > EPS10) {
    sinph0 = sin(P.phi0);
    cosph0 = cos(P.phi0);
    con = 1 - P.es * sinph0 * sinph0;
    B = cosph0 * cosph0;
    B = sqrt(1 + P.es * B * B / P.one_es);
    A = B * P.k0 * com / con;
    D = B * com / (cosph0 * sqrt(con));
    if ((F = D * D - 1) <= 0)
      F = 0;
    else {
      F = sqrt(F);
      if (P.phi0 < 0)
        F = -F;
    }
    E = F += D;
    E *= pow(pj_tsfn(P.phi0, sinph0, P.e), B);
  } else {
    B = 1 / com;
    A = P.k0;
    E = D = F = 1;
  }
  if (alp || gam) {
    if (alp) {
      gamma0 = asin(sin(alpha_c) / D);
      if (!gam)
          gamma = alpha_c;
    } else
        alpha_c = asin(D*sin(gamma0 = gamma));
    P.lam0 = lamc - asin(0.5 * (F - 1 / F) * tan(gamma0)) / B;
  } else {
    H = pow(pj_tsfn(phi1, sin(phi1), P.e), B);
    L = pow(pj_tsfn(phi2, sin(phi2), P.e), B);
    F = E / H;
    p = (L - H) / (L + H);
    J = E * E;
    J = (J - L * H) / (J + L * H);
    if ((con = lam1 - lam2) < -M_PI)
        lam2 -= M_TWOPI;
    else if (con > M_PI)
        lam2 += M_TWOPI;
    P.lam0 = adjlon(0.5 * (lam1 + lam2) - atan(J * tan(0.5 * B * (lam1 - lam2)) / p) / B);
    gamma0 = atan(2 * sin(B * adjlon(lam1 - P.lam0)) / (F - 1 / F));
    gamma = alpha_c = asin(D * sin(gamma0));
  }
  singam = sin(gamma0);
  cosgam = cos(gamma0);
  sinrot = sin(gamma);
  cosrot = cos(gamma);
  BrA = 1 / (ArB = A * (rB = 1 / B));
  AB = A * B;
  if (no_off)
    u_0 = 0;
  else {
    u_0 = fabs(ArB * atan(sqrt(D * D - 1) / cos(alpha_c)));
    if (P.phi0 < 0)
        u_0 = - u_0;
  }
  F = 0.5 * gamma0;
  v_pole_n = ArB * log(tan(M_FORTPI - F));
  v_pole_s = ArB * log(tan(M_FORTPI + F));

  P.fwd = e_fwd;
  P.inv = e_inv;

  function e_fwd(lp, xy) {
    var S, T, U, V, W, temp, u, v;

    if (fabs(fabs(lp.phi) - M_HALFPI) > EPS10) {
      W = E / pow(pj_tsfn(lp.phi, sin(lp.phi), P.e), B);
      temp = 1 / W;
      S = 0.5 * (W - temp);
      T = 0.5 * (W + temp);
      V = sin(B * lp.lam);
      U = (S * singam - V * cosgam) / T;
      if (fabs(fabs(U) - 1.0) < EPS10)
        f_error();
      v = 0.5 * ArB * log((1 - U)/(1 + U));
      temp = cos(B * lp.lam);
      if(fabs(temp) < TOL) {
          u = A * lp.lam;
      } else {
          u = ArB * atan2((S * cosgam + V * singam), temp);
      }
    } else {
        v = lp.phi > 0 ? v_pole_n : v_pole_s;
        u = ArB * lp.phi;
    }
    if (no_rot) {
        xy.x = u;
        xy.y = v;
    } else {
        u -= u_0;
        xy.x = v * cosrot + u * sinrot;
        xy.y = u * cosrot - v * sinrot;
    }
  }

  function e_inv(xy, lp) {
    var u, v, Qp, Sp, Tp, Vp, Up;
    if (no_rot) {
      v = xy.y;
      u = xy.x;
    } else {
      v = xy.x * cosrot - xy.y * sinrot;
      u = xy.y * cosrot + xy.x * sinrot + u_0;
    }
    Qp = exp(- BrA * v);
    Sp = 0.5 * (Qp - 1 / Qp);
    Tp = 0.5 * (Qp + 1 / Qp);
    Vp = sin(BrA * u);
    Up = (Vp * cosgam + Sp * singam) / Tp;
    if (fabs(fabs(Up) - 1) < EPS10) {
      lp.lam = 0;
      lp.phi = Up < 0 ? -M_HALFPI : M_HALFPI;
    } else {
      lp.phi = E / sqrt((1 + Up) / (1 - Up));
      if ((lp.phi = pj_phi2(pow(lp.phi, 1 / B), P.e)) == HUGE_VAL)
          i_error();
      lp.lam = - rB * atan2((Sp * cosgam - Vp * singam), cos(BrA * u));
    }
  }
}


pj_add(pj_ortho, 'ortho', 'Orthographic', 'Azi, Sph.');

function pj_ortho(P) {
  var EPS10 = 1.e-10,
      N_POLE = 0,
      S_POLE = 1,
      EQUIT = 2,
      OBLIQ = 3;
  var Q = {};

  if (fabs(fabs(P.phi0) - M_HALFPI) <= EPS10)
    Q.mode = P.phi0 < 0 ? S_POLE : N_POLE;
  else if (fabs(P.phi0) > EPS10) {
    Q.mode = OBLIQ;
    Q.sinph0 = sin(P.phi0);
    Q.cosph0 = cos(P.phi0);
  } else
    Q.mode = EQUIT;

  P.fwd = s_fwd;
  P.inv = s_inv;
  P.es = 0;

  function s_fwd(lp, xy) {
    var coslam, cosphi, sinphi;
    cosphi = cos(lp.phi);
    coslam = cos(lp.lam);
    switch (Q.mode) {
    case EQUIT:
      if (cosphi * coslam < - EPS10) f_error();
      xy.y = sin(lp.phi);
      break;
    case OBLIQ:
      if (Q.sinph0 * (sinphi = sin(lp.phi)) +
         Q.cosph0 * cosphi * coslam < - EPS10) f_error();
      xy.y = Q.cosph0 * sinphi - Q.sinph0 * cosphi * coslam;
      break;
    case N_POLE:
      coslam = -coslam;
      /* falls through */
    case S_POLE:
      if (fabs(lp.phi - P.phi0) - EPS10 > M_HALFPI) f_error();
      xy.y = cosphi * coslam;
      break;
    }
    xy.x = cosphi * sin(lp.lam);
  }

  function s_inv(xy, lp) {
    var rh, cosc, sinc;

    if ((sinc = (rh = hypot(xy.x, xy.y))) > 1) {
        if ((sinc - 1) > EPS10) i_error();
        sinc = 1;
    }
    cosc = sqrt(1 - sinc * sinc); /* in this range OK */
    if (fabs(rh) <= EPS10) {
        lp.phi = P.phi0;
        lp.lam = 0.0;
    } else {
        switch (Q.mode) {
        case N_POLE:
            xy.y = -xy.y;
            lp.phi = acos(sinc);
            break;
        case S_POLE:
            lp.phi = - acos(sinc);
            break;
        case EQUIT:
        case OBLIQ:
          if (Q.mode == EQUIT) {
            lp.phi = xy.y * sinc / rh;
            xy.x *= sinc;
            xy.y = cosc * rh;
          } else {
            lp.phi = cosc * Q.sinph0 + xy.y * sinc * Q.cosph0 /rh;
            xy.y = (cosc - Q.sinph0 * lp.phi) * rh;
            xy.x *= sinc * Q.cosph0;
          }
          if (fabs(lp.phi) >= 1)
              lp.phi = lp.phi < 0 ? -M_HALFPI : M_HALFPI;
          else
              lp.phi = asin(lp.phi);
          break;
        }
        lp.lam = (xy.y == 0 && (Q.mode == OBLIQ || Q.mode == EQUIT)) ?
          (xy.x == 0 ? 0 : xy.x < 0 ? -M_HALFPI : M_HALFPI) : atan2(xy.x, xy.y);
    }
  }
}


pj_add(pj_patterson, 'patterson', 'Patterson Cylindrical', 'Cyl., Sph.');

function pj_patterson(P) {
  var K1 = 1.0148,
    K2 = 0.23185,
    K3 = -0.14499,
    K4 = 0.02406,
    C1 = K1,
    C2 = (5.0 * K2),
    C3 = (7.0 * K3),
    C4 = (9.0 * K4),
    EPS = 1e-11,
    MAX_Y =  908571831.7;

  P.es = 0;
  P.fwd = s_fwd;
  P.inv = s_inv;

  function s_fwd(lp, xy) {
    var phi2 = lp.phi * lp.phi;
    xy.x = lp.lam;
    xy.y = lp.phi * (K1 + phi2 * phi2 * (K2 + phi2 * (K3 + K4 * phi2)));
  }

  function s_inv(xy, lp) {
    var MAX_ITER = 100;
    var yc, tol, y2, f, fder;
    var i;

    yc = xy.y;

    /* make sure y is inside valid range */
    if (xy.y > MAX_Y) {
      xy.y = MAX_Y;
    } else if (xy.y < -MAX_Y) {
      xy.y = -MAX_Y;
    }

    for (i = MAX_ITER; i ; --i) { /* Newton-Raphson */
      y2 = yc * yc;
      f = (yc * (K1 + y2 * y2 * (K2 + y2 * (K3 + K4 * y2)))) - xy.y;
      fder = C1 + y2 * y2 * (C2 + y2 * (C3 + C4 * y2));
      yc -= tol = f / fder;
      if (fabs(tol) < EPS) {
        break;
      }
    }
    // other projections don't error if non-convergent
    // if (i === 0) error(PJD_ERR_NON_CONVERGENT);
    lp.phi = yc;

    /* longitude */
    lp.lam = xy.x;
  }
}


pj_add(pj_poly, 'poly', 'Polyconic (American)', 'Conic, Sph&Ell');

function pj_poly(P) {
  var TOL = 1e-10,
      CONV = 1e-10,
      N_ITER = 10,
      I_ITER = 20,
      ITOL = 1.e-12,
      ml0, en;

  if (P.es) {
    en = pj_enfn(P.es);
    ml0 = pj_mlfn(P.phi0, sin(P.phi0), cos(P.phi0), en);
    P.fwd = e_fwd;
    P.inv = e_inv;
  } else {
    ml0 = -P.phi0;
    P.fwd = s_fwd;
    P.inv = s_inv;
  }

  function e_fwd(lp, xy) {
    var ms, sp, cp;

    if (fabs(lp.phi) <= TOL) {
      xy.x = lp.lam;
      xy.y = -ml0;
    } else {
      sp = sin(lp.phi);
      ms = fabs(cp = cos(lp.phi)) > TOL ? pj_msfn(sp, cp, P.es) / sp : 0;
      xy.x = ms * sin(lp.lam *= sp);
      xy.y = (pj_mlfn(lp.phi, sp, cp, en) - ml0) + ms * (1 - cos(lp.lam));
    }
  }

  function e_inv(xy, lp) {
    var x = xy.x, y = xy.y;
    var r, c, sp, cp, s2ph, ml, mlb, mlp, dPhi, i;
    y += ml0;
    if (fabs(y) <= TOL) {
      lp.lam = x;
      lp.phi = 0;
    } else {
      r = y * y + x * x;
      for (lp.phi = y, i = I_ITER; i>0 ; --i) {
        sp = sin(lp.phi);
        s2ph = sp * (cp = cos(lp.phi));
        if (fabs(cp) < ITOL)
          i_error();
        c = sp * (mlp = sqrt(1 - P.es * sp * sp)) / cp;
        ml = pj_mlfn(lp.phi, sp, cp, en);
        mlb = ml * ml + r;
        mlp = P.one_es / (mlp * mlp * mlp);
        lp.phi += (dPhi =
          ( ml + ml + c * mlb - 2 * y * (c * ml + 1) ) / (
          P.es * s2ph * (mlb - 2 * y * ml) / c +
          2 * (y - ml) * (c * mlp - 1 / s2ph) - mlp - mlp));
        if (fabs(dPhi) <= ITOL)
          break;
      }
      if (!i) {
        i_error();
      }
      c = sin(lp.phi);
      lp.lam = asin(x * tan(lp.phi) * sqrt(1 - P.es * c * c)) / sin(lp.phi);
    }
  }

  function s_fwd(lp, xy) {
    var cot, E;
    if (fabs(lp.phi) <= TOL) {
      xy.x = lp.lam;
      xy.y = ml0;
    } else {
      cot = 1 / tan(lp.phi);
      xy.x = sin(E = lp.lam * sin(lp.phi)) * cot;
      xy.y = lp.phi - P.phi0 + cot * (1 - cos(E));
    }
  }

  function s_inv(xy, lp) {
    var B, dphi, tp, i;
    if (fabs(xy.y = P.phi0 + xy.y) <= TOL) {
      lp.lam = xy.x;
      lp.phi = 0;
    } else {
      lp.phi = xy.y;
      B = xy.x * xy.x + xy.y * xy.y;
      i = N_ITER;
      do {
        tp = tan(lp.phi);
        lp.phi -= (dphi = (xy.y * (lp.phi * tp + 1) - lp.phi -
          0.5 * ( lp.phi * lp.phi + B) * tp) /
          ((lp.phi - xy.y) / tp - 1));
      } while (fabs(dphi) > CONV && --i);
      if (!i) i_error();
      lp.lam = asin(xy.x * tan(lp.phi)) / sin(lp.phi);
    }
  }
}


pj_add(pj_putp2, 'putp2', 'Putnins P2', 'PCyl., Sph.');

function pj_putp2(P) {
  var C_x = 1.89490,
      C_y = 1.71848,
      C_p = 0.6141848493043784,
      EPS = 1e-10,
      NITER = 10,
      PI_DIV_3 = 1.0471975511965977;
  P.es = 0;
  P.fwd = s_fwd;
  P.inv = s_inv;

  function s_fwd(lp, xy) {
    var p, c, s, V, i;
    p = C_p * sin(lp.phi);
    s = lp.phi * lp.phi;
    lp.phi *= 0.615709 + s * ( 0.00909953 + s * 0.0046292 );
    for (i = NITER; i ; --i) {
      c = cos(lp.phi);
      s = sin(lp.phi);
      lp.phi -= V = (lp.phi + s * (c - 1) - p) /
        (1 + c * (c - 1) - s * s);
      if (fabs(V) < EPS)
        break;
    }
    if (!i)
      lp.phi = lp.phi < 0 ? - PI_DIV_3 : PI_DIV_3;
    xy.x = C_x * lp.lam * (cos(lp.phi) - 0.5);
    xy.y = C_y * sin(lp.phi);
  }

  function s_inv(xy, lp) {
    var c;
    lp.phi = aasin(xy.y / C_y);
    lp.lam = xy.x / (C_x * ((c = cos(lp.phi)) - 0.5));
    lp.phi = aasin((lp.phi + sin(lp.phi) * (c - 1)) / C_p);
  }
}


pj_add(pj_putp3, 'putp3', 'Putnins P3', 'PCyl., Sph.');
pj_add(pj_putp3p, 'putp3p', 'Putnins P3\'', 'PCyl., Sph.');

function pj_putp3p(P) {
  pj_putp3(P, true);
}

function pj_putp3(P, prime) {
  var C = 0.79788456,
      RPISQ = 0.1013211836,
      A = (prime ? 2 : 4) * RPISQ;
  P.es = 0;
  P.fwd = s_fwd;
  P.inv = s_inv;

  function s_fwd(lp, xy) {
    xy.x = C * lp.lam * (1 - A * lp.phi * lp.phi);
    xy.y = C * lp.phi;
  }

  function s_inv(xy, lp) {
    lp.phi = xy.y / C;
    lp.lam = xy.x / (C * (1 - A * lp.phi * lp.phi));
  }
}


pj_add(pj_putp4p, 'putp4p', 'Putnins P4\'', 'PCyl., Sph.');
pj_add(pj_weren, 'weren', 'Werenskiold I', 'PCyl., Sph.');

function pj_putp4p(P) {
  pj_putp4p_init(P, 0.874038744, 3.883251825);
}

function pj_weren(P) {
  pj_putp4p_init(P, 1, 4.442882938);
}

function pj_putp4p_init(P, C_x, C_y) {
  P.es = 0;
  P.fwd = s_fwd;
  P.inv = s_inv;

  function s_fwd(lp, xy) {
    lp.phi = aasin(0.883883476 * sin(lp.phi));
    xy.x = C_x * lp.lam * cos(lp.phi);
    xy.x /= cos(lp.phi *= 0.333333333333333);
    xy.y = C_y * sin(lp.phi);
  }

  function s_inv(xy, lp) {
    lp.phi = aasin(xy.y / C_y);
    lp.lam = xy.x * cos(lp.phi) / C_x;
    lp.phi *= 3;
    lp.lam /= cos(lp.phi);
    lp.phi = aasin(1.13137085 * sin(lp.phi));
  }
}


pj_add(pj_putp5, 'putp5', 'Putnins P5', 'PCyl., Sph.');
pj_add(pj_putp5p, 'putp5p', 'Putnins P5\'', 'PCyl., Sph.');

function pj_putp5p(P) {
  pj_putp5(P, true);
}

function pj_putp5(P, prime) {
  var A = (prime ? 1.5 : 2),
      B = (prime ? 0.5 : 1),
      C = 1.01346,
      D = 1.2158542;

  P.es = 0;
  P.fwd = s_fwd;
  P.inv = s_inv;

  function s_fwd(lp, xy) {
    xy.x = C * lp.lam * (A - B * sqrt(1 + D * lp.phi * lp.phi));
    xy.y = C * lp.phi;
  }

  function s_inv(xy, lp) {
    lp.phi = xy.y / C;
    lp.lam = xy.x / (C * (A - B * sqrt(1 + D * lp.phi * lp.phi)));
  }
}


pj_add(pj_putp6, 'putp6', 'Putnins P6', 'PCyl., Sph.');
pj_add(pj_putp6p, 'putp6p', 'Putnins P6\'', 'PCyl., Sph.');

function pj_putp6p(P) {
  pj_putp6(P, true);
}

function pj_putp6(P, prime) {
  var EPS = 1e-10,
      NITER = 10,
      CON_POLE = 1.732050807568877,
      A, B, C_x, C_y, D;

  if (prime) {
    C_x = 0.44329;
    C_y = 0.80404;
    A   = 6;
    B   = 5.61125;
    D   = 3;
  } else {
    C_x = 1.01346;
    C_y = 0.91910;
    A   = 4;
    B   = 2.1471437182129378784;
    D   = 2;
  }

  P.es = 0;
  P.fwd = s_fwd;
  P.inv = s_inv;

  function s_fwd(lp, xy) {
    var p, r, V, i;
    p = B * sin(lp.phi);
    lp.phi *=  1.10265779;
    for (i = NITER; i ; --i) {
        r = sqrt(1 + lp.phi * lp.phi);
        lp.phi -= V = ( (A - r) * lp.phi - log(lp.phi + r) - p ) /
            (A - 2 * r);
        if (fabs(V) < EPS)
            break;
    }
    if (!i)
        lp.phi = p < 0 ? -CON_POLE : CON_POLE;
    xy.x = C_x * lp.lam * (D - sqrt(1 + lp.phi * lp.phi));
    xy.y = C_y * lp.phi;
  }

  function s_inv(xy, lp) {
    var r;
    lp.phi = xy.y / C_y;
    r = sqrt(1 + lp.phi * lp.phi);
    lp.lam = xy.x / (C_x * (D - r));
    lp.phi = aasin(((A - r) * lp.phi - log(lp.phi + r)) / B);
  }
}


pj_add(pj_qsc, 'qsc', 'Quadrilateralized Spherical Cube', 'Azi, Sph.');

function pj_qsc(P) {
  var EPS10 = 1.e-10;

  /* The six cube faces. */
  var FACE_FRONT = 0;
  var FACE_RIGHT = 1;
  var FACE_BACK = 2;
  var FACE_LEFT = 3;
  var FACE_TOP = 4;
  var FACE_BOTTOM = 5;

  /* The four areas on a cube face. AREA_0 is the area of definition,
   * the other three areas are counted counterclockwise. */
  var AREA_0 = 0;
  var AREA_1 = 1;
  var AREA_2 = 2;
  var AREA_3 = 3;
  var face;
  var a_squared;
  var b;
  var one_minus_f;
  var one_minus_f_squared;

  /* Determine the cube face from the center of projection. */
  if (P.phi0 >= M_HALFPI - M_FORTPI / 2.0) {
    face = FACE_TOP;
  } else if (P.phi0 <= -(M_HALFPI - M_FORTPI / 2.0)) {
    face = FACE_BOTTOM;
  } else if (fabs(P.lam0) <= M_FORTPI) {
    face = FACE_FRONT;
  } else if (fabs(P.lam0) <= M_HALFPI + M_FORTPI) {
    face = (P.lam0 > 0.0 ? FACE_RIGHT : FACE_LEFT);
  } else {
    face = FACE_BACK;
  }
  /* Fill in useful values for the ellipsoid <-> sphere shift
   * described in [LK12]. */
  if (P.es !== 0.0) {
    a_squared = P.a * P.a;
    b = P.a * sqrt(1.0 - P.es);
    one_minus_f = 1.0 - (P.a - b) / P.a;
    one_minus_f_squared = one_minus_f * one_minus_f;
  }

  P.fwd = e_fwd;
  P.inv = e_inv;

  function e_fwd(lp, xy) {
    var lat, lon;
    var theta, phi;
    var t, mu; /* nu; */
    var area;
    var q, r, s;
    var sinlat, coslat;
    var sinlon, coslon;
    var tmp;

    /* Convert the geodetic latitude to a geocentric latitude.
     * This corresponds to the shift from the ellipsoid to the sphere
     * described in [LK12]. */
    if (P.es !== 0.0) {
      lat = atan(one_minus_f_squared * tan(lp.phi));
    } else {
      lat = lp.phi;
    }

    /* Convert the input lat, lon into theta, phi as used by QSC.
     * This depends on the cube face and the area on it.
     * For the top and bottom face, we can compute theta and phi
     * directly from phi, lam. For the other faces, we must use
     * unit sphere cartesian coordinates as an intermediate step. */
    lon = lp.lam;
    if (face == FACE_TOP) {
      phi = M_HALFPI - lat;
      if (lon >= M_FORTPI && lon <= M_HALFPI + M_FORTPI) {
        area = AREA_0;
        theta = lon - M_HALFPI;
      } else if (lon > M_HALFPI + M_FORTPI || lon <= -(M_HALFPI + M_FORTPI)) {
        area = AREA_1;
        theta = (lon > 0.0 ? lon - M_PI : lon + M_PI);
      } else if (lon > -(M_HALFPI + M_FORTPI) && lon <= -M_FORTPI) {
        area = AREA_2;
        theta = lon + M_HALFPI;
      } else {
        area = AREA_3;
        theta = lon;
      }
    } else if (face == FACE_BOTTOM) {
      phi = M_HALFPI + lat;
      if (lon >= M_FORTPI && lon <= M_HALFPI + M_FORTPI) {
        area = AREA_0;
        theta = -lon + M_HALFPI;
      } else if (lon < M_FORTPI && lon >= -M_FORTPI) {
        area = AREA_1;
        theta = -lon;
      } else if (lon < -M_FORTPI && lon >= -(M_HALFPI + M_FORTPI)) {
        area = AREA_2;
        theta = -lon - M_HALFPI;
      } else {
        area = AREA_3;
        theta = (lon > 0.0 ? -lon + M_PI : -lon - M_PI);
      }
    } else {
      if (face == FACE_RIGHT) {
        lon = qsc_shift_lon_origin(lon, +M_HALFPI);
      } else if (face == FACE_BACK) {
        lon = qsc_shift_lon_origin(lon, +M_PI);
      } else if (face == FACE_LEFT) {
        lon = qsc_shift_lon_origin(lon, -M_HALFPI);
      }
      sinlat = sin(lat);
      coslat = cos(lat);
      sinlon = sin(lon);
      coslon = cos(lon);
      q = coslat * coslon;
      r = coslat * sinlon;
      s = sinlat;

      if (face == FACE_FRONT) {
        phi = acos(q);
        tmp = qsc_fwd_equat_face_theta(phi, s, r);
      } else if (face == FACE_RIGHT) {
        phi = acos(r);
        tmp = qsc_fwd_equat_face_theta(phi, s, -q);
      } else if (face == FACE_BACK) {
        phi = acos(-q);
        tmp = qsc_fwd_equat_face_theta(phi, s, -r);
      } else if (face == FACE_LEFT) {
        phi = acos(-r);
        tmp = qsc_fwd_equat_face_theta(phi, s, q);
      } else {
        /* Impossible */
        phi = 0.0;
        tmp = {
          area: AREA_0,
          theta: 0
        };
      }
      theta = tmp.theta;
      area = tmp.area;
    }

    /* Compute mu and nu for the area of definition.
     * For mu, see Eq. (3-21) in [OL76], but note the typos:
     * compare with Eq. (3-14). For nu, see Eq. (3-38). */
    mu = atan((12.0 / M_PI) * (theta + acos(sin(theta) * cos(M_FORTPI)) - M_HALFPI));
    t = sqrt((1.0 - cos(phi)) / (cos(mu) * cos(mu)) / (1.0 - cos(atan(1.0 / cos(theta)))));
    /* nu = atan(t);        We don't really need nu, just t, see below. */

    /* Apply the result to the real area. */
    if (area == AREA_1) {
      mu += M_HALFPI;
    } else if (area == AREA_2) {
      mu += M_PI;
    } else if (area == AREA_3) {
      mu += M_PI_HALFPI;
    }

    /* Now compute x, y from mu and nu */
    /* t = tan(nu); */
    xy.x = t * cos(mu);
    xy.y = t * sin(mu);
  }

  function e_inv(xy, lp) {
    var mu, nu, cosmu, tannu;
    var tantheta, theta, cosphi, phi;
    var t;
    var area;

    /* Convert the input x, y to the mu and nu angles as used by QSC.
     * This depends on the area of the cube face. */
    nu = atan(sqrt(xy.x * xy.x + xy.y * xy.y));
    mu = atan2(xy.y, xy.x);
    if (xy.x >= 0.0 && xy.x >= fabs(xy.y)) {
      area = AREA_0;
    } else if (xy.y >= 0.0 && xy.y >= fabs(xy.x)) {
      area = AREA_1;
      mu -= M_HALFPI;
    } else if (xy.x < 0.0 && -xy.x >= fabs(xy.y)) {
      area = AREA_2;
      mu = (mu < 0.0 ? mu + M_PI : mu - M_PI);
    } else {
      area = AREA_3;
      mu += M_HALFPI;
    }

    /* Compute phi and theta for the area of definition.
     * The inverse projection is not described in the original paper, but some
     * good hints can be found here (as of 2011-12-14):
     * http://fits.gsfc.nasa.gov/fitsbits/saf.93/saf.9302
     * (search for "Message-Id: <9302181759.AA25477 at fits.cv.nrao.edu>") */
    t = (M_PI / 12.0) * tan(mu);
    tantheta = sin(t) / (cos(t) - (1.0 / sqrt(2.0)));
    theta = atan(tantheta);
    cosmu = cos(mu);
    tannu = tan(nu);
    cosphi = 1.0 - cosmu * cosmu * tannu * tannu * (1.0 - cos(atan(1.0 / cos(theta))));
    if (cosphi < -1.0) {
      cosphi = -1.0;
    } else if (cosphi > +1.0) {
      cosphi = +1.0;
    }

    /* Apply the result to the real area on the cube face.
     * For the top and bottom face, we can compute phi and lam directly.
     * For the other faces, we must use unit sphere cartesian coordinates
     * as an intermediate step. */
    if (face == FACE_TOP) {
      phi = acos(cosphi);
      lp.phi = M_HALFPI - phi;
      if (area == AREA_0) {
        lp.lam = theta + M_HALFPI;
      } else if (area == AREA_1) {
        lp.lam = (theta < 0.0 ? theta + M_PI : theta - M_PI);
      } else if (area == AREA_2) {
        lp.lam = theta - M_HALFPI;
      } else /* area == AREA_3 */ {
        lp.lam = theta;
      }
    } else if (face == FACE_BOTTOM) {
      phi = acos(cosphi);
      lp.phi = phi - M_HALFPI;
      if (area == AREA_0) {
        lp.lam = -theta + M_HALFPI;
      } else if (area == AREA_1) {
        lp.lam = -theta;
      } else if (area == AREA_2) {
        lp.lam = -theta - M_HALFPI;
      } else /* area == AREA_3 */ {
        lp.lam = (theta < 0.0 ? -theta - M_PI : -theta + M_PI);
      }
    } else {
      /* Compute phi and lam via cartesian unit sphere coordinates. */
      var q, r, s;
      q = cosphi;
      t = q * q;
      if (t >= 1.0) {
        s = 0.0;
      } else {
        s = sqrt(1.0 - t) * sin(theta);
      }
      t += s * s;
      if (t >= 1.0) {
        r = 0.0;
      } else {
        r = sqrt(1.0 - t);
      }
      /* Rotate q,r,s into the correct area. */
      if (area == AREA_1) {
        t = r;
        r = -s;
        s = t;
      } else if (area == AREA_2) {
        r = -r;
        s = -s;
      } else if (area == AREA_3) {
        t = r;
        r = s;
        s = -t;
      }
      /* Rotate q,r,s into the correct cube face. */
      if (face == FACE_RIGHT) {
        t = q;
        q = -r;
        r = t;
      } else if (face == FACE_BACK) {
        q = -q;
        r = -r;
      } else if (face == FACE_LEFT) {
        t = q;
        q = r;
        r = -t;
      }
      /* Now compute phi and lam from the unit sphere coordinates. */
      lp.phi = acos(-s) - M_HALFPI;
      lp.lam = atan2(r, q);
      if (face == FACE_RIGHT) {
        lp.lam = qsc_shift_lon_origin(lp.lam, -M_HALFPI);
      } else if (face == FACE_BACK) {
        lp.lam = qsc_shift_lon_origin(lp.lam, -M_PI);
      } else if (face == FACE_LEFT) {
        lp.lam = qsc_shift_lon_origin(lp.lam, +M_HALFPI);
      }
    }

    /* Apply the shift from the sphere to the ellipsoid as described
     * in [LK12]. */
    if (P.es !== 0) {
      var invert_sign;
      var tanphi, xa;
      invert_sign = (lp.phi < 0.0 ? 1 : 0);
      tanphi = tan(lp.phi);
      xa = b / sqrt(tanphi * tanphi + one_minus_f_squared);
      lp.phi = atan(sqrt(P.a * P.a - xa * xa) / (one_minus_f * xa));
      if (invert_sign) {
        lp.phi = -lp.phi;
      }
    }
  }

  /* Helper function for forward projection: compute the theta angle
   * and determine the area number. */
  function qsc_fwd_equat_face_theta(phi, y, x) {
    var area, theta;
    if (phi < EPS10) {
      area = AREA_0;
      theta = 0.0;
    } else {
      theta = atan2(y, x);
      if (fabs(theta) <= M_FORTPI) {
        area = AREA_0;
      } else if (theta > M_FORTPI && theta <= M_HALFPI + M_FORTPI) {
        area = AREA_1;
        theta -= M_HALFPI;
      } else if (theta > M_HALFPI + M_FORTPI || theta <= -(M_HALFPI + M_FORTPI)) {
        area = AREA_2;
        theta = (theta >= 0.0 ? theta - M_PI : theta + M_PI);
      } else {
        area = AREA_3;
        theta += M_HALFPI;
      }
    }
    return {
      area: area,
      theta: theta
    };
  }

  /* Helper function: shift the longitude. */
  function qsc_shift_lon_origin(lon, offset) {
    var slon = lon + offset;
    if (slon < -M_PI) {
      slon += M_TWOPI;
    } else if (slon > +M_PI) {
      slon -= M_TWOPI;
    }
    return slon;
  }
}


pj_add(pj_robin, 'robin', 'Robinson', 'PCyl., Sph.');

function pj_robin(P) {
  var X = to_float([
    [1, 2.2199e-17, -7.15515e-05, 3.1103e-06],
    [0.9986, -0.000482243, -2.4897e-05, -1.3309e-06],
    [0.9954, -0.00083103, -4.48605e-05, -9.86701e-07],
    [0.99, -0.00135364, -5.9661e-05, 3.6777e-06],
    [0.9822, -0.00167442, -4.49547e-06, -5.72411e-06],
    [0.973, -0.00214868, -9.03571e-05, 1.8736e-08],
    [0.96, -0.00305085, -9.00761e-05, 1.64917e-06],
    [0.9427, -0.00382792, -6.53386e-05, -2.6154e-06],
    [0.9216, -0.00467746, -0.00010457, 4.81243e-06],
    [0.8962, -0.00536223, -3.23831e-05, -5.43432e-06],
    [0.8679, -0.00609363, -0.000113898, 3.32484e-06],
    [0.835, -0.00698325, -6.40253e-05, 9.34959e-07],
    [0.7986, -0.00755338, -5.00009e-05, 9.35324e-07],
    [0.7597, -0.00798324, -3.5971e-05, -2.27626e-06],
    [0.7186, -0.00851367, -7.01149e-05, -8.6303e-06],
    [0.6732, -0.00986209, -0.000199569, 1.91974e-05],
    [0.6213, -0.010418, 8.83923e-05, 6.24051e-06],
    [0.5722, -0.00906601, 0.000182, 6.24051e-06],
    [0.5322, -0.00677797, 0.000275608, 6.24051e-06]
  ]);

  var Y = to_float([
    [-5.20417e-18, 0.0124, 1.21431e-18, -8.45284e-11],
    [0.062, 0.0124, -1.26793e-09, 4.22642e-10],
    [0.124, 0.0124, 5.07171e-09, -1.60604e-09],
    [0.186, 0.0123999, -1.90189e-08, 6.00152e-09],
    [0.248, 0.0124002, 7.10039e-08, -2.24e-08],
    [0.31, 0.0123992, -2.64997e-07, 8.35986e-08],
    [0.372, 0.0124029, 9.88983e-07, -3.11994e-07],
    [0.434, 0.0123893, -3.69093e-06, -4.35621e-07],
    [0.4958, 0.0123198, -1.02252e-05, -3.45523e-07],
    [0.5571, 0.0121916, -1.54081e-05, -5.82288e-07],
    [0.6176, 0.0119938, -2.41424e-05, -5.25327e-07],
    [0.6769, 0.011713, -3.20223e-05, -5.16405e-07],
    [0.7346, 0.0113541, -3.97684e-05, -6.09052e-07],
    [0.7903, 0.0109107, -4.89042e-05, -1.04739e-06],
    [0.8435, 0.0103431, -6.4615e-05, -1.40374e-09],
    [0.8936, 0.00969686, -6.4636e-05, -8.547e-06],
    [0.9394, 0.00840947, -0.000192841, -4.2106e-06],
    [0.9761, 0.00616527, -0.000256, -4.2106e-06],
    [1, 0.00328947, -0.000319159, -4.2106e-06]
  ]);

  var FXC = 0.8487,
      FYC = 1.3523,
      C1 = 11.45915590261646417544,
      RC1 = 0.08726646259971647884,
      NODES = 18,
      ONEEPS = 1.000001,
      EPS = 1e-8;

  P.es = 0;
  P.fwd = s_fwd;
  P.inv = s_inv;

  function s_fwd(lp, xy) {
    var i, dphi;
    i = floor((dphi = fabs(lp.phi)) * C1);
    if (i < 0) f_error();
    if (i >= NODES) i = NODES - 1;
    dphi = RAD_TO_DEG * (dphi - RC1 * i);
    xy.x = V(X[i], dphi) * FXC * lp.lam;
    xy.y = V(Y[i], dphi) * FYC;
    if (lp.phi < 0) xy.y = -xy.y;
  }

  function s_inv(xy, lp) {
    var t, t1, T, i;
    lp.lam = xy.x / FXC;
    lp.phi = fabs(xy.y / FYC);
    if (lp.phi >= 1) { /* simple pathologic cases */
      if (lp.phi > ONEEPS) i_error();
      else {
        lp.phi = xy.y < 0 ? -M_HALFPI : M_HALFPI;
        lp.lam /= X[NODES][0];
      }
    } else { /* general problem */
      /* in Y space, reduce to table interval */
      i = floor(lp.phi * NODES);
      if (i < 0 || i >= NODES) {
        return i_error();
      }
      for (;;) {
        if (Y[i][0] > lp.phi) --i;
        else if (Y[i+1][0] <= lp.phi) ++i;
        else break;
      }
      T = new Float32Array(Y[i]); // copy row to avoid mutating constants
      /* first guess, linear interp */
      t = 5 * (lp.phi - T[0])/(Y[i+1][0] - T[0]);
      /* make into root */
      T[0] -= lp.phi;
      for (;;) { /* Newton-Raphson reduction */
        t -= t1 = V(T,t) / DV(T,t);
        if (fabs(t1) < EPS) break;
      }
      lp.phi = (5 * i + t) * DEG_TO_RAD;
      if (xy.y < 0) lp.phi = -lp.phi;
      lp.lam /= V(X[i], t);
    }
  }

  function V(C, z) {
    return C[0] + z * (C[1] + z * (C[2] + z * C[3]));
  }

  function DV(C, z) {
    return C[1] + z * (C[2] + C[2] + z * 3 * C[3]);
  }

  // convert constants to single-precision floats, for compatibility with
  // Proj.4 tests (PJ_robin.c uses floats instead of doubles)
  function to_float(rows) {
    return rows.map(function(row) {
      return new Float32Array(row);
    });
  }
}


pj_add(pj_get_sconic('EULER'), 'euler', 'Euler', 'Conic, Sph\nlat_1= and lat_2=');
pj_add(pj_get_sconic('MURD1'), 'murd1', 'Murdoch I', 'Conic, Sph\nlat_1= and lat_2=');
pj_add(pj_get_sconic('MURD2'), 'murd2', 'Murdoch II', 'Conic, Sph\nlat_1= and lat_2=');
pj_add(pj_get_sconic('MURD3'), 'murd3', 'Murdoch III', 'Conic, Sph\nlat_1= and lat_2=');
pj_add(pj_get_sconic('PCONIC'), 'pconic', 'Perspective Conic', 'Conic, Sph\nlat_1= and lat_2=');
pj_add(pj_get_sconic('TISSOT'), 'tissot', 'Tissot', 'Conic, Sph\nlat_1= and lat_2=');
pj_add(pj_get_sconic('VITK1'), 'vitk1', 'Vitkovsky I', 'Conic, Sph\nlat_1= and lat_2=');

function pj_get_sconic(type) {
  return function(P) {
    pj_sconic(P, type);
  };
}

function pj_sconic(P, type) {
  var del, cs;
  var p1, p2;
  var n;
  var rho_c;
  var rho_0;
  var sig;
  var c1, c2;
  var EPS = 1e-10;

  if (!pj_param(P.params, "tlat_1") || !pj_param(P.params, "tlat_2")) {
    e_error(-41);
  } else {
    p1 = pj_param(P.params, "rlat_1");
    p2 = pj_param(P.params, "rlat_2");
    del = 0.5 * (p2 - p1);
    sig = 0.5 * (p2 + p1);
    if (fabs(del) < EPS || fabs(sig) < EPS) {
      e_error(-42);
    }
  }

  switch (type) {
    case 'TISSOT':
      n = sin(sig);
      cs = cos(del);
      rho_c = n / cs + cs / n;
      rho_0 = sqrt((rho_c - 2 * sin(P.phi0)) / n);
      break;

    case 'MURD1':
      rho_c = sin(del) / (del * tan(sig)) + sig;
      rho_0 = rho_c - P.phi0;
      n = sin(sig);
      break;

    case 'MURD2':
      rho_c = (cs = sqrt(cos(del))) / tan(sig);
      rho_0 = rho_c + tan(sig - P.phi0);
      n = sin(sig) * cs;
      break;

    case 'MURD3':
      rho_c = del / (tan(sig) * tan(del)) + sig;
      rho_0 = rho_c - P.phi0;
      n = sin(sig) * sin(del) * tan(del) / (del * del);
      break;

    case 'EULER':
      n = sin(sig) * sin(del) / del;
      del *= 0.5;
      rho_c = del / (tan(del) * tan(sig)) + sig;
      rho_0 = rho_c - P.phi0;
      break;

    case 'PCONIC':
      n = sin(sig);
      c2 = cos(del);
      c1 = 1 / tan(sig);
      if (fabs(del = P.phi0 - sig) - EPS >= M_HALFPI)
        e_error(-43);
      rho_0 = c2 * (c1 - tan(del));
      break;

    case 'VITK1':
      n = (cs = tan(del)) * sin(sig) / del;
      rho_c = del / (cs * tan(sig)) + sig;
      rho_0 = rho_c - P.phi0;
      break;
  }

  P.inv = s_inv;
  P.fwd = s_fwd;
  P.es = 0;

  function s_fwd(lp, xy) {
    var rho;

    switch (type) {
      case 'MURD2':
        rho = rho_c + tan(sig - lp.phi);
        break;
      case 'PCONIC':
        rho = c2 * (c1 - tan(lp.phi - sig));
        break;
      default:
        rho = rho_c - lp.phi;
        break;
    }
    xy.x = rho * sin(lp.lam *= n);
    xy.y = rho_0 - rho * cos(lp.lam);
  }

  function s_inv(xy, lp) {
    var rho;

    rho = hypot(xy.x, xy.y = rho_0 - xy.y);
    if (n < 0) {
      rho = -rho;
      xy.x = -xy.x;
      xy.y = -xy.y;
    }

    lp.lam = atan2(xy.x, xy.y) / n;

    switch (type) {
      case 'PCONIC':
        lp.phi = atan(c1 - rho / c2) + sig;
        break;
      case 'MURD2':
        lp.phi = sig - atan(rho - rho_c);
        break;
      default:
        lp.phi = rho_c - rho;
    }
  }
}


pj_add(pj_somerc, 'somerc', 'Swiss. Obl. Mercator', 'Cyl, Ell\nFor CH1903');

function pj_somerc(P) {
  var K, c, hlf_e, kR, cosp0, sinp0;
  var EPS = 1.e-10;
  var NITER = 6;
  var cp, phip0, sp;
  hlf_e = 0.5 * P.e;
  cp = cos (P.phi0);
  cp *= cp;
  c = sqrt (1 + P.es * cp * cp * P.rone_es);
  sp = sin (P.phi0);
  cosp0 = cos(phip0 = aasin(sinp0 = sp / c));
  sp *= P.e;
  K = log (tan(M_FORTPI + 0.5 * phip0)) - c * (
      log (tan(M_FORTPI + 0.5 * P.phi0)) - hlf_e *
      log ((1 + sp) / (1 - sp)));
  kR = P.k0 * sqrt(P.one_es) / (1 - sp * sp);
  P.inv = e_inv;
  P.fwd = e_fwd;

  function e_fwd(lp, xy) {
    var phip, lamp, phipp, lampp, sp, cp;
    sp = P.e * sin(lp.phi);
    phip = 2* atan(exp(c * (log(tan(M_FORTPI + 0.5 * lp.phi)) -
        hlf_e * log((1 + sp)/(1 - sp))) + K)) - M_HALFPI;
    lamp = c * lp.lam;
    cp = cos(phip);
    phipp = aasin(cosp0 * sin(phip) - sinp0 * cp * cos(lamp));
    lampp = aasin(cp * sin(lamp) / cos(phipp));
    xy.x = kR * lampp;
    xy.y = kR * log(tan(M_FORTPI + 0.5 * phipp));
  }

  function e_inv(xy, lp) {
    var phip, lamp, phipp, lampp, cp, esp, con, delp;
    var i;
    phipp = 2 * (atan(exp(xy.y / kR)) - M_FORTPI);
    lampp = xy.x / kR;
    cp = cos (phipp);
    phip = aasin(cosp0 * sin(phipp) + sinp0 * cp * cos(lampp));
    lamp = aasin(cp * sin(lampp) / cos(phip));
    con = (K - log(tan(M_FORTPI + 0.5 * phip)))/c;
    for (i = NITER; i; --i) {
      esp = P.e * sin(phip);
      delp = (con + log(tan(M_FORTPI + 0.5 * phip)) - hlf_e *
        log((1 + esp)/(1 - esp))) * (1 - esp * esp) * cos(phip) * P.rone_es;
      phip -= delp;
      if (fabs(delp) < EPS)
        break;
    }
    if (i) {
      lp.phi = phip;
      lp.lam = lamp / c;
    } else
      i_error();
  }
}


pj_add(pj_stere, 'stere', 'Stereographic', 'Azi, Sph&Ell\nlat_ts=');
pj_add(pj_ups, 'ups', 'Universal Polar Stereographic', 'Azi, Sph&Ell\nsouth');

function pj_ups(P) {
  P.phi0 = pj_param(P.params, "bsouth") ? -M_HALFPI : M_HALFPI;
  P.k0 = 0.994;
  P.x0 = 2000000;
  P.y0 = 2000000;
  P.lam0 = 0;
  if (!P.es) e_error(-34);
  pj_stere_init(P, M_HALFPI);
}

function pj_stere(P) {
  var phits = pj_param (P.params, "tlat_ts") ? pj_param (P.params, "rlat_ts") : M_HALFPI;
  pj_stere_init(P, phits);
}

function pj_stere_init(P, phits) {
  var EPS10 = 1.e-10,
      TOL = 1.e-8,
      NITER = 8,
      CONV = 1.e-10,
      S_POLE = 0,
      N_POLE = 1,
      OBLIQ= 2,
      EQUIT = 3;
  var X, t, sinph0, cosph0;
  var sinX1, cosX1, akm1, mode;

  if (fabs((t = fabs (P.phi0)) - M_HALFPI) < EPS10)
      mode = P.phi0 < 0 ? S_POLE : N_POLE;
  else
      mode = t > EPS10 ? OBLIQ: EQUIT;
  phits = fabs (phits);

  if (P.es) {
    switch (mode) {
      case N_POLE:
      case S_POLE:
        if (fabs (phits - M_HALFPI) < EPS10)
            akm1 = 2 * P.k0 /
               sqrt(pow(1 + P.e, 1 + P.e) * pow(1 - P.e, 1 - P.e));
        else {
            akm1 = cos(phits) /
               pj_tsfn(phits, t = sin(phits), P.e);
            t *= P.e;
            akm1 /= sqrt(1 - t * t);
        }
        break;
      case EQUIT:
      case OBLIQ:
        t = sin(P.phi0);
        X = 2 * atan(ssfn(P.phi0, t, P.e)) - M_HALFPI;
        t *= P.e;
        akm1 = 2 * P.k0 * cos(P.phi0) / sqrt(1 - t * t);
        sinX1 = sin(X);
        cosX1 = cos(X);
        break;
    }
    P.fwd = e_fwd;
    P.inv = e_inv;
  } else {
    switch (mode) {
      case OBLIQ:
        sinph0 = sin(P.phi0);
        cosph0 = cos(P.phi0);
        /* falls through */
      case EQUIT:
        akm1 = 2 * P.k0;
        break;
      case S_POLE:
      case N_POLE:
        akm1 = fabs(phits - M_HALFPI) >= EPS10 ?
           cos(phits) / tan(M_FORTPI - 0.5 * phits) : 2 * P.k0;
        break;
    }
    P.fwd = s_fwd;
    P.inv = s_inv;
  }

  function e_fwd(lp, xy) {
    var coslam, sinlam, sinX = 0, cosX = 0, X, A, sinphi;
    coslam = cos(lp.lam);
    sinlam = sin(lp.lam);
    sinphi = sin(lp.phi);
    if (mode == OBLIQ|| mode == EQUIT) {
        sinX = sin(X = 2 * atan(ssfn(lp.phi, sinphi, P.e)) - M_HALFPI);
        cosX = cos(X);
    }

    switch (mode) {
      case OBLIQ:
        A = akm1 / (cosX1 * (1 + sinX1 * sinX +
           cosX1 * cosX * coslam));
        xy.y = A * (cosX1 * sinX - sinX1 * cosX * coslam);
        xy.x = A * cosX;
        break;
      case EQUIT:
        /* zero division is handled in pj_fwd */
        A = akm1 / (1 + cosX * coslam);
        xy.y = A * sinX;
        xy.x = A * cosX;
        break;
      case S_POLE:
        lp.phi = -lp.phi;
        coslam = -coslam;
        sinphi = -sinphi;
        /* falls through */
      case N_POLE:
        xy.x = akm1 * pj_tsfn (lp.phi, sinphi, P.e);
        xy.y = - xy.x * coslam;
        break;
    }
    xy.x = xy.x * sinlam;
  }

  function s_fwd(lp, xy) {
    var phi = lp.phi,
        sinphi = sin(phi),
        cosphi = cos(phi),
        coslam = cos(lp.lam),
        sinlam = sin(lp.lam);

    switch (mode) {
    case EQUIT:
    case OBLIQ:
      if (mode == EQUIT) {
        xy.y = 1 + cosphi * coslam;
      } else {
        xy.y = 1 + sinph0 * sinphi + cosph0 * cosphi * coslam;
      }
      if (xy.y <= EPS10) f_error();
      xy.x = (xy.y = akm1 / xy.y) * cosphi * sinlam;
      xy.y *= (mode == EQUIT) ? sinphi :
         cosph0 * sinphi - sinph0 * cosphi * coslam;
      break;
    case N_POLE:
      coslam = - coslam;
      phi = - phi;
      /* falls through */
    case S_POLE:
      if (fabs(phi - M_HALFPI) < TOL) f_error();
      xy.x = sinlam * (xy.y = akm1 * tan (M_FORTPI + 0.5 * phi));
      xy.y *= coslam;
      break;
    }
  }

  function e_inv(xy, lp) {
    var phi = lp.phi,
        tp=0, phi_l=0, halfe=0, halfpi=0,
        cosphi, sinphi, rho, i;
    rho = hypot (xy.x, xy.y);

    switch (mode) {
      case OBLIQ:
      case EQUIT:
        cosphi = cos ( tp = 2 * atan2(rho * cosX1 , akm1));
        sinphi = sin (tp);
                if ( rho == 0 )
            phi_l = asin (cosphi * sinX1);
                else
            phi_l = asin (cosphi * sinX1 + (xy.y * sinphi * cosX1 / rho));

        tp = tan (0.5 * (M_HALFPI + phi_l));
        xy.x *= sinphi;
        xy.y = rho * cosX1 * cosphi - xy.y * sinX1* sinphi;
        halfpi = M_HALFPI;
        halfe = 0.5 * P.e;
        break;
      case N_POLE:
        xy.y = -xy.y;
        /* falls through */
      case S_POLE:
        phi_l = M_HALFPI - 2 * atan (tp = - rho / akm1);
        halfpi = -M_HALFPI;
        halfe = -0.5 * P.e;
        break;
    }

    for (i = 0; i < NITER; i++, phi_l = lp.phi) {
      sinphi = P.e * sin(phi_l);
      lp.phi = 2 * atan (tp * pow ((1+sinphi)/(1-sinphi), halfe)) - halfpi;
      if (fabs(phi_l - lp.phi) < CONV) {
        if (mode == S_POLE)
          lp.phi = -lp.phi;
        lp.lam = (xy.x == 0 && xy.y == 0) ? 0 : atan2 (xy.x, xy.y);
        return;
      }
    }
    i_error();
  }

  function s_inv(xy, lp) {
    var c, rh, sinc, cosc;
    sinc = sin(c = 2 * atan ((rh = hypot(xy.x, xy.y)) / akm1));
    cosc = cos(c);
    lp.lam = 0;

    switch (mode) {
      case EQUIT:
        if (fabs (rh) <= EPS10)
            lp.phi = 0;
        else
            lp.phi = asin (xy.y * sinc / rh);
        if (cosc != 0 || xy.x != 0)
            lp.lam = atan2 (xy.x * sinc, cosc * rh);
        break;
      case OBLIQ:
        if (fabs (rh) <= EPS10)
            lp.phi = P.phi0;
        else
            lp.phi = asin (cosc * sinph0 + xy.y * sinc * cosph0 / rh);
        if ((c = cosc - sinph0 * sin (lp.phi)) != 0 || xy.x != 0)
            lp.lam = atan2 (xy.x * sinc * cosph0, c * rh);
        break;
      case N_POLE:
        xy.y = -xy.y;
        /* falls through */
      case S_POLE:
        if (fabs (rh) <= EPS10)
            lp.phi = P.phi0;
        else
            lp.phi = asin (mode == S_POLE ? - cosc : cosc);
        lp.lam = (xy.x == 0 && xy.y == 0) ? 0 : atan2 (xy.x, xy.y);
        break;
    }
  }

  function ssfn(phit, sinphi, eccen) {
    sinphi *= eccen;
    return tan(0.5 * (M_HALFPI + phit)) *
       pow ((1 - sinphi) / (1 + sinphi), 0.5 * eccen);
  }
}




function srat(esinp, exp) {
  return pow((1-esinp)/(1+esinp), exp);
}

function pj_gauss_ini(e, phi0) {
  var es = e * e,
      sphi = sin(phi0),
      cphi = cos(phi0),
      rc = sqrt(1 - es) / (1 - es * sphi * sphi),
      C = sqrt(1 + es * cphi * cphi * cphi * cphi / (1 - es)),
      // ignoring Proj.4 div0 check (seems unneccessary)
      chi = asin(sphi / C),
      ratexp = 0.5 * C * e,
      K = tan(0.5 * chi + M_FORTPI) / (pow(tan(0.5 * phi0 + M_FORTPI), C) *
        srat(e * sphi, ratexp));
  return {e: e, K: K, C: C, chi: chi, ratexp: ratexp, rc: rc};
}

function pj_gauss(elp, en) {
  return {
    phi: 2 * atan( en.K * pow(tan(0.5 * elp.phi + M_FORTPI), en.C) *
      srat(en.e * sin(elp.phi), en.ratexp) ) - M_HALFPI,
    lam: en.C * elp.lam
  };
}

function pj_inv_gauss(lp, en) {
  var MAX_ITER = 20,
      DEL_TOL = 1e-14,
      phi1 = lp.phi,
      num = pow(tan(0.5 * lp.phi + M_FORTPI)/en.K, 1/en.C),
      i, phi;
  lp.lam /= en.C;
  for (i = MAX_ITER; i>0; --i) {
    phi = 2 * atan(num * srat(en.e * sin(lp.phi), -0.5 * en.e)) - M_HALFPI;
    if (fabs(phi - lp.phi) < DEL_TOL) break;
    lp.phi = phi;
  }
  if (!i) pj_ctx_set_errno(-17); /* convergence failed */
}


pj_add(pj_sterea, 'sterea', 'Oblique Stereographic Alternative', 'Azimuthal, Sph&Ell');

function pj_sterea(P) {
  var en = pj_gauss_ini(P.e, P.phi0),
      phic0 = en.chi,
      R = en.rc,
      R2 = 2 * R,
      sinc0 = sin(phic0),
      cosc0 = cos(phic0);

  P.fwd = e_fwd;
  P.inv = e_inv;

  function e_fwd(lp, xy) {
    var cosc, sinc, cosl, k;
    lp = pj_gauss(lp, en);
    sinc = sin(lp.phi);
    cosc = cos(lp.phi);
    cosl = cos(lp.lam);
    k = P.k0 * R2 / (1 + sinc0 * sinc + cosc0 * cosc * cosl);
    xy.x = k * cosc * sin(lp.lam);
    xy.y = k * (cosc0 * sinc - sinc0 * cosc * cosl);
  }

  function e_inv(xy, lp) {
    var x = xy.x / P.k0,
        y = xy.y / P.k0,
        rho, c, sinc, cosc;
    if ((rho = hypot(x, y))) {
      c = 2 * atan2(rho, R2);
      sinc = sin(c);
      cosc = cos(c);
      lp.phi = asin(cosc * sinc0 + y * sinc * cosc0 / rho);
      lp.lam = atan2(x * sinc, rho * cosc0 * cosc - y * sinc0 * sinc);
    } else {
      lp.phi = phic0;
      lp.lam = 0;
    }
    pj_inv_gauss(lp, en);
  }
}


pj_add(pj_kav5, 'kav5', 'Kavraisky V', 'PCyl., Sph.');
pj_add(pj_qua_aut, 'qua_aut', 'Quartic Authalic', 'PCyl., Sph.');
pj_add(pj_fouc, 'fouc', 'Foucaut', 'PCyl., Sph.');
pj_add(pj_mbt_s, 'mbt_s', 'McBryde-Thomas Flat-Polar Sine (No. 1)', 'PCyl., Sph.');

function pj_kav5(P) {
  pj_sts(P, 1.50488, 1.35439, false);
}

function pj_qua_aut(P) {
  pj_sts(P, 2, 2, false);
}

function pj_fouc(P) {
  pj_sts(P, 2, 2, true);
}

function pj_mbt_s(P) {
  pj_sts(P, 1.48875, 1.36509, false);
}

function pj_sts(P, p, q, tan_mode) {
  var C_x = q / p;
  var C_y = p;
  var C_p = 1 / q;
  P.inv = s_inv;
  P.fwd = s_fwd;
  P.es = 0;

  function s_fwd(lp, xy) {
    var c;
    xy.x = C_x * lp.lam * cos(lp.phi);
    xy.y = C_y;
    lp.phi *= C_p;
    c = cos(lp.phi);
    if (tan_mode) {
      xy.x *= c * c;
      xy.y *= tan(lp.phi);
    } else {
      xy.x /= c;
      xy.y *= sin (lp.phi);
    }
  }

  function s_inv(xy, lp) {
    var c;
    xy.y /= C_y;
    c = cos (lp.phi = tan_mode ? atan(xy.y) : aasin(xy.y));
    lp.phi /= C_p;
    lp.lam = xy.x / (C_x * cos(lp.phi));
    if (tan_mode)
      lp.lam /= c * c;
    else
      lp.lam *= c;
  }
}


pj_add(pj_tcea, 'tcea', 'Transverse Cylindrical Equal Area', 'Cyl, Sph');

function pj_tcea(P) {
  P.es = 0;
  P.fwd = s_fwd;
  P.inv = s_inv;

  function s_fwd(lp, xy) {
    xy.x = cos (lp.phi) * sin (lp.lam) / P.k0;
    xy.y = P.k0 * (atan2 (tan (lp.phi), cos (lp.lam)) - P.phi0);
  }

  function s_inv(xy, lp) {
    var t;
    xy.y = xy.y / P.k0 + P.phi0;
    xy.x *= P.k0;
    t = sqrt (1 - xy.x * xy.x);
    lp.phi = asin (t * sin (xy.y));
    lp.lam = atan2 (xy.x, t * cos (xy.y));
  }
}


pj_add(pj_times, 'times', 'Times', 'Cyl, Sph');

function pj_times(P) {
  P.es = 0;
  P.fwd = function(lp, xy) {
    var t = tan(lp.phi / 2);
    var s = sin(M_FORTPI * t);
    xy.x = lp.lam * (0.74482 - 0.34588 * s * s);
    xy.y = 1.70711 *  t;
  };
  P.inv = function (xy, lp) {
    var t = xy.y / 1.70711;
    var s = sin(M_FORTPI * t);
    lp.lam = xy.x / (0.74482 - 0.34588 * s * s);
    lp.phi = 2 * atan(t);
  };
}


pj_add(pj_tmerc, 'tmerc', 'Transverse Mercator', 'Cyl, Sph&Ell');
pj_add(pj_utm, 'utm', 'Universal Transverse Mercator (UTM)', 'Cyl, Sph\nzone= south');

function pj_utm_zone(P) {

}

function pj_utm(P) {
  var zone;
  if (!P.es) e_error(-34);
  P.y0 = pj_param(P.params, "bsouth") ? 10000000 : 0;
  P.x0 = 500000;
  if (pj_param(P.params, "tzone")) {
    if ((zone = pj_param(P.params, "izone")) > 0 && zone <= 60)
      --zone;
    else
      e_error(-35);
  } else { /* nearest central meridian input */
    zone = floor((adjlon(P.lam0) + M_PI) * 30 / M_PI);
    if (zone < 0)
      zone = 0;
    else if (zone >= 60)
      zone = 59;
  }
  P.lam0 = (zone + 0.5) * M_PI / 30 - M_PI;
  P.k0 = 0.9996;
  P.phi0 = 0;
  pj_etmerc(P);
}

function pj_tmerc(P) {
  // TODO: support +algo option
  if (pj_param(P.params, "bapprox")) {
    pj_tmerc_approx(P);
  } else {
    pj_tmerc_auto(P);
  }
}

function pj_tmerc_auto(P) {
  if (P.es === 0) {
    return pj_tmerc_approx(P);
  }
  pj_etmerc(P);
  var etfwd = P.fwd;
  var etinv = P.inv;
  pj_tmerc_approx(P);
  var fwd = P.fwd;
  var inv = P.inv;

  P.fwd = function(lp, xy) {
    if (fabs(lp.lam) > 3 * DEG_TO_RAD) etfwd(lp, xy);
    else fwd(lp, xy);
  };

  P.inv = function(xy, lp) {
    // See https://github.com/OSGeo/PROJ/blob/master/src/projections/tmerc.cpp
    if (fabs(xy.x) > 0.053 - 0.022 * xy.y * xy.y) etinv(xy, lp);
    else inv(xy, lp);
  };
}

function pj_tmerc_approx(P) {
  var EPS10 = 1e-10,
      FC1 = 1,
      FC2 = 0.5,
      FC3 = 0.16666666666666666666,
      FC4 = 0.08333333333333333333,
      FC5 = 0.05,
      FC6 = 0.03333333333333333333,
      FC7 = 0.02380952380952380952,
      FC8 = 0.01785714285714285714;
  var esp, ml0, en;

  if (P.es) {
    if (!(en = pj_enfn(P.es))) // in pj_mlfn.js
        e_error_0();
    ml0 = pj_mlfn(P.phi0, sin(P.phi0), cos(P.phi0), en);
    esp = P.es / (1 - P.es);
    P.fwd = e_fwd;
    P.inv = e_inv;
  } else {
    esp = P.k0;
    ml0 = 0.5 * esp;
    P.fwd = s_fwd;
    P.inv = s_inv;
  }

  function e_fwd(lp, xy) {
    var sinphi, cosphi, t, al, als, n;
    if ( lp.lam < -M_HALFPI || lp.lam > M_HALFPI ) {
      pj_ctx_set_errno(-14);
      return;
    }

    sinphi = sin (lp.phi);
    cosphi = cos (lp.phi);
    t = fabs(cosphi) > EPS10 ? sinphi/cosphi : 0;
    t *= t;
    al = cosphi * lp.lam;
    als = al * al;
    al /= sqrt(1 - P.es * sinphi * sinphi);
    n = esp * cosphi * cosphi;
    xy.x = P.k0 * al * (FC1 +
        FC3 * als * (1 - t + n +
        FC5 * als * (5 + t * (t - 18) + n * (14 - 58 * t) +
        FC7 * als * (61 + t * ( t * (179 - t) - 479 ) )
        )));
    xy.y = P.k0 * (pj_mlfn(lp.phi, sinphi, cosphi, en) - ml0 +
        sinphi * al * lp.lam * FC2 * ( 1 +
        FC4 * als * (5 - t + n * (9 + 4 * n) +
        FC6 * als * (61 + t * (t - 58) + n * (270 - 330 * t) +
        FC8 * als * (1385 + t * ( t * (543 - t) - 3111) )
        ))));
  }

  function s_fwd(lp, xy) {
    var b, cosphi;
    /*
     * Fail if our longitude is more than 90 degrees from the
     * central meridian since the results are essentially garbage.
     * Is error -20 really an appropriate return value?
     *
     *  http://trac.osgeo.org/proj/ticket/5
     */
    if( lp.lam < -M_HALFPI || lp.lam > M_HALFPI ) {
        pj_ctx_set_errno(-14);
        return;
    }
    cosphi = cos(lp.phi);
    b = cosphi * sin (lp.lam);
    if (fabs(fabs(b) - 1) <= EPS10) f_error();

    xy.x = ml0 * log ((1 + b) / (1 - b));
    xy.y = cosphi * cos(lp.lam) / sqrt(1 - b * b);

    b = fabs ( xy.y );
    if (b >= 1) {
      if ((b - 1) > EPS10) {
        f_error();
      } else {
        xy.y = 0;
      }
    } else
      xy.y = acos(xy.y);

    if (lp.phi < 0)
      xy.y = -xy.y;
    xy.y = esp * (xy.y - P.phi0);
  }

  function e_inv(xy, lp) {
    var n, con, cosphi, d, ds, sinphi, t;
    lp.phi = pj_inv_mlfn(ml0 + xy.y / P.k0, P.es, en);
    if (fabs(lp.phi) >= M_HALFPI) {
      lp.phi = xy.y < 0 ? -M_HALFPI : M_HALFPI;
      lp.lam = 0;
    } else {
      sinphi = sin(lp.phi);
      cosphi = cos(lp.phi);
      t = fabs (cosphi) > 1e-10 ? sinphi/cosphi : 0;
      n = esp * cosphi * cosphi;
      d = xy.x * sqrt (con = 1 - P.es * sinphi * sinphi) / P.k0;
      con *= t;
      t *= t;
      ds = d * d;
      lp.phi -= (con * ds / (1-P.es)) * FC2 * (1 -
        ds * FC4 * (5 + t * (3 - 9 *  n) + n * (1 - 4 * n) -
        ds * FC6 * (61 + t * (90 - 252 * n + 45 * t) + 46 * n -
        ds * FC8 * (1385 + t * (3633 + t * (4095 + 1575 * t)))
        )));
      lp.lam = d * (FC1 - ds * FC3 * (1 + 2 * t + n -
        ds * FC5 * (5 + t * (28 + 24*t + 8*n) + 6 * n -
        ds * FC7 * (61 + t * (662 + t * (1320 + 720 * t)))
        ))) / cosphi;
    }
  }

  function s_inv(xy, lp) {
    var h = exp(xy.x / esp);
    var g = 0.5 * (h - 1 / h);
    h = cos (P.phi0 + xy.y / esp);
    lp.phi = asin(sqrt((1 - h * h) / (1 + g * g)));
    /* Make sure that phi is on the correct hemisphere when false northing is used */
    if (xy.y < 0 && -lp.phi + P.phi0 < 0) lp.phi = -lp.phi;
    lp.lam = (g || h) ? atan2(g, h) : 0;
  }
}


pj_add(pj_tpeqd, 'tpeqd', 'Two Point Equidistant', 'Misc Sph\nlat_1= lon_1= lat_2= lon_2=');

function pj_tpeqd(P) {
  var cp1, sp1, cp2, sp2, ccs, cs, sc, r2z0, z02, dlam2;
  var hz0, thz0, rhshz0, ca, sa, lamp, lamc;
  var lam_1, lam_2, phi_1, phi_2, A12, pp;

  /* get control point locations */
  phi_1 = pj_param(P.params, "rlat_1");
  lam_1 = pj_param(P.params, "rlon_1");
  phi_2 = pj_param(P.params, "rlat_2");
  lam_2 = pj_param(P.params, "rlon_2");

  if (phi_1 == phi_2 && lam_1 == lam_2)
      e_error(-25);
  P.lam0  = adjlon(0.5 * (lam_1 + lam_2));
  dlam2 = adjlon(lam_2 - lam_1);
  cp1 = cos (phi_1);
  cp2 = cos (phi_2);
  sp1 = sin (phi_1);
  sp2 = sin (phi_2);
  cs = cp1 * sp2;
  sc = sp1 * cp2;
  ccs = cp1 * cp2 * sin(dlam2);
  z02 = aacos(sp1 * sp2 + cp1 * cp2 * cos(dlam2));
  hz0 = 0.5 * z02;
  A12 = atan2(cp2 * sin(dlam2),
    cp1 * sp2 - sp1 * cp2 * cos(dlam2));
  ca = cos(pp = aasin(cp1 * sin(A12)));
  sa = sin(pp);
  lamp = adjlon(atan2(cp1 * cos(A12), sp1) - hz0);
  dlam2 *= 0.5;
  lamc = M_HALFPI - atan2(sin(A12) * sp1, cos(A12)) - dlam2;
  thz0 = tan (hz0);
  rhshz0 = 0.5 / sin(hz0);
  r2z0 = 0.5 / z02;
  z02 *= z02;

  P.fwd = s_fwd;
  P.inv = s_inv;
  P.es = 0;

  function s_fwd(lp, xy) {
    var t, z1, z2, dl1, dl2, sp, cp;
    sp = sin(lp.phi);
    cp = cos(lp.phi);
    z1 = aacos(sp1 * sp + cp1 * cp * cos (dl1 = lp.lam + dlam2));
    z2 = aacos(sp2 * sp + cp2 * cp * cos (dl2 = lp.lam - dlam2));
    z1 *= z1;
    z2 *= z2;
    xy.x = r2z0 * (t = z1 - z2);
    t = z02 - t;
    xy.y = r2z0 * asqrt (4 * z02 * z2 - t * t);
    if ((ccs * sp - cp * (cs * sin(dl1) - sc * sin(dl2))) < 0)
      xy.y = -xy.y;
  }

  function s_inv(xy, lp) {
    var cz1, cz2, s, d, cp, sp;
    cz1 = cos(hypot(xy.y, xy.x + hz0));
    cz2 = cos(hypot(xy.y, xy.x - hz0));
    s = cz1 + cz2;
    d = cz1 - cz2;
    lp.lam = - atan2(d, (s * thz0));
    lp.phi = aacos(hypot(thz0 * s, d) * rhshz0);
    if ( xy.y < 0 )
      lp.phi = - lp.phi;
    /* lam--phi now in system relative to P1--P2 base equator */
    sp = sin(lp.phi);
    cp = cos(lp.phi);
    lp.phi = aasin(sa * sp + ca * cp * (s = cos(lp.lam -= lamp)));
    lp.lam = atan2(cp * sin(lp.lam), sa * cp * s - ca * sp) + lamc;
  }
}


pj_add(pj_urm5, 'urm5', 'Urmaev V', 'PCyl., Sph., no inv.\nn= q= alpha=');

function pj_urm5(P) {
  var m, rmn, q3, n;
  var alpha, t;
  n = pj_param(P.params, "dn");
  if (n > 0 && n <= 1 === false) {
    e_error(-40);
  }
  q3 = pj_param(P.params, "dq") / 3;
  alpha = pj_param(P.params, "ralpha");
  t = n * sin (alpha);
  m = cos (alpha) / sqrt (1 - t * t);
  rmn = 1 / (m * n);

  P.fwd = s_fwd;
  P.es = 0;

  function s_fwd(lp, xy) {
    var t = lp.phi = aasin (n * sin (lp.phi));
    xy.x = m * lp.lam * cos (lp.phi);
    t *= t;
    xy.y = lp.phi * (1 + t * q3) * rmn;
  }
}


pj_add(pj_urmfps, 'urmfps', 'Urmaev Flat-Polar Sinusoidal', 'PCyl, Sph.\nn=');
pj_add(pj_wag1, 'wag1', 'Wagner I (Kavraisky VI)', 'PCyl, Sph.');


function pj_wag1(P) {
  pj_urmfps_init(P, 0.8660254037844386467637231707);
}

function pj_urmfps(P) {
  var n = pj_param(P.params, "dn");
  if (n <= 0 || n > 1) e_error(-40);
  pj_urmfps_init(P, n);
}

function pj_urmfps_init(P, n) {
  var C_x = 0.8773826753,
      C_y = 1.139753528477 / n;

  P.es = 0;
  P.fwd = s_fwd;
  P.inv = s_inv;

  function s_fwd(lp, xy) {
    var phi = aasin(n * sin(lp.phi));
    xy.x = C_x * lp.lam * cos(phi);
    xy.y = C_y * phi;
  }

  function s_inv(xy, lp) {
    xy.y /= C_y;
    lp.phi = aasin(sin(xy.y) / n);
    lp.lam = xy.x / (C_x * cos(xy.y));
  }
}


pj_add(pj_vandg, 'vandg', 'van der Grinten (I)', 'Misc Sph');
pj_add(pj_vandg2, 'vandg2', 'van der Grinten II', 'Misc Sph, no inv.');
pj_add(pj_vandg3, 'vandg3', 'van der Grinten III', 'Misc Sph, no inv.');
pj_add(pj_vandg4, 'vandg4', 'van der Grinten IV', 'Misc Sph, no inv.');

function pj_vandg(P) {
  var TOL = 1.e-10,
      THIRD = 0.33333333333333333333,
      TWO_THRD = 0.66666666666666666666,
      C2_27 = 0.07407407407407407407,
      PI4_3 = 4.18879020478639098458,
      PISQ = 9.86960440108935861869,
      TPISQ = 19.73920880217871723738,
      HPISQ = 4.93480220054467930934;

  P.fwd = s_fwd;
  P.inv = s_inv;

  function s_fwd(lp, xy) {
    var al, al2, g, g2, p2;
    p2 = fabs(lp.phi / M_HALFPI);
    if ((p2 - TOL) > 1) f_error();
    if (p2 > 1)
      p2 = 1;
    if (fabs(lp.phi) <= TOL) {
      xy.x = lp.lam;
      xy.y = 0;
    } else if (fabs(lp.lam) <= TOL || fabs(p2 - 1) < TOL) {
      xy.x = 0;
      xy.y = M_PI * tan(0.5 * asin(p2));
      if (lp.phi < 0) xy.y = -xy.y;
    } else {
      al = 0.5 * fabs(M_PI / lp.lam - lp.lam / M_PI);
      al2 = al * al;
      g = sqrt(1 - p2 * p2);
      g = g / (p2 + g - 1);
      g2 = g * g;
      p2 = g * (2 / p2 - 1);
      p2 = p2 * p2;
      xy.x = g - p2; g = p2 + al2;
      xy.x = M_PI * (al * xy.x + sqrt(al2 * xy.x * xy.x - g * (g2 - p2))) / g;
      if (lp.lam < 0) xy.x = -xy.x;
      xy.y = fabs(xy.x / M_PI);
      xy.y = 1 - xy.y * (xy.y + 2 * al);
      if (xy.y < -TOL) f_error();
      if (xy.y < 0)
        xy.y = 0;
      else
        xy.y = sqrt(xy.y) * (lp.phi < 0 ? -M_PI : M_PI);
    }
  }

  function s_inv(xy, lp) {
    var t, c0, c1, c2, c3, al, r2, r, m, d, ay, x2, y2;
    x2 = xy.x * xy.x;
    if ((ay = fabs(xy.y)) < TOL) {
      lp.phi = 0;
      t = x2 * x2 + TPISQ * (x2 + HPISQ);
      lp.lam = fabs(xy.x) <= TOL ? 0 :
         0.5 * (x2 - PISQ + sqrt(t)) / xy.x;
      return (lp);
    }
    y2 = xy.y * xy.y;
    r = x2 + y2;    r2 = r * r;
    c1 = - M_PI * ay * (r + PISQ);
    c3 = r2 + M_TWOPI * (ay * r + M_PI * (y2 + M_PI * (ay + M_HALFPI)));
    c2 = c1 + PISQ * (r - 3 *  y2);
    c0 = M_PI * ay;
    c2 /= c3;
    al = c1 / c3 - THIRD * c2 * c2;
    m = 2 * sqrt(-THIRD * al);
    d = C2_27 * c2 * c2 * c2 + (c0 * c0 - THIRD * c2 * c1) / c3;
    if (((t = fabs(d = 3 * d / (al * m))) - TOL) <= 1) {
      d = t > 1 ? (d > 0 ? 0 : M_PI) : acos(d);
      lp.phi = M_PI * (m * cos(d * THIRD + PI4_3) - THIRD * c2);
      if (xy.y < 0) lp.phi = -lp.phi;
      t = r2 + TPISQ * (x2 - y2 + HPISQ);
      lp.lam = fabs(xy.x) <= TOL ? 0 :
         0.5 * (r - PISQ + (t <= 0 ? 0 : sqrt(t))) / xy.x;
    } else
        i_error();
  }
}

function pj_vandg2(P) {
  pj_vandg2_init(P, false);
}

function pj_vandg3(P) {
  pj_vandg2_init(P, true);
}

function pj_vandg2_init(P, vdg3) {
  var TOL = 1e-10;
  P.fwd = s_fwd;
  P.es = 0;

  function s_fwd(lp, xy) {
    var x1, at, bt, ct;
    bt = fabs(M_TWO_D_PI * lp.phi);
    if ((ct = 1 - bt * bt) < 0)
      ct = 0;
    else
      ct = sqrt(ct);
    if (fabs(lp.lam) < TOL) {
      xy.x = 0;
      xy.y = M_PI * (lp.phi < 0 ? -bt : bt) / (1 + ct);
    } else {
      at = 0.5 * fabs(M_PI / lp.lam - lp.lam / M_PI);
      if (vdg3) {
          x1 = bt / (1 + ct);
          xy.x = M_PI * (sqrt(at * at + 1 - x1 * x1) - at);
          xy.y = M_PI * x1;
      } else {
          x1 = (ct * sqrt(1 + at * at) - at * ct * ct) /
              (1 + at * at * bt * bt);
          xy.x = M_PI * x1;
          xy.y = M_PI * sqrt(1 - x1 * (x1 + 2 * at) + TOL);
      }
      if ( lp.lam < 0) xy.x = -xy.x;
      if ( lp.phi < 0) xy.y = -xy.y;
    }
  }
}

function pj_vandg4(P) {
  P.es = 0;
  P.fwd = function(lp, xy) {
    var TOL = 1e-10;
    var x1, t, bt, ct, ft, bt2, ct2, dt, dt2;
    if (fabs(lp.phi) < TOL) {
      xy.x = lp.lam;
      xy.y = 0;
    } else if (fabs(lp.lam) < TOL || fabs(fabs(lp.phi) - M_HALFPI) < TOL) {
      xy.x = 0;
      xy.y = lp.phi;
    } else {
      bt = fabs(M_TWO_D_PI * lp.phi);
      bt2 = bt * bt;
      ct = 0.5 * (bt * (8 - bt * (2 + bt2)) - 5) / (bt2 * (bt - 1));
      ct2 = ct * ct;
      dt = M_TWO_D_PI * lp.lam;
      dt = dt + 1 / dt;
      dt = sqrt(dt * dt - 4);
      if ((fabs(lp.lam) - M_HALFPI) < 0) dt = -dt;
      dt2 = dt * dt;
      x1 = bt + ct; x1 *= x1;
      t = bt + 3*ct;
      ft = x1 * (bt2 + ct2 * dt2 - 1) + (1-bt2) * (
          bt2 * (t * t + 4 * ct2) +
          ct2 * (12 * bt * ct + 4 * ct2) );
      x1 = (dt*(x1 + ct2 - 1) + 2*sqrt(ft)) /
          (4* x1 + dt2);
      xy.x = M_HALFPI * x1;
      xy.y = M_HALFPI * sqrt(1 + dt * fabs(x1) - x1 * x1);
      if (lp.lam < 0) xy.x = -xy.x;
      if (lp.phi < 0) xy.y = -xy.y;
    }
  };
}


pj_add(pj_wag2, 'wag2', 'Wagner II', 'PCyl., Sph.');
pj_add(pj_wag3, 'wag3', 'Wagner III', 'PCyl., Sph.\nlat_ts=');
pj_add(pj_wag7, 'wag7', 'Wagner VII', 'Misc Sph, no inv.');

function pj_wag2(P) {
  var C_x = 0.92483,
      C_y = 1.38725,
      C_p1 = 0.88022,
      C_p2 = 0.88550;

  P.fwd = s_fwd;
  P.inv = s_inv;

  function s_fwd(lp, xy) {
    lp.phi = aasin(C_p1 * sin (C_p2 * lp.phi));
    xy.x = C_x * lp.lam * cos (lp.phi);
    xy.y = C_y * lp.phi;
  }

  function s_inv(xy, lp) {
    lp.phi = xy.y / C_y;
    lp.lam = xy.x / (C_x * cos(lp.phi));
    lp.phi = aasin(sin(lp.phi) / C_p1) / C_p2;
  }
}

function pj_wag3(P) {
  var TWOTHIRD = 0.6666666666666666666667,
      ts = pj_param(P.params, "rlat_ts"),
      C_x = cos(ts) / cos(2*ts/3);

  P.es = 0;
  P.fwd = s_fwd;
  P.inv = s_inv;

  function s_fwd(lp, xy) {
    xy.x = C_x * lp.lam * cos(TWOTHIRD * lp.phi);
    xy.y = lp.phi;
  }

  function s_inv(xy, lp) {
    lp.phi = xy.y;
    lp.lam = xy.x / (C_x * cos(TWOTHIRD * lp.phi));
  }
}

function pj_wag7(P) {
  P.es = 0;
  P.fwd = function(lp, xy) {
    var theta, ct, D;
    theta = asin (xy.y = 0.90630778703664996 * sin(lp.phi));
    xy.x  = 2.66723 * (ct = cos (theta)) * sin (lp.lam /= 3);
    xy.y *= 1.24104 * (D = 1/(sqrt (0.5 * (1 + ct * cos(lp.lam)))));
    xy.x *= D;
  };
}



pj_add(pj_wink1, 'wink1', 'Winkel I', 'PCyl., Sph.\nlat_ts=');
pj_add(pj_wink2, 'wink2', 'Winkel II', 'PCyl., Sph., no inv.\nlat_1=');

function pj_wink1(P) {
  var cosphi1 = cos(pj_param(P.params, "rlat_ts"));
  P.fwd = s_fwd;
  P.inv = s_inv;
  P.es = 0;

  function s_fwd(lp, xy) {
    xy.x = 0.5 * lp.lam * (cosphi1 + cos(lp.phi));
    xy.y = lp.phi;
  }

  function s_inv(xy, lp) {
    lp.phi = xy.y;
    lp.lam = 2 * xy.x / (cosphi1 + cos(lp.phi));
  }
}

function pj_wink2(P) {
  var cosphi1 = cos(pj_param(P.params, "rlat_1"));
  var MAX_ITER = 10,
      LOOP_TOL = 1e-7;
  P.fwd = s_fwd;
  P.inv = null;
  P.es = 0;

  function s_fwd(lp, xy) {
    var k, V, i, phi = lp.phi;
    xy.y = phi * M_TWO_D_PI;
    k = M_PI * sin(phi);
    phi *= 1.8;
    for (i = MAX_ITER; i ; --i) {
      phi -= V = (phi + sin (phi) - k) /
        (1 + cos(phi));
      if (fabs(V) < LOOP_TOL)
        break;
    }
    if (!i)
      phi = (phi < 0) ? -M_HALFPI : M_HALFPI;
    else
      phi *= 0.5;
    xy.x = 0.5 * lp.lam * (cos(phi) + cosphi1);
    xy.y = M_FORTPI * (sin(phi) + xy.y);
  }
}


// Projections are inserted here by the build script

var api = proj4js; // (partial) support for proj4js api

// Add Proj.4-style api
api.pj_init = pj_init;
api.pj_fwd = pj_fwd;
api.pj_inv = pj_inv;
api.pj_transform = pj_transform;
api.pj_add = pj_add;

// Convenience functions not in Proj.4
api.pj_fwd_deg = pj_fwd_deg;
api.pj_inv_deg = pj_inv_deg;
api.pj_transform_point = pj_transform_point;

// Export some functions for testing
api.internal = {
  dmstod: dmstod,
  dmstor: dmstor,
  get_rtodms: get_rtodms,
  get_dtodms: get_dtodms,
  get_proj_defn: get_proj_defn,
  pj_latlong_from_proj: pj_latlong_from_proj,
  pj_get_params: pj_get_params,
  pj_datums: pj_datums,
  pj_list: pj_list,
  pj_ellps: pj_ellps,
  pj_units: pj_units,
  pj_read_init_opts: pj_read_init_opts,
  find_datum: find_datum,
  DEG_TO_RAD: DEG_TO_RAD,
  RAD_TO_DEG: RAD_TO_DEG,
  wkt_parse: wkt_parse,
  wkt_unpack: wkt_unpack,
  convert_wkt_quotes: convert_wkt_quotes,
  wkt_to_proj4: wkt_to_proj4,
  wkt_from_proj4: wkt_from_proj4,
  wkt_make_projcs: wkt_make_projcs,
  wkt_get_geogcs_name: wkt_get_geogcs_name,
  wkt_stringify: wkt_stringify,
  mproj_insert_libcache: mproj_insert_libcache,
  mproj_search_libcache: mproj_search_libcache,
  GeographicLib: GeographicLib
};

if (typeof define == 'function' && define.amd) {
  define('mproj', api);
} else if (typeof exports == 'object') {
  module.exports = api;
} else {
  this.mproj = api;
}

// TODO: move to better file
function pj_latlong_from_proj(P) {
  var defn = '+proj=latlong' + get_geod_defn(P);
  return pj_init(defn);
}

}());

}).call(this)}).call(this,"/node_modules/mproj/dist/mproj.js")
},{"fs":1,"path":6}],38:[function(require,module,exports){
'use strict';

var replace = String.prototype.replace;
var percentTwenties = /%20/g;

module.exports = {
    'default': 'RFC3986',
    formatters: {
        RFC1738: function (value) {
            return replace.call(value, percentTwenties, '+');
        },
        RFC3986: function (value) {
            return value;
        }
    },
    RFC1738: 'RFC1738',
    RFC3986: 'RFC3986'
};

},{}],39:[function(require,module,exports){
'use strict';

var stringify = require('./stringify');
var parse = require('./parse');
var formats = require('./formats');

module.exports = {
    formats: formats,
    parse: parse,
    stringify: stringify
};

},{"./formats":38,"./parse":40,"./stringify":41}],40:[function(require,module,exports){
'use strict';

var utils = require('./utils');

var has = Object.prototype.hasOwnProperty;

var defaults = {
    allowDots: false,
    allowPrototypes: false,
    arrayLimit: 20,
    decoder: utils.decode,
    delimiter: '&',
    depth: 5,
    parameterLimit: 1000,
    plainObjects: false,
    strictNullHandling: false
};

var parseValues = function parseQueryStringValues(str, options) {
    var obj = {};
    var cleanStr = options.ignoreQueryPrefix ? str.replace(/^\?/, '') : str;
    var limit = options.parameterLimit === Infinity ? undefined : options.parameterLimit;
    var parts = cleanStr.split(options.delimiter, limit);

    for (var i = 0; i < parts.length; ++i) {
        var part = parts[i];

        var bracketEqualsPos = part.indexOf(']=');
        var pos = bracketEqualsPos === -1 ? part.indexOf('=') : bracketEqualsPos + 1;

        var key, val;
        if (pos === -1) {
            key = options.decoder(part, defaults.decoder);
            val = options.strictNullHandling ? null : '';
        } else {
            key = options.decoder(part.slice(0, pos), defaults.decoder);
            val = options.decoder(part.slice(pos + 1), defaults.decoder);
        }
        if (has.call(obj, key)) {
            obj[key] = [].concat(obj[key]).concat(val);
        } else {
            obj[key] = val;
        }
    }

    return obj;
};

var parseObject = function (chain, val, options) {
    var leaf = val;

    for (var i = chain.length - 1; i >= 0; --i) {
        var obj;
        var root = chain[i];

        if (root === '[]') {
            obj = [];
            obj = obj.concat(leaf);
        } else {
            obj = options.plainObjects ? Object.create(null) : {};
            var cleanRoot = root.charAt(0) === '[' && root.charAt(root.length - 1) === ']' ? root.slice(1, -1) : root;
            var index = parseInt(cleanRoot, 10);
            if (
                !isNaN(index)
                && root !== cleanRoot
                && String(index) === cleanRoot
                && index >= 0
                && (options.parseArrays && index <= options.arrayLimit)
            ) {
                obj = [];
                obj[index] = leaf;
            } else {
                obj[cleanRoot] = leaf;
            }
        }

        leaf = obj;
    }

    return leaf;
};

var parseKeys = function parseQueryStringKeys(givenKey, val, options) {
    if (!givenKey) {
        return;
    }

    // Transform dot notation to bracket notation
    var key = options.allowDots ? givenKey.replace(/\.([^.[]+)/g, '[$1]') : givenKey;

    // The regex chunks

    var brackets = /(\[[^[\]]*])/;
    var child = /(\[[^[\]]*])/g;

    // Get the parent

    var segment = brackets.exec(key);
    var parent = segment ? key.slice(0, segment.index) : key;

    // Stash the parent if it exists

    var keys = [];
    if (parent) {
        // If we aren't using plain objects, optionally prefix keys
        // that would overwrite object prototype properties
        if (!options.plainObjects && has.call(Object.prototype, parent)) {
            if (!options.allowPrototypes) {
                return;
            }
        }

        keys.push(parent);
    }

    // Loop through children appending to the array until we hit depth

    var i = 0;
    while ((segment = child.exec(key)) !== null && i < options.depth) {
        i += 1;
        if (!options.plainObjects && has.call(Object.prototype, segment[1].slice(1, -1))) {
            if (!options.allowPrototypes) {
                return;
            }
        }
        keys.push(segment[1]);
    }

    // If there's a remainder, just add whatever is left

    if (segment) {
        keys.push('[' + key.slice(segment.index) + ']');
    }

    return parseObject(keys, val, options);
};

module.exports = function (str, opts) {
    var options = opts ? utils.assign({}, opts) : {};

    if (options.decoder !== null && options.decoder !== undefined && typeof options.decoder !== 'function') {
        throw new TypeError('Decoder has to be a function.');
    }

    options.ignoreQueryPrefix = options.ignoreQueryPrefix === true;
    options.delimiter = typeof options.delimiter === 'string' || utils.isRegExp(options.delimiter) ? options.delimiter : defaults.delimiter;
    options.depth = typeof options.depth === 'number' ? options.depth : defaults.depth;
    options.arrayLimit = typeof options.arrayLimit === 'number' ? options.arrayLimit : defaults.arrayLimit;
    options.parseArrays = options.parseArrays !== false;
    options.decoder = typeof options.decoder === 'function' ? options.decoder : defaults.decoder;
    options.allowDots = typeof options.allowDots === 'boolean' ? options.allowDots : defaults.allowDots;
    options.plainObjects = typeof options.plainObjects === 'boolean' ? options.plainObjects : defaults.plainObjects;
    options.allowPrototypes = typeof options.allowPrototypes === 'boolean' ? options.allowPrototypes : defaults.allowPrototypes;
    options.parameterLimit = typeof options.parameterLimit === 'number' ? options.parameterLimit : defaults.parameterLimit;
    options.strictNullHandling = typeof options.strictNullHandling === 'boolean' ? options.strictNullHandling : defaults.strictNullHandling;

    if (str === '' || str === null || typeof str === 'undefined') {
        return options.plainObjects ? Object.create(null) : {};
    }

    var tempObj = typeof str === 'string' ? parseValues(str, options) : str;
    var obj = options.plainObjects ? Object.create(null) : {};

    // Iterate over the keys and setup the new object

    var keys = Object.keys(tempObj);
    for (var i = 0; i < keys.length; ++i) {
        var key = keys[i];
        var newObj = parseKeys(key, tempObj[key], options);
        obj = utils.merge(obj, newObj, options);
    }

    return utils.compact(obj);
};

},{"./utils":42}],41:[function(require,module,exports){
'use strict';

var utils = require('./utils');
var formats = require('./formats');

var arrayPrefixGenerators = {
    brackets: function brackets(prefix) { // eslint-disable-line func-name-matching
        return prefix + '[]';
    },
    indices: function indices(prefix, key) { // eslint-disable-line func-name-matching
        return prefix + '[' + key + ']';
    },
    repeat: function repeat(prefix) { // eslint-disable-line func-name-matching
        return prefix;
    }
};

var toISO = Date.prototype.toISOString;

var defaults = {
    delimiter: '&',
    encode: true,
    encoder: utils.encode,
    encodeValuesOnly: false,
    serializeDate: function serializeDate(date) { // eslint-disable-line func-name-matching
        return toISO.call(date);
    },
    skipNulls: false,
    strictNullHandling: false
};

var stringify = function stringify( // eslint-disable-line func-name-matching
    object,
    prefix,
    generateArrayPrefix,
    strictNullHandling,
    skipNulls,
    encoder,
    filter,
    sort,
    allowDots,
    serializeDate,
    formatter,
    encodeValuesOnly
) {
    var obj = object;
    if (typeof filter === 'function') {
        obj = filter(prefix, obj);
    } else if (obj instanceof Date) {
        obj = serializeDate(obj);
    } else if (obj === null) {
        if (strictNullHandling) {
            return encoder && !encodeValuesOnly ? encoder(prefix, defaults.encoder) : prefix;
        }

        obj = '';
    }

    if (typeof obj === 'string' || typeof obj === 'number' || typeof obj === 'boolean' || utils.isBuffer(obj)) {
        if (encoder) {
            var keyValue = encodeValuesOnly ? prefix : encoder(prefix, defaults.encoder);
            return [formatter(keyValue) + '=' + formatter(encoder(obj, defaults.encoder))];
        }
        return [formatter(prefix) + '=' + formatter(String(obj))];
    }

    var values = [];

    if (typeof obj === 'undefined') {
        return values;
    }

    var objKeys;
    if (Array.isArray(filter)) {
        objKeys = filter;
    } else {
        var keys = Object.keys(obj);
        objKeys = sort ? keys.sort(sort) : keys;
    }

    for (var i = 0; i < objKeys.length; ++i) {
        var key = objKeys[i];

        if (skipNulls && obj[key] === null) {
            continue;
        }

        if (Array.isArray(obj)) {
            values = values.concat(stringify(
                obj[key],
                generateArrayPrefix(prefix, key),
                generateArrayPrefix,
                strictNullHandling,
                skipNulls,
                encoder,
                filter,
                sort,
                allowDots,
                serializeDate,
                formatter,
                encodeValuesOnly
            ));
        } else {
            values = values.concat(stringify(
                obj[key],
                prefix + (allowDots ? '.' + key : '[' + key + ']'),
                generateArrayPrefix,
                strictNullHandling,
                skipNulls,
                encoder,
                filter,
                sort,
                allowDots,
                serializeDate,
                formatter,
                encodeValuesOnly
            ));
        }
    }

    return values;
};

module.exports = function (object, opts) {
    var obj = object;
    var options = opts ? utils.assign({}, opts) : {};

    if (options.encoder !== null && options.encoder !== undefined && typeof options.encoder !== 'function') {
        throw new TypeError('Encoder has to be a function.');
    }

    var delimiter = typeof options.delimiter === 'undefined' ? defaults.delimiter : options.delimiter;
    var strictNullHandling = typeof options.strictNullHandling === 'boolean' ? options.strictNullHandling : defaults.strictNullHandling;
    var skipNulls = typeof options.skipNulls === 'boolean' ? options.skipNulls : defaults.skipNulls;
    var encode = typeof options.encode === 'boolean' ? options.encode : defaults.encode;
    var encoder = typeof options.encoder === 'function' ? options.encoder : defaults.encoder;
    var sort = typeof options.sort === 'function' ? options.sort : null;
    var allowDots = typeof options.allowDots === 'undefined' ? false : options.allowDots;
    var serializeDate = typeof options.serializeDate === 'function' ? options.serializeDate : defaults.serializeDate;
    var encodeValuesOnly = typeof options.encodeValuesOnly === 'boolean' ? options.encodeValuesOnly : defaults.encodeValuesOnly;
    if (typeof options.format === 'undefined') {
        options.format = formats['default'];
    } else if (!Object.prototype.hasOwnProperty.call(formats.formatters, options.format)) {
        throw new TypeError('Unknown format option provided.');
    }
    var formatter = formats.formatters[options.format];
    var objKeys;
    var filter;

    if (typeof options.filter === 'function') {
        filter = options.filter;
        obj = filter('', obj);
    } else if (Array.isArray(options.filter)) {
        filter = options.filter;
        objKeys = filter;
    }

    var keys = [];

    if (typeof obj !== 'object' || obj === null) {
        return '';
    }

    var arrayFormat;
    if (options.arrayFormat in arrayPrefixGenerators) {
        arrayFormat = options.arrayFormat;
    } else if ('indices' in options) {
        arrayFormat = options.indices ? 'indices' : 'repeat';
    } else {
        arrayFormat = 'indices';
    }

    var generateArrayPrefix = arrayPrefixGenerators[arrayFormat];

    if (!objKeys) {
        objKeys = Object.keys(obj);
    }

    if (sort) {
        objKeys.sort(sort);
    }

    for (var i = 0; i < objKeys.length; ++i) {
        var key = objKeys[i];

        if (skipNulls && obj[key] === null) {
            continue;
        }

        keys = keys.concat(stringify(
            obj[key],
            key,
            generateArrayPrefix,
            strictNullHandling,
            skipNulls,
            encode ? encoder : null,
            filter,
            sort,
            allowDots,
            serializeDate,
            formatter,
            encodeValuesOnly
        ));
    }

    var joined = keys.join(delimiter);
    var prefix = options.addQueryPrefix === true ? '?' : '';

    return joined.length > 0 ? prefix + joined : '';
};

},{"./formats":38,"./utils":42}],42:[function(require,module,exports){
'use strict';

var has = Object.prototype.hasOwnProperty;

var hexTable = (function () {
    var array = [];
    for (var i = 0; i < 256; ++i) {
        array.push('%' + ((i < 16 ? '0' : '') + i.toString(16)).toUpperCase());
    }

    return array;
}());

var compactQueue = function compactQueue(queue) {
    var obj;

    while (queue.length) {
        var item = queue.pop();
        obj = item.obj[item.prop];

        if (Array.isArray(obj)) {
            var compacted = [];

            for (var j = 0; j < obj.length; ++j) {
                if (typeof obj[j] !== 'undefined') {
                    compacted.push(obj[j]);
                }
            }

            item.obj[item.prop] = compacted;
        }
    }

    return obj;
};

var arrayToObject = function arrayToObject(source, options) {
    var obj = options && options.plainObjects ? Object.create(null) : {};
    for (var i = 0; i < source.length; ++i) {
        if (typeof source[i] !== 'undefined') {
            obj[i] = source[i];
        }
    }

    return obj;
};

var merge = function merge(target, source, options) {
    if (!source) {
        return target;
    }

    if (typeof source !== 'object') {
        if (Array.isArray(target)) {
            target.push(source);
        } else if (typeof target === 'object') {
            if (options.plainObjects || options.allowPrototypes || !has.call(Object.prototype, source)) {
                target[source] = true;
            }
        } else {
            return [target, source];
        }

        return target;
    }

    if (typeof target !== 'object') {
        return [target].concat(source);
    }

    var mergeTarget = target;
    if (Array.isArray(target) && !Array.isArray(source)) {
        mergeTarget = arrayToObject(target, options);
    }

    if (Array.isArray(target) && Array.isArray(source)) {
        source.forEach(function (item, i) {
            if (has.call(target, i)) {
                if (target[i] && typeof target[i] === 'object') {
                    target[i] = merge(target[i], item, options);
                } else {
                    target.push(item);
                }
            } else {
                target[i] = item;
            }
        });
        return target;
    }

    return Object.keys(source).reduce(function (acc, key) {
        var value = source[key];

        if (has.call(acc, key)) {
            acc[key] = merge(acc[key], value, options);
        } else {
            acc[key] = value;
        }
        return acc;
    }, mergeTarget);
};

var assign = function assignSingleSource(target, source) {
    return Object.keys(source).reduce(function (acc, key) {
        acc[key] = source[key];
        return acc;
    }, target);
};

var decode = function (str) {
    try {
        return decodeURIComponent(str.replace(/\+/g, ' '));
    } catch (e) {
        return str;
    }
};

var encode = function encode(str) {
    // This code was originally written by Brian White (mscdex) for the io.js core querystring library.
    // It has been adapted here for stricter adherence to RFC 3986
    if (str.length === 0) {
        return str;
    }

    var string = typeof str === 'string' ? str : String(str);

    var out = '';
    for (var i = 0; i < string.length; ++i) {
        var c = string.charCodeAt(i);

        if (
            c === 0x2D // -
            || c === 0x2E // .
            || c === 0x5F // _
            || c === 0x7E // ~
            || (c >= 0x30 && c <= 0x39) // 0-9
            || (c >= 0x41 && c <= 0x5A) // a-z
            || (c >= 0x61 && c <= 0x7A) // A-Z
        ) {
            out += string.charAt(i);
            continue;
        }

        if (c < 0x80) {
            out = out + hexTable[c];
            continue;
        }

        if (c < 0x800) {
            out = out + (hexTable[0xC0 | (c >> 6)] + hexTable[0x80 | (c & 0x3F)]);
            continue;
        }

        if (c < 0xD800 || c >= 0xE000) {
            out = out + (hexTable[0xE0 | (c >> 12)] + hexTable[0x80 | ((c >> 6) & 0x3F)] + hexTable[0x80 | (c & 0x3F)]);
            continue;
        }

        i += 1;
        c = 0x10000 + (((c & 0x3FF) << 10) | (string.charCodeAt(i) & 0x3FF));
        out += hexTable[0xF0 | (c >> 18)]
            + hexTable[0x80 | ((c >> 12) & 0x3F)]
            + hexTable[0x80 | ((c >> 6) & 0x3F)]
            + hexTable[0x80 | (c & 0x3F)];
    }

    return out;
};

var compact = function compact(value) {
    var queue = [{ obj: { o: value }, prop: 'o' }];
    var refs = [];

    for (var i = 0; i < queue.length; ++i) {
        var item = queue[i];
        var obj = item.obj[item.prop];

        var keys = Object.keys(obj);
        for (var j = 0; j < keys.length; ++j) {
            var key = keys[j];
            var val = obj[key];
            if (typeof val === 'object' && val !== null && refs.indexOf(val) === -1) {
                queue.push({ obj: obj, prop: key });
                refs.push(val);
            }
        }
    }

    return compactQueue(queue);
};

var isRegExp = function isRegExp(obj) {
    return Object.prototype.toString.call(obj) === '[object RegExp]';
};

var isBuffer = function isBuffer(obj) {
    if (obj === null || typeof obj === 'undefined') {
        return false;
    }

    return !!(obj.constructor && obj.constructor.isBuffer && obj.constructor.isBuffer(obj));
};

module.exports = {
    arrayToObject: arrayToObject,
    assign: assign,
    compact: compact,
    decode: decode,
    encode: encode,
    isBuffer: isBuffer,
    isRegExp: isRegExp,
    merge: merge
};

},{}],43:[function(require,module,exports){
exports.dash = require("./lib/rw/dash");
exports.readFile = require("./lib/rw/read-file");
exports.readFileSync = require("./lib/rw/read-file-sync");
exports.writeFile = require("./lib/rw/write-file");
exports.writeFileSync = require("./lib/rw/write-file-sync");

},{"./lib/rw/dash":44,"./lib/rw/read-file":48,"./lib/rw/read-file-sync":47,"./lib/rw/write-file":50,"./lib/rw/write-file-sync":49}],44:[function(require,module,exports){
var slice = Array.prototype.slice;

function dashify(method, file) {
  return function(path) {
    var argv = arguments;
    if (path == "-") (argv = slice.call(argv)).splice(0, 1, file);
    return method.apply(null, argv);
  };
}

exports.readFile = dashify(require("./read-file"), "/dev/stdin");
exports.readFileSync = dashify(require("./read-file-sync"), "/dev/stdin");
exports.writeFile = dashify(require("./write-file"), "/dev/stdout");
exports.writeFileSync = dashify(require("./write-file-sync"), "/dev/stdout");

},{"./read-file":48,"./read-file-sync":47,"./write-file":50,"./write-file-sync":49}],45:[function(require,module,exports){
(function (Buffer){(function (){
module.exports = function(options) {
  if (options) {
    if (typeof options === "string") return encoding(options);
    if (options.encoding !== null) return encoding(options.encoding);
  }
  return identity();
};

function identity() {
  var chunks = [];
  return {
    push: function(chunk) { chunks.push(chunk); },
    value: function() { return Buffer.concat(chunks); }
  };
}

function encoding(encoding) {
  var chunks = [];
  return {
    push: function(chunk) { chunks.push(chunk); },
    value: function() { return Buffer.concat(chunks).toString(encoding); }
  };
}

}).call(this)}).call(this,require("buffer").Buffer)
},{"buffer":4}],46:[function(require,module,exports){
(function (Buffer){(function (){
module.exports = function(data, options) {
  return typeof data === "string"
      ? new Buffer(data, typeof options === "string" ? options
          : options && options.encoding !== null ? options.encoding
          : "utf8")
      : data;
};

}).call(this)}).call(this,require("buffer").Buffer)
},{"buffer":4}],47:[function(require,module,exports){
(function (Buffer){(function (){
var fs = require("fs"),
    decode = require("./decode");

module.exports = function(filename, options) {
  if (fs.statSync(filename).isFile()) {
    return fs.readFileSync(filename, options);
  } else {
    var fd = fs.openSync(filename, options && options.flag || "r"),
        decoder = decode(options);

    while (true) { // eslint-disable-line no-constant-condition
      try {
        var buffer = new Buffer(bufferSize),
            bytesRead = fs.readSync(fd, buffer, 0, bufferSize);
      } catch (e) {
        if (e.code === "EOF") break;
        fs.closeSync(fd);
        throw e;
      }
      if (bytesRead === 0) break;
      decoder.push(buffer.slice(0, bytesRead));
    }

    fs.closeSync(fd);
    return decoder.value();
  }
};

var bufferSize = 1 << 16;

}).call(this)}).call(this,require("buffer").Buffer)
},{"./decode":45,"buffer":4,"fs":1}],48:[function(require,module,exports){
(function (process){(function (){
var fs = require("fs"),
    decode = require("./decode");

module.exports = function(path, options, callback) {
  if (arguments.length < 3) callback = options, options = null;

  switch (path) {
    case "/dev/stdin": return readStream(process.stdin, options, callback);
  }

  fs.stat(path, function(error, stat) {
    if (error) return callback(error);
    if (stat.isFile()) return fs.readFile(path, options, callback);
    readStream(fs.createReadStream(path, options ? {flags: options.flag || "r"} : {}), options, callback); // N.B. flag / flags
  });
};

function readStream(stream, options, callback) {
  var decoder = decode(options);
  stream.on("error", callback);
  stream.on("data", function(d) { decoder.push(d); });
  stream.on("end", function() { callback(null, decoder.value()); });
}

}).call(this)}).call(this,require('_process'))
},{"./decode":45,"_process":7,"fs":1}],49:[function(require,module,exports){
var fs = require("fs"),
    encode = require("./encode");

module.exports = function(filename, data, options) {
  var stat;

  try {
    stat = fs.statSync(filename);
  } catch (error) {
    if (error.code !== "ENOENT") throw error;
  }

  if (!stat || stat.isFile()) {
    fs.writeFileSync(filename, data, options);
  } else {
    var fd = fs.openSync(filename, options && options.flag || "w"),
        bytesWritten = 0,
        bytesTotal = (data = encode(data, options)).length;

    while (bytesWritten < bytesTotal) {
      try {
        bytesWritten += fs.writeSync(fd, data, bytesWritten, bytesTotal - bytesWritten, null);
      } catch (error) {
        if (error.code === "EPIPE") break; // ignore broken pipe, e.g., | head
        fs.closeSync(fd);
        throw error;
      }
    }

    fs.closeSync(fd);
  }
};

},{"./encode":46,"fs":1}],50:[function(require,module,exports){
(function (process){(function (){
var fs = require("fs"),
    encode = require("./encode");

module.exports = function(path, data, options, callback) {
  if (arguments.length < 4) callback = options, options = null;

  switch (path) {
    case "/dev/stdout": return writeStream(process.stdout, "write", data, options, callback);
    case "/dev/stderr": return writeStream(process.stderr, "write", data, options, callback);
  }

  fs.stat(path, function(error, stat) {
    if (error && error.code !== "ENOENT") return callback(error);
    if (stat && stat.isFile()) return fs.writeFile(path, data, options, callback);
    writeStream(fs.createWriteStream(path, options ? {flags: options.flag || "w"} : {}), "end", data, options, callback); // N.B. flag / flags
  });
};

function writeStream(stream, send, data, options, callback) {
  stream.on("error", function(error) { callback(error.code === "EPIPE" ? null : error); }); // ignore broken pipe, e.g., | head
  stream[send](encode(data, options), function(error) { callback(error && error.code === "EPIPE" ? null : error); });
}

}).call(this)}).call(this,require('_process'))
},{"./encode":46,"_process":7,"fs":1}],51:[function(require,module,exports){
(function (process){(function (){
/* eslint-disable node/no-deprecated-api */

'use strict'

var buffer = require('buffer')
var Buffer = buffer.Buffer

var safer = {}

var key

for (key in buffer) {
  if (!buffer.hasOwnProperty(key)) continue
  if (key === 'SlowBuffer' || key === 'Buffer') continue
  safer[key] = buffer[key]
}

var Safer = safer.Buffer = {}
for (key in Buffer) {
  if (!Buffer.hasOwnProperty(key)) continue
  if (key === 'allocUnsafe' || key === 'allocUnsafeSlow') continue
  Safer[key] = Buffer[key]
}

safer.Buffer.prototype = Buffer.prototype

if (!Safer.from || Safer.from === Uint8Array.from) {
  Safer.from = function (value, encodingOrOffset, length) {
    if (typeof value === 'number') {
      throw new TypeError('The "value" argument must not be of type number. Received type ' + typeof value)
    }
    if (value && typeof value.length === 'undefined') {
      throw new TypeError('The first argument must be one of type string, Buffer, ArrayBuffer, Array, or Array-like Object. Received type ' + typeof value)
    }
    return Buffer(value, encodingOrOffset, length)
  }
}

if (!Safer.alloc) {
  Safer.alloc = function (size, fill, encoding) {
    if (typeof size !== 'number') {
      throw new TypeError('The "size" argument must be of type number. Received type ' + typeof size)
    }
    if (size < 0 || size >= 2 * (1 << 30)) {
      throw new RangeError('The value "' + size + '" is invalid for option "size"')
    }
    var buf = Buffer(size)
    if (!fill || fill.length === 0) {
      buf.fill(0)
    } else if (typeof encoding === 'string') {
      buf.fill(fill, encoding)
    } else {
      buf.fill(fill)
    }
    return buf
  }
}

if (!safer.kStringMaxLength) {
  try {
    safer.kStringMaxLength = process.binding('buffer').kStringMaxLength
  } catch (e) {
    // we can't determine kStringMaxLength in environments where process.binding
    // is unsupported, so let's not set it
  }
}

if (!safer.constants) {
  safer.constants = {
    MAX_LENGTH: safer.kMaxLength
  }
  if (safer.kStringMaxLength) {
    safer.constants.MAX_STRING_LENGTH = safer.kStringMaxLength
  }
}

module.exports = safer

}).call(this)}).call(this,require('_process'))
},{"_process":7,"buffer":4}],52:[function(require,module,exports){
"use strict";
exports.__esModule = true;
var handle_qs_js_1 = require("then-request/lib/handle-qs.js");
var GenericResponse = require("http-response-object");
var fd = FormData;
exports.FormData = fd;
function doRequest(method, url, options) {
    var xhr = new XMLHttpRequest();
    // check types of arguments
    if (typeof method !== 'string') {
        throw new TypeError('The method must be a string.');
    }
    if (url && typeof url === 'object') {
        url = url.href;
    }
    if (typeof url !== 'string') {
        throw new TypeError('The URL/path must be a string.');
    }
    if (options === null || options === undefined) {
        options = {};
    }
    if (typeof options !== 'object') {
        throw new TypeError('Options must be an object (or null).');
    }
    method = method.toUpperCase();
    options.headers = options.headers || {};
    // handle cross domain
    var match;
    var crossDomain = !!((match = /^([\w-]+:)?\/\/([^\/]+)/.exec(url)) && match[2] != location.host);
    if (!crossDomain)
        options.headers['X-Requested-With'] = 'XMLHttpRequest';
    // handle query string
    if (options.qs) {
        url = handle_qs_js_1["default"](url, options.qs);
    }
    // handle json body
    if (options.json) {
        options.body = JSON.stringify(options.json);
        options.headers['content-type'] = 'application/json';
    }
    if (options.form) {
        options.body = options.form;
    }
    // method, url, async
    xhr.open(method, url, false);
    for (var name in options.headers) {
        xhr.setRequestHeader(name.toLowerCase(), '' + options.headers[name]);
    }
    // avoid sending empty string (#319)
    xhr.send(options.body ? options.body : null);
    var headers = {};
    xhr
        .getAllResponseHeaders()
        .split('\r\n')
        .forEach(function (header) {
        var h = header.split(':');
        if (h.length > 1) {
            headers[h[0].toLowerCase()] = h
                .slice(1)
                .join(':')
                .trim();
        }
    });
    return new GenericResponse(xhr.status, headers, xhr.responseText, url);
}
exports["default"] = doRequest;
module.exports = doRequest;
module.exports["default"] = doRequest;
module.exports.FormData = fd;

},{"http-response-object":15,"then-request/lib/handle-qs.js":53}],53:[function(require,module,exports){
"use strict";
exports.__esModule = true;
var qs_1 = require("qs");
function handleQs(url, query) {
    var _a = url.split('?'), start = _a[0], part2 = _a[1];
    var qs = (part2 || '').split('#')[0];
    var end = part2 && part2.split('#').length > 1 ? '#' + part2.split('#')[1] : '';
    var baseQs = qs_1.parse(qs);
    for (var i in query) {
        baseQs[i] = query[i];
    }
    qs = qs_1.stringify(baseQs);
    if (qs !== '') {
        qs = '?' + qs;
    }
    return start + qs + end;
}
exports["default"] = handleQs;

},{"qs":39}]},{},[36])(36)
});
